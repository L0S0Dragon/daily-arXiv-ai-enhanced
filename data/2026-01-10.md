<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [quant-ph](#quant-ph) [Total: 47]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Chaos in high-dimensional dynamical systems with tunable non-reciprocity](https://arxiv.org/abs/2601.04702)
*Samantha Fournier,Pierfrancesco Urbani*

Main category: cond-mat.dis-nn

TL;DR: Partially symmetric interactions in high-dimensional systems create chaotic attractors with non-monotonic maximal Lyapunov exponent dependence on non-reciprocity parameter α.


<details>
  <summary>Details</summary>
Motivation: To understand how varying degrees of non-reciprocity in interactions affect dynamics of high-dimensional systems, bridging between completely symmetric (gradient descent) and totally uncorrelated (chaotic) regimes.

Method: Introduce parameter α tuning degree of non-reciprocity in interactions, analyze resulting dynamical systems, and characterize chaotic attractors and maximal Lyapunov exponent behavior.

Result: For any α with non-reciprocal interactions, dynamics lands on chaotic attractor; maximal Lyapunov exponent is non-monotonic function of non-reciprocity degree; conservative forcing from gradient field can enhance chaos.

Conclusion: Partial symmetry in interactions induces chaotic behavior, with non-monotonic relationship between chaos intensity and non-reciprocity, showing gradient-like conservative forcing can paradoxically increase system chaos.

Abstract: High-dimensional dynamical systems of interacting degrees of freedom are ubiquitous in the study of complex systems. When the directed interactions are totally uncorrelated, sufficiently strong and non-linear, many of these systems exhibit a chaotic attractor characterized by a positive maximal Lyapunov exponent (MLE). On the contrary, when the interactions are completely symmetric, the dynamics takes the form of a gradient descent on a carefully defined cost function, and it exhibits slow dynamics and aging. In this work, we consider the intermediate case in which the interactions are partially symmetric, with a parameter α tuning the degree of non-reciprocity. We show that for any value of α for which the corresponding system has non-reciprocal interactions, the dynamics lands on a chaotic attractor. Correspondingly, the MLE is a non-monotonous function of the degree of non-reciprocity. This implies that conservative forcing deriving from the gradient field of a rough energy landscape can make the system more chaotic.

</details>


### [2] [Spin-aligned butterfly spectral map in Non-Hermitian quasicrystals](https://arxiv.org/abs/2601.04986)
*Soumya Ranjan Padhi,Souvik Roy,Debashree Chowdhury,Tapan Mishra*

Main category: cond-mat.dis-nn

TL;DR: Non-Hermitian spinful AAH model with Rashba SOC and textured magnetic field yields butterfly spectral map with asymmetric spin alignment, driven by combined effects of non-Hermiticity, SOC, and magnetic texture.


<details>
  <summary>Details</summary>
Motivation: To investigate the interplay between non-Hermiticity, spin-orbit coupling, and textured magnetic fields in the Aubry-André-Harper model, exploring how these combined effects produce novel spectral and localization phenomena.

Method: Study of the Non-Hermitian spinful Aubry-André-Harper model incorporating Rashba-type spin-orbit coupling and a spatially varying textured magnetic field, analyzing spectral properties and localization characteristics.

Result: The analysis produces a butterfly spectral map with non-trivial state localization patterns, exhibiting asymmetric spin alignment across the butterfly wings, indicating that the spectral structure emerges from the combined effects of non-Hermiticity, spin-orbit interaction, and textured magnetic field.

Conclusion: The butterfly spectral map with asymmetric spin alignment is a unique feature arising from the synergistic combination of non-Hermiticity, Rashba spin-orbit coupling, and textured magnetic fields in the AAH model, revealing complex interplay between these quantum phenomena.

Abstract: The Non-Hermitian spinful Aubry-André-Harper (AAH) model in the presence of Rashba-type spin-orbit coupling (RSOC) and a spatially varying textured magnetic field is studied. Interestingly, our analysis produces a butterfly spectral map due to the non-trivial extent of localization of the states in the spectrum. This spectral map also exhibits an asymmetric spin alignment with respect to the wings of the butterfly. Our analysis also suggests that the onset of such a spectral map is a combined effect of the non-hermiticity, spin-orbit interaction, and the textured magnetic field.

</details>


### [3] [Beyond the imbalance: site-resolved dynamics probing resonances in many-body localization](https://arxiv.org/abs/2601.05177)
*Asmi Haldar,Thibault Scoquart,Fabien Alet,Nicolas Laflorencie*

Main category: cond-mat.dis-nn

TL;DR: Spatial averaging in imbalance dynamics masks microscopic features of many-body localization; site-resolved spin autocorrelators reveal complex local dynamics, resonant structures, and rare instabilities within the MBL phase.


<details>
  <summary>Details</summary>
Motivation: To explore limitations of imbalance dynamics as a diagnostic tool for many-body localization (MBL) and demonstrate that spatial averaging obscures important microscopic features, necessitating a more refined, site-resolved approach.

Method: State-of-the-art numerical techniques (Krylov time evolution and full diagonalization) applied to the strongly disordered regime of the random-field XXZ chain, analyzing site-resolved spin autocorrelators; supported by analytical few-site toy model.

Result: Site-resolved spin autocorrelators reveal rich complex dynamical behavior, resonant structures, and rare local instabilities within MBL phase; local magnetization histograms show multiple-peak structure indicating local resonances; explains finite-size effects of long-time imbalance and sensitivity to initial conditions.

Conclusion: Spatial averaging masks crucial microscopic features of MBL; site-resolved approach reveals local resonances and rare-region effects, providing more detailed understanding of ergodicity-breaking dynamics and experimentally testable predictions for refined MBL characterization.

Abstract: We explore the limitations of using imbalance dynamics as a diagnostic tool for many-body localization (MBL) and show that spatial averaging can mask important microscopic features. Focusing on the strongly disordered regime of the random-field XXZ chain, we use state-of-the-art numerical techniques (Krylov time evolution and full diagonalization) to demonstrate that site-resolved spin autocorrelators reveal a rich and complex dynamical behavior that is obscured by the imbalance observable. By analyzing the time evolution and infinite-time limits of these local probes, we reveal resonant structures and rare local instabilities within the MBL phase. These numerical findings are supported by an analytical, few-site toy model that captures the emergence of a multiple-peak structure in local magnetization histograms, which is a hallmark of local resonances. These few-body local effects provide a more detailed understanding of ergodicity-breaking dynamics, and also allow us to explain the finite-size effects of long-time imbalance, and its sensitivity to the initial conditions in quench protocols. Overall, our experimentally testable predictions highlight the necessity of a refined, site-resolved approach to fully understand the complexities of MBL and its connection to rare-region effects.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [4] [Microscopic Dynamics of False Vacuum Decay in the $2+1$D Quantum Ising Model](https://arxiv.org/abs/2601.04305)
*Umberto Borla,Achilleas Lazarides,Christian Groß,Jad C. Halimeh*

Main category: quant-ph

TL;DR: Study of false vacuum decay dynamics in 2+1D quantum Ising model using tree tensor networks to simulate bubble nucleation and evolution, with quantum simulation proposal using Rydberg arrays.


<details>
  <summary>Details</summary>
Motivation: Understanding microscopic dynamics of false vacuum decay in higher spatial dimensions is a major challenge in particle physics and cosmology, requiring numerical techniques to study intermediate timescales.

Method: Use tree tensor networks to simulate 2+1D quantum Ising model with longitudinal field creating true/false vacuum states; study spin-down domain (bubble) in spin-up background after homogeneous quench.

Result: Identified dependence of bubble fate (expansion or collapse) on geometrical features and microscopic Hamiltonian parameters; provided quantum simulation scheme using atomic Rydberg arrays.

Conclusion: Demonstrated tractable approach to study false vacuum decay dynamics in higher dimensions, with practical quantum simulation implementation for experimental verification.

Abstract: False vacuum decay, which is understood to happen through bubble nucleation, is a prominent phenomenon relevant to elementary particle physics and early-universe cosmology. Understanding its microscopic dynamics in higher spatial dimensions is currently a major challenge and research thrust. Recent advances in numerical techniques allow for the extraction of related signatures in tractable systems in two spatial dimensions over intermediate timescales. Here, we focus on the $2+1$D quantum Ising model, where a longitudinal field is used to energetically separate the two $\mathbb{Z}_2$ symmetry-broken ferromagnetic ground states, turning them into a ``true'' and ``false'' vacuum. Using tree tensor networks, we simulate the microscopic dynamics of a spin-down domain in a spin-up background after a homogeneous quench, with parameters chosen so that the domain corresponds to a bubble of the true vacuum in a false-vacuum background. Our study identifies how the ultimate fate of the bubble -- indefinite expansion or collapse -- depends on its geometrical features and on the microscopic parameters of the Ising Hamiltonian. We further provide a realistic quantum-simulation scheme, aimed at probing bubble dynamics on atomic Rydberg arrays.

</details>


### [5] [Rare-Event Quantum Sensing using Logical Qubits](https://arxiv.org/abs/2601.04313)
*Robert Ott,Torsten V. Zache,Soonwon Choi,Adam M. Kaufman,Hannes Pichler*

Main category: quant-ph

TL;DR: Quantum error correction enables rare signal detection in noisy environments by leveraging higher-order correlations from syndrome extraction, sacrificing some signal for improved noise correction and extended coherence time.


<details>
  <summary>Details</summary>
Motivation: To detect rare signals in noisy environments where conventional sensing strategies are limited by noise interference and signal rarity.

Method: Uses quantum error correction (QEC) protocol that discriminates signals from noise through distinct higher-order correlations during syndrome extraction, with non-linear processing that records reduced stochastic logical phase while correcting physical noise.

Result: Demonstrates improved sensitivity over conventional sensing strategies for rare signals occurring at random times in presence of local Markovian noise, with logical phase scaling as φ_L = O(ε³).

Conclusion: QEC-based sensing protocol offers superior rare signal detection by exploiting higher-order correlations and noise correction capabilities, enabling extended coherence time for signal acquisition in noisy environments.

Abstract: We present a novel protocol to detect rare signals in a noisy environment using quantum error correction (QEC). The key feature of our protocol is the discrimination between signal and noise through distinct higher-order correlations, realized by the non-linear processing that occurs during syndrome extraction in QEC. In this scheme, QEC has two effects: First, it sacrifices part of the signal $ε$ by recording a reduced, stochastic, logical phase $φ_L = \mathcal{O}(ε^3)$. Second, it corrects the physical noise and extends the (logical) coherence time for signal acquisition. For rare signals occurring at random times in the presence of local Markovian noise, we explicitly demonstrate an improved sensitivity of our approach over more conventional sensing strategies.

</details>


### [6] [Quantum sensing with critical systems: impact of symmetry, imperfections, and decoherence](https://arxiv.org/abs/2601.04364)
*Yinan Chen,Sara Murciano,Pablo Sala,Jason Alicea*

Main category: quant-ph

TL;DR: Critical wavefunctions enable quantum sensing beyond standard limits, outperforming GHZ states in certain regimes, with symmetry-based optimization and robustness to decoherence.


<details>
  <summary>Details</summary>
Motivation: To develop quantum sensing protocols using quantum critical wavefunctions that can surpass the standard quantum limit, comparing their performance with established entangled states like GHZ and spin-squeezed states.

Method: Develop interferometric sensing protocols based on quantum critical wavefunctions; introduce symmetry-based algorithm to identify optimal measurement strategies; apply to magnetic systems with internal symmetries and Rydberg-atom arrays with spatial symmetries; study robustness under non-unitary deformations, symmetry-preserving/breaking decoherence, and qubit loss.

Result: Identified regimes where critical systems outperform GHZ states; showed that non-unitary deformation can enhance sensing precision; demonstrated symmetry-based optimization algorithm works for both internal and spatial symmetries; found critical wavefunctions maintain sensing advantages under various decoherence scenarios.

Conclusion: Interferometric sensing with quantum critical wavefunctions is promising for high-precision quantum sensing, especially given recent advances in log-depth preparation of such states and demonstrated robustness to realistic experimental imperfections.

Abstract: Entangled many-body states enable high-precision quantum sensing beyond the standard quantum limit. We develop interferometric sensing protocols based on quantum critical wavefunctions and compare their performance with Greenberger-Horne-Zeilinger (GHZ) and spin-squeezed states. Building on the idea of symmetries as a metrological resource, we introduce a symmetry-based algorithm to identify optimal measurement strategies. We illustrate this algorithm both for magnetic systems with internal symmetries and Rydberg-atom arrays with spatial symmetries. We study the robustness of criticality for quantum sensing under non-unitary deformations, symmetry-preserving and symmetry-breaking decoherence, and qubit loss -- identifying regimes where critical systems outperform GHZ states and showing that non-unitary deformation can even enhance sensing precision. Combined with recent results on log-depth preparation of critical wavefunctions, interferometric sensing in this setting appears increasingly promising.

</details>


### [7] [Solving nonlinear PDEs with Quantum Neural Networks: A variational approach to the Bratu Equation](https://arxiv.org/abs/2601.04372)
*Nikolaos Cheimarios*

Main category: quant-ph

TL;DR: VQA solves 1D Bratu equation using quantum neural network encoding, accurately capturing both solution branches with boundary-enforcing trial functions.


<details>
  <summary>Details</summary>
Motivation: To develop a variational quantum algorithm for solving nonlinear differential equations, specifically the Bratu equation, demonstrating quantum computing's potential for boundary value problems.

Method: Formulate Bratu equation as variational problem, encode solution in parameterized QNN, use trial solution with classical approximations and boundary-enforcing terms, optimize quantum circuit parameters to minimize differential operator residual.

Result: Method accurately captures both solution branches of Bratu equation, shows excellent agreement with classical pseudo arc-length continuation results on noiseless quantum simulator.

Conclusion: Variational quantum algorithm successfully solves nonlinear Bratu equation, demonstrating quantum computing's capability for differential equation problems with multiple solution branches.

Abstract: We present a variational quantum algorithm (VQA) to solve the nonlinear one-dimensional Bratu equation. By formulating the boundary value problem within a variational framework and encoding the solution in a parameterized quantum neural network (QNN), the problem reduces to an optimization task over quantum circuit parameters. The trial solution incorporates both classical approximations and boundary-enforcing terms, allowing the circuit to focus on minimizing the residual of the differential operator. Using a noiseless quantum simulator, we demonstrate that the method accurately captures both solution branches of the Bratu equation and shows excellent agreement with classical pseudo arc-length continuation results.

</details>


### [8] [Thermodynamic significance of QUBO encoding on quantum annealers](https://arxiv.org/abs/2601.04402)
*Emery Doucet,Zakaria Mzaouali,Reece Robertson,Bartłomiej Gardas,Sebastian Deffner,Krzysztof Domino*

Main category: quant-ph

TL;DR: QUBO penalty weights control both computational hardness and thermodynamic dissipation in quantum annealing for Job Shop Scheduling, with optimal encoding balancing feasibility and energy scale.


<details>
  <summary>Details</summary>
Motivation: To understand how QUBO encoding penalty choices affect both computational performance and thermodynamic behavior in quantum annealing, particularly for constrained optimization problems like Job Shop Scheduling.

Method: Study a Job Shop Scheduling instance using a two-parameter family of QUBO encodings controlled by penalty weights p_sum (one-hot constraints) and p_pair (precedence constraints). Sweep penalty parameters, analyze feasibility and solver success across classical heuristics and D-Wave Advantage processor. Use cyclic reverse-annealing experiments initialized from thermal samples to measure stochastic processor energy change, infer entropy production, work, and exchanged heat via thermodynamic uncertainty relations, and corroborate with adiabatic master equation simulations.

Result: Observed sharp transitions in feasibility and solver success across penalty parameter space. Found that encoding transitions governing computational hardness also reorganize dissipation: weak penalties generate low-energy infeasible manifolds, while overly strong penalties suppress effective problem energy scale and increase irreversibility, reducing thermodynamic efficiency.

Conclusion: QUBO penalty weights act as thermodynamic control knobs, motivating thermodynamics-aware encoding strategies for noisy intermediate-scale quantum annealers to balance computational performance with thermodynamic efficiency.

Abstract: Quadratic unconstrained binary optimization (QUBO) is the standard interface to quantum annealers, yet a single constrained task admits many QUBO encodings whose penalty choices reshape the energy landscape experienced by hardware. We study a Job Shop Scheduling instance using a two-parameter family of encodings controlled by penalty weights $p_{\rm sum}$ (one-hot/sum constraints) and $p_{\rm pair}$ (precedence constraints). Sweeping $(p_{\rm sum},p_{\rm pair})$, we observe sharp transitions in feasibility and solver success across classical annealing-inspired heuristics and on a D-Wave Advantage processor. Going beyond solution probability, we treat the annealer as an open thermodynamic system and perform cyclic reverse-annealing experiments initialized from thermal samples, measuring the stochastic processor energy change. From the first two moments of this energy change we infer lower bounds on entropy production, work, and exchanged heat via thermodynamic uncertainty relations, and corroborate the observed trends with adiabatic master equation simulations. We find that the same encoding transitions that govern computational hardness also reorganize dissipation: weak penalties generate low-energy infeasible manifolds, while overly strong penalties suppress the effective problem energy scale and increase irreversibility, reducing the thermodynamic efficiency. Our results establish QUBO penalties as thermodynamic control knobs and motivate thermodynamics-aware encoding strategies for noisy intermediate-scale quantum annealers.

</details>


### [9] [Exact Multimode Quantization of Superconducting Circuits via Boundary Admittance](https://arxiv.org/abs/2601.04407)
*Mustafa Bakr,Robin Wopalenski*

Main category: quant-ph

TL;DR: The paper presents a systematic four-step quantization procedure for superconducting circuits using the Schur complement of the nodal admittance matrix, deriving dressed mode spectra from driving-point admittance and proving UV convergence without imposed cutoffs.


<details>
  <summary>Details</summary>
Motivation: To develop a rigorous quantization framework for superconducting quantum circuits that naturally handles multiport electromagnetic environments, avoids arbitrary cutoffs, and provides explicit validity conditions for standard circuit QED parameters.

Method: Four-step procedure: (1) compute/measure driving-point admittance Y_in(s) via Schur complement of nodal admittance matrix, (2) solve boundary condition sY_in(s) + 1/L_J = 0 for dressed frequencies, (3) synthesize equivalent passive network, (4) quantize retaining full cosine nonlinearity. Uses lumped-element circuit theory to prove UV convergence properties.

Result: Proves junction participation decays as O(ω_n^{-1}) at high frequencies when junction port has finite shunt capacitance, ensuring ultraviolet convergence without imposed cutoffs. Derives standard circuit QED parameters (g, α, χ) as controlled limits with explicit validity conditions.

Conclusion: The Schur complement approach provides a systematic, mathematically rigorous framework for quantizing superconducting circuits that naturally handles complex electromagnetic environments, ensures UV convergence, and yields explicit validity conditions for standard approximations in circuit QED.

Abstract: We show that the Schur complement of the nodal admittance matrix, which reduces a multiport electromagnetic environment to the driving-point admittance $Y_{\mathrm{in}}(s)$ at the Josephson junction, naturally leads to an eigenvalue-dependent boundary condition determining the dressed mode spectrum. This identification provides a four-step quantization procedure: (i) compute or measure $Y_{\mathrm{in}}(s)$, (ii) solve the boundary condition $sY_{\mathrm{in}}(s) + 1/L_J = 0$ for dressed frequencies, (iii) synthesize an equivalent passive network, (iv) quantize with the full cosine nonlinearity retained. Within passive lumped-element circuit theory, we prove that junction participation decays as, we prove that junction participation decays as $O(ω_n^{-1})$ at high frequencies when the junction port has finite shunt capacitance, ensuring ultraviolet convergence of perturbative sums without imposed cutoffs. The standard circuit QED parameters, coupling strength $g$, anharmonicity $α$, and dispersive shift $χ$, emerge as controlled limits with explicit validity conditions.

</details>


### [10] [Implementation of Tensor Network Simulation TN-Sim under NWQ-Sim](https://arxiv.org/abs/2601.04422)
*Aaron C. Hoyt,Jonathan S. Bersson,Sean Garner,Chenxu Liu,Ang Li*

Main category: quant-ph

TL;DR: TN-Sim is a tensor network simulator backend for quantum circuit simulation that leverages the TAMM framework to enable both local and distributed HPC-scale computations, demonstrating scalability on modern supercomputers.


<details>
  <summary>Details</summary>
Motivation: Large-scale tensor network simulations are essential for establishing complexity-theoretic bounds on classical quantum simulation, enabling circuit cutting approaches, optimizing circuit compilation, and facilitating efficient quantum computation on limited quantum resources. Modern exascale HPC platforms offer significant potential for advancing tensor network quantum circuit simulation capabilities.

Method: Implemented TN-Sim as a tensor network simulator backend within the NWQ-Sim software package, utilizing the Tensor Algebra for Many-body Methods (TAMM) framework to support both distributed HPC-scale computations and local simulations with ITensor. Implemented a task-based parallelization scheme for parallelized gate contraction in wide quantum circuits with many gates per layer. Integrated TAMM framework with Matrix Product State (MPS) tensor network approaches.

Result: Demonstrated an MPS tensor network simulator running on the state-of-the-art Perlmutter (NVIDIA) supercomputer. Discussed potential portability to other HPC clusters such as Frontier (AMD) and Aurora (Intel). The system can scale from local systems to HPC clusters.

Conclusion: TN-Sim provides a scalable tensor network simulation environment that bridges local and HPC-scale quantum circuit simulations. Future improvements include support for different tensor network topologies and enhanced computational efficiency.

Abstract: Large-scale tensor network simulations are crucial for developing robust complexity-theoretic bounds on classical quantum simulation, enabling circuit cutting approaches, and optimizing circuit compilation, all of which aid efficient quantum computation on limited quantum resources. Modern exascale high-performance computing platforms offer significant potential for advancing tensor network quantum circuit simulation capabilities. We implement TN-Sim, a tensor network simulator backend within the NWQ-Sim software package that utilizes the Tensor Algebra for Many-body Methods (TAMM) framework to support both distributed HPC-scale computations and local simulations with ITensor. To optimize the scale up in computation across multiple nodes we implement a task based parallelization scheme to demonstrate parallelized gate contraction for wide quantum circuits with many gates per layer. Through the integration of the TAMM framework with Matrix Product State (MPS) tensor network approaches, we deliver a simulation environment that can scale from local systems to HPC clusters. We demonstrate an MPS tensor network simulator running on the state-of-the-art Perlmutter (NVIDIA) supercomputer and discuss the potential portability of this software to HPC clusters such as Frontier (AMD) and Aurora (Intel). We also discuss future improvements including support for different tensor network topologies and enhanced computational efficiency.

</details>


### [11] [Solving nonlinear differential equations on noisy $156$-qubit quantum computers](https://arxiv.org/abs/2601.04439)
*Karla Baumann,Youcef Modheb,Roman Randrianarisoa,Roland Katz,Aoife Boyle,Frédéric Holweck*

Main category: quant-ph

TL;DR: Hybrid classical-quantum algorithm H-DES solves nonlinear differential equations (1D material deformation and inviscid Burgers' equation) on IBM's 156-qubit quantum computers, advancing NISQ-era physical simulations.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that physically relevant simulations can be performed on current NISQ devices by solving nonlinear differential equations using quantum computing platforms.

Method: Uses hybrid classical-quantum algorithm H-DES (Hybrid Differential Equation Solver) implemented on IBM's 156-qubit quantum computers to solve nonlinear differential equations.

Result: Successfully solved two nonlinear differential equations: a one-dimensional material deformation problem and the inviscid Burgers' equation on IBM quantum hardware.

Conclusion: The results represent progress toward performing physically relevant simulations on present-day NISQ devices, demonstrating practical quantum computing applications for solving nonlinear differential equations.

Abstract: In this paper, we report on the resolution of nonlinear differential equations using IBM's quantum platform. More specifically, we demonstrate that the hybrid classical-quantum algorithm H-DES successfully solves a one-dimensional material deformation problem and the inviscid Burgers' equation on IBM's 156-qubit quantum computers. These results constitute a step toward performing physically relevant simulations on present-day Noisy Intermediate-Scale Quantum (NISQ) devices.

</details>


### [12] [A Broadband Nanowire Quantum Dot Cavity Design for the Efficient Extraction of Entangled Photons](https://arxiv.org/abs/2601.04440)
*Sayan Gangopadhyay,Sasan V. Grayli,Sathursan Kokilathasan,Michael E. Reimer*

Main category: quant-ph

TL;DR: Nanowire cavity design using quasi-bound states in continuum enables high-Purcell enhancement (~17) with 4nm bandwidth, directional emission, and 74% extraction efficiency for quantum dot entangled photon sources.


<details>
  <summary>Details</summary>
Motivation: Quantum dot entangled photon sources in nanowire waveguides suffer from poor single-photon indistinguishability, limiting their applicability in quantum networks. Existing approaches using broadband optical cavities struggle to achieve high Purcell enhancement while maintaining nanowire advantages like directional emission, broad bandwidth, and high extraction efficiency.

Method: Proposed a nanowire cavity design based on quasi-bound states in the continuum formed by strong coupling of two resonant optical modes. Numerical analysis predicts cavity properties including bandwidth, Purcell enhancement, far-field emission profile, and light extraction efficiency.

Result: Numerical predictions show: 4 nm bandwidth cavity mode, Purcell enhancement of ~17, directional far-field emission with 88% overlap with Gaussian profile, and light extraction efficiency of ~74%.

Conclusion: The proposed nanowire cavity design enables enhanced extraction efficiency and single-photon indistinguishability for quantum dot entangled photon sources, opening a route toward practical realization of quantum networks.

Abstract: A bright source of on-demand entangled photons is needed for quantum networks. A single quantum dot in a site-selected nanowire waveguide is a promising candidate for realizing such sources. However, such sources are associated with poor single-photon indistinguishability, limiting their applicability in quantum networks. A common approach for enhancing the single-photon indistinguishability in quantum dot-based entangled photon sources is to implement a broadband optical cavity. Achieving a high-Purcell cavity while retaining the advantages of the nanowire, such as directional emission, a broad operational bandwidth, and high light extraction efficiency, has been a significant challenge. Here, we propose a nanowire cavity based on quasi-bound states in the continuum formed by the strong coupling of two resonant optical modes. We numerically predict this design to support a cavity mode with 4 nm bandwidth and a Purcell enhancement of $\sim$17. This cavity mode enables a directional far-field emission profile (88% overlap with a Gaussian) with a light extraction efficiency of $\sim$74%. Our solution opens up a route for generating entangled photon pairs with enhanced extraction efficiency and single-photon indistinguishability for the practical realization of quantum networks.

</details>


### [13] [Pauli Measurements Are Near-Optimal for Pure State Tomography](https://arxiv.org/abs/2601.04444)
*Sabee Grewal,Meghal Gupta,William He,Aniruddha Sen,Mihir Singhal*

Main category: quant-ph

TL;DR: Pure state tomography algorithm using nonadaptive Pauli measurements achieves near-optimal copy complexity of $\widetilde{O}(2^n/ε)$ for n-qubit states, improving previous $\widetilde{O}(3^n/ε)$ bound.


<details>
  <summary>Details</summary>
Motivation: Current quantum state tomography methods for pure states have suboptimal copy complexity, particularly requiring $\widetilde{O}(3^n/ε)$ copies. There's a need for more efficient algorithms that achieve near-optimal complexity while maintaining practical measurement strategies.

Method: The algorithm uses only nonadaptive Pauli measurements on $\widetilde{O}(2^n/ε)$ copies of an unknown pure n-qubit state. It runs in polynomial time relative to $2^n$ and $1/ε$, and outputs a state estimate with high fidelity.

Result: The algorithm achieves fidelity $1-ε$ with high probability using $\widetilde{O}(2^n/ε)$ copies, which is near-optimal and improves upon the previous best bound of $\widetilde{O}(3^n/ε)$. The method uses only single-qubit Pauli measurements and runs efficiently.

Conclusion: This work demonstrates that near-optimal pure state tomography is achievable with simple nonadaptive Pauli measurements, significantly reducing the copy complexity from exponential base 3 to base 2 while maintaining computational efficiency.

Abstract: We give an algorithm for pure state tomography with near-optimal copy complexity using single-qubit measurements. Specifically, given $\widetilde{O}(2^n/ε)$ copies of an unknown pure $n$-qubit state $\lvertψ\rangle$, the algorithm performs only \textit{nonadaptive Pauli measurements}, runs in time $\mathrm{poly}(2^n,1/ε)$, and outputs $\lvert \widehatψ \rangle$ that has fidelity $1-ε$ with $\lvert ψ\rangle$ with high probability. This improves upon the previous best copy complexity bound of $\widetilde{O}(3^n/ε)$.

</details>


### [14] [Holographic codes seen through ZX-calculus](https://arxiv.org/abs/2601.04467)
*Kwok Ho Wan,H. C. W. Price,Qing Yao*

Main category: quant-ph

TL;DR: ZX-calculus analysis of pentagon holographic quantum error correction codes, extending to hyperbolic tessellations and evaluating logical error rates with belief propagation decoders.


<details>
  <summary>Details</summary>
Motivation: To re-examine the pentagon holographic quantum error correcting code using ZX-calculus framework for better diagrammatic understanding and to extend this approach to create new code families from hyperbolic tessellations.

Method: Express pentagon holographic code tensors as ZX-diagrams, analyze stabilizer structure via Pauli webs, then construct new code families from ZX-diagrams on dual hyperbolic tessellations and evaluate using belief propagation decoders.

Result: Obtained diagrammatic understanding of logical operators, encoding isometries, Rényi entropy, and toy models of black holes/wormholes. Introduced new code families from hyperbolic tessellations with logical error rate analysis.

Conclusion: ZX-calculus provides powerful framework for analyzing holographic quantum codes, enabling both deeper understanding of existing codes and systematic construction of new code families with practical decoder evaluation.

Abstract: We re-visit the pentagon holographic quantum error correcting code from a ZX-calculus perspective. By expressing the underlying tensors as ZX-diagrams, we study the stabiliser structure of the code via Pauli webs. In addition, we obtain a diagrammatic understanding of its logical operators, encoding isometries, Rényi entropy and toy models of black holes/wormholes. Then, motivated by the pentagon holographic code's ZX-diagram, we introduce a family of codes constructed from ZX-diagrams on its dual hyperbolic tessellations and study their logical error rates using belief propagation decoders.

</details>


### [15] [Momentum-Space Entanglement Entropy as a Universal Signature of Dynamical Quantum Phase Transitions](https://arxiv.org/abs/2601.04535)
*Kaiyuan Cao,Mingzhi Li,Xiang-Ping Jiang,Shu Chen,Jian Wang*

Main category: quant-ph

TL;DR: Momentum-space entanglement entropy saturates to maximal value at critical momenta associated with dynamical quantum phase transitions, providing universal signature of DQPTs.


<details>
  <summary>Details</summary>
Motivation: To establish a unified, entanglement-based perspective on dynamical quantum phase transitions by quantifying quantum correlations between distinct momentum modes following a quench.

Method: Introduce momentum-space entanglement entropy and prove analytically in transverse-field Ising model and Su-Schrieffer-Heeger chain that every critical momentum associated with DQPT saturates its entanglement entropy to maximal value ln(d).

Result: Critical momenta associated with DQPTs saturate entanglement entropy to maximal value ln(d) (d=2 in TFI and SSH models), coinciding with vanishing Loschmidt echo. This saturation provides universal, direct signature of DQPTs.

Conclusion: Momentum-space entanglement entropy saturation establishes a unified, entanglement-based perspective on dynamical quantum phase transitions, offering a universal signature that coincides with Loschmidt echo behavior.

Abstract: We introduce a momentum-space entanglement entropy to quantify quantum correlations between distinct momentum modes following a quench. We prove analytically in the transverse-field Ising (TFI) model and the Su-Schrieffer-Heeger (SSH) chain that every critical momentum $k^{*}$ associated with a dynamical quantum phase transition (DQPT) saturates its entanglement entropy to the maximal value $\ln{d}$ ($d=2$ in TFI and SSH models), coinciding with the vanishing of the Loschmidt echo. This saturation of mode entanglement thus provides a universal, direct signature of DQPTs. Our work thus establishes a unified, entanglement-based perspective on dynamical quantum phase transitions.

</details>


### [16] [Increasing the secret key rates and point-to-multipoint extension for experimental coherent-one-way quantum key distribution protocol](https://arxiv.org/abs/2601.04543)
*Venkat Abhignan,Mohit Mittal,Aditi Das,Megha Shrivastava*

Main category: quant-ph

TL;DR: Experimental demonstration of improved secret key rates in COW QKD by combining time-bin information from two detectors and implementing point-to-multipoint protocol with dual receivers.


<details>
  <summary>Details</summary>
Motivation: Single-photon detectors create bottlenecks in QKD systems due to limited detection rates, low efficiency, and high dead-time, restricting secret key rates in real-world quantum communication networks.

Method: 1) Combined time-bin information from two detectors on the receiver's data line for COW QKD protocol; 2) Implemented point-to-multipoint COW QKD with additional receiver module for three-user system (one transmitter, two receivers); 3) Used post-processing with OTP encryption for key sharing.

Result: Increased secret key rates with minimal increase in QBER; dual-receiver extension improved combined secret key rates of the system when experimental parameters were optimized within security margins.

Conclusion: The methods are general and applicable to any COW protocol implementation, demonstrating practical approaches to overcome detector limitations and enhance QKD performance in multi-user networks.

Abstract: Using quantum key distribution (QKD) protocols, a secret key is created between two distant users (transmitter and receiver) at a particular key rate. Quantum technology can facilitate secure communication for cryptographic applications, combining QKD with one-time-pad (OTP) encryption. In order to ensure the continuous operation of QKD in real-world networks, efforts have been concentrated on optimizing the use of components and effective QKD protocols to improve secret key rates and increase the transmission between multiple users. Generally, in experimental implementations, the secret key rates are limited by single-photon detectors, which are used at the receivers of QKD and create a bottleneck due to their limited detection rates (detectors with low detection efficiency and high detector dead-time). We experimentally show that secret key rates can be increased by combining the time-bin information of two such detectors on the data line of the receiver for the coherent-one-way (COW) QKD protocol with a minimal increase in quantum bit error rate (QBER, the proportion of erroneous bits). Further, we implement a point-to-multipoint COW QKD protocol, introducing an additional receiver module. The three users (one transmitter and two receivers) share the secret key in post-processing, relying on OTP encryption. Typically, the dual-receiver extension can improve the combined secret key rates of the system; however, one has to optimise the experimental parameters to achieve this within security margins. These methods are general and can be applied to any implementation of the COW protocol.

</details>


### [17] [Observation of ΔJ=0 Rotational Excitation in Dense Hydrogens](https://arxiv.org/abs/2601.04549)
*Jie Feng,XiaoDi Liu,Haian Xu,Pu Wang,Graeme J. Ackland,Eugene Gregoryanz*

Main category: quant-ph

TL;DR: Raman spectroscopy reveals a unique ΔJ=0 rotational excitation in dense hydrogen isotopes that is isotope-independent and fundamentally different from conventional harmonic oscillators or quantum rotors.


<details>
  <summary>Details</summary>
Motivation: To investigate the unusual behavior of rotational excitations in dense hydrogen isotopes under extreme pressure-temperature conditions, particularly the ΔJ=0 transition that shows unexpected isotope independence.

Method: Raman spectroscopy measurements on dense H2, D2, and H2+D2 mixtures across a wide pressure-temperature range, including gas/fluid and solid phases up to ~50 GPa and 10 K.

Result: ΔJ=0 excitation has zero Raman shift in gas/fluid state but shifts to ~75 cm⁻¹ in solid phase at 50 GPa/10 K for all isotopes. In deuterium phase II, the mode splits, indicating complex molecular environment. The transition frequencies show complete isotope independence, not scaling with rotational (factor of 2) or vibrational (square root of 2) modes.

Conclusion: The ΔJ=0 transition represents a fundamentally different type of excitation from conventional harmonic oscillators and quantum rotors, characterized by its mass independence and unique behavior in broken symmetry phases.

Abstract: Raman measurements performed on dense H2, D2 and H2+D2 in a wide pressure-temperature range reveal the presence of the ΔJ=0 rotational excitation. In the gas/fluid state this excitation has zero Raman shift, but in the solid, the crystal field drive s it away from the zero value e.g. 75 cm-1 at around 50 GPa and 10 K for both isotopes and their mixture. In the case of deuterium, the ΔJ=0 mode splits upon entering phase II suggesting a very complex molecular environment of the broken symmetry phase (BSP). In the fluid state and phases I and II the frequencies (energies) of the ΔJ=0 transition for H2 and D2 do not scale either as rotational (by factor of 2) nor vibrational (by square 2) modes and appear to be completely isotope independent. This independence on mass marks this transition as unique and a fundamentally different type of excitation from the commonly considered harmonic oscillator and quantum rotor.

</details>


### [18] [Multimode Fock-State Measurements using Dispersive Shifts in a Trapped Ion](https://arxiv.org/abs/2601.04591)
*Wonhyeong Choi,Jiyong Kang,Kyunghye Kim,Jaehun You,Kyungmin Lee,Taehyun Kim*

Main category: quant-ph

TL;DR: Single-spin multimode measurement for trapped-ion bosonic registers using dispersive shifts and selective decoupling enables Fock-state distribution extraction, parity filtering, and nondestructive single-shot Fock-state measurements.


<details>
  <summary>Details</summary>
Motivation: Trapped ions provide scalable multimode bosonic registers with multiple motional modes alongside spin qubits, but efficient characterization requires accessing many motional modes with limited spin resources.

Method: Introduces a single-spin, multimode measurement primitive using dispersive shifts in far-detuned multimode Jaynes-Cummings interaction. Implements Ramsey sequence mapping phonon-number-dependent phases onto spin (multimode spin-dependent rotation). Also introduces selective-decoupling scheme to cancel carrier AC-Stark shift phase while preserving phonon-number-dependent phase from dispersive shift.

Result: Experimental demonstration on single trapped ion: extracted two-mode Fock-state distributions, performed parity-based filtering of two-mode motional states, and realized nondestructive single-shot measurement of single-mode Fock state via repeated filtering steps.

Conclusion: The SDR-based Ramsey sequence with selective decoupling provides an efficient measurement primitive for characterizing multimode bosonic registers in trapped-ion systems, enabling advanced quantum state analysis with limited spin resources.

Abstract: Trapped ions naturally host multiple motional modes alongside long-lived spin qubits, providing a scalable multimode bosonic register. Efficiently characterizing such bosonic registers requires the ability to access many motional modes with limited spin resources. Here we introduce a single-spin, multimode measurement primitive using dispersive shifts in the far-detuned multimode Jaynes-Cummings interaction. We implement a Ramsey sequence that maps phonon-number-dependent phases onto the spin, thereby realizing a multimode spin-dependent rotation (SDR). We also introduce a selective-decoupling scheme that cancels the phase induced by the carrier AC-Stark shift while preserving the phonon-number-dependent phase induced by the dispersive shift. Using this SDR-based Ramsey sequence on a single trapped ion, we experimentally extract two-mode Fock-state distributions, perform parity-based filtering of two-mode motional states, and realize a nondestructive single-shot measurement of a single-mode Fock state via repeated filtering steps.

</details>


### [19] [Path Integral Lindblad Dynamics in Presence of Time-Dependent Fields](https://arxiv.org/abs/2601.04604)
*Amartya Bose*

Main category: quant-ph

TL;DR: The authors present an improved formulation of the Path Integral Lindblad Dynamics (PILD) method that overcomes limitations of the original approach, enabling application to time-dependent external fields and Floquet systems without requiring direct evaluation of non-Markovian memory kernels.


<details>
  <summary>Details</summary>
Motivation: The original PILD method was limited to time-translationally invariant systems and couldn't handle time-dependent external fields due to its reliance on the Nakajima-Zwanzig memory kernel's time-translational invariance. This limitation prevented application to important systems like those with external driving fields or Floquet systems.

Method: The authors develop an alternative, simpler formulation of PILD that avoids direct evaluation of the non-Markovian memory kernel. This new approach circumvents the time-translational invariance requirement, making it applicable to systems with time-dependent external fields.

Result: The new formulation successfully extends PILD to handle time-dependent external fields and Floquet systems, overcoming the key limitation of the original method while maintaining the ability to incorporate empirical processes like pumps and drains in quantum systems interacting with thermal environments.

Conclusion: The revised PILD formulation provides a more versatile tool for studying quantum system dynamics under time-dependent external fields and in Floquet systems, expanding the applicability of the method beyond the original time-translationally invariant cases.

Abstract: The path integral Lindblad dynamics (PILD) method [A. Bose, J. Phys. Chem. Lett. 15(12), 3363-3368 (2024)] had been introduced as a way of incorporating the impact of certain empirical processes like pumps and drains on the dynamics of quantum systems interacting with thermal environments. The method being based on the time-translational invariance of the Nakajima-Zwanzig memory kernel, however, was not able to account for time-dependent external fields. In this communication, we give an alternate, simpler formulation of PILD, that allows us to go beyond this limitation. It does not require the evaluation of the non-Markovian memory kernel directly, and consequently can be applied to Floquet systems as well.

</details>


### [20] [Hardy nonlocality for entangled pairs in a four-particle system](https://arxiv.org/abs/2601.04636)
*Duc Manh Doan,Hung Q. Nguyen*

Main category: quant-ph

TL;DR: The paper demonstrates enhanced Hardy-type nonlocality in cyclic four-particle entanglement configurations compared to fully entangled systems, with experimental implementation on IBM quantum hardware showing deviations from simulations.


<details>
  <summary>Details</summary>
Motivation: Hardy's paradox provides a nonlocality test without inequalities, but previous studies focused mainly on fully entangled systems, leaving other entanglement configurations like cyclic arrangements underexplored.

Method: Investigates a four-particle cyclic entanglement configuration where each particle is entangled with two neighbors, implements quantum circuits compatible with this structure, performs simulations, and executes circuits on IBM Brisbane backend.

Result: The cyclic entanglement structure offers more conditions leading to contradictions with local hidden variable models than fully entangled systems, attributed to multiple excluded states and correlations where measurement results only influence paired partners. Experimental results on IBM hardware show significant deviations from simulations.

Conclusion: Cyclic entanglement configurations enhance Hardy-type nonlocality compared to fully entangled systems, though practical quantum hardware implementations face challenges in reproducing theoretical predictions due to noise and imperfections.

Abstract: Nonlocality can be studied through different approaches, such as Bell's inequalities, and it can be found in numerous quantum states, including GHZ states or graph states. Hardy's paradox, or Hardy-type nonlocality, provides a way to investigate nonlocality for entangled states of particles without using inequalities. Previous studies of Hardy's nonlocality have mostly focused on the fully entangled systems, while other entanglement configurations remain less explored. In this work, the system under investigation consists of four particles arranged in a cyclic entanglement configuration, where each particle forms entangled pairs with two neighbors, while non-neighboring particles remain unentangled. We found that this entanglement structure offers a larger set of conditions that lead to the contradiction with the LHV model, compared to the fully entangled systems. This enhancement can be attributed to the presence of multiple excluded states and correlations, in which the measurement result of a particle only influences the result of its paired partners. We implement quantum circuits compatible with the cyclic entanglement structure, and through simulation, the correlation patterns and the states of interest are identified. We further execute the proposed circuits on IBM Brisbane, a practical backend; however, the results show considerable deviations from the simulation counterparts.

</details>


### [21] [SurgeQ: A Hybrid Framework for Ultra-Fast Quantum Processor Design and Crosstalk-Aware Circuit Execution](https://arxiv.org/abs/2601.04645)
*Xinxuan Chen,Hongxiang Zhu,Zhaohui Yang,Zhaofeng Su,Jianxin Chen,Feng Wu,Hui-Hai Zhao*

Main category: quant-ph

TL;DR: SurgeQ is a hardware-software co-design strategy that uses coupling-strengthened faster gates with tailored scheduling to accelerate quantum circuit execution while mitigating increased crosstalk, achieving significant fidelity improvements.


<details>
  <summary>Details</summary>
Motivation: Executing quantum circuits on superconducting platforms requires balancing the trade-off between gate errors and crosstalk. Current approaches struggle with this fundamental tension between faster gates (which increase crosstalk) and slower gates (which accumulate more errors).

Method: SurgeQ employs a two-phase hardware-software co-design: 1) Design phase: Uses coupling-strengthened, faster two-qubit gates while establishing a systematic evaluation pipeline with composite noise models to identify optimal coupling strength. 2) Execution phase: Implements tailored scheduling strategies to mitigate increased crosstalk from faster gates.

Result: Evaluations on comprehensive real-world benchmarks show SurgeQ generally achieves higher fidelity than up-to-date baselines. It effectively combats exponential fidelity decay, achieving up to a million-fold improvement in large-scale circuits.

Conclusion: SurgeQ successfully addresses the gate error-crosstalk trade-off through hardware-software co-design, demonstrating that coupling-strengthened gates with intelligent scheduling can significantly accelerate circuit execution while improving overall program fidelity on superconducting quantum platforms.

Abstract: Executing quantum circuits on superconducting platforms requires balancing the trade-off between gate errors and crosstalk. To address this, we introduce SurgeQ, a hardware-software co-design strategy consisting of a design phase and an execution phase, to achieve accelerated circuit execution and improve overall program fidelity. SurgeQ employs coupling-strengthened, faster two-qubit gates while mitigating their increased crosstalk through a tailored scheduling strategy. With detailed consideration of composite noise models, we establish a systematic evaluation pipeline to identify the optimal coupling strength. Evaluations on a comprehensive suite of real-world benchmarks show that SurgeQ generally achieves higher fidelity than up-to-date baselines, and remains effective in combating exponential fidelity decay, achieving up to a million-fold improvement in large-scale circuits.

</details>


### [22] [Regularization from Superpositions of Time Evolutions](https://arxiv.org/abs/2601.04685)
*Eliahu Cohen,Tomer Shushi*

Main category: quant-ph

TL;DR: The paper introduces a novel regularization method for path integrals using coherently controlled, postselected superpositions of evolutions, which naturally produces Gaussian energy filters that suppress high-energy contributions without manual imposition.


<details>
  <summary>Details</summary>
Motivation: Standard regulators for path integrals (cutoffs, higher-derivative terms, heat-kernel smearing, lattice discretizations) are imposed manually and may not preserve symmetries. The paper aims to develop regulators that arise naturally from quantum interference in controlled superpositions, providing suppressive yet removable regularization that maintains symmetry compatibility.

Method: The method uses coherently controlled, postselected superpositions of time evolutions. A successful postselection implements a single heralded operator that is a coherent linear combination of time-evolution operators. For a Gaussian superposition of time translations, this produces $V_{σ,Δt}=e^{-iHΔt}\,e^{-\frac12σ^2Δt^2H^2}$, combining the desired unitary step with a Gaussian energy filter. In scalar QFT, this induces local Gaussian smearing of interactions.

Result: The Gaussian energy filter suppresses energies above order $1/(σΔt)$, rendering short-time kernels in time-sliced path integrals well behaved for singular potentials. In scalar QFT with quartic coupling, the method induces a positive $(σ^2/2)φ^8$ term in the Euclidean action, providing a symmetry-compatible large-field stabilizer. The target unitary dynamics is recovered as $σ→0$ and as $Δt→0$ at fixed $t$.

Conclusion: The paper demonstrates that smooth regulators can arise naturally from quantum interference in coherently controlled, postselected superpositions, providing an alternative to manually imposed regulators. These regulators are suppressive yet removable, maintain symmetry compatibility, and can be renormalized at fixed $σ$ before removal by taking $σ→0$.

Abstract: Short-time approximations and path integrals can be dominated by high-energy or large-field contributions, especially in the presence of singular interactions, motivating regulators that are suppressive yet removable. Standard regulators typically impose such suppressions by hand (e.g. cutoffs, higher-derivative terms, heat-kernel smearing, lattice discretizations), while here we show that closely related smooth filters can arise as the conditional map produced by interference in a coherently controlled, postselected superposition of evolutions. A successful postselection implements a single heralded operator that is a coherent linear combination of time-evolution operators. For a Gaussian superposition of time translations in quantum mechanics, the postselected step is $V_{σ,Δt}=e^{-iHΔt}\,e^{-\frac12σ^2Δt^2H^2}$, i.e.\ the desired unitary step multiplied by a Gaussian energy filter suppressing energies above order $1/(σΔt)$. This renders short-time kernels in time-sliced path-integral approximations well behaved for singular potentials, while the target unitary dynamics is recovered as $σ\to0$ and (for fixed $σ$) also as $Δt\to0$ at fixed $t$. In scalar QFT, a local Gaussian smearing of the quartic coupling induces a positive $(σ^2/2)φ^8$ term in the Euclidean action, providing a symmetry-compatible large-field stabilizer; it is naturally viewed as an irrelevant operator whose effects can be renormalized at fixed $σ$ (together with a conventional UV regulator) and removed by taking $σ\to0$. We give short-time error bounds and analyze multi-step success probabilities.

</details>


### [23] [The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment](https://arxiv.org/abs/2601.04732)
*Dominik Freinberger,Philipp Moser*

Main category: quant-ph

TL;DR: Hybrid quantum-classical neural networks show comparable performance to classical models in best cases but generally deteriorate with quantum components, requiring cautious design choices.


<details>
  <summary>Details</summary>
Motivation: To investigate the specific contribution of quantum components to hybrid quantum-classical neural network performance, addressing the open question about quantum processing's impact in near-term quantum machine learning applications.

Method: Conducted a rigorous statistical study systematically assessing common hybrid models on medical signal data, planar images, and volumetric images, examining classical and quantum aspects including encoding schemes, entanglement, and circuit size.

Result: In best-case scenarios, hybrid models show performance comparable to classical counterparts, but in most cases, performance metrics deteriorate under the influence of quantum components.

Conclusion: Multi-modal analysis provides realistic insights into quantum component contributions and advocates for cautious claims and design choices for hybrid models in near-term applications.

Abstract: Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications.

</details>


### [24] [A scalable gallium-phosphide-on-diamond spin-photon interface](https://arxiv.org/abs/2601.04733)
*Nicholas S. Yama,Chun-Chi Wu,Fariba Hatami,Kai-Mei C. Fu*

Main category: quant-ph

TL;DR: First demonstration of high-cooperativity coupling of silicon-vacancy centers to hybrid-integrated gallium phosphide nanophotonic cavities on diamond, enabling spin-dependent transmission switching and single-shot spin readout.


<details>
  <summary>Details</summary>
Motivation: Current quantum defect platforms using diamond nanophotonic cavities face scalability limitations due to suspended geometries and weak nonlinearity, requiring coupling to secondary processing chips. A scalable, planar platform with strong nonlinear properties is needed for quantum networking applications.

Method: Integrated over 600 gallium phosphide (GaP) nanophotonic cavities on a diamond substrate with near-surface silicon-vacancy (SiV) centers. Examined a specific device with two strongly coupled SiV centers, confirmed above-unity cooperativity via multiple independent measurements. Applied external magnetic field via permanent magnet to resolve spin transitions and measured spin-relaxation time.

Result: Achieved first high-cooperativity coupling of quantum defects to hybrid-integrated nanophotonics in a scalable planar platform. Demonstrated cooperativity C>1, spin-relaxation time T₁>0.4 ms at 4 K, spin-dependent transmission switching, and quantum jumps of SiV spin via single-shot readout.

Conclusion: GaP-on-diamond platform establishes a scalable planar architecture for quantum network applications, combining the excellent optical/spin coherence of SiV centers with GaP's strong nonlinear properties and integrated photonic processing capabilities.

Abstract: The efficient interfacing of quantum emitters and photons is fundamental to quantum networking. Quantum defects embedded in integrated nanophotonic circuits are promising for such applications due to the deterministic light-matter interactions of high-cooperativity ($C>1$) cavity quantum electrodynamics and potential for scalable integration with active photonic processing. Silicon-vacancy (SiV) centers embedded in diamond nanophotonic cavities are a leading approach due to their excellent optical and spin coherence, however their long-term scalability is limited by the diamond itself, as its suspended geometry and weak nonlinearity necessitates coupling to a second processing chip. Here we realize the first high-cooperativity coupling of quantum defects to hybrid-integrated nanophotonics in a scalable, planar platform. We integrate more than 600 gallium phosphide (GaP) nanophotonic cavities on a diamond substrate with near-surface SiV centers. We examine a particular device with two strongly coupled SiV centers in detail, confirming above-unity cooperativity via multiple independent measurements. Application of an external magnetic field via a permanent magnet enables optical resolution of the SiV spin transitions from which we determine a spin-relaxation time $T_1>0.4$ ms at 4 K. We utilize the high cooperativity coupling to observe spin-dependent transmission switching and the quantum jumps of the SiV spin via single-shot readout. These results, coupled with GaP's strong nonlinear properties, establish GaP-on-diamond as a scalable planar platform for quantum network applications.

</details>


### [25] [Bound state solutions with a linear combination of Yuakawa plus four-parameter diatomic potentials using path integral approach: Thermodynamic properties](https://arxiv.org/abs/2601.04806)
*Mohamed Améziane Sadoun,Redouane Zamoum,Abdellah Touati*

Main category: quant-ph

TL;DR: Analytical bound states for diatomic molecule potentials (Yukawa + four-parameter) derived using path integral formalism with centrifugal approximation, yielding energy spectrum, wave functions, partition function, and thermodynamic properties.


<details>
  <summary>Details</summary>
Motivation: To investigate approximate analytical bound states for diatomic molecules using a combination of Yukawa and four-parameter potentials within the path integral formalism, enabling derivation of energy spectra, wave functions, and thermodynamic properties.

Method: Path integral formalism with appropriate approximation for centrifugal term; energy spectrum and normalized wave functions derived from poles of Green's function and its residues; partition function obtained from compact energy equation.

Result: Derived analytical expressions for bound state energy spectrum, normalized wave functions, partition function, and other thermodynamic properties for the combined Yukawa and four-parameter potentials.

Conclusion: The path integral approach with centrifugal approximation successfully provides analytical solutions for bound states of diatomic molecule potentials, enabling calculation of both quantum mechanical and thermodynamic properties.

Abstract: In this paper, we investigate the approximate analytical bound states with a linear combination of two diatomic molecule potentials, Yukawa and four parameters potentials, within the framework of the path integral formalism. With the help of an appropriate approximation to evaluate the centrifugal term, the energy spectrum and the normalized wave functions of the bound states are derived from the poles of Green's function and its residues. The partition function and other thermodynamic properties were obtained using the compact form of the energy equation.

</details>


### [26] [Fast thermal state preparation beyond native interactions](https://arxiv.org/abs/2601.04810)
*Alexander van Lomwel,Paul M. Schindler,Modesto Orozco-Ruiz,Marin Bukov,Nguyen H. Le,Florian Mintert*

Main category: quant-ph

TL;DR: A framework using unitary dynamics to design quantum simulations for thermal states with respect to Hamiltonians containing non-native interactions, applicable to both digital and analogue quantum devices.


<details>
  <summary>Details</summary>
Motivation: Most quantum simulation work focuses on ground states with effective interactions or thermal dynamics with native interactions, but many open questions require thermal states with synthetic interactions.

Method: A framework based solely on unitary dynamics to design control sequences for reaching target thermal states with non-native interactions, using classical optimization to find sequences for large system sizes beyond state-vector or density-matrix methods.

Result: The method successfully designs control sequences for thermal states in the cluster Ising model with three-body interactions, showing that required experimental resources (total evolution time) are independent of temperature and criticality.

Conclusion: The framework enables quantum simulation of thermal states with synthetic interactions on current quantum hardware, overcoming limitations of existing approaches and showing favorable resource scaling properties.

Abstract: While questions on quantum simulation of ground state physics are mostly focussed on the realization of effective interactions, most work on quantum simulation of thermal physics explores the realization of dynamics towards a thermal mixed state under native interactions. Many open questions that could be answered with quantum simulations, however, involve thermal states with respect to synthetic interactions. We present a framework based solely on unitary dynamics to design quantum simulations for thermal states with respect to Hamiltonians that include non-native interactions, suitable for both present-day digital and analogue devices. By classical means, our method finds the control sequence to reach a target thermal state for system sizes well out of reach of state-vector or density-matrix control methods, even though quantum hardware is required to explicitly simulate the thermal state dynamics. With the illustrative example of the cluster Ising model that includes non-native three-body interactions, we find that required experimental resources, such as the total evolution time, are independent of temperature and criticality.

</details>


### [27] [Quantum Wiener architecture for quantum reservoir computing](https://arxiv.org/abs/2601.04812)
*Alessio Benavoli,Felix Binder*

Main category: quant-ph

TL;DR: Quantum Wiener architectures (qWiener) combine quantum linear dynamic networks with weak continuous measurements and classical nonlinear readouts, proving they retain fading-memory and universality properties while offering performance gains over classical and quantum reservoir computing models.


<details>
  <summary>Details</summary>
Motivation: To extend classical Wiener architectures (linear dynamic networks with nonlinear readouts) to quantum systems, addressing whether quantum constraints (linear dynamics limitations and measurement back-action) preserve the fundamental properties of fading-memory and universality that make Wiener systems effective for reservoir computing.

Method: Develop quantum Wiener architectures (qWiener) consisting of quantum linear dynamic networks with weak continuous measurements and classical nonlinear static readouts. Provide rigorous mathematical proofs of fading-memory property and universality. Develop kernel-theoretic interpretation showing qWiener reservoirs induce deep kernels. Characterize simplest instantiation using concatenated quantum harmonic oscillators and compare with classical case. Conduct empirical evaluation on standard reservoir computing benchmarks.

Result: First rigorous proof that qWiener systems retain fading-memory property and universality of classical Wiener architectures despite quantum constraints. Kernel-theoretic interpretation reveals qWiener reservoirs naturally induce deep kernels. Characterization shows differences between quantum and classical implementations. Empirical evaluation demonstrates systematic performance gains over prior classical and quantum reservoir computing models on standard benchmarks.

Conclusion: Quantum Wiener architectures successfully extend classical Wiener systems to quantum domain while preserving essential computational properties, offering a principled framework for quantum reservoir computing with demonstrated performance advantages over existing approaches.

Abstract: This work focuses on quantum reservoir computing and, in particular, on quantum Wiener architectures (qWiener), consisting of quantum linear dynamic networks with weak continuous measurements and classical nonlinear static readouts. We provide the first rigorous proof that qWiener systems retain the fading-memory property and universality of classical Wiener architectures, despite quantum constraints on linear dynamics and measurement back-action. Furthermore, we develop a kernel-theoretic interpretation showing that qWiener reservoirs naturally induce deep kernels, providing a principled framework for analysing their expressiveness. We further characterise the simplest qWiener instantiation, consisting of concatenated quantum harmonic oscillators, and show the difference with respect to the classical case. Finally, we empirically evaluate the architecture on standard reservoir computing benchmarks, demonstrating systematic performance gains over prior classical and quantum reservoir computing models.

</details>


### [28] [PACOX: A FPGA-based Pauli Composer Accelerator for Pauli String Computation](https://arxiv.org/abs/2601.04827)
*Tran Xuan Hieu Le,Tuan Hai Vu,Vu Trung Duong Le,Hoai Luan Pham,Yasuhiko Nakashima*

Main category: quant-ph

TL;DR: PACOX is the first FPGA-based accelerator for Pauli string computation, achieving 100x speedup over CPU methods with superior energy efficiency for hybrid quantum-classical systems.


<details>
  <summary>Details</summary>
Motivation: Classical computation of Pauli strings suffers from exponential complexity and becomes a performance bottleneck in hybrid quantum-classical algorithms as qubit count increases, necessitating specialized hardware acceleration.

Method: Proposes PACOX accelerator using compact binary encoding with XOR-based index permutation and phase accumulation, implemented as parallel and pipelined processing element cluster architecture on FPGA to exploit data-level parallelism.

Result: PACOX operates at 250 MHz with 0.33W dynamic power, using 8,052 LUTs, 10,934 FFs, and 324 BRAMs. Achieves up to 100x speedup for Pauli strings up to 19 qubits compared to state-of-the-art CPU methods, with significantly lower memory usage and power-delay product.

Conclusion: PACOX delivers high computational speed with superior energy efficiency for Pauli-based workloads, demonstrating the effectiveness of FPGA-based acceleration for hybrid quantum-classical systems.

Abstract: Pauli strings are a fundamental computational primitive in hybrid quantum-classical algorithms. However, classical computation of Pauli strings suffers from exponential complexity and quickly becomes a performance bottleneck as the number of qubits increases. To address this challenge, this paper proposes the Pauli Composer Accelerator (PACOX), the first dedicated FPGA-based accelerator for Pauli string computation. PACOX employs a compact binary encoding with XOR-based index permutation and phase accumulation. Based on this formulation, we design a parallel and pipelined processing element (PE) cluster architecture that efficiently exploits data-level parallelism on FPGA. Experimental results on a Xilinx ZCU102 FPGA show that PACOX operates at 250 MHz with a dynamic power consumption of 0.33 W, using 8,052 LUTs, 10,934 FFs, and 324 BRAMs. For Pauli strings of up to 19 qubits, PACOX achieves speedups of up to 100 times compared with state-of-the-art CPU-based methods, while requiring significantly less memory and achieving a much lower power-delay product. These results demonstrate that PACOX delivers high computational speed with superior energy efficiency for Pauli-based workloads in hybrid quantum-classical systems.

</details>


### [29] [Noise tailoring for error mitigation and for diagnozing digital quantum computers](https://arxiv.org/abs/2601.04830)
*Thibault Scoquart,Hugo Perrin,Kyrylo Snizhko*

Main category: quant-ph

TL;DR: Noise Tailoring (NT) modifies two-qubit gate noise via statistical sampling to enhance error mitigation effectiveness, achieving up to 5x accuracy improvement in simulations but facing challenges on real hardware due to non-Markovian noise.


<details>
  <summary>Details</summary>
Motivation: Error mitigation methods are essential for NISQ computers but often assume specific noise types that may not match actual hardware noise, limiting their effectiveness.

Method: Noise Tailoring (NT) protocol that statistically samples and modifies the structure of two-qubit gate noise to better align with assumptions of existing error mitigation methods.

Result: Classical emulation shows NT+EM can be up to 5 times more accurate than EM alone for realistic Pauli noise, but real IBM quantum computers reveal limitations due to non-Markovian noise sources.

Conclusion: NT can enhance error mitigation for specific noise types but also serves as a diagnostic tool to characterize complex error sources on actual quantum hardware, informing future hardware development.

Abstract: Error mitigation (EM) methods are crucial for obtaining reliable results in the realm of noisy intermediate-scale quantum (NISQ) computers, where noise significantly impacts output accuracy. Some EM protocols are particularly efficient for specific types of noise. Yet the noise in the actual hardware may not align with that. In this article, we introduce Noise Tailoring (NT) -- an innovative strategy designed to modify the structure of the noise associated with two-qubit gates through statistical sampling. We perform classical emulation of the protocol behavior and find that the NT+EM results can be up to 5 times more accurate than the results of EM alone for realistic Pauli noise acting on two-qubit gates. At the same time, on actual IBM quantum computers, the NT method falls victim to various small error sources beyond Markovian Pauli noise. We propose to use the NT method for characterizing such error sources on quantum computers in order to inform hardware development.

</details>


### [30] [Unconditionally teleported quantum gates between remote solid-state qubit registers](https://arxiv.org/abs/2601.04848)
*Mariagrazia Iuliano,Nicolas Demetriou,H. Benjamin van Ommen,Constantijn Karels,Tim H. Taminiau,Ronald Hanson*

Main category: quant-ph

TL;DR: Demonstration of an unconditional remote CNOT gate between diamond-based qubits using NV centers for local logic and entanglement, enabling distributed quantum computing without post-selection.


<details>
  <summary>Details</summary>
Motivation: To enable distributed quantum computing through quantum networks by implementing non-local quantum gates between remote qubits, which is essential for modular quantum computation architectures.

Method: Used diamond-based qubit devices with Carbon-13 nuclear spins as control/target qubits and NV electron spins for local logic, readout, and remote entanglement generation. Implemented deterministic logic, single-shot readout, and real-time feed-forward to achieve unconditional remote CNOT gates without post-selection.

Result: Successfully demonstrated an unconditional remote Controlled-NOT gate between remote diamond-based qubits and created a Greenberger-Horne-Zeilinger state showing genuine 4-partite entanglement shared between nodes.

Conclusion: This work demonstrates a key capability for solid-state quantum networks, enabling exploration of distributed quantum computing and testing of complex network protocols on fully integrated systems.

Abstract: Quantum networks connecting quantum processing nodes via photonic links enable distributed and modular quantum computation. In this framework, quantum gates between remote qubits can be realized using quantum teleportation protocols. The essential requirements for such non-local gates are remote entanglement, local quantum logic within each processor, and classical communication between nodes to perform operations based on measurement outcomes. Here, we demonstrate an unconditional Controlled-NOT quantum gate between remote diamond-based qubit devices. The control and target qubits are Carbon-13 nuclear spins, while NV electron spins enable local logic, readout, and remote entanglement generation. We benchmark the system by creating a Greenberger-Horne-Zeilinger state, showing genuine 4-partite entanglement shared between nodes. Using deterministic logic, single-shot readout, and real-time feed-forward, we implement non-local gates without post-selection. These results demonstrate a key capability for solid-state quantum networks, enabling exploration of distributed quantum computing and testing of complex network protocols on fully integrated systems.

</details>


### [31] [Distinguishing Coherent and Incoherent Errors in Multi-Round Time-Reversed Dynamics via Scramblons](https://arxiv.org/abs/2601.04856)
*Zeyu Liu,Pengfei Zhang*

Main category: quant-ph

TL;DR: The paper analyzes how coherent and incoherent errors accumulate differently in multi-round time-reversed quantum dynamics, showing linear accumulation for incoherent errors and a quadratic-to-linear crossover for coherent errors.


<details>
  <summary>Details</summary>
Motivation: To understand how coherent errors (from imperfect Hamiltonian control) and incoherent errors (from environmental coupling) imprint distinct signatures on the irreversibility of many-body dynamics in quantum chaotic systems, where both types of errors are exponentially amplified by information scrambling.

Method: Investigates multi-round time-reversed dynamics with both error types, applies scramblon theory to obtain closed-form expressions for Loschmidt echo over different rounds of time-reversed evolution, and explicitly verifies predictions using the solvable Sachdev-Ye-Kitaev (SYK) model.

Result: For incoherent errors, error accumulation is linear with the number of rounds; for coherent errors, there is a crossover from quadratic to linear accumulation. These distinct signatures are derived theoretically and verified using the SYK model.

Conclusion: The results provide a theoretical foundation for characterizing and calibrating coherent and incoherent errors in reversed dynamics, with particular relevance to nuclear magnetic resonance systems where such error differentiation is crucial.

Abstract: Despite the rapid development of quantum science and technology, errors are inevitable and play a crucial role in quantum simulation and quantum computation. In quantum chaotic systems, coherent errors arising from imperfect Hamiltonian control and incoherent errors induced by coupling to the environment are both exponentially amplified during time evolution due to information scrambling. A fundamental question is how these two classes of errors imprint distinct signatures on the emergent irreversibility of many-body dynamics. In this Letter, we address this question by investigating multi-round time-reversed dynamics in the presence of both coherent and incoherent errors. By applying scramblon theory, we obtain closed-form expressions for the Loschmidt echo over different rounds of time-reversed evolution. For incoherent errors, the error accumulates linearly with the number of rounds, whereas coherent errors exhibit a crossover from quadratic to linear accumulation. These predictions are explicitly verified using the solvable Sachdev-Ye-Kitaev model. Our results provide a theoretical foundation for characterizing and calibrating coherent and incoherent errors in reversed dynamics, with particular relevance to nuclear magnetic resonance systems.

</details>


### [32] [Quantenlogische Systeme und Tensorproduktraeume](https://arxiv.org/abs/2601.04880)
*Tobias Starke*

Main category: quant-ph

TL;DR: The paper provides a detailed logical construction and proof showing that composed quantum systems must be described using tensor product spaces, based on Mackey's axiomatic system and extending Aerts and Daubechies' work.


<details>
  <summary>Details</summary>
Motivation: To provide an intuitive construction of Mackey's quantum logical axiomatic system and demonstrate how composed physical systems from classical and quantum mechanics should be described logically, specifically extending the results from Aerts and Daubechies' work on physical justification for using tensor products.

Method: Uses Mackey's quantum logical axiomatic system, discusses a special class of axiomatically defined composed physical systems, and employs results from lattice theory and c-morphism theory to construct detailed proofs about system composition.

Result: Presents a detailed proof that in quantum mechanics, a composed physical system must be described via a tensor product space, establishing the logical necessity of this mathematical structure for quantum system composition.

Conclusion: The work successfully demonstrates the logical foundations for using tensor products in quantum mechanics, providing rigorous justification for this mathematical description of composed quantum systems based on axiomatic principles.

Abstract: In this work we present an intuitive construction of the quantum logical axiomatic system provided by George Mackey. The goal of this work is a detailed discussion of the results from the paper 'Physical justification for using the tensor product to describe two quantum systems as one joint system' [1] published by Diederik Aerts and Ingrid Daubechies. This means that we want to show how certain composed physical systems from classical and quantum mechanics should be described logically. To reach this goal, we will, like in [1], discuss a special class of axiomatically defined composed physical systems. With the help of certain results from lattice and c-morphism theory (see [2] and [23]), we will present a detailed proof of the statement, that in the quantum mechanical case, a composed physical system must be described via a tensor product space.

</details>


### [33] [Virtual temperatures as a key quantifier for passive states in quantum thermodynamic processes](https://arxiv.org/abs/2601.04905)
*Sachin Sonkar,Ramandeep S. Johal*

Main category: quant-ph

TL;DR: Virtual temperatures of passive quantum states analyzed via majorization theory, revealing their role in heat flow direction and quantum Otto engine efficiency bounds.


<details>
  <summary>Details</summary>
Motivation: To establish virtual temperature as a key operational quantity linking passivity and majorization to optimal performance of quantum thermal machines, and to draw parallels between quantum and classical thermodynamic processes.

Method: Majorization theory applied to passive quantum states; definition of mean temperature over virtual temperatures of adjacent energy levels; characterization of intermediate passive states in quantum Otto engine; derivation of efficiency bounds in terms of min-max virtual temperatures; explicit analysis of coupled-spins system.

Result: Virtual temperatures determine heat flow direction between system and environment via majorization relations; upper bound for Otto efficiency expressed in terms of min-max virtual temperatures; coupled-spins example demonstrates practical application; parallels drawn between quantum and classical thermodynamic processes.

Conclusion: Virtual temperature emerges as fundamental operational quantity connecting passivity, majorization, and optimal performance in quantum thermal machines, providing theoretical framework for analyzing quantum thermodynamic processes.

Abstract: We analyze the role of virtual temperatures for passive quantum states through the lens of majorization theory. A mean temperature over the virtual temperatures of adjacent energy levels is defined to compare the passive states of the system resulting from isoenergetic and isoentropic transformations. The role of the minimum and the maximum (min-max) values of the virtual temperatures in determining the direction of heat flow between the system and the environment is argued based on majorization relations. We characterize the intermediate passive states in a quantum Otto engine using these virtual temperatures and derive an upper bound for the Otto efficiency that can be expressed in terms of the min-max virtual temperatures of the working medium. An explicit example of the coupled-spins system is worked out. Moreover, virtual temperatures serve to draw interesting parallels between the quantum thermodynamic processes and their classical counterparts. Thus, virtual temperature emerges as a key operational quantity linking passivity and majorization to the optimal performance of quantum thermal machines.

</details>


### [34] [High-Rate Free-Running Reference-Frame-Independent Measurement-Device-Independent Quantum Key Distribution with Classified Distillation](https://arxiv.org/abs/2601.04949)
*Xin Liu,Zhicheng Luo,Kaibiao Qin,Jiawang Liu,Zhenrong Zhang,Kejin Wei*

Main category: quant-ph

TL;DR: A free-running RFI-MDI-QKD protocol that maintains high key rates under rapid reference-frame variations using a classification-distillation method, achieving 9x higher key rates and tolerating >24 dB channel loss.


<details>
  <summary>Details</summary>
Motivation: Existing RFI-MDI-QKD implementations assume fixed or slowly drifting reference-frame misalignment, which is unrealistic outside laboratory settings. Rapid, free-running reference-frame variations in real-world environments severely degrade key rates and transmission distances of conventional RFI-MDI-QKD.

Method: Proposes a free-running RFI-MDI-QKD protocol that introduces a classification-distillation method to reclassify total detection events, enabling secure key extraction without modifying the experimental setup.

Result: Achieves a key rate more than nine times higher than the best previous RFI-MDI-QKD scheme and tolerates channel losses exceeding 24 dB, where earlier approaches fail.

Conclusion: The protocol enables practical quantum key distribution on mobile platforms, including satellite-to-ground links and airborne nodes, by overcoming limitations of conventional RFI-MDI-QKD in realistic environments with rapid reference-frame variations.

Abstract: Reference-frame-independent measurement-device-independent quantum key distribution (RFI-MDI-QKD) eliminates detector side-channel attacks and avoids reference-frame calibration. While its feasibility has been widely demonstrated, existing implementations typically assume fixed or slowly drifting reference-frame misalignment, conditions rarely satisfied outside the laboratory. In realistic environments, rapid and free-running reference-frame variations can severely degrade both the key rate and transmission distance of conventional RFI-MDI-QKD. Here we propose a free-running RFI-MDI-QKD protocol that maintains high-rate key generation under rapid reference-frame variations. By introducing a classification-distillation method that reclassifies total detection events, secure keys can be extracted without modifying the experimental setup. Our protocol achieves a key rate more than nine times higher than the best previous RFI-MDI-QKD scheme and tolerates channel losses exceeding 24 dB, where earlier approaches fail. These results enable practical quantum key distribution on mobile platforms, including satellite-to-ground links and airborne nodes.

</details>


### [35] [Fast, high-fidelity Transmon readout with intrinsic Purcell protection via nonperturbative cross-Kerr coupling](https://arxiv.org/abs/2601.04975)
*Guillaume Beaulieu,Jun-Zhe Chen,Marco Scigliuzzo,Othmane Benhayoune-Khadraoui,Alex A. Chapple,Peter A. Spring,Alexandre Blais,Pasquale Scarlino*

Main category: quant-ph

TL;DR: Junction readout architecture achieves fast, high-fidelity qubit measurement using hybrid capacitive-Josephson coupling for strong cross-Kerr interaction without transverse coupling, enabling bifurcation-based readout with 99.4% assignment fidelity in 68 ns.


<details>
  <summary>Details</summary>
Motivation: Dispersive readout of superconducting qubits suffers from Purcell decay and measurement-induced state transitions, limiting speed and fidelity compared to single- and two-qubit gates. Current approaches require Purcell filters and near-quantum-limited amplifiers, adding hardware complexity.

Method: Junction readout architecture couples a transmon qubit to its readout resonator through both a capacitance and a Josephson junction, creating a strong qubit-resonator cross-Kerr interaction without transverse coupling. This hybrid coupling provides intrinsic Purcell protection and enhanced resilience to measurement-induced state transitions. The nonlinear coupling is exploited to engineer large Kerr nonlinearity in the resonator, enabling bifurcation-based readout.

Result: Achieved 99.4% assignment fidelity with 68 ns integration time and 98.4% QND fidelity without requiring external Purcell filter or near-quantum-limited amplifier. The architecture enables readout at high photon numbers with intrinsic Purcell protection.

Conclusion: Junction readout with bifurcation-based readout represents a scalable and practical alternative to dispersive readout, enabling fast, high-fidelity qubit measurement with reduced hardware overhead, addressing current limitations in superconducting qubit readout systems.

Abstract: Dispersive readout of superconducting qubits relies on a transverse capacitive coupling that hybridizes the qubit with the readout resonator, subjecting the qubit to Purcell decay and measurement-induced state transitions (MIST). Despite the widespread use of Purcell filters to suppress qubit decay and near-quantum-limited amplifiers, dispersive readout often lags behind single- and two-qubit gates in both speed and fidelity. Here, we experimentally demonstrate junction readout, a simple readout architecture that realizes a strong qubit-resonator cross-Kerr interaction without relying on a transverse coupling. This interaction is achieved by coupling a transmon qubit to its readout resonator through both a capacitance and a Josephson junction. By varying the qubit frequency, we show that this hybrid coupling provides intrinsic Purcell protection and enhanced resilience to MIST, enabling readout at high photon numbers. While junction readout is compatible with conventional linear measurement, in this work we exploit the nonlinear coupling to intentionally engineer a large Kerr nonlinearity in the resonator, enabling bifurcation-based readout. Using this approach, we achieve a 99.4 % assignment fidelity with a 68 ns integration time and a 98.4 % QND fidelity without an external Purcell filter or a near-quantum-limited amplifier. These results establish the junction readout architecture with bifurcation-based readout as a scalable and practical alternative to dispersive readout, enabling fast, high-fidelity qubit measurement with reduced hardware overhead.

</details>


### [36] [Machine learning-aided direct estimation of coherence and entanglement for unknown states](https://arxiv.org/abs/2601.04976)
*Ting Lin,Zhihua Chen,Kai Wu,Zhihua Guo,Zhihao Ma,Shao-Ming Fei*

Main category: quant-ph

TL;DR: Machine learning approach using support vector regression to estimate quantum coherence and entanglement measures with minimal experimental resources, requiring only diagonal entries and traces of density matrices.


<details>
  <summary>Details</summary>
Motivation: Efficient estimation of quantum coherence and entanglement for unknown states remains challenging in high-dimensional systems, with quantum state tomography being resource-intensive. There's a need for methods that use minimal experimental resources while maintaining accuracy.

Method: Uses support vector regression (SVR) to directly estimate coherence measures and geometric measure of entanglement. Requires only diagonal entries of density matrix plus traces of squared and cubed density matrices for coherence, and additionally traces of squared and cubed reduced density matrix for entanglement. These quantities can be obtained via random measurements or hybrid quantum-classical framework. Support vector quantile regression with pinball loss prevents SVR overestimation.

Result: Significantly reduces resource overhead compared to quantum state tomography while maintaining high accuracy. SVQR ensures over 95% of predictions are conservative lower bounds in most cases, with lower-bound reliability maintained for over 93% of predictions despite 2% perturbations in input features.

Conclusion: The technique provides a practical and scalable tool for characterizing quantum resources across computation, communication, and metrology applications, offering efficient resource estimation with minimal experimental requirements.

Abstract: Quantum coherence and entanglement are fundamental resources in quantum technologies, yet their efficient estimation for unknown states by employing minimal resources in experimental settings remains challenging, particularly in high-dimensional systems. We present a machine learning approach based on support vector regression (SVR) that directly estimates the coherence measures and the geometric measure of quantum entanglement using minimal experimental resources. Our method requires only the diagonal entries of the density matrix, along with the traces of the squared and cubed density matrices for quantum coherence, and additionally along with the traces of the squared and cubed reduced density matrix for estimating quantum entanglement. These quantities can be obtained through random measurements or a hybrid quantum-classical framework. This approach significantly reduces the resource overhead compared to quantum state tomography while maintaining high accuracy. {Furthermore, the support vector quantile regression (SVQR) with pinball loss is employed to prevent SVR overestimation. This model not only ensures that over 95\% of predictions are conservative lower bounds in most cases, but also maintains this lower-bound reliability for over 93\% of predictions, despite 2\% perturbations in the input features.} The proposed technique provides a practical and scalable tool for characterizing quantum resources across computation, communication, and metrology applications.

</details>


### [37] [Signatures of Spin Coherence in Chiral Coupled Quantum Dots](https://arxiv.org/abs/2601.04981)
*Hanna T. Fridman,Rotem Malkinson,Amir Hen,Shira Yochelis,Yossi Paltiel,Nir Bar-gill*

Main category: quant-ph

TL;DR: Chiral quantum dot assemblies show spin-dependent photoluminescence lifetime modulation via CISS effect, demonstrating quantum coherence at room temperature.


<details>
  <summary>Details</summary>
Motivation: While chiral-induced spin selectivity (CISS) enables spin selectivity in chiral molecular systems without magnets, its quantum coherence properties remain unexplored despite extensive investigation of spin selectivity.

Method: Investigated spin-dependent photoluminescence dynamics in multilayer quantum-dot assemblies coupled by chiral linkers using circularly polarized excitation with external magnetic field, measuring PL lifetime modulation dependent on magnetic field magnitude and geometry.

Result: Observed pronounced PL lifetime modulation with magnetic field dependence; lifetime difference between left- and right-circularly polarized excitations shows field-angle dependence consistent with spin precession driven by transverse magnetic-field component relative to chiral axis; model incorporating coupled spin precession and decay processes reproduces experimental trends.

Conclusion: Establishes chiral QD assemblies as a room-temperature platform for probing quantum coherent manifestations of the CISS effect, with implications for spintronic and quantum technologies.

Abstract: Chiral-induced spin selectivity (CISS) enables spin selectivity of charge carriers in chiral molecular systems without magnetic materials. While spin selectivity has been widely investigated, its quantum coherence has not yet been explored. Here, we investigate spin-dependent photoluminescence (PL) dynamics in multilayer quantum-dot (QD) assemblies coupled by chiral linkers. Using circularly polarized excitation in the presence of an external magnetic field, we observe a pronounced modulation of the PL lifetime that depends on the magnetic field magnitude and geometry. The lifetime difference between left- and right-circularly polarized excitations exhibits a field-angle dependence, consistent with spin precession driven by the transverse magnetic-field component relative to the chiral axis. A model incorporating coupled spin precession and decay processes reproduces the experimental trends. These results establish chiral QD assemblies as a room-temperature platform for probing quantum coherent manifestations of the CISS effect, with implications for spintronic and quantum technologies.

</details>


### [38] [Quantum Neural Network Training and Inference with Low Resolution Control Electronics](https://arxiv.org/abs/2601.04983)
*Rupayan Bhattacharjee,Sergi Abadal,Carmen G. Almudever,Eduard Alarcon*

Main category: quant-ph

TL;DR: QNNs maintain near-perfect accuracy with 6-bit DACs, but training requires stochastic methods to overcome gradient deadlock below 12-bit resolution.


<details>
  <summary>Details</summary>
Motivation: Scaling quantum computers requires cryogenic control electronics with severe power/area constraints, necessitating investigation of DAC resolution limits for quantum neural networks.

Method: Investigate QNN training/inference under finite DAC resolution constraints; introduce temperature-controlled stochasticity for probabilistic parameter updates to overcome gradient deadlock.

Result: Pre-trained QNNs achieve near-infinite-precision accuracy with 6-bit DACs (elbow curve at 4 bits). Training requires stochastic methods below 12-bit resolution, enabling successful training at 4-10 bits matching/exceeding baseline performance.

Conclusion: Low-resolution control electronics need not compromise QML performance, enabling significant power/area reduction in cryogenic control systems for practical quantum hardware scaling.

Abstract: Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales.

</details>


### [39] [Encoding complex-balanced thermalization in quantum circuits](https://arxiv.org/abs/2601.04998)
*Yiting Mao,Peigeng Zhong,Haiqing Lin,Xiaoqun Wang,Shijie Hu*

Main category: quant-ph

TL;DR: Protocol for implementing complex-balanced thermalization via Markovian processes on quantum-circuit platform using engineered reservoir qubits, enabling non-uniform heating and amplification-dissipation dynamics for out-of-equilibrium states at finite temperatures.


<details>
  <summary>Details</summary>
Motivation: To develop a new approach for realizing out-of-equilibrium quantum states at given temperatures, overcoming limitations of conventional thermal reservoirs in achieving phenomena like temporally-correlated dichromatic emission and quantum synchronization at finite temperatures.

Method: Quantum-circuit platform coupling system with engineered reservoir qubits, leveraging non-orthogonality of qubit eigenstates to facilitate non-uniform heating through modified Kubo-Martin-Schwinger relation, while supporting amplification-dissipation dynamics by violating microscopic time-reversibility.

Result: Demonstrated two applications: temporally-correlated dichromatic emission and Liouvillian exceptional point protected quantum synchronization at finite temperatures, both challenging to achieve with conventional thermal reservoirs.

Conclusion: The proposed protocol offers a novel platform for implementing complex-balanced thermalization and realizing out-of-equilibrium quantum phenomena at finite temperatures using engineered reservoir qubits in quantum-circuit architectures.

Abstract: We propose a protocol for effectively implementing complex-balanced thermalization via Markovian processes on a quantum-circuit platform that couples the system with engineered reservoir qubits. The non-orthogonality of qubit eigenstates facilitates non-uniform heating through a modified Kubo-Martin-Schwinger relation, while simultaneously supports amplification-dissipation dynamics by violating microscopic time-reversibility. This offers a new approach to realizing out-of-equilibrium states at given temperatures. We show two applications of this platform: temporally-correlated dichromatic emission and Liouvillian exception point protected quantum synchronization at finite temperatures, both of which are challenging to achieve with conventional thermal reservoirs.

</details>


### [40] [Landau Zener Interaction Enhanced Quantum Sensing in Spin Defects of Hexagonal Boron Nitride](https://arxiv.org/abs/2601.05013)
*Mohammad Abdullah Sadi,Tiamike Dudley,Luca Basso,Thomas Poirier,James H. Edgar,Jacob Henshaw,Peter A. Bermel,Yong P. Chen,Andrew Mounce*

Main category: quant-ph

TL;DR: Frequency-ramped microwave pulses via FPGA achieve 4x better spin-state population transfer than resonant excitation for boron vacancy defects in hBN, enabling 16x faster quantum sensing.


<details>
  <summary>Details</summary>
Motivation: Boron vacancies in hBN are promising quantum sensors but suffer from broad hyperfine-split spin transitions that limit spectral coverage with conventional resonant excitation, even in isotopically enriched materials.

Method: Implemented frequency-ramped microwave pulses using FPGA-based frequency modulation, analyzed quantum dynamics with simulations incorporating Landau-Zener model and relaxations.

Result: Frequency-ramped pulses achieved ~4x greater spin-state population transfer (|0⟩→|-1⟩) and contrast than resonant excitation, enabling 16x shorter measurement time for spin relaxation-based quantum sensing.

Conclusion: The FPGA-implemented frequency-ramping approach is robust and valuable for quantum relaxometry with spin defects in hBN, particularly in noisy environments where spectral broadening is problematic.

Abstract: Negatively charged boron vacancies (V$_{\text{B}}^{-}$) in hexagonal boron nitride (hBN) comprise a promising quantum sensing platform, optically addressable at room temperature and transferrable onto samples. However, broad hyperfine-split spin transitions of the ensemble pose challenges for quantum sensing with conventional resonant excitation due to limited spectral coverage. While isotopically enriched hBN using $^{10}$B and $^{15}$N isotopes (h$^{10}$B$^{15}$N) exhibits sharper spectral features, significant inhomogeneous broadening persists. We demonstrate that, implemented via frequency modulation on an FPGA, a frequency-ramped microwave pulse achieves around 4-fold greater $|0\rangle\rightarrow|-1\rangle$ spin-state population transfer and thus contrast than resonant microwave excitation and thus 16-fold shorter measurement time for spin relaxation based quantum sensing. Quantum dynamics simulations reveal that an effective two-state Landau-Zener model captures the complex relationship between population inversion and pulse length with relaxations incorporated. Our approach is robust and valuable for quantum relaxometry with spin defects in hBN in noisy environments.

</details>


### [41] [Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs](https://arxiv.org/abs/2601.05036)
*Milan Liepelt,Julien Baglio*

Main category: quant-ph

TL;DR: Quantum generative adversarial networks (QGANs) show exponential advantage in capacity scaling for image generation when using hybrid latent style-based architecture with quantum generators, requiring far fewer parameters than classical counterparts for comparable performance.


<details>
  <summary>Details</summary>
Motivation: While QGANs have shown promise in various applications with potential parameter efficiency advantages over classical models, this advantage has never been systematically studied or quantified, leaving an important research gap in understanding quantum generative modeling's practical benefits.

Method: The study uses a hybrid latent style-based QGAN architecture: a classical variational autoencoder encodes input data into latent space, then a style-based quantum generator creates data. Comprehensive experimental analysis on SAT4 image generation with careful autoencoder tuning to ensure stable, reliable results.

Result: When training is stable with low, stable FID scores, the optimal capacity (number of trainable parameters) of both classical discriminator and classical generator scales exponentially with respect to the capacity of the quantum generator, demonstrating exponential advantage in capacity scaling.

Conclusion: The exponential scaling advantage in capacity requirements provides evidence for a type of quantum advantage in quantum generative modeling, where quantum generators can achieve comparable performance with far fewer parameters than classical counterparts.

Abstract: Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.

</details>


### [42] [Anomaly to Resource: The Mpemba Effect in Quantum Thermometry](https://arxiv.org/abs/2601.05046)
*Pritam Chattopadhyay,Jonas F. G. Santos,Avijit Misra*

Main category: quant-ph

TL;DR: The paper demonstrates that the Mpemba effect (hotter states relaxing faster) can enhance quantum thermometry by transiently boosting the quantum Fisher information for temperature estimation, enabling faster and more sensitive nonequilibrium sensing protocols.


<details>
  <summary>Details</summary>
Motivation: Current quantum thermometry strategies rely on equilibrium probes, which have intrinsic limitations: sensitivity requires long thermalization times and cannot be improved in fast, noisy, or nonstationary settings. The Mpemba effect has been viewed as a thermodynamic anomaly rather than a practical resource.

Method: The authors prove that Mpemba-type inversions generically yield finite-time enhancement of quantum Fisher information (QFI) for temperature estimation. They provide explicit analyses of two-level and Λ-level probes coupled to bosonic baths to demonstrate the metrological Mpemba effect.

Result: Nonequilibrium initializations can transiently outperform both equilibrium strategies and colder states, realizing a "metrological Mpemba effect." This converts anomalous relaxation into a concrete metrological resource for temperature estimation.

Conclusion: Anomalous relaxation (Mpemba effect) serves as a general design principle for nonequilibrium quantum thermometry, enabling ultrafast and nanoscale sensing protocols that exploit transient dynamics rather than avoiding them.

Abstract: Quantum thermometry provides a key capability for nanoscale devices and quantum technologies, but most existing strategies rely on probes initialized near equilibrium. This equilibrium paradigm imposes intrinsic limitations: sensitivity is tied to long-time thermalization and often cannot be improved in fast, noisy, or nonstationary settings. In contrast, the \textit{Mpemba effect}, the counterintuitive phenomenon where hotter states relax faster than colder ones, has mostly been viewed as a thermodynamic anomaly. Here, we bridge this gap by proving that Mpemba-type inversions generically yield a finite-time enhancement of the quantum Fisher information (QFI) for temperature estimation, thereby converting an anomalous relaxation effect into a concrete metrological resource. Through explicit analyses of two-level and $Λ$-level probes coupled to bosonic baths, we show that nonequilibrium initializations can transiently outperform both equilibrium strategies and colder states, realizing a \emph{metrological Mpemba effect}. Our results establish anomalous relaxation as a general design principle for nonequilibrium quantum thermometry, enabling ultrafast and nanoscale sensing protocols that exploit, rather than avoid, transient dynamics.

</details>


### [43] [Preconditioned Multivariate Quantum Solution Extraction](https://arxiv.org/abs/2601.05077)
*Gumaro Rendon,Stepan Smid*

Main category: quant-ph

TL;DR: Quantum algorithm for extracting smooth positive functions from quantum state amplitudes with Heisenberg-limit scaling, overcoming limitations of previous methods for PDE solutions.


<details>
  <summary>Details</summary>
Motivation: Quantum computers offer polynomial speed-ups for solving PDEs, but existing methods only prepare quantum states encoding solutions. Extracting explicit solution properties via amplitude estimation diminishes speed-up advantages, creating a need for efficient function extraction techniques.

Method: Technique samples cumulative distribution of encoded function, fits with Chebyshev polynomials, and extracts complete function representation. Key improvements: supports higher-dimensional functions, reduces quantum complexity with respect to encoding qubits, and removes dependency on function minimum via preconditioning.

Result: Achieves Heisenberg-limit scaling for extracting smooth positive functions from quantum state amplitudes. Method validated through small-scale numerical simulations demonstrating improved efficiency over previous approaches.

Conclusion: Proposed technique enables efficient extraction of PDE solutions from quantum states while preserving quantum speed-up advantages, addressing a critical bottleneck in quantum PDE algorithms.

Abstract: Numerically solving partial differential equations is a ubiquitous computational task with broad applications in many fields of science. Quantum computers can potentially provide high-degree polynomial speed-ups for solving PDEs, however many algorithms simply end with preparing the quantum state encoding the solution in its amplitudes. Trying to access explicit properties of the solution naively with quantum amplitude estimation can subsequently diminish the potential speed-up. In this work, we present a technique for extracting a smooth positive function encoded in the amplitudes of a quantum state, which achieves the Heisenberg limit scaling. We improve upon previous methods by allowing higher dimensional functions, by significantly reducing the quantum complexity with respect to the number of qubits encoding the function, and by removing the dependency on the minimum of the function using preconditioning. Our technique works by sampling the cumulative distribution of the given function, fitting it with Chebyshev polynomials, and subsequently extracting a representation of the whole encoded function. Finally, we trial our method by carrying out small scale numerical simulations.

</details>


### [44] [Unitary fault-tolerant encoding of Pauli states in surface codes](https://arxiv.org/abs/2601.05113)
*Luis Colmenarez,Remmy Zen,Jan Olle,Florian Marquardt,Markus Müller*

Main category: quant-ph

TL;DR: A unitary, scalable encoding scheme for preparing Pauli eigenstates in surface codes that preserves code distance protection, uses only local gates compatible with 2D connectivity, and outperforms measurement-based approaches.


<details>
  <summary>Details</summary>
Motivation: State preparation is critical for fault-tolerant quantum computation, but existing methods face challenges. Unitary approaches often fail to preserve fault-distance scaling with code distance, while measurement-based schemes are costly for platforms where measurements are expensive relative to gates.

Method: Generalizes reinforcement-learned strategies from surface-17 code to arbitrary distances and both rotated/unrotated surface codes. Uses only geometrically local gates compatible with planar 2D connectivity. Designs explicit stabilizer-expanding circuits with and without ancilla-mediated connectivity, achieving O(d) circuit depth consistent with entanglement-generation bounds.

Result: Numerical simulations under depolarizing noise show unitary encoding without ancillas outperforms standard stabilizer-measurement-based schemes, reducing logical error rates by up to an order of magnitude. The scheme preserves code distance protection during state preparation.

Conclusion: The work bridges measurement-based and unitary encodings for surface-code states, enabling distance-preserving state preparation particularly beneficial for platforms like trapped ions and neutral atoms where measurements are costly and idling noise is weak relative to gate noise.

Abstract: In fault-tolerant quantum computation, the preparation of logical states is a ubiquitous subroutine, yet significant challenges persist even for the simplest states required. In the present work, we present a unitary, scalable, distance-preserving encoding scheme for preparing Pauli eigenstates in surface codes. Unlike previous unitary approaches whose fault-distance remains constant with increasing code distance, our scheme ensures that the protection offered by the code is preserved during state preparation. Building on strategies discovered by reinforcement learning for the surface-17 code, we generalize the construction to arbitrary code distances and both rotated and unrotated surface codes. The proposed encoding relies only on geometrically local gates, and is therefore fully compatible with planar 2D qubit connectivity, and it achieves circuit depth scaling as $\mathcal{O}(d)$, consistent with fundamental entanglement-generation bounds. We design explicit stabilizer-expanding circuits with and without ancilla-mediated connectivity and analyze their error-propagation behavior. Numerical simulations under depolarizing noise show that our unitary encoding without ancillas outperforms standard stabilizer-measurement-based schemes, reducing logical error rates by up to an order of magnitude. These results make the scheme particularly relevant for platforms such as trapped ions and neutral atoms, where measurements are costly relative to gates and idling noise is considerably weaker than gate noise. Our work bridges the gap between measurement-based and unitary encodings of surface-code states and opens new directions for distance-preserving state preparation in fault-tolerant quantum computation.

</details>


### [45] [Scalable Generation of Macroscopic Fock States Exceeding 10,000 Photons](https://arxiv.org/abs/2601.05118)
*Ming Li,Weizhou Cai,Ziyue Hua,Yifang Xu,Yilong Zhou,Zi-Jie Chen,Xu-Bo Zou,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: A Kerr-engineered multi-lens protocol generates macroscopic Fock states with over 10,000 photons using quantum-optical duality, achieving high fidelity and scaling inversely with photon number.


<details>
  <summary>Details</summary>
Motivation: Scalable preparation of bosonic quantum states with macroscopic excitations is fundamentally challenging due to control complexity and photon-loss rates, limiting prior efforts to merely dozens of excitations per mode.

Method: Based on the duality between quantum state evolution in Fock space and optical wave-function propagation in waveguide arrays, the authors introduce a Kerr-engineered multi-lens protocol in a single bosonic mode. The approach optimizes phase and displacement operations across lens groups to compensate for non-paraxial aberrations.

Result: The protocol deterministically generates Fock states exceeding 10,000 photons, achieving fidelities above 73% in numerical simulations for photon numbers up to N=100,000. Counterintuitively, execution time scales as N^{-1/2} with target photon number N, exhibiting robustness against photon loss.

Conclusion: The framework enables exploration of quantum-to-classical transitions of giant Fock states, paving the way for advanced quantum metrology with significant quantum gains and error-corrected quantum information processing in high-dimensional Hilbert spaces.

Abstract: The scalable preparation of bosonic quantum states with macroscopic excitations poses a fundamental challenge in quantum technologies, limited by control complexity and photon-loss rates that severely constrain prior theoretical and experimental efforts to merely dozens of excitations per mode. Here, based on the duality of the quantum state evolution in Fock state space and the optical wave-function propagation in a waveguide array, we introduce a Kerr-engineered multi-lens protocol in a single bosonic mode to deterministically generate Fock states exceeding $10,000$ photons. By optimizing phase and displacement operations across lens groups, our approach compensates for non-paraxial aberrations, achieving fidelities above $73\%$ in numerical simulations for photon numbers up to $N=100,000$. Counterintuitively, the protocol's execution time scales as $N^{-1/2}$ with the target photon number $N$, exhibiting robustness against the photon loss. Our framework enables exploration of quantum-to-classical transitions of giant Fock states, paving the way for advanced quantum metrology with significant quantum gains, and error-corrected quantum information processing in high-dimensional Hilbert spaces.

</details>


### [46] [Simulation of noisy quantum circuits using frame representations](https://arxiv.org/abs/2601.05131)
*Janek Denzler,Jose Carrasco,Jens Eisert,Tommaso Guaita*

Main category: quant-ph

TL;DR: A unified frame theory framework for classical simulation of quantum circuits that generalizes existing methods, provides quantitative cost measures, and enables discovery of new simulation algorithms with improved performance.


<details>
  <summary>Details</summary>
Motivation: To understand the precise boundaries between classical simulability and quantum advantage for noisy quantum circuits, and to develop a comprehensive framework that unifies and extends existing classical simulation strategies.

Method: Introduces a frame theory-based framework where simulation algorithms are associated with quasi-probability distributions, with computational cost measured by the one-norm. Uses convex optimization tools to explore different frame choices, enabling both analysis of existing methods (stabilizer simulation, Pauli back-propagation) and discovery of new approaches.

Result: Developed a unified framework that encompasses existing simulation strategies, provides common quantitative measures, yields new insights and improved bounds for existing methods, and discovers a new simulation approach based on generalized Pauli frames with improved performance.

Conclusion: Frame theory provides a powerful perspective beyond traditional quantum resource classification for classical simulation, enabling systematic development of improved algorithms and better understanding of quantum-classical boundaries.

Abstract: One of the core research questions in the theory of quantum computing is to find out to what precise extent the classical simulation of a noisy quantum circuits is possible and where potential quantum advantages can set in. In this work, we introduce a unified framework for the classical simulation of quantum circuits based on frame theory, encompassing and generalizing a broad class of existing simulation strategies. Within this framework, the computational cost of a simulation algorithm is determined by the one-norm of an associated quasi-probability distribution, providing a common quantitative measure across different simulation approaches. This enables a comprehensive perspective on common methods for the simulation of noisy circuits based on different quantum resources, such as entanglement or non-stabilizerness. It further provides a clear scheme for generating novel classical simulation algorithms. Indeed, by exploring different choices of frames within this formalism and resorting to tools of convex optimization, we are able not only to obtain new insights and improved bounds for existing methods -- such as stabilizer state simulation or Pauli back-propagation -- but also to discover a new approach with an improved performance based on a generalization of the Pauli frame. We, thereby, show that classical simulation techniques can directly benefit from a perspective -- that of frames -- that goes beyond the traditional classification of quantum resources.

</details>


### [47] [Composable simultaneous purification: when all communication scenarios reduce to spatial correlations](https://arxiv.org/abs/2601.05158)
*Matilde Baroni,Dominik Leichtle,Ivan Šupić,Damian Markham,Marco Túlio Quintino*

Main category: quant-ph

TL;DR: The paper extends simultaneous purification results to multipartite communication scenarios, showing that compositions of non-signalling assemblages cannot exceed standard Bell correlations, requiring signalling assemblages for correlations beyond that set.


<details>
  <summary>Details</summary>
Motivation: To extend simultaneous purification results from bipartite to multipartite communication scenarios, since many quantum features are genuinely multipartite and cannot be reduced to two-party behavior.

Method: Unify and extend simultaneous purification from states to instruments and super-instruments (composable structures), then analyze arbitrary compositions of non-signalling assemblages in multipartite communication schemes.

Result: Arbitrary compositions of non-signalling assemblages cannot exceed the standard spatial quantum Bell correlations set. Correlations outside this set require at least one signalling assemblage of quantum operations, even when resulting correlations are non-signalling.

Conclusion: The simultaneous purification framework restricts multipartite communication scenarios to standard Bell correlations unless signalling assemblages are involved, establishing fundamental limits on quantum correlations achievable through non-signalling compositions.

Abstract: Bell non-locality is a powerful framework to distinguish classical, quantum and post-quantum resources, which relies on non-communicating players. Under which restriction can we have the same separations, if we allow for communication? Non-signalling state assemblages, and the fact that they can always be simultaneously purified, turned out to be the key element to restrict the simplest bipartite communication scenario, the prepare-and-measure, to the standard bipartite Bell scenario. Yet, many distinctive features of quantum theory are genuinely multipartite and cannot be reduced to two-party behaviour. In this work we are interested in extending this simultaneous purification inspired result to all multipartite communication schemes. As a first step, we unify and extend the simultaneous purification result from states to instruments and super-instruments, which are composable structures, and open up the possibility to explore more complex communication scenarios. Our main contribution is to establish that arbitrary compositions of non-signalling assemblages cannot escape the standard spatial quantum Bell correlations set. As a consequence, any interactive quantum realization of correlations outside of this set must involve at least one signalling assemblage of quantum operations, even when the resulting correlations are non-signalling.

</details>


### [48] [Quantum Elastic Network Models and their Application to Graphene](https://arxiv.org/abs/2601.05161)
*Ioannis Kolotouros,Adithya Sireesh,Stuart Ferguson,Sean Thrasher,Petros Wallden,Julien Michel*

Main category: quant-ph

TL;DR: Quantum algorithm enables exponential speedup for simulating macroscopic-scale elastic network models of materials using ~160 logical qubits, demonstrated on centimeter-scale graphene sheets.


<details>
  <summary>Details</summary>
Motivation: Classical molecular dynamics simulations of materials at atomic resolution on macroscopic scales are computationally infeasible, even with simplified elastic network models, due to memory requirements (hundreds of petabytes) and prohibitive runtimes.

Method: Introduce Quantum Elastic Network Models (QENMs) using Babbush et al.'s quantum algorithm (PRX, 2023) that provides exponential advantage for simulating coupled oscillators under specific conditions. Apply to planar materials like graphene, analyzing complexity for initial-state preparation, Hamiltonian simulation, and measurement.

Result: Demonstrate efficient simulation of 2D graphene sheets, estimating that centimeter-scale atomistic simulations requiring hundreds of petabytes classically can be encoded with ~160 logical qubits. Provide applications to heat transfer and out-of-plane rippling effects.

Conclusion: QENMs enable quantum simulation of macroscopic-scale materials with atomic resolution using modest quantum resources, overcoming classical computational limitations for materials design applications.

Abstract: Molecular dynamics simulations are a central computational methodology in materials design for relating atomic composition to mechanical properties. However, simulating materials with atomic-level resolution on a macroscopic scale is infeasible on current classical hardware, even when using the simplest elastic network models (ENMs) that represent molecular vibrations as a network of coupled oscillators. To address this issue, we introduce Quantum Elastic Network Models (QENMs) and utilize the quantum algorithm of Babbush et al. (PRX, 2023), which offers an exponential advantage when simulating systems of coupled oscillators under some specific conditions and assumptions. Here, we demonstrate how our method enables the efficient simulation of planar materials. As an example, we apply our algorithm to the task of simulating a 2D graphene sheet. We analyze the exact complexity for initial-state preparation, Hamiltonian simulation, and measurement of this material, and provide two real-world applications: heat transfer and the out-of-plane rippling effect. We estimate that an atomistic simulation of a graphene sheet on the centimeter scale, classically requiring hundreds of petabytes of memory and prohibitive runtimes, could be encoded and simulated with as few as $\sim 160$ logical qubits.

</details>


### [49] [Fast convergence of Majorana Propagation for weakly interacting fermions](https://arxiv.org/abs/2601.05226)
*Giorgio Facelli,Hamza Fawzi,Omar Fawzi*

Main category: quant-ph

TL;DR: Majorana Propagation algorithm efficiently finds low-degree approximations for time-evolved observables in Hamiltonian evolution, with provable guarantees and applications to sparse quartic Hamiltonians.


<details>
  <summary>Details</summary>
Motivation: Simulating time dynamics under Hamiltonian evolution is a promising path to quantum advantage, but classical algorithms are only efficient in restricted settings. The paper aims to provide the first provable guarantee for the Majorana Propagation algorithm in such settings.

Method: Majorana Propagation combines Trotter steps and truncations to efficiently find low-degree approximations of time-evolved observables when such approximations exist. The algorithm's runtime scales as N^O(log(t/ε)) for time horizons t ≤ t_max(u).

Result: The paper proves that Majorana Propagation can efficiently simulate time dynamics of any sparse quartic Hamiltonian up to time t_max(u) depending on interaction strength u. In the small u limit, t_max(u) → ∞, showing the algorithm is accurate at all times for quadratic Hamiltonians.

Conclusion: Majorana Propagation provides the first provable guarantee for efficient classical simulation of Hamiltonian evolution in restricted settings, bridging the gap between quadratic and quartic Hamiltonians and offering insights into when quantum advantage might be achievable.

Abstract: Simulating the time dynamics of an observable under Hamiltonian evolution is one of the most promising candidates for quantum advantage as we do not expect efficient classical algorithms for this problem except in restricted settings. Here, we introduce such a setting by showing that Majorana Propagation, a simple algorithm combining Trotter steps and truncations, efficiently finds a low-degree approximation of the time-evolved observable as soon as such an approximation exists. This provides the first provable guarantee about Majorana Propagation for Hamiltonian evolution. As an application of this result, we prove that Majorana Propagation can efficiently simulate the time dynamics of any sparse quartic Hamiltonian up to time $t_{\text{max}}(u)$ depending on the interaction strength $u$. For a time horizon $t \leq t_{\text{max}}(u)$, the runtime of the algorithm is $N^{O(\log(t/\varepsilon))}$ where $N$ is the number of Majorana modes and $\varepsilon$ is the error measured in the normalized Frobenius norm. Importantly, in the limit of small $u$, $t_{\text{max}}(u)$ goes to $+\infty$, formalizing the intuition that the algorithm is accurate at all times when the Hamiltonian is quadratic.

</details>


### [50] [Scalable Suppression of XY Crosstalk by Pulse-Level Control in Superconducting Quantum Processors](https://arxiv.org/abs/2601.05231)
*Hui-Hang Chen,Chiao-Hsuan Wang*

Main category: quant-ph

TL;DR: A scalable pulse-level control framework using frequency modulation and dynamical decoupling to suppress XY crosstalk errors in dense superconducting quantum processors, enabling high-fidelity operation without requiring hardware-level frequency separation.


<details>
  <summary>Details</summary>
Motivation: As superconducting quantum processors scale, crosstalk errors from unwanted XY interactions between nearby qubits limit operational performance. Hardware-level frequency detuning becomes constrained by frequency crowding in large-scale systems, creating a need for control-level solutions to suppress residual XY coupling during single-qubit operations.

Method: Proposes a scalable pulse-level control framework combining frequency modulation (FM) and dynamical decoupling (DD) to suppress XY crosstalk errors. The framework operates independently of coupling strengths, reduces calibration overhead, and naturally supports multi-qubit connectivity without requiring hardware modifications.

Result: Numerical simulations demonstrate orders-of-magnitude reductions in infidelity for both idle and single-qubit gates in a two-qubit system. Scalability is validated in a five-qubit layout where crosstalk between a central qubit and four neighbors is simultaneously suppressed.

Conclusion: The crosstalk suppression framework provides a practical route toward high-fidelity operation in dense superconducting architectures by addressing XY coupling challenges at the control level rather than relying solely on hardware-level frequency separation.

Abstract: As superconducting quantum processors continue to scale, high-performance quantum control becomes increasingly critical. In densely integrated architectures, unwanted interactions between nearby qubits give rise to crosstalk errors that limit operational performance. In particular, direct exchange-type (XY) interactions are typically minimized by designing large frequency detunings between neighboring qubits at the hardware level. However, frequency crowding in large-scale systems ultimately restricts the achievable frequency separation. While such XY coupling facilitates entangling gate operations, its residual presence poses a key challenge during single-qubit controls. Here, we propose a scalable pulse-level control framework, incorporating frequency modulation (FM) and dynamical decoupling (DD), to suppress XY crosstalk errors. This framework operates independently of coupling strengths, reducing calibration overhead and naturally supporting multi-qubit connectivity. Numerical simulations show orders-of-magnitude reductions in infidelity for both idle and single-qubit gates in a two-qubit system. We further validate scalability in a five-qubit layout, where crosstalk between a central qubit and four neighbors is simultaneously suppressed. Our crosstalk suppression framework provides a practical route toward high-fidelity operation in dense superconducting architectures.

</details>
