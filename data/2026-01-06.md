<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 5]
- [quant-ph](#quant-ph) [Total: 68]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Disordered Dynamics in High Dimensions: Connections to Random Matrices and Machine Learning](https://arxiv.org/abs/2601.01010)
*Blake Bordelon,Cengiz Pehlevan*

Main category: cond-mat.dis-nn

TL;DR: Review of dynamical mean field theory (DMFT) for high-dimensional random matrix systems, with applications to machine learning models including gradient flow, random feature models, and deep linear networks, analyzing training dynamics, bias-variance decompositions, and non-monotonic loss behaviors.


<details>
  <summary>Details</summary>
Motivation: To provide a unified framework for analyzing high-dimensional dynamical systems driven by random matrices in machine learning contexts, particularly for understanding learning and generalization dynamics in modern ML models where traditional methods are insufficient.

Method: Uses dynamical mean field theory (DMFT) with cavity method arguments and path integrals to characterize infinite-dimensional coupled systems as single-site stochastic processes, focusing on two-time correlation and response functions, with applications to linear time-invariant systems, random matrix resolvents, and various ML training algorithms.

Result: Demonstrates how DMFT enables computation of bias-variance decompositions through averaging over noise variables, reveals that non-Hermitian random matrices (like in random feature models) can exhibit non-monotonic loss curves unlike Hermitian matrices with matching spectra, and provides asymptotic descriptions of training/test loss dynamics for deep linear networks in feature learning regimes.

Conclusion: DMFT provides a powerful, flexible framework for analyzing high-dimensional random matrix systems in machine learning, offering insights into training dynamics, generalization behavior, and novel phenomena like non-monotonic loss curves that arise from non-Hermitian matrix structure rather than small eigenvalue instabilities.

Abstract: We provide an overview of high dimensional dynamical systems driven by random matrices, focusing on applications to simple models of learning and generalization in machine learning theory. Using both cavity method arguments and path integrals, we review how the behavior of a coupled infinite dimensional system can be characterized as a stochastic process for each single site of the system. We provide a pedagogical treatment of dynamical mean field theory (DMFT), a framework that can be flexibly applied to these settings. The DMFT single site stochastic process is fully characterized by a set of (two-time) correlation and response functions. For linear time-invariant systems, we illustrate connections between random matrix resolvents and the DMFT response. We demonstrate applications of these ideas to machine learning models such as gradient flow, stochastic gradient descent on random feature models and deep linear networks in the feature learning regime trained on random data. We demonstrate how bias and variance decompositions (analysis of ensembling/bagging etc) can be computed by averaging over subsets of the DMFT noise variables. From our formalism we also investigate how linear systems driven with random non-Hermitian matrices (such as random feature models) can exhibit non-monotonic loss curves with training time, while Hermitian matrices with the matching spectra do not, highlighting a different mechanism for non-monotonicity than small eigenvalues causing instability to label noise. Lastly, we provide asymptotic descriptions of the training and test loss dynamics for randomly initialized deep linear neural networks trained in the feature learning regime with high-dimensional random data. In this case, the time translation invariance structure is lost and the hidden layer weights are characterized as spiked random matrices.

</details>


### [2] [Hopping transport regimes and dimensionality transition: a unified Monte Carlo Random Resistor Network approach](https://arxiv.org/abs/2601.01243)
*Alejandro Toral-Lopez,Damiano Marian,Gianluca Fiori*

Main category: cond-mat.dis-nn

TL;DR: A Monte Carlo Random Resistor Network simulator is developed to model hopping transport in disordered materials, capturing both Variable Range Hopping and Nearest Neighbor Hopping regimes and their temperature-dependent transition.


<details>
  <summary>Details</summary>
Motivation: Hopping transport in disordered materials (organic semiconductors, perovskites, nitride alloys, 2D material inks) exhibits two main regimes (Variable Range Hopping and Nearest Neighbor Hopping) with temperature-dependent transitions, but modeling of this transition remains insufficiently explored and not fully understood.

Method: Development of an in-house Monte Carlo Random Resistor Network-based simulator that can capture both hopping transport regimes. The simulator models material properties defining the network: localization length, spatial and energetic distribution of sites.

Result: The simulator successfully captures both hopping transport regimes and their transition, accurately reproducing 1D, 2D, and 3D variable range hopping behavior. It has been validated against experimental data with excellent agreement, showing how material properties determine the dominant transport regime.

Conclusion: The Monte Carlo Random Resistor Network simulator provides both a theoretical framework for interpreting hopping transport experiments and a powerful computational tool for studying transport mechanisms in disordered materials, bridging the gap between insufficiently explored transition modeling and experimental observations.

Abstract: Hopping transport, characterized by carrier tunneling between localized states, is a key mechanism in disordered materials such as organic semiconductors, perovskites, nitride alloys, and 2D material-based inks. Two main regimes are typically observed: Variable Range Hopping and Nearest Neighbor Hopping, with a transition between them upon temperature variation. Despite numerous experimental observations, the modeling of this transition remain insufficiently explored and not fully understood. In this work, we present an in-house Monte Carlo Random Resistor Network-based simulator capable of capturing both hopping transport regimes. We demonstrate how material properties that define the network, such as localization length and the spatial and energetic distribution of sites, determine the dominant transport regime. The simulator has been successfully validated against experimental data, showing excellent agreement, reproducing the transition from one regime to the other and accurately capturing 1D, 2D and 3D variable range hopping behavior, providing both a theoretical framework for interpreting experiments and a powerful tool for studying transport mechanisms.

</details>


### [3] [Simulating diffusion and disorder-induced localization in random walks and transmission lines](https://arxiv.org/abs/2601.01381)
*Jake S. Bobowski*

Main category: cond-mat.dis-nn

TL;DR: Two complementary simulations explore Anderson localization: one uses classical random walk to model disorder-limited transport, and another uses electromagnetic pulse propagation in a disordered transmission line to demonstrate wave interference effects.


<details>
  <summary>Details</summary>
Motivation: To provide accessible instructional tools for investigating Anderson localization phenomena by building intuition through complementary approaches that bridge classical and wave-based perspectives.

Method: Two simulation approaches: 1) Classical random walk of non-interacting point particles to model disorder-limited transport, and 2) Electromagnetic pulse propagation through a 1D lossless transmission line with randomly varying propagation constant and characteristic impedance to capture interference effects.

Result: Quantitative measures reveal transition from normal diffusion to particle localization in the classical case, and exponential confinement of wave energy in the electromagnetic case, demonstrating both manifestations of Anderson localization.

Conclusion: The two complementary simulations provide accessible instructional tools for exploring localization phenomena, bridging classical transport limitations with wave interference effects that characterize true Anderson localization.

Abstract: We present two complementary simulations that lead to an exploration of Anderson localization, a phenomenon in which wave diffusion is suppressed in disordered media by interference from multiple scattering. To build intuition, the first models the random walk of classical, non-interacting point-like particles, providing a clear analogy to the way disorder can limit transport. The second examines the propagation of an electromagnetic pulse through a one-dimensional, lossless transmission line with randomly varying propagation constant and characteristic impedance along its length, a system that captures the interference effects essential for true Anderson localization. We evaluate quantitative measures that reveal the transition from normal diffusion to localization of particles in one case, and the exponential confinement of wave energy in the other. Together, these simulations offer a pair of accessible tools for investigating localization phenomena in an instructional setting.

</details>


### [4] [Exact Mobility Edges in a Disorder-Free Dimerized Stark Lattice with Effective Unbounded Hopping](https://arxiv.org/abs/2601.02259)
*Yunyao Qi,Heng Lin,Quanfeng Lu,Dong Ruan,Gui-Lu Long*

Main category: cond-mat.dis-nn

TL;DR: A disorder-free 1D single-particle Hamiltonian with exact mobility edge is proposed, using linear Stark potential on one sublattice of dimerized chain to create unbounded staggered hopping, evading no-go theorems.


<details>
  <summary>Details</summary>
Motivation: To construct a disorder-free system with exact mobility edge that circumvents existing no-go theorems (Simon-Spencer theorem and constraints on Jacobi matrices) regarding unbounded potentials.

Method: Apply linear Stark potential selectively to one sublattice of dimerized chain, generating effective Hamiltonian with unbounded, staggered hopping amplitudes. Analytically derive bulk spectrum in reciprocal space and perform finite-size scaling of inverse participation ratio up to L∼10^9.

Result: Identified sharp mobility edge where energy magnitude equals inter-cell hopping strength, separating extended continuum from two localized branches: standard unbounded Wannier-Stark ladder and anomalous bounded branch accumulating at mobility edge. Extended states confirmed by finite-size scaling. Experimental realization proposed using photonic frequency synthetic dimensions with robustness against imperfections.

Conclusion: Demonstrated disorder-free Hamiltonian with exact mobility edge by exploiting unbounded staggered hopping to evade no-go theorems, providing practical path for experimental observation in photonic systems.

Abstract: We propose a disorder-free one-dimensional single-particle Hamiltonian hosting an exact mobility edge (ME), placing the system outside the assumptions of no-go theorems regarding unbounded potentials. By applying a linear Stark potential selectively to one sublattice of a dimerized chain, we generate an effective Hamiltonian with unbounded, staggered hopping amplitudes. The unbounded nature of the hopping places the model outside the scope of the Simon-Spencer theorem, while the staggered scaling allows it to evade broader constraints on Jacobi matrices. We analytically derive the bulk spectrum in reciprocal space, identifying a sharp ME where the energy magnitude equals the inter-cell hopping strength. This edge separates a continuum of extended states from two distinct localized branches: a standard unbounded Wannier-Stark ladder and an anomalous bounded branch accumulating at the ME. The existence of extended states is supported by finite-size scaling of the inverse participation ratio up to system sizes $L \sim 10^9$. Furthermore, we propose an experimental realization using photonic frequency synthetic dimensions. Our numerical results indicate that the ME is robust against potential experimental imperfections, including frequency detuning errors and photon loss, establishing a practical path for observing MEs in disorder-free systems.

</details>


### [5] [Strong Disorder Renormalization Group Method for Bond Disordered Antiferromagnetic Quantum Spin Chains with Long Range Interactions: Excited States and Finite Temperature Properties](https://arxiv.org/abs/2509.17828)
*Stefan Kettemann*

Main category: cond-mat.dis-nn

TL;DR: Extension of strong disorder renormalization group method to study excited states and finite temperature properties of disordered antiferromagnetic quantum spin chains with power law interactions.


<details>
  <summary>Details</summary>
Motivation: To extend the recently developed strong disorder renormalization group method from ground state analysis to study excited states and finite temperature properties of disordered quantum spin chains with power law interactions.

Method: Extends the strong disorder renormalization group method in real space to excited states and finite temperature. Applies it to: 1) short-range coupled spin chains (keeping only adjacent spin interactions), 2) power law long-range interactions between all spins with exponent α. Derives Master equation for the long-range case.

Result: For short-range case: coupling magnitude distribution follows infinite randomness fixed point, but sign becomes distributed with increasing negative couplings at higher T. For long-range case: coupling amplitude follows strong disorder distribution with finite width 2α (with small corrections for α>2). Derives finite temperature properties including magnetic susceptibility, concurrence, and entanglement entropy for both systems.

Conclusion: The extended strong disorder renormalization group method successfully captures finite temperature and excited state properties of disordered quantum spin chains with power law interactions, revealing important differences in coupling distributions between short-range and long-range cases.

Abstract: We extend the recently introduced strong disorder renormalization group method in real space, well suited to study bond disordered antiferromagnetic power law coupled quantum spin chains, to study excited states, and finite temperature properties. First, we apply it to a short range coupled spin chain, which is defined by the model with power law interaction, keeping only interactions between adjacent spins. We show that the distribution of the absolute value of the couplings is the infinite randomness fixed point distribution. However, the sign of the couplings becomes distributed, and the number of negative couplings increases with temperature $T.$ Next, we derive the Master equation for the power law long range interaction between all spins with power exponent $α$. While the sign of the couplings is found to be distributed, the distribution of the coupling amplitude is given by the strong disorder distribution with finite width $2α,$ with small corrections for $α>2$. Resulting finite temperature properties of both short and power law long ranged spin systems are derived, including the magnetic susceptibility, concurrence and entanglement entropy.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [6] [Evidence for a two-dimensional quantum glass state at high temperatures](https://arxiv.org/abs/2601.01309)
*Aleksey Lunkin,Nicole S. Ticea,Shashwat Kumar,Connie Miao,Jaehong Choi,Mohammed Alghadeer,Ilya Drozdov,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Alexandre Bourassa,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. Graaf,Alejandro Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Cody Jones,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Dvir Kafri,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Julian Kelly,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joonho Lee,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Ming Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Laura Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Gabrielle Roberts,Roberto Rodriguez,Emma Ropes,Lucia B. Rose,Eliott Rosenberg,Emma Rosenfeld,Dario Rosenstock,Elizabeth Rossi,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Kevin J. Satzinger,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Vladimir Shvarts,Volodymyr Sivak,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Sergio Boixo,Hartmut Neven,Vadim Smelyanskiy,Trond I. Andersen,Pedram Roushan,Mikhail V. Feigelman,Lev B. Ioffe*

Main category: quant-ph

TL;DR: Experimental observation of a finite-temperature quantum glass transition in a 2D superconducting qubit array, showing an intermediate non-ergodic regime with glass-like characteristics between ergodic and localized phases.


<details>
  <summary>Details</summary>
Motivation: To resolve debates about the existence and nature of ergodic-non-ergodic transitions in disordered quantum many-body systems, particularly in two dimensions at finite temperature.

Method: Used a two-dimensional array of superconducting qubits to implement an interacting spin model in a disordered landscape, tracking dynamics in both real space and Hilbert space at finite temperature.

Result: Observed an intermediate non-ergodic regime with glass-like characteristics: broad distribution of physical observables, partial freezing of degrees of freedom, slow power-law decay in Hilbert-space return probability, onset of finite Edwards-Anderson order parameter, and disappearance of spin diffusion.

Conclusion: There exists a transition out of the ergodic phase in two-dimensional systems, characterized by finite-temperature quantum glassiness with distinct signatures in both real-space and Hilbert-space dynamics.

Abstract: Disorder in quantum many-body systems can drive transitions between ergodic and non-ergodic phases, yet the nature--and even the existence--of these transitions remains intensely debated. Using a two-dimensional array of superconducting qubits, we study an interacting spin model at finite temperature in a disordered landscape, tracking dynamics both in real space and in Hilbert space. Over a broad disorder range, we observe an intermediate non-ergodic regime with glass-like characteristics: physical observables become broadly distributed and some, but not all, degrees of freedom are effectively frozen. The Hilbert-space return probability shows slow power-law decay, consistent with finite-temperature quantum glassiness. In the same regime, we detect the onset of a finite Edwards-Anderson order parameter and the disappearance of spin diffusion. By contrast, at lower disorder, spin transport persists with a nonzero diffusion coefficient. Our results show that there is a transition out of the ergodic phase in two-dimensional systems.

</details>


### [7] [Bond Additivity and Persistent Geometric Imprints of Entanglement in Quantum Thermalization](https://arxiv.org/abs/2601.01327)
*Chun-Yue Zhang,Shi-Xin Zhang,Zi-Xiang Li*

Main category: quant-ph

TL;DR: Multi-bipartition entanglement tomography framework reveals geometric structure of entanglement through bond-additive law and entanglement bond tensions, distinguishing Hamiltonian thermalization from random circuit/Floquet dynamics.


<details>
  <summary>Details</summary>
Motivation: Standard entanglement measures obscure geometric details in quantum many-body systems, creating a need for frameworks that can characterize the intricate structure of entanglement across different bipartitions.

Method: Introduces multi-bipartition entanglement tomography framework that probes entanglement across exhaustive ensemble of distinct bipartitions. Key discovery is bond-additive law: entanglement entropy decomposes into bulk volume-law baseline plus geometric correction from sum of local contributions from crossed bonds of varying ranges, distilled into entanglement bond tensions {ω_j}.

Result: Reveals fundamental distinction between thermalization mechanisms: Hamiltonian thermalized states retain persistent geometric imprint with significantly non-zero ω₁, while this structure is completely erased in random quantum circuit and Floquet dynamics.

Conclusion: Establishes multi-bipartition entanglement tomography as versatile toolbox for analyzing geometric structure of quantum information in many-body systems, providing quantitative fingerprint of interaction locality through entanglement bond tensions.

Abstract: Characterizing the intricate structure of entanglement in quantum many-body systems remains a central challenge, as standard measures often obscure underlying geometric details. In this Letter, we introduce a powerful framework, termed multi-bipartition entanglement tomography, which probes the fine structure of entanglement across an exhaustive ensemble of distinct bipartitions. Our cornerstone is the discovery of a ``bond-additive law'', which reveals that the entanglement entropy can be precisely decomposed into a bulk volume-law baseline plus a geometric correction formed by a sum of local contributions from crossed bonds of varying ranges. This law distills complex entanglement landscapes into a concise set of entanglement bond tensions $\{ω_j\}$, serving as a quantitative fingerprint of interaction locality. By applying this tomography to Hamiltonian dynamics, random quantum circuits, and Floquet dynamics, we resolve a fundamental distinction between thermalization mechanisms: Hamiltonian thermalized states retain a persistent geometric imprint characterized by a significantly non-zero $ω_1$, while this structure is completely erased in random quantum circuit and Floquet dynamics. Our work establishes multi-bipartition entanglement tomography as a versatile toolbox for the geometric structure of quantum information in many-body systems.

</details>


### [8] [Sample Complexity for Embedded Multipartite Entanglement Witness via Pauli and Clifford Classical Shadows](https://arxiv.org/abs/2601.00859)
*Ziran Zhang*

Main category: quant-ph

TL;DR: The paper analyzes sample complexity for estimating n-partite entanglement witnesses in N-qubit systems using classical shadows, showing different scaling behaviors for local vs. global witnesses.


<details>
  <summary>Details</summary>
Motivation: Multipartite entanglement detection in many-qubit systems requires extensive measurements, motivating protocols that efficiently estimate selected observables with provable efficiency guarantees.

Method: Uses the classical shadow protocol to study sample complexity for estimating subsystem n-partite entanglement witnesses in larger N-qubit systems, deriving ensemble-dependent variance bounds and performing numerical simulations.

Result: Derived variance bounds lead to qualitatively distinct scaling for snapshot cost at fixed additive error ε, with numerical simulations confirming a clear crossover from Pauli-favorable performance for local witnesses to Clifford-favorable performance as witnesses become more global.

Conclusion: The classical shadow protocol exhibits different optimal measurement strategies depending on witness locality: Pauli measurements are efficient for local entanglement witnesses, while Clifford measurements become favorable for more global witnesses.

Abstract: Detecting multipartite entanglement in many qubit systems is measurement-intensive, motivating protocols that estimate only selected observables with provable efficiency. In this work we use the classical shadow protocol to study the sample complexity required to estimate a family of subsystem $n$-partite entanglement witness embedded in an larger $N$-qubit system. We derive ensemble dependent variance bounds that lead to qualitatively distinct scaling for the snapshots cost at fixed additive error $ε$ with numerical simulations confirm these trends, exhibiting a clear crossover from Pauli favorable performance for local witness to Clifford favorable performance as the witness becomes more global.

</details>


### [9] [The Quantum State Continuity Problem and Temporal Enforcement Against Fork Attacks](https://arxiv.org/abs/2601.00870)
*Samet Ünsal*

Main category: quant-ph

TL;DR: The paper introduces Quantum State Continuity Problem (QSCP) as a new security objective for ensuring execution continuity, shows classical/quantum authentication fails against fork attacks, proposes Quantum State Continuity Witness (QSCW) primitive using stateful quantum evolution, and demonstrates exponential suppression of fork attacks via GHZ-based instantiation and simulations.


<details>
  <summary>Details</summary>
Motivation: Current authentication mechanisms (both classical and stateless quantum) fail to enforce execution continuity, leaving systems vulnerable to fork attacks where an adversary can create unauthorized parallel executions. There's a need for security mechanisms that ensure temporal linkage between current and past executions as a distinct security dimension orthogonal to identity authentication.

Method: Proposes Quantum State Continuity Witness (QSCW), a minimal quantum-assisted primitive that enforces temporal linkage through stateful quantum evolution and cumulative auditing. Uses a GHZ-based toy instantiation for proof-of-concept and conducts extensive simulations to evaluate performance under various conditions including noise and system parameters.

Result: Temporal enforcement through QSCW suppresses fork attacks with exponential decay in success probability. The approach remains robust to noise and system parameter variations. Demonstrates that execution continuity can be effectively enforced as a distinct security dimension using quantum-assisted mechanisms.

Conclusion: Execution continuity represents a distinct and underexplored dimension of system security that cannot be addressed by traditional authentication mechanisms. The proposed Quantum State Continuity Witness provides a viable quantum-assisted solution that enforces temporal linkage and effectively mitigates fork attacks through stateful quantum evolution.

Abstract: We introduce the Quantum State Continuity Problem (QSCP), a security objective orthogonal to identity authentication that captures whether a systems current execution is a legitimate continuation of a unique past execution. We show that classical and stateless quantum authentication mechanisms fail to enforce continuity and remain vulnerable to fork attacks. To address this gap, we propose the Quantum State Continuity Witness (QSCW), a minimal quantum-assisted primitive that enforces temporal linkage of execution through stateful quantum evolution and cumulative auditing. Using a GHZ-based toy instantiation and extensive simulation, we demonstrate that temporal enforcement suppresses fork attacks with exponential decay in success probability, while remaining robust to noise and system parameters. Our results highlight execution continuity as a distinct and underexplored dimension of system security.

</details>


### [10] [Entanglement dynamics of multi-fluxonium-qubits under Non-Markovian TLS noise](https://arxiv.org/abs/2601.00884)
*Chenghong Ji,Chaoying Zhao*

Main category: quant-ph

TL;DR: Proposes a TLS-tailored dynamical decoupling protocol for Fluxonium qubits to suppress non-Markovian two-level system noise by optimizing pulse locations to minimize overlap with Lorentzian noise spectrum, improving entanglement gate fidelity.


<details>
  <summary>Details</summary>
Motivation: Traditional dynamic decoupling fails to effectively suppress non-Markovian TLS noise in Fluxonium qubits due to its low-frequency concentration, requiring specialized protocols to improve entanglement gate fidelity in NISQ devices.

Method: Develops a novel DD sequence based on Ornstein-Uhlenbeck process, optimizes pulse locations to minimize noise power spectral overlap with Lorentzian shape, and uses PMME-consistent framework for modeling non-Markovian TLS noise dynamics.

Result: Achieves stronger low-frequency suppression, significantly prolongs both Bell-based fidelity and entanglement, and effectively improves entanglement gates fidelity in NISQ quantum devices.

Conclusion: The TLS-tailored dynamical decoupling protocol provides an effective solution for suppressing non-Markovian noise in Fluxonium qubits, enhancing entanglement gate performance for practical quantum computing applications.

Abstract: The research on open quantum systems is important for both quantum computing and quantum sensing. So far, we can only use the main equation to make an approximate description. The dynamics of a single Fluxonium qubit under Markovian environment satisfied Lindblad Master Equation. In experiments, pulse sequence dynamic decoupling (DD) can enhance the coherence of qubits and effectively suppress noise. Two Fluxonium qubits sensitive to two-level systems (TLS) noise. TLS formed by material defects results in noise with significant non-Markovian characteristics. The dynamics of non-Markovian noise satisfied the post Markov Master Equation (PMME). The TLS noise spectrum is mainly concentrated in low frequencies, so traditional DD cannot effectively suppress TLS noise. The relaxation and dephasing behavior with a complex dynamic characteristics. Based on Ornstein-Uhlenbeck process, we put forward a novel DD sequence and design a TLS-tailored dynamical decoupling protocol by optimizing pulse locations to minimize noise power spectral overlap with the Lorentzian shape. Using PMME-consistent framework, we can obtain a stronger low frequency suppression and significantly prolong both Bell-based fidelity and entanglement. We explore specific DD design and precise modeling of entanglement dynamics under non-Markovian TLS noise. Our dynamical decoupling protocol can effectively improve entanglement gates fidelity in NISQ quantum devices.

</details>


### [11] [Four-Photon Interference with a High-Efficiency Quantum Dot Source](https://arxiv.org/abs/2601.00966)
*Alistair J. Brash,Luke Brunswick,Mark R. Hogg,Catherine L. Phillips,Malwina A. Marczak,Timon L. Baltisberger,Sascha R. Valentin,Arne Ludwig,Richard J. Warburton*

Main category: quant-ph

TL;DR: Researchers demonstrate high-visibility quantum interference of up to four photons from a quantum dot source using deterministic demultiplexing, achieving 93% visibility for two photons and 84% for four photons, revealing "deep fringes" robust to photon distinguishability and showing potential for quantum metrology applications beyond the standard quantum limit.


<details>
  <summary>Details</summary>
Motivation: Current quantum dot sources have been limited to two-photon interference due to efficiency constraints, but many optical quantum technologies require generation and manipulation of larger photonic states. There's a need to scale quantum interference beyond two photons for practical quantum applications.

Method: Combined a state-of-the-art quantum dot single-photon source with deterministic demultiplexing to enable observation of quantum interference fringes from up to four photons. Used a theoretical model to analyze the complex fringe structure and performed Fisher information analysis to assess phase sensitivity.

Result: Achieved high mean interference contrasts: 93.0 ± 0.1% for two photons and 84.1 ± 1.0% for four photons. Observed "deep fringes" whose minima remain unaffected by distinguishable photons, making four-photon interference highly sensitive to multi-photon emission but robust against photon distinguishability. Demonstrated phase sensitivity beyond the standard quantum limit.

Conclusion: The work successfully scales quantum interference beyond two photons using quantum dot sources, revealing fundamental properties of multi-photon interference and demonstrating potential for quantum metrology applications. The phenomena are predicted to extend to larger photon numbers, with relevance across various optical quantum technologies.

Abstract: While two-photon Hong-Ou-Mandel interference visibility has become a standard metric for single-photon sources, many optical quantum technologies require the generation and manipulation of larger photonic states. To date, efficiency limitations have prevented scaling quantum dot-based interference to the coalescence of more than two photons at a single beamsplitter. We overcome this limitation by combining a state-of-the-art quantum dot source with deterministic demultiplexing, enabling the direct observation of quantum interference fringes arising from up to four photons. We measure high mean interference contrasts of $93.0 \pm 0.1~\%$ for two photons, and $84.1 \pm 1.0~\%$ for four photons, with the complex fringe structure fully reproduced by a theoretical model. These results reveal the existence of "deep fringes" whose minima are unaffected by distinguishable photons, rendering the maximum contrast of four-photon interference highly sensitive to multi-photon emission but robust against photon distinguishability. We predict that these phenomena will extend to interference of larger numbers of photons, with relevance across a range of potential optical quantum technologies. A Fisher information analysis demonstrates that interference fringes from our source can exhibit phase sensitivity beyond the standard quantum limit, illustrating potential applications in quantum metrology.

</details>


### [12] [Impersonating Quantum Secrets over Classical Channels](https://arxiv.org/abs/2601.01058)
*Luowen Qian,Mark Zhandry*

Main category: quant-ph

TL;DR: Eavesdropping on classical communication between entangled quantum parties enables impersonation attacks; one-way puzzles are necessary for reusable authentication with quantum pre-shared secrets; quantum money verified via classical queries cannot be information-theoretically secure.


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish fundamental limitations in quantum cryptography: understanding security requirements for authentication with quantum pre-shared secrets, and determining necessary conditions for information-theoretically secure quantum money schemes.

Method: The authors demonstrate a simple eavesdropping attack on classical communication between potentially entangled quantum parties, showing it enables impersonation. They prove this attack is efficient if one-way puzzles don't exist. For quantum money, they generalize prior work by showing any scheme verifiable through only classical queries to any oracle cannot be information-theoretically secure.

Result: One-way puzzles are implied by reusable authentication schemes over classical channels with quantum pre-shared secrets. Quantum money schemes verifiable through only classical queries to any oracle cannot achieve information-theoretical security, significantly generalizing prior results limited to random oracles.

Conclusion: Reusable authentication with quantum pre-shared secrets requires one-way puzzles, and information-theoretically secure quantum money must involve coherent evaluation of underlying cryptographic tools rather than just classical queries, posing challenges for near-term quantum devices.

Abstract: We show that a simple eavesdropper listening in on classical communication between potentially entangled quantum parties will eventually be able to impersonate any of the parties. Furthermore, the attack is efficient if one-way puzzles do not exist. As a direct consequence, one-way puzzles are implied by reusable authentication schemes over classical channels with quantum pre-shared secrets that are potentially evolving.
  As an additional application, we show that any quantum money scheme that can be verified through only classical queries to any oracle cannot be information-theoretically secure. This significantly generalizes the prior work by Ananth, Hu, and Yuen (ASIACRYPT'23) where they showed the same but only for the specific case of random oracles. Therefore, verifying black-box constructions of quantum money inherently requires coherently evaluating the underlying cryptographic tools, which may be difficult for near-term quantum devices.

</details>


### [13] [Molchanov's Formula and Quantum Walks: A Probabilistic Approach](https://arxiv.org/abs/2601.01071)
*Hoang Vu*

Main category: quant-ph

TL;DR: Probabilistic representation of both continuous-time and discrete-time quantum walks using adapted Molchanov formula, enabling classical stochastic analysis of quantum systems.


<details>
  <summary>Details</summary>
Motivation: Establish robust connections between quantum dynamics and classical stochastic processes by developing probabilistic representations for quantum walks, overcoming limitations of traditional unitary evolution approaches.

Method: Adapt Molchanov formula (originally for Schrödinger operators on multidimensional integer lattice) to characterize continuous-time quantum walks; extend framework to develop probabilistic method for discrete-time quantum walks on infinite integer line, bypassing locality constraints.

Result: Successfully derived probabilistic representations for both continuous-time and discrete-time quantum walks; empirical validation through benchmark analysis of Hadamard walk shows high fidelity with traditional unitary evolution.

Conclusion: Probabilistic representation offers powerful alternative for analyzing multidimensional quantum walks and provides new analytical pathways for investigating quantum systems via classical stochastic processes.

Abstract: This paper establishes a robust link between quantum dynamics and classical ones by deriving probabilistic representation for both continuous time and discrete time quantum walks. We first adapt Molchanov formula, originally employed in the study of Schrodinger operators on multidimensional integer lattice, to characterize the evolution of continuous time quantum walks. Extending this framework, we develop a probabilistic method to represent discrete time quantum walks on an infinite integer line, bypassing the locality constraints that typically inhibit direct application of Molchanov formula. The validity of our representation is empirically confirmed through a benchmark analysis of the Hadamard walk, demonstrating high fidelity with traditional unitary evolution. Our results suggest that this probabilistic lens offer a powerful alternative for learning multidimensional quantum walks and provides new analytical pathways for investigating quantum systems via classical stochastic processes.

</details>


### [14] [Single-Step Hybrid CV-DV Transfer of Multipartite W States Using Cat-State Qubits](https://arxiv.org/abs/2601.01078)
*Muhammad Nehal Khan,Sumrah Hussain*

Main category: quant-ph

TL;DR: Deterministic hybrid CV-DV scheme for single-step transfer of n-qubit W states encoded in photonic cat-state qubits within circuit QED, achieving ~0.92 fidelity for 3-qubit transfer.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable method for transferring multipartite entanglement (W states) between continuous-variable (cat-state) and discrete-variable encodings in circuit QED systems, enabling hybrid quantum information processing while suppressing decoherence.

Method: Uses deterministic hybrid CV-DV scheme with cat-state qubits encoded in bosonic modes. A single superconducting flux qutrit mediates effective Raman-type interactions between resonator pairs in dispersive regime. Protocol transfers W state in single collective operation without populating higher atomic levels. Numerical simulations based on full Lindblad master equation include realistic cavity dissipation, qutrit relaxation/dephasing, and inter-cavity crosstalk.

Result: Three-qubit cat-state W state can be transferred with maximum fidelity of approximately 0.92. The protocol strongly suppresses decoherence by avoiding population of higher excited atomic levels.

Conclusion: Demonstrates feasibility of scalable hybrid CV-DV entanglement transfer using current circuit QED technology, enabling efficient multipartite state transfer between different quantum encodings.

Abstract: We propose a deterministic hybrid continuous-variable-discrete-variable (CV-DV) scheme for the single-step transfer of an $n$-qubit W state encoded in photonic Schr$\ddot{o}$dinger cat-state qubits within a circuit QED architecture. Logical qubits are encoded in even- and odd-parity cat states of bosonic modes, while effective Raman-type interactions between resonator pairs are mediated by a single superconducting flux qutrit operating in the dispersive regime. The protocol coherently transfers the multipartite W state in a single collective operation without populating higher excited atomic levels, thereby strongly suppressing decoherence. Numerical simulations based on the full Lindblad master equation, including realistic cavity dissipation, qutrit relaxation and dephasing, and inter-cavity crosstalk, show that a three-qubit cat-state W state can be transferred with a maximum fidelity of approximately $0.92$. These results demonstrate the feasibility of scalable hybrid CV-DV entanglement transfer using current circuit QED technology.

</details>


### [15] [Quantum optimisation applied to the Quadratic Assignment Problem](https://arxiv.org/abs/2601.01104)
*Andrew Freeland,Jingbo Wang*

Main category: quant-ph

TL;DR: NV-QWOA outperforms classical heuristics (MMAS, GLS) and Grover search on small QAP instances, requiring fewer function evaluations and iterations to find optimal/near-optimal solutions, demonstrating quantum walks' potential for combinatorial optimization.


<details>
  <summary>Details</summary>
Motivation: Address limitations of classical exact methods and current quantum algorithms; VQAs like QAOA/VQE suffer from costly parameter tuning and barren plateaus; explore non-variational quantum approaches for potentially more efficient and scalable combinatorial optimization.

Method: Benchmark NV-QWOA against classical heuristics (MaxMin Ant System, Greedy Local Search) and Grover quantum search; evaluate using two metrics: number of objective function evaluations and algorithm iterations required to consistently reach optimal/near-optimal solutions across QAP instances with 5-10 facilities.

Result: NV-QWOA demonstrates superior performance compared to classical heuristics and Grover search, requiring fewer function evaluations and iterations to consistently find optimal or near-optimal solutions for small QAP instances.

Conclusion: Non-variational quantum walk approaches show practical utility for complex combinatorial problems; NV-QWOA provides a foundation for future quantum optimization algorithms and offers a potentially more efficient alternative to variational quantum approaches.

Abstract: This paper investigates the performance of the emerging non-variational Quantum Walk-based Optimisation Algorithm (NV-QWOA) for solving small instances of the Quadratic Assignment Problem (QAP). NV-QWOA is benchmarked against classical heuristics, the MaxMin Ant System (MMAS) and Greedy Local Search (GLS), as well as the Grover quantum search algorithm, which serves as a quantum baseline. Performance is evaluated using two metrics: the number of objective function evaluations and the number of algorithm iterations required to consistently reach optimal or near optimal solutions across QAP instances with 5 to 10 facilities. The motivation for this study stems from limitations of both classical exact methods and current quantum algorithms. Variational Quantum Algorithms (VQAs), such as QAOA and VQE, while widely studied, suffer from costly parameter tuning and barren plateaus that hinder convergence. By adopting a non-variational approach, this work explores a potentially more efficient and scalable quantum strategy for combinatorial optimisation. The results provide a direct comparative analysis between classical and quantum frameworks, characterising the average case performance of NV-QWOA. Our findings highlight the practical utility of quantum walks for complex combinatorial problems and establish a foundation for future quantum optimisation algorithms.

</details>


### [16] [Non-Markovian and Thermodynamic Signatures in the Classicality Assessment via Kolmogorov Consistency](https://arxiv.org/abs/2601.01122)
*Arghya Maity,Ahana Ghoshal,Kelvin Onggadinata,Teck Seng Koh*

Main category: quant-ph

TL;DR: The paper establishes analytical connections between Kolmogorov consistency condition violation and non-Markovianity in open quantum systems, linking KCC violation to information-theoretic and thermodynamic quantities, and revealing correspondences with other temporal quantum non-classicality witnesses.


<details>
  <summary>Details</summary>
Motivation: To understand how the violation of the Kolmogorov consistency condition (which defines the classical-quantum boundary for temporal correlations) relates to non-Markovianity in open quantum dynamics, and to establish quantitative connections between KCC violation and information-theoretic/thermodynamic quantities for a thermodynamic interpretation of temporal quantum correlations.

Method: Using a generic two-level open quantum system framework, the authors establish direct analytical connections between KCC violation magnitude and key quantities including mutual information, Fano factor, heat exchange, and entropy production rate. They also uncover formal correspondences between KCC violation, Leggett-Garg inequality, and negativity of Kirkwood-Dirac quasi-distribution.

Result: The work reveals how memory effects manifest as departures from classical probabilistic consistency, enables thermodynamic interpretation of temporal quantum correlations through quantitative connections, and identifies KCC violation, Leggett-Garg inequality, and Kirkwood-Dirac negativity as complementary witnesses of temporal quantum non-classicality.

Conclusion: The results provide a unified framework linking information-theoretic, thermodynamic, and temporal indicators of quantumness in open quantum systems, establishing KCC violation as a fundamental marker connecting different aspects of quantum non-classicality.

Abstract: The Kolmogorov consistency condition (KCC) defines the statistical boundary between classical and quantum dynamics. Its violation signifies the breakdown of a classical Markov description of temporal correlations. In this work, we establish a direct analytical connection between KCC violation and non-Markovianity in open quantum dynamics, revealing how memory effects manifest as departures from classical probabilistic consistency. Within a generic two-level open quantum system framework, we establish quantitative connections between the magnitude of KCC violation and key information-theoretic and thermodynamic quantities, such as mutual information, the Fano factor, heat exchange, and entropy production rate, thereby enabling a thermodynamic interpretation of temporal quantum correlations. Furthermore, we uncover formal correspondences between KCC violation, the Leggett-Garg inequality, and the negativity of the Kirkwood-Dirac quasi-distribution, identifying them as complementary witnesses of temporal quantum non-classicality. Our results thus provide a unified framework linking information-theoretic, thermodynamic, and temporal indicators of quantumness in open quantum systems.

</details>


### [17] [The Completeness of Eigenstates in Quantum Mechanics](https://arxiv.org/abs/2601.01136)
*Guoping Zhang*

Main category: quant-ph

TL;DR: The paper analyzes completeness of eigenstates in quantum mechanics, categorizing proofs into eight cases based on potential behavior at infinity, providing theoretical proofs/numerical simulations, defining orthonormalization for free states, and establishing spectral functions with physical interpretation.


<details>
  <summary>Details</summary>
Motivation: To systematically address the completeness problem of eigenstates in quantum mechanics, which is fundamental for ensuring that any quantum state can be expanded in terms of a complete set of eigenstates, enabling proper mathematical formulation and physical interpretation of quantum systems.

Method: 1. Classify completeness proofs into eight cases based on potential function behavior at infinity. 2. Provide theoretical proofs or numerical simulations for each case. 3. Define orthonormalization for general free states and solve normalization coefficients. 4. Introduce a general set of initial states to simplify completeness proofs. 5. Define spectral function for continuous energy eigenvalues and use it as integral variable for expansion functions.

Result: 1. Systematic framework for completeness proofs covering eight potential behavior cases. 2. Solutions for normalization coefficients of free states. 3. Simplified proof approach using general initial states. 4. Physical interpretation linking measured probability amplitude to expansion functions via spectral functions, establishing coordinate-momentum transformation relationship.

Conclusion: The paper provides a comprehensive framework for analyzing eigenstate completeness in quantum mechanics, offering systematic classification, mathematical tools for normalization, and physical interpretation through spectral functions that connect mathematical expansions to measurable probability amplitudes.

Abstract: We delineate the scope of research on the completeness of eigenstates in quantum mechanics. Based on the limit of the potential function at infinity, the proof of completeness is divided into eight cases, and theoretical proofs or numerical simulations are provided for each case. We present the definition of orthonormalization for general free states and the solution to the normalization coefficients, as well as a general set of initial states, which simplifies and concretizes the proof of completeness. Additionally, we define the spectral function for continuous energy eigenvalues. By taking the spectral function as the original integral variable of the expansion function, the relationship between the measured probability amplitude and the expansion function is endowed with the physical meaning of coordinate-momentum transformation.

</details>


### [18] [Constant Depth Digital-Analog Counterdiabatic Quantum Computing](https://arxiv.org/abs/2601.01154)
*Balaganchi A. Bhargava,Shubham Kumar,Anne-Maria Visuri,Paolo A. Erdman,Enrique Solano,Narendra N. Hegade*

Main category: quant-ph

TL;DR: Digital-analog quantum computing framework enables constant-depth implementation of counterdiabatic protocols for efficient quantum state preparation on current hardware.


<details>
  <summary>Details</summary>
Motivation: Counterdiabatic protocols suppress diabatic excitations in finite-time adiabatic evolution but face practical limitations: non-local Hamiltonian structure and resource overhead of fully digital implementations.

Method: Express counterdiabatic terms as truncated expansions of nested commutators, then realize this algebraic structure using commutator product formulas in digital-analog setting with native multi-qubit analog interactions augmented by local single-qubit rotations.

Result: Higher-order counterdiabatic protocols can be implemented with constant number of analog blocks for any fixed truncation order, independent of system size; demonstrated for 2D spin models with analysis of approximation errors.

Conclusion: Digital-analog quantum computing enables qualitatively new resource scaling for counterdiabatic protocols and quantum control primitives, with direct implications for quantum simulation, optimization, and algorithmic state preparation on current devices.

Abstract: We introduce a digital-analog quantum computing framework that enables counterdiabatic protocols to be implemented at constant circuit depth, allowing fast and resource-efficient quantum state preparation on current quantum hardware. Counterdiabatic protocols suppress diabatic excitations in finite-time adiabatic evolution, but their practical application is limited by the non-local structure of the required Hamiltonians and the resource overhead of fully digital implementations. Counterdiabatic terms can be expressed as truncated expansions of nested commutators of the adiabatic Hamiltonian and its parametric derivative. Here, we show how this algebraic structure can be efficiently realized in a digital-analog setting using commutator product formulas. Using native multi-qubit analog interactions augmented by local single-qubit rotations, this approach enables higher-order counterdiabatic protocols whose implementation requires a constant number of analog blocks for any fixed truncation order, independent of system size. We demonstrate the method for two-dimensional spin models and analyze the associated approximation errors. These results show that digital-analog quantum computing enables a qualitatively new resource scaling for counterdiabatic protocols and related quantum control primitives, with direct implications for quantum simulation, optimization, and algorithmic state preparation on current quantum devices.

</details>


### [19] [Harnessing Environmental Memory with Reinforcement Learning in Open Quantum Systems](https://arxiv.org/abs/2601.01252)
*Safae Gaidi,Abdallah Slaoui,Mohammed EL Falaki,Amine Jaouadi*

Main category: quant-ph

TL;DR: RL framework learns to amplify non-Markovian memory effects in open quantum systems, outperforming optimal control by generating sustained information backflow over longer durations.


<details>
  <summary>Details</summary>
Motivation: Non-Markovian memory effects in open quantum systems are valuable resources for preserving coherence and enhancing controllability, but exploiting them requires strategies adapted to history-dependent dynamics.

Method: Introduce reinforcement-learning framework using PPO and SAC agents with reward based on positive time derivative of trace distance (Breuer-Laine-Piilo measure). Benchmark against gradient-based optimal control theory (OCT).

Result: RL policies broaden the dominant backflow peak and activate additional contributions in later memory windows, producing sustained positive trace-distance growth over longer duration. Integrated non-Markovianity achieved by RL substantially exceeds OCT results.

Conclusion: Long-horizon, model-free learning naturally uncovers distributed-backflow strategies, highlighting RL's potential for engineering memory effects in open quantum systems.

Abstract: Non-Markovian memory effects in open quantum systems provide valuable resources for preserving coherence and enhancing controllability. However, exploiting them requires strategies adapted to history-dependent dynamics. We introduce a reinforcement-learning framework that autonomously learns to amplify information backflow in a driven two-level system coupled to a structured reservoir. Using a reward based on the positive time derivative of the trace distance associated with the Breuer-Laine-Piilo measure, we train PPO and SAC agents and benchmark their performance against gradient-based optimal control theory (OCT). While OCT enhances a single dominant backflow peak, RL policies broaden this revival and activate additional contributions in later memory windows, producing sustained positive trace-distance growth over a longer duration. Consequently, the integrated non-Markovianity achieved by RL substantially exceeds that obtained with OCT. These results demonstrate how long-horizon, model-free learning naturally uncovers distributed-backflow strategies and highlight the potential of reinforcement learning for engineering memory effects in open quantum systems.

</details>


### [20] [Simulating Wigner Localisation with the IBM Heron 2 Quantum Processor: A Proof-of-Principle Benchmarking Study](https://arxiv.org/abs/2601.01263)
*Airat Kiiamov,Dmitrii Tayurskii*

Main category: quant-ph

TL;DR: Digital quantum simulation of Wigner localization in a quasi-1D electron system using IBM Heron 2 quantum processor, achieving <7% relative error in strong-interaction limit.


<details>
  <summary>Details</summary>
Motivation: To benchmark superconducting quantum hardware by translating foundational experimental models of electron systems into quantum computing domain, providing proof-of-principle validation for simulating strongly correlated phases of matter.

Method: Used 6-qubit segment of IBM Heron 2 quantum processor to map Coulomb interaction Hamiltonian onto 6-qubit ring lattice, reconstructing ground-state energy landscape for 2-electron Wigner dimer across 15 interaction regimes (U ∈ [5, 75]).

Result: Digital simulation accurately captured energy minimization trends associated with Wigner dimer formation, achieving relative error below 7% in strong-interaction limit, demonstrating high-fidelity quantum simulation capabilities.

Conclusion: Provides crucial proof-of-principle validation for using superconducting quantum hardware to probe strongly correlated phases with high precision, establishing baseline for future simulations beyond classical computational limits.

Abstract: We report on a high-fidelity digital quantum simulation of Wigner localisation in a quasi-one-dimensional (quasi-1D) electron system using a 6-qubit segment of the state-of-the-art \textbf{IBM\,Heron\,2} quantum processor. By mapping the Coulomb interaction Hamiltonian onto a 6-qubit ring lattice, we reconstruct the ground-state energy landscape for a 2-electron Wigner dimer across fifteen interaction regimes in the range $U \in [5, 75]$. This study serves as a rigorous \textbf{benchmarking} exercise, translating foundational experimental models originally developed for electrons on liquid helium into the domain of modern quantum computing. Leveraging the enhanced gate fidelity and tunable coupler architecture of the Heron 2, we demonstrate that the digital simulation accurately captures the energy minimisation trends associated with Wigner dimer formation, achieving a relative error below 7\% in the strong-interaction limit. Our results provide a crucial \textbf{proof-of-principle} validation for using superconducting quantum hardware to probe strongly correlated phases of matter with high precision, establishing a baseline for future simulations beyond the classical limit.

</details>


### [21] [Thermodynamic analysis of autonomous quantum systems](https://arxiv.org/abs/2601.01272)
*Tiago F. F. Santos,Camille Latune*

Main category: quant-ph

TL;DR: The paper applies an autonomous quantum thermodynamic framework to experimental quantum systems, revealing work exchange mechanisms (population inversion, coherence generation/consumption, athermality) that traditional frameworks miss, providing refined analysis for realistic quantum devices.


<details>
  <summary>Details</summary>
Motivation: Traditional thermodynamic frameworks associate work with unitary transformations from external controls and heat with bath interactions, but these fail to capture genuine quantum phenomena in autonomous systems without external controls. The authors aim to extend thermodynamic formalism to realistic quantum experimental settings where systems interact directly without external driving.

Method: The paper applies a recently developed autonomous quantum thermodynamic framework to common experimental situations of interacting quantum systems. This framework analyzes energy exchanges in systems free from external controls, identifying work exchange mechanisms through population inversion, coherence generation/consumption, and athermality effects that traditional frameworks would classify as heat.

Result: The autonomous framework reveals work exchanges in situations where traditional frameworks detect only heat: (1) work from population inversion, (2) work from coherence generation/consumption (related to ergotropy), and (3) genuine non-unitary work exchange from athermality. In the semi-classical limit, all energy exchanges are identified as pure work, distinguishing between local work and interaction energy.

Conclusion: The autonomous framework provides a refined analysis of work exchange mechanisms in quantum systems, capturing genuine quantum phenomena missed by traditional approaches. It serves as a consistent approach for analyzing thermodynamic processes in realistic quantum devices and highlights the limitations of traditional thermodynamic frameworks in quantum settings.

Abstract: Traditional quantum thermodynamic frameworks associate work to energy exchanges induced by unitary transformations generated by external controls, and heat to energy exchanges induced by bath interaction. Recently, a framework was introduced aiming at extending the thermodynamic formalism to genuine quantum settings, also referred to as autonomous quantum systems: free from external controls, only quantum systems interacting with each other. In this paper, we apply such a thermodynamic framework to common experimental situations of interacting quantum systems. In situations where traditional frameworks detect only heat exchanges, the recent autonomous thermodynamic framework points at work exchanges based on two mechanisms: population inversion and coherence generation / consumption. Such mechanisms are well known in the literature for being related to work expenditure and extraction, in particular in relation with ergotropy, which emphasizes the relevance of the autonomous framework and the limitations of traditional ones. Furthermore, the autonomous framework also identifies a genuine non-unitary mechanism of work exchange related to athermality. %, also pointed out as a resource for work extraction. Finally, in the semi-classical limit, the autonomous framework identifies all energy exchanges as pure work, but distinguishes between local work and interaction energy.
  Our results show that the autonomous framework provides a refined analysis of work exchange mechanisms in the quantum realm and serves as a consistent approach to analyze thermodynamic processes in realistic quantum devices.

</details>


### [22] [Assessing the entanglement of three coupled harmonic oscillators](https://arxiv.org/abs/2601.01292)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abderrahim El Allati,Abdallah Slaoui*

Main category: quant-ph

TL;DR: Geometrical diagonalization approach with constrained Euler angles enables analytical entanglement analysis for three coupled harmonic oscillators, revealing excitation-enhanced correlation redistribution governed by mixing angle θ.


<details>
  <summary>Details</summary>
Motivation: Quantum entanglement in many-body systems lacks analytical results for coupled three-body oscillators, creating a gap in understanding correlations in such systems.

Method: Introduces geometrical diagonalization approach that constrains Euler angles to reduce degrees of freedom; derives analytical expressions for linear entropy and purity under bipartitions (x|yz), (y|xz), and (xy|z) using Wigner function framework.

Result: Excitations in any oscillator enhance redistribution of correlations; mixing angle θ governs entanglement intensity from separability to maximal correlation; reveals symmetry relations S_Ly[(n,m,l),θ]=S_Lz[(n,m,l),-θ] and intrinsic symmetry within (x|yz).

Conclusion: Clarifies how excitation levels and mixing angles create and enhance entanglement in three coupled harmonic oscillators through analytical framework with constrained geometrical approach.

Abstract: Quantum entanglement serves as a key phenomenon in understanding correlations in many-body systems, but analytical results remain scarce for coupled three-body oscillators. In this work, we address this gap by introducing a geometrical diagonalization approach that constrains Euler angles, thereby reducing the degrees of freedom in the entanglement analysis. It consists of deriving analytical expressions for linear entropy and purity under the bipartitions $(x|yz)$, $(y|xz)$, and $(xy|z)$ using the Wigner function framework. Our results indicate that excitations in any oscillator basically enhance the redistribution of correlations across the system. The mixing angle $θ$ governs entanglement intensity, ranging from separability to maximal correlation. Moreover, we reveal the symmetry relations, notably $S_{Ly}[(n,m,l),θ]=S_{Lz}[(n,m,l),-θ]$ and an intrinsic symmetry within $(x|yz)$. Hence, we clarify how excitation levels and mixing angles create and enhance entanglement in the three coupled harmonic oscillators.

</details>


### [23] [Einstein-Podolsky-Rosen Steering in Three Coupled Harmonic Oscillators](https://arxiv.org/abs/2601.01307)
*Ayoub Ghaba,Radouan Hab Arrih,Elhoussine Atmani,Abdallah Slaoui*

Main category: quant-ph

TL;DR: Analytical study of quantum steering in three coupled harmonic oscillators using geometrical diagonalization and Wigner functions, showing excitations enhance steering while ground state exhibits no steerable correlations.


<details>
  <summary>Details</summary>
Motivation: Quantum steering is crucial for understanding multi-body quantum correlations, but analytical results for coupled three-body oscillators are scarce, motivating this investigation.

Method: Geometrical diagonalization approach to reduce degrees of freedom, with analytical expressions derived using Wigner function framework for complete quantum state description.

Result: Excitations significantly enhance quantum steering across the system; ground state (0,0,0) shows no steerable correlations; steering directionality and topology governed by spatial distribution rather than magnitude of excitations; symmetric steering behavior observed between oscillators under equivalent excitation conditions.

Conclusion: Excitation levels and mixing angles generate and enhance steering in three coupled harmonic oscillators, with spatial distribution of excitations determining correlation patterns rather than their magnitude.

Abstract: Quantum steering is one of the most intriguing phenomena in quantum mechanics and is essential for understanding correlations in multi-body systems. Despite its importance, analytical results for coupled three-body oscillators remain scarce. In this work, we investigate this phenomenon through a geometrical diagonalization approach, which reduces the degrees of freedom associated with the system's steering properties. Specifically, we derive analytical expressions for quantum steering in all possible directions using the Wigner function framework, as it provides a complete description of the system's quantum state. Our results indicate that excitations significantly enhance quantum steering across the system; this stands in contrast to the ground state $(0,0,0)$, which exhibits no steerable correlations. Furthermore, both the directionality and topology of these correlations are governed by the spatial distribution of the excitations rather than their magnitude. We also observe symmetric steering behavior between oscillators $x$, $y$, and $z$ under equivalent excitation conditions, which can be formalized as $S^{(n,m,l)}_{x\to z}(θ)=S^{(n,m,l)}_{x\to y}(-θ),\quad S^{(n,m,l)}_{z\to x}(θ)=S^{(n,m,l)}_{y\to x}(-θ)$, and $S^{(n,m,l)}_{y\to z}(θ)=S^{(n,m,l)}_{z\to y}(-θ)$. Therefore, we elucidate how excitation levels and mixing angles generate and enhance steering in three coupled harmonic oscillators.

</details>


### [24] [Quantum Kaczmarz Algorithm for Solving Linear Algebraic Equations](https://arxiv.org/abs/2601.01342)
*Nhat A. Nghiem,Tuan K. Do,Trung V. Phan*

Main category: quant-ph

TL;DR: Quantum linear system solver based on Kaczmarz method with improved complexity: O(1/ε log m) for low-rank structured systems, and O(1/ε log s) for arbitrary sparse systems, achieving exponential improvement over previous quantum solvers.


<details>
  <summary>Details</summary>
Motivation: Existing quantum linear solvers face practicality bottlenecks due to oracle access requirements and poor scaling with condition number (κ) and sparsity (s). The Kaczmarz method's simplicity and low memory cost make it attractive for practical applications in data regression, tomographic reconstruction, and optimization.

Method: Quantum adaptation of the classical Kaczmarz method, which solves linear systems by iteratively enforcing one equation at a time. The algorithm avoids oracle access to matrix entries and leverages row structure properties. For low-rank systems with structured rows, it achieves O(1/ε log m) complexity; for arbitrary sparse rows with s nonzeros, it uses O(s) ancilla qubits to achieve O(1/ε log s) circuit depth.

Result: Significant improvement over previous quantum linear solvers: (1) For low-rank structured systems: O(1/ε log m) circuit complexity without dependence on sparsity s and possibly without explicit dependence on condition number κ. (2) For arbitrary sparse systems: O(1/ε log s) circuit depth using O(s) ancilla qubits. When s = O(log m), achieves exponential improvement in circuit depth compared to existing quantum algorithms while using asymptotically the same number of qubits.

Conclusion: The quantum Kaczmarz method provides a practical quantum linear system solver that relaxes key practicality bottlenecks of existing approaches, offering improved scaling with sparsity and condition number, and enabling exponential improvements for moderately sparse systems.

Abstract: We introduce a quantum linear system solving algorithm based on the Kaczmarz method, a widely used workhorse for large linear systems and least-squares problems that updates the solution by enforcing one equation at a time. Its simplicity and low memory cost make it a practical choice across data regression, tomographic reconstruction, and optimization. In contrast to many existing quantum linear solvers, our method does not rely on oracle access to query entries, relaxing a key practicality bottleneck. In particular, when the rank of the system of interest is sufficiently small and the rows of the matrix of interest admit an appropriate structure, we achieve circuit complexity $\mathcal{O}\left(\frac{1}{\varepsilon}\log m\right)$, where $m$ is the number of variables and $\varepsilon$ is the target precision, without dependence on the sparsity $s$, and could possibly be without explicit dependence on condition number $κ$. This shows a significant improvement over previous quantum linear solvers where the dependence on $κ,s$ is at least linear. At the same time, when the rows have an arbitrary structure and have at most $s$ nonzero entries, we obtain the circuit depth $\mathcal{O}\left(\frac{1}{\varepsilon}\log s\right)$ using extra $\mathcal{O}(s)$ ancilla qubits, so the depth grows only logarithmically with sparsity $s$. When the sparsity $s$ grows as $\mathcal{O}(\log m)$, then our method can achieve an exponential improvement with respect to circuit depth compared to existing quantum algorithms, while using (asymptotically) the same amount of qubits.

</details>


### [25] [Distant Entanglement Generation between Magnon and Superconducting Qubits in Magnon-Mediated Hybrid Systems](https://arxiv.org/abs/2601.01394)
*Guosen Liu,Pei Pei*

Main category: quant-ph

TL;DR: Efficient two-stage protocol for generating distant entanglement in a magnon-mediated hybrid quantum system using magnons as both mediators and qubits, achieving high fidelity and robustness.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable and practical building block for distributed quantum networks by leveraging magnons' advantages (strong coupling, low dissipation, high integrability) while reducing physical component count through an integrated design.

Method: Two-stage protocol: (1) deterministic Bell-state generation between superconducting qubit (SQ) and local magnonic system (QM1) using shortcuts to adiabaticity; (2) coherent state transfer to remote magnonic system (QM2) via engineered Hamiltonian dynamics. System uses superconducting resonator interface between SQ and QM1, with waveguide coupling between QM1 and QM2.

Result: Numerical simulations under realistic noise conditions show strong resilience to decoherence, achieving fidelity F > 0.90 and negativity N₂ > 0.40, demonstrating the protocol's robustness.

Conclusion: The protocol establishes a scalable and practical building block for distributed quantum networks by efficiently generating distant entanglement with magnons serving dual roles as interaction mediators and qubits.

Abstract: We propose an efficient two-stage protocol for generating distant entanglement in a magnon-mediated hybrid quantum system, where magnons serve dual roles as both interaction mediators and qubits. This integrated design reduces the physical component count while leveraging the inherent advantages of magnons, such as their strong coupling via magnetic dipole interactions, low dissipation, and high integrability. In our setup, a superconducting resonator interfaces between a local superconducting qubit (SQ) and a local magnonic system (QM1), which is waveguide-coupled to a remote magnonic system (QM2). The protocol comprises two stages: (i) deterministic Bell-state generation between the SQ and QM1 using shortcuts to adiabaticity, and (ii) coherent state transfer to QM2 via engineered Hamiltonian dynamics. This adiabatic characteristic enhances robustness against environmental dissipation. Numerical simulations under realistic noise conditions confirm strong resilience to decoherence, achieving fidelity $F > 0.90$ and negativity $\mathcal{N}_2 > 0.40$. These results establish the protocol as a scalable and practical building block for distributed quantum networks.

</details>


### [26] [Noise-Resilient Heisenberg-limited Quantum Sensing via Indefinite-Causal-Order Error Correction](https://arxiv.org/abs/2601.01404)
*Hang Xu,Xiaoyang Deng,Ze Zheng,Tailong Xiao,Guihua Zeng*

Main category: quant-ph

TL;DR: ICO-based QEC protocol enables Heisenberg-limited sensing in noisy quantum devices by using indefinite causal order to herald and correct errors without conventional QEC constraints.


<details>
  <summary>Details</summary>
Motivation: Quantum sensing faces fundamental limitations: Heisenberg-limited scaling is theoretically possible but practically unattainable due to noise, while conventional quantum error correction imposes stringent requirements (prior noise characterization, signal-noise compatibility, measurement-based syndrome extraction) that limit its applicability to sensing.

Method: Introduces an indefinite causal order (ICO)-based quantum error correction protocol that coherently places auxiliary controls and noisy evolution in an indefinite causal order. This creates noncommutative interference enabling an auxiliary system to herald and correct errors in real time, circumventing conventional QEC limitations.

Result: The protocol restores Heisenberg-limited scaling in noisy quantum sensors, works for single- and multi-noise scenarios, and demonstrates performance in single-qubit, many-body, and continuous-variable platforms. Identifies regimes where error correction can be implemented entirely by unitary control without measurements.

Conclusion: Indefinite causal order emerges as a powerful resource for metrological quantum error correction, providing a broadly applicable framework for noise-resilient quantum information processing that overcomes fundamental limitations of conventional approaches.

Abstract: Quantum resources can, in principle, enable Heisenberg-limited (HL) sensing, yet no-go theorems imply that HL scaling is generically unattainable in realistic noisy devices. While quantum error correction (QEC) can suppress noise, its use in quantum sensing is constrained by stringent requirements, including prior noise characterization, restrictive signal-noise compatibility conditions, and measurement-based syndrome extraction with global control. Here we introduce an ICO-based QEC protocol, providing the first application of indefinite causal order (ICO) to QEC. By coherently placing auxiliary controls and noisy evolution in an indefinite causal order, the resulting noncommutative interference enables an auxiliary system to herald and correct errors in real time, thereby circumventing the limitations of conventional QEC and restoring HL scaling. We rigorously establish the protocol for single- and multi-noise scenarios and demonstrate its performance in single-qubit, many-body, and continuous-variable platforms. We further identify regimes in which error correction can be implemented entirely by unitary control, without measurements. Our results reveal ICO as a powerful resource for metrological QEC and provide a broadly applicable framework for noise-resilient quantum information processing.

</details>


### [27] [Implicitly Restarted Lanczos Enables Chemically-Accurate Shallow Neural Quantum States](https://arxiv.org/abs/2601.01437)
*Wei Liu,Wenjie Dou*

Main category: quant-ph

TL;DR: The paper introduces the implicitly restarted Lanczos (IRL) method as a second-order optimization framework for neural quantum states, achieving extreme precision with minimal optimization steps and dramatic speed-ups compared to conventional methods like Adam.


<details>
  <summary>Details</summary>
Motivation: Conventional first-order stochastic optimization methods (e.g., Adam) for neural quantum states suffer from slow convergence, hyperparameter sensitivity, and numerical instability, preventing the high accuracy required for fundamental science applications.

Method: The authors introduce the implicitly restarted Lanczos (IRL) method as a core optimization engine, recasting the ill-conditioned parameter update problem into a small, well-posed Hermitian eigenvalue problem that is solved efficiently and robustly with IRL.

Result: IRL enables shallow NQS architectures with orders of magnitude fewer parameters to achieve extreme precision (1e-12 kcal/mol) in just 3-5 optimization steps, with a 17,900-fold speed-up for the F2 molecule compared to Adam.

Conclusion: IRL establishes a superior, robust, and efficient second-order optimization strategy for variational quantum models, enabling practical high-fidelity application of neural networks in quantum physics and chemistry.

Abstract: The variational optimization of high-dimensional neural network models, such as those used in neural quantum states (NQS), presents a significant challenge in machine intelligence. Conventional first-order stochastic methods (e.g., Adam) are plagued by slow convergence, sensitivity to hyperparameters, and numerical instability, preventing NQS from reaching the high accuracy required for fundamental science. We address this fundamental optimization bottleneck by introducing the implicitly restarted Lanczos (IRL) method as the core engine for NQS training. Our key innovation is an inherently stable second-order optimization framework that recasts the ill-conditioned parameter update problem into a small, well-posed Hermitian eigenvalue problem. By solving this problem efficiently and robustly with IRL, our approach automatically determines the optimal descent direction and step size, circumventing the need for demanding hyperparameter tuning and eliminating the numerical instabilities common in standard iterative solvers. We demonstrate that IRL enables shallow NQS architectures (with orders of magnitude fewer parameters) to consistently achieve extreme precision (1e-12 kcal/mol) in just 3 to 5 optimization steps. For the F2 molecule, this translates to an approximate 17,900-fold speed-up in total runtime compared to Adam. This work establishes IRL as a superior, robust, and efficient second-order optimization strategy for variational quantum models, paving the way for the practical, high-fidelity application of neural networks in quantum physics and chemistry.

</details>


### [28] [The Equivalence between Hardy-type paradox and Logical Contextuality](https://arxiv.org/abs/2601.01445)
*Songyi Liu,Yongjun Wang,Baoshan Wang,Chang He,Yunyi Jia*

Main category: quant-ph

TL;DR: Logical Hardy-type paradoxes provide a unified framework for quantum contextuality, with existence equivalent to logical contextuality and strong contextuality equivalent to SP=1 paradoxes.


<details>
  <summary>Details</summary>
Motivation: To establish a unified logical formulation for Hardy-type paradoxes that generalizes prior work and resolves misconceptions about the equivalence between such paradoxes and logical contextuality in general scenarios.

Method: Develop a unified logical formulation for general Hardy-type paradoxes (termed logical Hardy-type paradoxes), prove equivalence theorems for finite scenarios, and analyze specific Bell scenarios (2,2,2, 2,3,3) and the KCBS scenario.

Result: 1) Existence of logical Hardy-type paradoxes is equivalent to logical contextuality for any finite scenario. 2) Strong contextuality is equivalent to logical Hardy-type paradoxes with success probability SP=1. 3) KCBS scenario admits only one kind of Hardy-type paradox with SP≈10.56% for specific parameters.

Conclusion: Logical Hardy-type paradoxes provide a comprehensive framework that unifies and generalizes previous results on Hardy-type paradoxes, establishing their fundamental equivalence with logical contextuality and resolving previous misconceptions about this relationship.

Abstract: Hardy-type paradoxes offer elegant, inequality-free proof of quantum contextuality. In this work, we introduce a unified logical formulation for general Hardy-type paradoxes, which we term logical Hardy-type paradoxes. We prove that for any finite scenario, the existence of a logical Hardy-type paradox is equivalent to logical contextuality. Specially, strong contextuality is equivalent to logical Hardy-type paradoxes with success probability SP = 1. These results generalize prior work on (2,k,2), (2,2,d), and n-cycle scenarios, and resolve a misconception that such equivalence does not hold for general scenarios [1]. We analyse the logical Hardy-type paradoxes on the (2,2,2) and (2,3,3) Bell scenarios, as well as the Klyachko-Can-Binicioglu-Shumovsky (KCBS) scenario. We show that the KCBS scenario admits only one kind of Hardy-type paradox, achieving a success probability of SP \approx 10.56% for a specific parameter setting.

</details>


### [29] [Constraint-Aware Quantum Optimization via Hamming Weight Operators](https://arxiv.org/abs/2601.01516)
*Yajie Hao,Qiming Ding,Xiao Yuan,Xiaoting Wang*

Main category: quant-ph

TL;DR: AHAWO-QAOA uses constraint-aware Hamming Weight Operators to keep quantum evolution strictly within feasible subspaces, enabling faster convergence and higher approximation ratios with shallower circuits than penalty-based QAOA for constrained combinatorial optimization problems.


<details>
  <summary>Details</summary>
Motivation: Constrained combinatorial optimization with strict linear constraints is computationally demanding for classical algorithms at large scales. Conventional QAOA uses penalty-based formulations that distort optimization landscapes and require deep circuits, undermining scalability on near-term quantum hardware.

Method: Introduces Hamming Weight Operators that confine quantum evolution strictly within the feasible subspace, and develops Adaptive Hamming Weight Operator QAOA (AHAWO-QAOA) which dynamically selects the most effective operators to construct shallow, problem-tailored circuits.

Result: Validated on portfolio optimization and two-jet clustering with energy balance benchmarks. The method inherently satisfies all constraints by construction, converges faster, achieves higher Approximation Ratios than penalty-based QAOA, while requiring roughly half as many gates.

Conclusion: By embedding constraint-aware operators into an adaptive variational framework, the approach establishes a scalable and hardware-efficient pathway for solving practical constrained optimization problems on near-term quantum devices.

Abstract: Constrained combinatorial optimization with strict linear constraints underpins applications in drug discovery, power grids, logistics, and finance, yet remains computationally demanding for classical algorithms, especially at large scales. The Quantum Approximate Optimization Algorithm (QAOA) offers a promising quantum framework, but conventional penalty-based formulations distort optimization landscapes and demand deep circuits, undermining scalability on near-term hardware. In this work, we introduce Hamming Weight Operators, a new class of constraint-aware operators that confine quantum evolution strictly within the feasible subspace. Building on this idea, we develop Adaptive Hamming Weight Operator QAOA, which dynamically selects the most effective operators to construct shallow, problem-tailored circuits. We validate our approach on benchmark tasks from both finance and high-energy physics, specifically portfolio optimization and two-jet clustering with energy balance. Across these problems, our method inherently satisfies all constraints by construction, converges faster, and achieves higher Approximation Ratios than penalty-based QAOA, while requiring roughly half as many gates. By embedding constraint-aware operators into an adaptive variational framework, our approach establishes a scalable and hardware-efficient pathway for solving practical constrained optimization problems on near-term quantum devices.

</details>


### [30] [Entropy and Variance Squeezing of V-type Atom in Dissipative Cavity](https://arxiv.org/abs/2601.01519)
*Zijin Liang,Qiying Pan,Hong-Mei Zou,Chenrui Bi*

Main category: quant-ph

TL;DR: Study of entropy and variance squeezing in a V-type atom in dissipative cavity, analyzing effects of SGI parameter, cavity-environment coupling, detuning, and initial states on atomic squeezing properties.


<details>
  <summary>Details</summary>
Motivation: To investigate quantum squeezing properties of a V-type atom in a dissipative cavity system, examining how various parameters affect squeezing behavior for potential applications in quantum information processing as low-noise resources.

Method: Analysis of entropy and variance squeezing using different initial states, examining influences of spontaneously generated interference (θ), cavity-environment coupling (γ₀/κ), and atom-cavity detuning (Δ) on atomic squeezing properties.

Result: No squeezing of S_y occurs under any conditions; variance squeezing of S_x appears only when Δ>0; entropy squeezing provides more precise quantification of quantum fluctuations than variance squeezing; atomic squeezing of S_x depends on θ, γ₀/κ, Δ, and initial state.

Conclusion: The findings demonstrate parameter-dependent squeezing behavior in V-type atoms in dissipative cavities, with entropy squeezing offering superior quantum fluctuation quantification, making these systems potentially valuable as ultra-low-noise resources for quantum information processing.

Abstract: Based on Ref.\cite{Riccardi A}, we investigate the entropy and variance squeezing of a V-type atom in a dissipative cavity, and discuss the influences of parameters including the spontaneously generated interference (SGI) ($θ$), the cavity-environment coupling ($γ_0/κ$) and the atom-cavity detuning ($Δ$) on the atomic squeezing by using different initial states. The results show that no squeezing of $S_y$ occurs under any condition and that variance squeezing of $S_x$ appears only when $Δ>0$. Entropy squeezing quantifies quantum fluctuations more precisely than variance squeezing. Moreover, the atomic squeezing of $S_x$ clearly depends on $θ$, $γ_0/κ$, $Δ$ and the initial state. These findings are meaningful for quantum information processing as an ultra-low-noise resource.

</details>


### [31] [Overcoming Stark-Shift Constraints in Phase-Controlled Rydberg Two-Qubit Gates](https://arxiv.org/abs/2601.01521)
*Ignacio R. Sola,Sebastian C. Carrasco,Vladimir S. Malinovsky,Seokmin Shin,Bo Y. Chang*

Main category: quant-ph

TL;DR: Three-pulse sequence enables any two-qubit phase gate in Rydberg blockade systems despite Stark shifts, with robust control schemes for different gate types.


<details>
  <summary>Details</summary>
Motivation: Stark shifts in Rydberg blockade systems constrain entangling gates via two-photon transitions; need methods to prepare arbitrary two-qubit phase gates despite these constraints.

Method: Control absolute phases and local amplitudes at each qubit using three-pulse sequence; introduce two robust control schemes tailored for different phase gates using even or odd pulse lengths.

Result: Any two-qubit phase gate can be prepared with high fidelity; robust control schemes yield better results for specific gate types.

Conclusion: Phase control and amplitude modulation enable universal two-qubit phase gates in Rydberg blockade systems despite Stark shift limitations, with optimized schemes for different gate requirements.

Abstract: Stark shifts introduce additional phases that constrain the set of entangling gates that can be prepared via two-photon transitions in the strong Rydberg blockade limit. For non-independently addressed qubits, by controlling the absolute phases and the local amplitudes of the pulses at each qubit, we show that any two-qubit phase gate can be prepared with high fidelity using a three-pulse sequence. Based on these insights, we introduce two robust control schemes tailored to different phase gates that yield better results with pulse sequences of either even or odd length.

</details>


### [32] [Non-Hermitian second-order topological insulator with point gap](https://arxiv.org/abs/2601.01524)
*Xue-Min Yang,Hao Lin,Jian Li,Jia-Ji Zhu,Jun-Li Zhu,Hong Wu*

Main category: quant-ph

TL;DR: Non-Hermitian SSH model's zero-mode corner states are not robust in large systems; new framework links zero-mode singular states to topological corner states via real-space winding numbers, establishing bulk-boundary correspondence for static and Floquet systems.


<details>
  <summary>Details</summary>
Motivation: To challenge the general belief that zero-mode corner states in 2D non-Hermitian SSH models are robust to infinitesimal perturbations preserving chiral symmetry, particularly in large-sized systems, and to establish a proper framework for characterizing higher-order topology in non-Hermitian systems.

Method: Establish a correspondence between stable zero-mode singular states and topologically protected corner states in the thermodynamic limit. Define real-space winding numbers to count the number of stable zero-mode singular states, linking them directly to the number of mid-gap corner states.

Result: The robustness of zero-mode corner states breaks down in large-sized systems despite chiral symmetry preservation. A bulk-boundary correspondence is formulated for both static and Floquet non-Hermitian systems, where topology emerges intrinsically from non-Hermiticity without requiring symmetries.

Conclusion: The paper establishes a new framework for understanding higher-order topology in non-Hermitian systems by connecting zero-mode singular states to topological corner states via real-space winding numbers, providing a comprehensive bulk-boundary correspondence that works even without symmetries.

Abstract: The zero-mode corner states in the gap of two-dimensional non-Hermitian Su-Schrieffer-Heeger model are robust to infinitesimal perturbations that preserve chiral symmetry. However, we demonstrate that this general belief is no longer valid in large-sized systems. To reveal the higher-order topology of non-Hermitian systems, we establish a correspondence between the stable zero-mode singular states and the topologically protected corner states of energy spectrum in the thermodynamic limit. Within this framework, the number of zero-mode singular values is directly linked to the number of mid-gap corner states. The winding numbers in real space can be defined to count the number of stable zero-mode singular states. Our results formulate a bulk-boundary correspondence for both static and Floquet non-Hermitian systems, where topology arises intrinsically from the non-Hermiticity, even without symmetries.

</details>


### [33] [Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace](https://arxiv.org/abs/2601.01550)
*Shuo Zhou,Zhaokai Pan,Weiyuan Gong,Tongyang Li*

Main category: quant-ph

TL;DR: Improved quantum simulation algorithms for time-dependent Hamiltonians under low-energy assumptions, showing reduced Trotter number requirements and proving query complexity lower bounds.


<details>
  <summary>Details</summary>
Motivation: Hamiltonian simulations are crucial for adiabatic quantum computation, quantum control, and quantum many-body physics, where dynamics often occur in low-energy sectors. While time-independent Hamiltonian simulation is well-understood, comprehensive understanding of algorithms for time-dependent Hamiltonians under low-energy assumptions remains limited.

Method: Analyze product formulas (Trotterization) for time-dependent spin Hamiltonians under low-energy assumptions. Use adiabatic perturbation theory to derive simulation error with commutator scaling. Compute Trotter number requirements when initial state is supported on small number of low-energy eigenstates.

Result: Show improvements over standard cost for full unitary simulations. Derive low-energy simulation error bounds with commutator scaling. Prove lower bound on query complexity for generic time-dependent Hamiltonian simulations.

Conclusion: The paper demonstrates that low-energy assumptions enable more efficient quantum simulations of time-dependent Hamiltonians using product formulas, with applications to non-equilibrium quantum many-body dynamics and adiabatic state preparation.

Abstract: Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.

</details>


### [34] [Utilizing intermediate states in quantum annealing for multi-objective optimization](https://arxiv.org/abs/2601.01559)
*Keita Takahashi,Shu Tanaka*

Main category: quant-ph

TL;DR: The paper proposes using intermediate quantum states during quantum annealing to explore non-convex regions of Pareto fronts in multi-objective optimization, overcoming limitations of linear weighted sum methods.


<details>
  <summary>Details</summary>
Motivation: The linear weighted sum method for multi-objective optimization fails to reach non-convex regions of the Pareto front. Quantum annealing typically only provides final solutions, missing intermediate states that could reveal diverse trade-offs.

Method: The researchers investigate obtaining intermediate quantum states during quantum annealing using two approaches: physical experiments with quench-based readout and numerical simulations assuming ideal mid-anneal measurements.

Result: Both methods show a clear trade-off: earlier timing enhances solution diversity, while later timing ensures convergence to non-dominated solutions. A practical compromise timing balances both metrics. Qualitative agreement between practical quench and ideal simulation suggests potential for comprehensive Pareto front exploration.

Conclusion: Accessing intermediate quantum states during annealing enables exploration of non-convex Pareto front regions, overcoming limitations of traditional multi-objective optimization methods and providing a balanced approach to solution diversity and quality.

Abstract: We investigate obtaining intermediate quantum states during the quantum annealing process to address the limitation of the linear weighted sum method in multi-objective optimization, which inherently fails to reach non-convex regions of the Pareto front. We validate this approach through physical experiments utilizing quench-based readout and numerical simulations assuming ideal mid-anneal measurements. Both methods consistently demonstrate a clear trade-off where earlier timing enhances diversity of the solutions, whereas later timing ensures convergence to non-dominated solutions. Notably, a practical compromise timing balances both metrics. The qualitative agreement between practical quench and ideal simulation indicates the potential of accessing the intermediate states for comprehensive Pareto front exploration.

</details>


### [35] [Learning Relationship between Quantum Walks and Underdamped Langevin Dynamics](https://arxiv.org/abs/2601.01589)
*Yazhen Wang*

Main category: quant-ph

TL;DR: The paper establishes asymptotic equivalence between randomized quantum walks and underdamped Langevin dynamics via Le Cam deficiency distance, revealing connections between quantum search algorithms and classical sampling methods in machine learning.


<details>
  <summary>Details</summary>
Motivation: To investigate the relationship between quantum walk-based search algorithms (which achieve quadratic speedups) and classical sampling algorithms based on underdamped Langevin dynamics (which provide quadratic acceleration), since both address learning tasks in machine learning.

Method: Analyzes learning relationship between coined quantum walks and underdamped Langevin dynamics using Le Cam deficiency distance to establish asymptotic equivalence between randomized quantum walks and underdamped Langevin dynamics.

Result: Randomized quantum walks are asymptotically equivalent to underdamped Langevin dynamics, while non-randomized quantum walks are not equivalent due to high-frequency oscillations; these findings provide insights into computational and inferential properties of associated algorithms.

Conclusion: The equivalence results offer new understanding of relationships between quantum walks and underdamped Langevin dynamics, revealing intrinsic mechanisms behind quantum speedup and classical gradient acceleration in machine learning tasks.

Abstract: Fast computational algorithms are in constant demand, and their development has been driven by advances such as quantum speedup and classical acceleration. This paper intends to study search algorithms based on quantum walks in quantum computation and sampling algorithms based on Langevin dynamics in classical computation. On the quantum side, quantum walk-based search algorithms can achieve quadratic speedups over their classical counterparts. In classical computation, a substantial body of work has focused on gradient acceleration, with gradient-adjusted algorithms derived from underdamped Langevin dynamics providing quadratic acceleration over conventional Langevin algorithms.
  Since both search and sampling algorithms are designed to address learning tasks, we study learning relationship between coined quantum walks and underdamped Langevin dynamics. Specifically, we show that, in terms of the Le Cam deficiency distance, a quantum walk with randomization is asymptotically equivalent to underdamped Langevin dynamics, whereas the quantum walk without randomization is not asymptotically equivalent due to its high-frequency oscillatory behavior. We further discuss the implications of these equivalence and nonequivalence results for the computational and inferential properties of the associated algorithms in machine learning tasks. Our findings offer new insight into the relationship between quantum walks and underdamped Langevin dynamics, as well as the intrinsic mechanisms underlying quantum speedup and classical gradient acceleration.

</details>


### [36] [Generation of circular polarized high-order harmonics from single color quantum light](https://arxiv.org/abs/2601.01611)
*Lidija Petrovic,Philipp Stammer,Maciej Lewenstein,Javier Rivera-Dean*

Main category: quant-ph

TL;DR: Squeezed highly elliptically polarized drivers enable high-harmonic generation in classically forbidden regimes, producing highly elliptical harmonics with super-Poissonian statistics while encoding quantum field information.


<details>
  <summary>Details</summary>
Motivation: Classical circularly polarized drivers suppress high-harmonic generation, but quantum features in the driving field can overcome this limitation and enable HHG in previously forbidden regimes.

Method: Using squeezed highly elliptically polarized quantum drivers to generate high-harmonic radiation, analyzing spectral intensity dependence on driver ellipticity and squeezing orientation.

Result: Squeezed drivers enable HHG in classically forbidden large ellipticity regimes, produce highly elliptical harmonic radiation with super-Poissonian photon statistics, and encode quantum field information in spectral features.

Conclusion: HHG with squeezed elliptical drivers provides a means to probe quantum properties of driving fields in high-photon number regimes, overcoming classical limitations and revealing squeezed field fluctuations.

Abstract: The atomic response to an ultra-intense driving field produces a characteristic high-harmonic spectrum featuring a rapid drop in intensity for the lower harmonics, followed by a plateau and a sharp cutoff. This response vanishes for circularly polarized classical drivers -- a limitation that can be overcome by introducing quantum features into the driving field. In this work, we show that squeezed highly elliptically polarized drivers not only enable the high-harmonic generation (HHG) process in classically forbidden regimes of large ellipticity, but also yield highly elliptical harmonic radiation with pronounced super-Poissonian photon statistics. Moreover, we show that the HHG spectral features encode information about the quantum nature of the driving field, revealing the presence of its squeezed field fluctuations. By analyzing the HHG spectral intensity dependence as a function of the driver's ellipticity and squeezing orientation, we identify a means to probe the driving field's quantum properties that intrinsically lie in the high-photon number regime.

</details>


### [37] [Scattering Cross Section Formula Derived From Macroscopic Model of Detectors](https://arxiv.org/abs/2601.01625)
*Rashi Kaimal,Roderich Tumulka*

Main category: quant-ph

TL;DR: The paper justifies the asymptotic scattering cross-section formula for free non-relativistic quantum particles detected on large spheres, providing two derivations using different detector models and comparing with Bohmian mechanics.


<details>
  <summary>Details</summary>
Motivation: To rigorously justify the commonly used formula for scattering cross-section in quantum scattering theory, which relates detection probability distribution to the Fourier transform of the initial wave function, addressing the gap between heuristic usage and proper derivation.

Method: Two distinct macroscopic detector models: (1) negative imaginary potential in detector volume with limits R→∞, λ→0, Rλ→∞; (2) repeated nearly-projective measurements of position outside sphere with limits R→∞, T→∞, T/R→0. Also compares with Bohmian mechanics and extends to non-spherical surfaces, N particles, time-dependent surfaces, and Dirac equation.

Result: Both detector models yield the same asymptotic scattering cross-section formula σ(x,t) = m³ℏ⁻³Rt⁻⁴|Ψ̂₀(mx/ℏt)|². Bohmian trajectories show similar asymptotic distribution but with non-negligible deviations from detection times/places, though small compared to R in far-field regime.

Conclusion: The scattering cross-section formula is rigorously justified through two independent detector models, establishing its validity in quantum scattering theory. The presence of detectors has negligible effect in far-field regime, and the results generalize to various extensions including non-spherical surfaces and relativistic Dirac equation.

Abstract: We are concerned with the justification of the statement, commonly (explicitly or implicitly) used in quantum scattering theory, that for a free non-relativistic quantum particle with initial wave function $Ψ_0(\boldsymbol{x})$, surrounded by detectors along a sphere of large radius $R$, the probability distribution of the detection time and place has asymptotic density (i.e., scattering cross section) $σ(\boldsymbol{x},t)= m^3 \hbar^{-3} R t^{-4} |\widehatΨ_0(m\boldsymbol{x}/\hbar t)|^2$ with $\widehatΨ_0$ the Fourier transform of $Ψ_0$. We give two derivations of this formula, based on different macroscopic models of the detection process. The first one consists of a negative imaginary potential of strength $λ>0$ in the detector volume (i.e., outside the sphere of radius $R$) in the limit $R\to\infty,λ\to 0, Rλ\to \infty$. The second one consists of repeated nearly-projective measurements of (approximately) the observable $1_{|\boldsymbol{x}|>R}$ at times $\mathscr{T},2\mathscr{T},3\mathscr{T},\ldots$ in the limit $R\to\infty,\mathscr{T}\to\infty,\mathscr{T}/R\to 0$; this setup is similar to that of the quantum Zeno effect, except that there one considers $\mathscr{T}\to 0$ instead of $\mathscr{T}\to\infty$. We also provide a comparison to Bohmian mechanics: while in the absence of detectors, the arrival times and places of the Bohmian trajectories on the sphere of radius $R$ have asymptotic distribution density given by the same formula as $σ$, their deviation from the detection times and places is not necessarily small, although it is small compared to $R$, so the effect of the presence of detectors on the particle can be neglected in the far-field regime. We also cover the generalization to surfaces with non-spherical shape, to the case of $N$ non-interacting particles, to time-dependent surfaces, and to the Dirac equation.

</details>


### [38] [Quantum simulation with Rydberg ions in a Penning trap](https://arxiv.org/abs/2601.01626)
*Wilson S. Martins,Markus Hennrich,Ferdinand Schmidt-Kaler,Igor Lesanovsky*

Main category: quant-ph

TL;DR: A new trapped-ion quantum simulator platform using Rydberg states in a Penning trap enables 2D spin systems with MHz-range interactions, allowing study of slow relaxation in frustrated systems.


<details>
  <summary>Details</summary>
Motivation: Current trapped-ion quantum simulators have limited interaction strengths, restricting study of phenomena requiring long timescales like slow relaxation in frustrated spin systems.

Method: Utilizes strong dipolar interactions among electronic Rydberg states combined with planar confinement in a Penning trap, analyzing how trap fields affect Rydberg properties.

Result: Spin-spin interaction strengths on the order of MHz are achievable under realistic experimental conditions, demonstrated by studying entanglement in a three-ion frustrated spin system.

Conclusion: The platform enables quantum simulation of 2D spin systems with orders-of-magnitude stronger interactions, opening avenues for exploring long-timescale phenomena in frustrated and kinetically constrained systems.

Abstract: Quantum simulation of interacting many-body spin systems is routinely performed with cold trapped ions, and systems with hundreds of spins have been studied in one and two dimensions. In the most common realizations of these platforms, spin degrees of freedom are encoded in low-lying electronic levels, and interactions among the spins are mediated through crystal vibrations. Here we propose a new approach which enables the quantum simulation of two-dimensional spin systems with interaction strengths that are increased by orders of magnitude. This, together with the unprecedented longevity of trapped ions, opens an avenue for the exploration of phenomena that take place on long timescales, e.g., slow and collective relaxation in frustrated and kinetically constrained systems. Our platform makes use of the strong dipolar interactions among electronic Rydberg states and planar confinement provided by a Penning trap. We investigate how the strong electric and magnetic fields that form this trap affect the properties of the Rydberg states and show that spin-spin interaction strengths on the order of MHz are achievable under experimentally realistic conditions. As a brief illustration of the capabilities of this quantum simulator, we study the entanglement in a frustrated spin system realized by three ions.

</details>


### [39] [Design and Characterization of Compact Acousto-Optic-Deflector Individual Addressing System for Trapped-Ion Quantum Computing](https://arxiv.org/abs/2601.01647)
*Jiyong Yu,Kavyashree Ranawat,Andrew Van Horn,Jacob Whitlow,Seunghyun Baek,Junki Kim,Jungsang Kim*

Main category: quant-ph

TL;DR: Compact AOD-based beam-steering system for individual ion addressing in trapped-ion quantum computing achieves <1 sq ft footprint, 355nm Gaussian beams, ~50× beam steering range, <9×10⁻⁴ intensity crosstalk, and ~240ns switching time.


<details>
  <summary>Details</summary>
Motivation: To develop a compact, stable individual addressing system for trapped-ion quantum computing that minimizes optomechanical degrees of freedom and optical beam paths to improve optical stability for long ion chains.

Method: Uses acousto-optic deflectors (AODs) as beam-steering elements in a compact design (<1 square foot footprint) with minimized optomechanical components and optical paths to enhance stability.

Result: Achieved clean Gaussian beams at 355nm with ~50× beam steering range, intensity crosstalk <9×10⁻⁴ for neighboring ions in 5-ion chain, demonstrated individual addressing of 30-ion chain, and estimated AOD switching time of ~240ns.

Conclusion: The compact AOD-based system provides high optical stability and fast switching, enabling high-fidelity trapped-ion quantum computing with long ion chains through effective individual addressing.

Abstract: We present a compact design for a beam-steering system based on acousto-optic-deflectors (AODs) used as an individual addressing system for trapped-ion quantum computing. The design targets to minimize the optomechanical degrees of freedom and the optical beam paths to improve optical stability, and we successfully implemented a solution with a compact footprint of less than 1 square foot. The system characterization results show that we achieve clean Gaussian beams at 355nm wavelength with a beam steering range of $\sim$50 times the beam diameter, and an intensity crosstalk of $< 9 \times 10^{-4}$ at all neighboring ions in a five-ion chain. Based on these capabilities, we experimentally demonstrate individual addressing of a 30-ion chain. We estimate the beam switching time of the AOD to be $\sim$240 ns. The compact system design is expected to provide high optical stability, providing the potential for high-fidelity trapped-ion quantum computing with long ion chains.

</details>


### [40] [A Geometric Approach to Strongly Correlated Bosons: From $N$-Representability to the Generalized BEC Force](https://arxiv.org/abs/2601.01652)
*Chih-Chun Wang,Christian Schilling*

Main category: quant-ph

TL;DR: Geometric framework for strongly correlated lattice bosons using reduced density matrix theory, establishing exact functional formulation via momentum occupation numbers and revealing universal boundary force structure.


<details>
  <summary>Details</summary>
Motivation: To develop a geometric framework for describing strongly correlated lattice bosons by leveraging recent advances in reduced density matrix theory, aiming to establish exact functional formulations and reveal universal structural properties of ground-state functionals.

Method: Utilize constrained-search formalism and geometric correspondence between N-boson configuration states and their one-particle reduced density matrices; exploit translational symmetry and fixed pair interactions to derive exact functional formulation expressed solely in momentum occupation numbers; demonstrate results analytically for few-site lattice systems.

Result: Established that translational symmetry enables exact functional formulation via momentum occupation numbers; derived general form of ground-state functional highlighting significance of one-body N-representability: (i) domain exactly determined by N-representability conditions, (ii) gradient diverges repulsively at boundary (generalizing BEC force), (iii) explicit expression for boundary force from geometric arguments; demonstrated analytically for few-site systems and illustrated systematic hierarchy of functional approximations.

Conclusion: The geometric framework provides fundamental insights into strongly correlated lattice bosons, revealing universal structural properties of ground-state functionals and establishing systematic approach for functional approximations based on N-representability conditions and boundary force behavior.

Abstract: Building on recent advances in reduced density matrix theory, we develop a geometric framework for describing strongly correlated lattice bosons. We first establish that translational symmetry, together with a fixed pair interaction, enables an exact functional formulation expressed solely in terms of momentum occupation numbers. Employing the constrained-search formalism and exploiting a geometric correspondence between $N$-boson configuration states and their one-particle reduced density matrices, we derive the general form of the ground-state functional. Its structure highlights the omnipresent significance of one-body $N$-representability: (i) the domain is exactly determined by the $N$-representability conditions; (ii) at its boundary, the gradient of the functional diverges repulsively, thereby generalizing the recently discovered Bose-Einstein condensate (BEC) force; and (iii) an explicit expression for this boundary force follows directly from geometric arguments. These key results are demonstrated analytically for few-site lattice systems, and we illustrate the broader significance of our functional form in defining a systematic hierarchy of functional approximations.

</details>


### [41] [Demonstration of Discrete-Time Quantum Walks and Observation of Topological Edge States in a Superconducting Qutrit Chain](https://arxiv.org/abs/2601.01759)
*Kun Zhou,Jian-Wen Xu,Qi-Ping Su,Yu Zhang,Xiang-Min Yu,Zhuang Ma,Han-Yu Zhang,Hong-Yi Shi,Wen Zheng,Shu-Yi Pan,Yi-Hao Kang,Zhi-Guo Huang,Chui-Ping Yang,Shao-Xiong Li,Yang Yu*

Main category: quant-ph

TL;DR: Experimental demonstration of a scalable discrete-time quantum walk using superconducting qutrits, enabling observation of ballistic spreading and topological edge states for the first time in superconducting platforms.


<details>
  <summary>Details</summary>
Motivation: Current implementations of discrete-time quantum walks with superconducting circuits face limitations in operation precision, circuit depth, and connectivity. There's a need for more hardware-efficient approaches to enable scalable quantum walks for quantum computing and simulation applications.

Method: Used superconducting qutrits (three-level systems) to implement a scalable DTQW, allowing hardware-efficient encoding of both walker position and coin degree of freedom. Exploited flexibility and intrinsic symmetries of qutrit-based DTQWs to prepare two topological phases in the chain.

Result: Successfully demonstrated ballistic spreading of quantum walk in a qutrit chain. Observed particle-hole-symmetry-protected edge states bounded at the interface between two topological phases - the first such observation in superconducting platforms. Measured parameter dependencies validated edge state properties.

Conclusion: The qutrit-based approach provides a scalable and gate-control compatible implementation of DTQWs, offering a versatile tool for superconducting quantum computing and quantum simulation with improved hardware efficiency.

Abstract: Quantum walk serves as a versatile tool for universal quantum computing and algorithmic research. However, the implementation of discrete-time quantum walks (DTQWs) with superconducting circuits is still constrained by some limitations such as operation precision, circuit depth and connectivity. With improved hardware efficiency by using superconducting qutrits (three-level systems), we experimentally demonstrate a scalable DTQW in a superconducting circuit, observing the ballistic spreading of quantum walk in a qutrit chain. The usage of qutrits in our implementation allows hardware efficiently encoding of the walker position and the coin degree of freedom. By exploiting the flexibility and intrinsic symmetries of qutrit-based DTQWs, we successfully prepare two topological phases in the chain. For the first time, particle-hole-symmetry-protected edge states, bounded at the interface between these two topological phases, are observed in the superconducting platform. Measured parameter dependencies further validate the properties of edge states. The scalability and gate-control compatibility of the demonstrated DTQWs enable a versatile tool for superconducting quantum computing and quantum simulation.

</details>


### [42] [A Survey on Applications of Quantum Computing for Unit Commitment](https://arxiv.org/abs/2601.01777)
*Milad Hasanzadeh,Ali Rajabi,Amin Kargarian*

Main category: quant-ph

TL;DR: Survey paper reviewing quantum computing applications for Unit Commitment, covering quantum annealing, variational algorithms, quantum machine learning, and quantum-inspired methods.


<details>
  <summary>Details</summary>
Motivation: Traditional UC methods face scalability challenges with growing system size and uncertainty; quantum computing offers potential acceleration through quantum parallelism and entanglement.

Method: Comprehensive literature survey categorizing quantum UC approaches by paradigm: annealing-based, variational hybrid, quantum machine learning, and quantum-inspired methods.

Result: Analysis of key modeling strategies, hardware implementations, computational trade-offs, current progress, and limitations in quantum-enabled UC research.

Conclusion: Quantum computing shows promise for accelerating UC solutions but faces current limitations; future directions needed for large-scale quantum-enabled UC implementation.

Abstract: Unit Commitment (UC) is a core optimization problem in power system operation and electricity market scheduling. It determines the optimal on/off status and dispatch of generating units while satisfying system, operational, and market constraints. Traditionally, UC has been solved using mixed-integer programming, dynamic programming, or metaheuristic methods, all of which face scalability challenges as systems grow in size and uncertainty. Recent advances in quantum computing, spanning quantum annealing, variational algorithms, and hybrid quantum classical optimization, have opened new opportunities to accelerate UC solution processes by exploiting quantum parallelism and entanglement. This paper presents a comprehensive survey of existing research on the applications of quantum computing for solving the UC problem. The reviewed works are categorized based on the employed quantum paradigms, including annealing-based, variational hybrid, quantum machine learning, and quantum-inspired methods. Key modeling strategies, hardware implementations, and computational trade-offs are discussed, highlighting the current progress, limitations, and potential future directions for large-scale quantum-enabled UC.

</details>


### [43] [Physically natural metric-measure Lindbladian ensembles and their learning hardness](https://arxiv.org/abs/2601.01806)
*Caisheng Cheng,Ruicheng Bao*

Main category: quant-ph

TL;DR: The paper studies learnability of random Lindbladian open quantum systems, proves exponential query lower bounds for learning them, and designs cryptographic protocols based on this learning hardness.


<details>
  <summary>Details</summary>
Motivation: To understand how well one can infer noise and dissipation generator structures from finite-time measurement statistics in open quantum systems, bridging quantum information, statistical physics, and many-body dynamics.

Method: Introduces physically motivated ensembles of random local Lindbladians via linear parametrization around reference generators in the affine hull of the GKSL cone. Extends statistical query (SQ) and quantum-process statistical query (QPStat) frameworks to open systems and proves exponential lower bounds on query complexity for learning random Lindbladian dynamics.

Result: Establishes average-case SQ-hardness for learning output distributions in total variation distance and average-case QPStat-hardness for learning Lindbladian channels in diamond norm. Derives linear-response expression for ensemble-averaged total variation distance and verifies nonvanishing scaling in random local amplitude-damping chain. Designs two Lindbladian physically unclonable function (Lindbladian-PUF) protocols with distribution-level and tomography-based verification.

Conclusion: The learning hardness of random Lindbladian dynamics can be translated into cryptographic security guarantees, providing open-system examples where computational hardness enables practical cryptographic applications through physically unclonable functions.

Abstract: In open quantum systems, a basic question at the interface of quantum information, statistical physics, and many-body dynamics is how well can one infer the structure of noise and dissipation generators from finite-time measurement statistics alone. Motivated by this question, we study the learnability and cryptographic applications of random open-system dynamics generated by Lindblad-Gorini-Kossakowski-Sudarshan (GKSL) master equations. Working in the affine hull of the GKSL cone, we introduce physically motivated ensembles of random local Lindbladians via a linear parametrisation around a reference generator. On top of this geometric structure, we extend statistical query (SQ) and quantum-process statistical query (QPStat) frameworks to the open-system setting and prove exponential (in the parameter dimension $M$) lower bounds on the number of queries required to learn random Lindbladian dynamics. In particular, we establish average-case SQ-hardness for learning output distributions in total variation distance and average-case QPStat-hardness for learning Lindbladian channels in diamond norm. To support these results physically, we derive a linear-response expression for the ensemble-averaged total variation distance and verify the required nonvanishing scaling in a random local amplitude-damping chain. Finally, we design two Lindbladian physically unclonable function (Lindbladian-PUF) protocols based on random Lindbladian ensembles with distribution-level and tomography-based verification, thereby providing open-system examples where learning hardness can be translated into cryptographic security guarantees.

</details>


### [44] [Photon blockade effect from synergistic optical parametric amplification and driving force in Kerr-medium single-mode cavity](https://arxiv.org/abs/2601.01819)
*Zhang Zhiqiang*

Main category: quant-ph

TL;DR: Photon blockade control in a Kerr-nonlinear cavity coupled to an optical parametric amplifier is achieved through destructive quantum interference, with driving phase regulating the optimal blockade region and Kerr nonlinearity maintaining robustness across wide parameter ranges.


<details>
  <summary>Details</summary>
Motivation: To investigate photon blockade control in hybrid quantum systems combining Kerr-nonlinear cavities with optical parametric amplifiers, aiming to understand the mechanisms for achieving and optimizing single-photon sources with enhanced brightness.

Method: Derived an effective Hamiltonian including cavity decay, expanded quantum state in Fock basis up to two-photon level, solved steady-state Schrödinger equation analytically, and validated with numerical simulations of steady-state equal-time second-order correlation function.

Result: Photon blockade is achievable with suitable parameters; analytical solutions match numerical simulations; average intracavity photon number increases significantly under resonance; driving phase regulates optimal blockade region by shifting parabolic region in parameter space; photon blockade remains robust across wide range of Kerr nonlinearities.

Conclusion: Photon blockade in this hybrid system is attributed to destructive quantum interference between two excitation pathways, with driving phase providing control over optimal blockade conditions and Kerr nonlinearity maintaining effect stability, offering theoretical pathway for enhanced single-photon source brightness.

Abstract: This work investigates photon blockade control in a hybrid quantum system containing a Kerr-nonlinear cavity coupled to an optical parametric amplifier (OPA). The dynamics are governed by a master equation derived from an effective Hamiltonian that includes cavity decay.To obtain analytical solutions, the system's quantum state is expanded in the Fock basis up to the two-photon level. Solving the steady-state Schrodinger equation yields probability amplitudes and the analytical conditions for optimal photon blockade. Results confirm that photon blockade is achievable with suitable parameters. Excellent agreement is found between the analytical solutions and numerical simulations for the steady-state, equal-time second-order correlation function, validating both the analytical method and the blockade effect.Numerically, the average intracavity photon number increases significantly under resonance, providing a theoretical pathway for enhancing single-photon source brightness. Furthermore, the driving phase is shown to regulate the optimal blockade region: it shifts the parabolic region within the two-dimensional parameter space of driving strength and OPA nonlinearity and can even reverse its opening direction.The influence of Kerr nonlinearity is also examined. Photon blockade remains robust across a wide range of Kerr strengths. Physical analysis attributes the effect to destructive quantum interference between two distinct excitation pathways that suppress two-photon states. While Kerr nonlinearity shifts the system's energy levels, it does not disrupt this interference mechanism, explaining the effect's stability over a broad parameter range.

</details>


### [45] [Quantum information of optical magnetometry: Semiclassical Cramer-Rao bound violation and Heisenberg scaling](https://arxiv.org/abs/2601.01820)
*Georg Engelhardt,Ming Li,Xingchang Wang,JunYan Luo,J. F. Chen*

Main category: quant-ph

TL;DR: Quantum analysis of optical magnetometers reveals semiclassical model violates quantum Cramer-Rao bound, while collective spin model respects it and predicts Heisenberg scaling from measurement-induced quantum correlations.


<details>
  <summary>Details</summary>
Motivation: To investigate quantum information aspects of optical magnetometers, comparing semiclassical and quantum models to understand fundamental limits and scaling behavior in quantum sensing.

Method: Two distinct quantum information models: (1) semiclassical model treating atoms classically, and (2) collective spin model describing atoms as a collective quantum system. Both models are analyzed for their quantum Fisher information and scaling behavior.

Result: Semiclassical model violates quantum Cramer-Rao bound by orders of magnitude for weak dissipation and large atom numbers, invalidating this approach. Collective spin model respects the bound and predicts Heisenberg scaling for quantum Fisher information, arising from measurement-induced quantum correlations in non-interacting systems.

Conclusion: Heisenberg scaling emerges from measurement-induced quantum correlations in macroscopic quantum systems, representing a new paradigm in quantum sensing. Model comparison with experimental data could test quantum mechanics foundations in macroscopic atomic ensembles.

Abstract: Optical magnetometers use the rotation of linearly polarized laser light induced by the Faraday effect for high precision magnetic field measurements. Here, we carry out an in-depth quantum information investigation, deploying two distinct models: The first, semiclassical model can violate the quantum Cramer-Rao bound by several orders of magnitude for weak dissipation and large atom numbers, invalidating the semiclassical approach in this parameter regime. The second model, describing the atoms as a collective spin, respects the Cramer-Rao bound for all parameters. Interestingly, the collective model also predicts Heisenberg scaling for the quantum Fisher information. The comparison of both models shows that Heisenberg scaling is a result of measurement-induced quantum correlation in an otherwise non-interacting quantum system. As the Heisenberg scaling appears in a stationary state of a macroscopic quantum system, it can be thus viewed as a new paradigm in quantum sensing. Intriguingly, the comparison of both models with experimental data can constitute a test for the foundations of quantum mechanics in a macroscopic ensemble of atoms.

</details>


### [46] [Global Parametric Gates for Multi-qubit Entanglement](https://arxiv.org/abs/2601.01826)
*Jize Yang,Lin Guo,Haonan Xiong,Jiahui Wang,Yan Li,Yunfan Yang,Chenjie An,Hongyi Zhang,Luyan Sun,Yipu Song,Luming Duan*

Main category: quant-ph

TL;DR: Experimental demonstration of a global parametric gate that generates multi-qubit entangled states in a single step using microwave drives on fixed-frequency qubits.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient, reconfigurable method for generating multi-qubit entanglement that works with fixed-frequency qubits using only microwave drives, avoiding complex pulse sequences.

Method: Apply parametric drive to a common qubit at precise detunings relative to computational qubits to directly produce multi-qubit entanglement in a single step.

Result: Achieved two-, three-, and four-qubit entanglement with state fidelities of 99.4%±0.2%, 93.4%±0.3%, and 91.4%±0.3% respectively. Error analysis shows infidelity primarily from decoherence and control errors.

Conclusion: The global parametric gate enables efficient multi-qubit entanglement generation compatible with fixed-frequency qubits, with simulations predicting 99.70% fidelity for up to six-qubit systems using state-of-the-art parameters.

Abstract: We propose and experimentally demonstrate a global parametric gate that generates multi-qubit entangled states in a single step. By applying a parametric drive to a common qubit at precise detunings relative to computational qubits, we directly produce two-, three-, and four-qubit entanglement with state fidelities of 99.4\%\pm0.2\%, 93.4\%\pm0.3\%, and 91.4\%\pm0.3\%, respectively. This scheme enables efficient, reconfigurable control using only microwave drives and is compatible with fixed-frequency qubits. Error analyses indicate that infidelity stems primarily from decoherence and coherent control errors, with negligible contributions from static ZZ coupling and flux noise. Furthermore, simulations with state-of-the-art parameters predict this global gate can generate high-fidelity (99.70\%) entanglement in systems of up to six qubits.

</details>


### [47] [Quantum Interaction Between Free Electrons and Light Involving First-order and Second-order Process](https://arxiv.org/abs/2601.01846)
*Hongteng Lin,Xiaotong Xiong,Junjie Liu,Yidong Huang,Fang Liu*

Main category: quant-ph

TL;DR: The paper develops a full quantum theory of electron-photon interaction including two-photon processes, revealing enhanced two-photon emission/absorption via optical near-field manipulation, quantum interference between single- and two-photon processes, and connections to Kapitza-Dirac effect and nonlinear Compton scattering.


<details>
  <summary>Details</summary>
Motivation: While PINEM has demonstrated quantum interactions between free electrons and optical near fields, existing studies focus primarily on single-photon processes. The physical mechanisms and phenomena of free electron-two-photon interactions remain unexplored, and the relationships between PINEM, Kapitza-Dirac effect, and nonlinear Compton scattering are unclear.

Method: Development of a full quantum theory of electron-photon interaction that explicitly includes two-photon processes. The theory analyzes how manipulating the electric field component of optical near fields can enhance two-photon emission/absorption and examines quantum interference between single- and two-photon processes.

Result: Two-photon emission/absorption by electrons can be greatly enhanced through optical near-field manipulation. Quantum interference between single- and two-photon processes affects photon number states, electron energy states, and electron-photon entanglement. The Kapitza-Dirac effect (elastic scattering) and nonlinear Compton scattering (inelastic scattering) are identified as specific types of two-photon processes, with electron distributions derivable analytically from the quantum theory.

Conclusion: The work uncovers rich phenomena in free electron-two-photon interactions, establishes connections between previously separate effects (PINEM, Kapitza-Dirac, nonlinear Compton), and provides a theoretical foundation for future studies of nonlinear processes in electron-photon quantum interactions.

Abstract: Photon-induced Near-field Electron Microscopy (PINEM) effect has revealed the quantum interaction between free electrons and optical near filed, which demonstrated plenty of novel phenomena of manipulating free electron wave packet and detecting/shaping quantum photonic states. However, free electrons generally only absorb/emit one photon at a time, while the physical mechanism and phenomena of free electron-two-photon interaction have not been studied yet. Moreover, the relationship between PINEM and Kapitza-Dirac (KD) effect and nonlinear Compton scattering is still unclear. Here we develop the full quantum theory of electron-photon interaction considering the two-photon process. It is revealed that the emission/absorption of two photons by electrons can be greatly enhanced by manipulating the electric field component of optical near field, and the quantum interference between single-photon and two-photon processes can occur in some circumstances, which affects the photon number state, electron energy states and electron-photon entanglement. Meanwhile, it is found that the KD effect (elastic electron-photon scattering) and nonlinear Compton scattering (inelastic electron-photon scattering) are also a kind of two-photon process and the distribution of electrons can be deduced analytically based on the full quantum theory. Our work uncovers the possible abundant phenomena when free electron interacting with two photons, paves the way for more in-depth studies of nonlinear processes in electron-photon quantum interactions in the future.

</details>


### [48] [A Survey of Bargmann Invariants: Geometric Foundations and Applications](https://arxiv.org/abs/2601.01858)
*Lin Zhang,Bing Xie*

Main category: quant-ph

TL;DR: Survey paper on Bargmann invariants - gauge-invariant quantities from quantum state overlaps that characterize the geometric structure of quantum mechanics and have applications in quantum information science.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive overview of Bargmann invariants and demonstrate their importance in understanding the geometric structure of quantum mechanics, particularly their role in shaping the informational geometry of quantum state space and their applications in modern quantum information science.

Method: Survey methodology synthesizing historical context with recent advances, demonstrating how Bargmann invariants serve as tools for characterizing intrinsic geometry of quantum state space, determining local unitary equivalence, constructing polynomial invariants for mixed states, and developing operational entanglement detection methods.

Result: Bargmann invariants provide a unifying framework for understanding quantum geometry, serve as powerful tools for characterizing state space geometry, enable determination of local unitary equivalence, provide complete polynomial invariants for mixed states, and facilitate operational entanglement detection without full state tomography.

Conclusion: Bargmann invariants are essential instruments for probing relational and geometric features of quantum systems, not merely mathematical curiosities, with significant applications in quantum information science including entanglement detection and state characterization.

Abstract: Bargmann invariants, a class of gauge-invariant quantities arising from the overlaps of quantum state vectors, provide a profound and unifying framework for understanding the geometric structure of quantum mechanics. This survey offers a comprehensive overview of Bargmann invariants, with a particular focus on their role in shaping the informational geometry of the state space. The core of this review demonstrates how these invariants serve as a powerful tool for characterizing the intrinsic geometry of the space of quantum states, leading to applications in determining local unitary equivalence and constructing a complete set of polynomial invariants for mixed states. Furthermore, we explore their pivotal role in modern quantum information science, specifically in developing operational methods for entanglement detection without the need for full state tomography. By synthesizing historical context with recent advances, this survey aims to highlight Bargmann invariants not merely as mathematical curiosities, but as essential instruments for probing the relational and geometric features of quantum systems.

</details>


### [49] [Random-Matrix-Induced Simplicity Bias in Over-parameterized Variational Quantum Circuits](https://arxiv.org/abs/2601.01877)
*Jun Qi,Chao-Han Huck Yang,Pin-Yu Chen,Min-Hsiu Hsieh*

Main category: quant-ph

TL;DR: Over-parameterized variational quantum circuits exhibit poor trainability and generalization due to function-class collapse into a Haar-like universality class, causing exponential concentration of observables and gradients. Tensor-structured architectures avoid this collapse by restricting unitary ensembles.


<details>
  <summary>Details</summary>
Motivation: To explain why deeper, more highly parameterized variational quantum circuits (VQCs) often show poor trainability and limited generalization despite increased expressivity, and to understand the underlying structural mechanisms beyond barren plateaus.

Method: Theoretical analysis using tools from random matrix theory and concentration of measure to characterize the universality class of unstructured variational ansatze. Comparison with tensor-structured VQCs (tensor-network-based and tensor-hypernetwork parameterizations) that restrict accessible unitary ensembles through bounded tensor rank or bond dimension.

Result: Sufficiently expressive, unstructured VQCs enter a Haar-like universality class where observable expectation values and parameter gradients concentrate exponentially with system size, leading to hypothesis class collapse (simplicity bias). Tensor-structured architectures prevent this concentration, preserve output variability for local observables, and maintain non-degenerate gradient signals even when over-parameterized.

Conclusion: Barren plateaus, expressivity limits, and generalization collapse in VQCs are unified under a single structural mechanism rooted in random-matrix universality. Architectural inductive bias (specifically tensor structure) is crucial for preventing function-class collapse and maintaining trainability in over-parameterized variational quantum algorithms.

Abstract: Over-parameterization is commonly used to increase the expressivity of variational quantum circuits (VQCs), yet deeper and more highly parameterized circuits often exhibit poor trainability and limited generalization. In this work, we provide a theoretical explanation for this phenomenon from a function-class perspective. We show that sufficiently expressive, unstructured variational ansatze enter a Haar-like universality class in which both observable expectation values and parameter gradients concentrate exponentially with system size. As a consequence, the hypothesis class induced by such circuits collapses with high probability to a narrow family of near-constant functions, a phenomenon we term simplicity bias, with barren plateaus arising as a consequence rather than the root cause. Using tools from random matrix theory and concentration of measure, we rigorously characterize this universality class and establish uniform hypothesis-class collapse over finite datasets. We further show that this collapse is not unavoidable: tensor-structured VQCs, including tensor-network-based and tensor-hypernetwork parameterizations, lie outside the Haar-like universality class. By restricting the accessible unitary ensemble through bounded tensor rank or bond dimension, these architectures prevent concentration of measure, preserve output variability for local observables, and retain non-degenerate gradient signals even in over-parameterized regimes. Together, our results unify barren plateaus, expressivity limits, and generalization collapse under a single structural mechanism rooted in random-matrix universality, highlighting the central role of architectural inductive bias in variational quantum algorithms.

</details>


### [50] [Pervasive Vulnerability Analysis and Defense for QKD-based Quantum Private Query](https://arxiv.org/abs/2601.01918)
*Xiaoyu Peng,Bin Liu,Shiyu He,Nankun Mu,Wei Huang,Bingjie Xu,Fei Gao*

Main category: quant-ph

TL;DR: QKD-based Quantum Private Query protocols have severe overlooked security vulnerabilities in post-processing stages, allowing information leakage through simple attacks; a multi-encryption defense scheme is proposed to address these flaws.


<details>
  <summary>Details</summary>
Motivation: Most existing QKD-based QPQ protocols have prevalent security vulnerabilities in their post-processing stages that have been severely overlooked, posing serious threats to database security even without complex quantum resources.

Method: The study analyzes hidden information extraction under undetermined signal bits, revealing two attack vectors: direct observation attack causing incremental information leakage, and minimum error discrimination attack efficiently stealing additional database information. A multi-encryption defense scheme compatible with existing QPQ protocols is proposed.

Result: The research demonstrates that most QKD-based QPQ protocols face severe security threats from simple attacks, and shows the necessity of the multi-encryption strategy for securing databases in QPQ applications.

Conclusion: The multi-encryption defense scheme provides key theoretical and technical support for constructing practical QPQ protocols resistant to real-world attacks, addressing critical security flaws in existing implementations.

Abstract: Quantum Private Query (QPQ) based on Quantum Key Distribution (QKD) is among the most practically viable quantum communication protocols, with application value second only to QKD itself. However, prevalent security vulnerabilities in the post-processing stages of most existing QKD-based QPQ protocols have been severely overlooked. This study focuses on hidden information extraction under undetermined signal bits, revealing that most such QPQ protocols face severe security threats even without complex quantum resources. Specifically, direct observation attack causes incremental information leakage, while the minimum error discrimination attack efficiently steals additional database inforamtion. To address these critical flaws, the proposed multi-encryption defense scheme is compatible with existing QPQ protocols. The study demonstrates the necessity of the multi-encryption strategy for the security of databases in QPQ, providing key theoretical and technical support for constructing practical QPQ protocols resistant to real-world attacks.

</details>


### [51] [Interpretation of Unfair Sampling in Quantum Annealing by Node Centrality](https://arxiv.org/abs/2601.01920)
*Naoki Maruyama,Masayuki Ohzeki*

Main category: quant-ph

TL;DR: Quantum annealing samples degenerate ground states with bias; analysis using degenerate perturbation theory reveals eigenvector centralities predict sampling probabilities, relating fairness to local energy landscape flatness.


<details>
  <summary>Details</summary>
Motivation: Quantum annealing (QA) exhibits strong bias when sampling degenerate ground states, but it's unclear which features are preferentially sampled and why. Understanding this bias is crucial for applications requiring multiple optimal solutions.

Method: Analyze final states using degenerate perturbation theory, revealing adjacency matrix of ground state graph emerges naturally. Predict eigenvector centralities relate to state probabilities. Verify on toy models where degeneracy is lifted at first and second order.

Result: Second-order weights encode local barrier information, connecting sampling fairness to flatness of local energy landscape. Eigenvector centralities successfully predict sampling probabilities in tested models.

Conclusion: Two practical routes toward fair sampling: promoting connectivity of the ground state graph and reducing heterogeneity of centralities. Results consistent with higher-order drivers and minor-embedding transformations.

Abstract: In applications where multiple optimal solutions are needed, transverse-field quantum annealing (QA) is known to sample degenerate ground states in a strongly biased manner. Despite extensive empirical observations, it remains unclear which features of degenerate ground states are preferentially sampled and why by QA. Here we analyze the final states using degenerate perturbation theory to characterize the preference among them. In this analysis, the adjacency matrix of the graph composed by the ground states naturally emerges, and we can predict the eigenvector centralities (one of the node centralities) are related to the probabilities of these states. We verify this prediction on toy models where degeneracy is lifted at first and second order, and we show that second-order weights encode local barrier information, relating sampling fairness to the flatness of the local energy landscape. Finally, this perspective suggests two practical routes toward fair sampling -- promoting connectivity of the graph and reducing heterogeneity of centralities -- and we illustrate consistency with higher-order drivers and minor-embedding transformations.

</details>


### [52] [Self-Supervised Learning with Noisy Dataset for Rydberg Microwave Sensors Denoising](https://arxiv.org/abs/2601.01924)
*Zongkai Liu,Qiming Ren,Wenguang Yang,Yanjie Tong,Huizhen Wang,Yijie Zhang,Ruohao Zhi,Junyao Xie,Mingyong Jing,Hao Zhang,Liantuan Xiao,Suotang Jia,Ke Tang,Linjie Zhang*

Main category: quant-ph

TL;DR: Self-supervised deep learning framework for Rydberg sensors achieves single-shot noise suppression matching multi-measurement averaging accuracy without clean reference signals.


<details>
  <summary>Details</summary>
Motivation: Quantum sensing with Rydberg atoms requires noise suppression, but traditional methods like multi-measurement averaging are computationally expensive and time-consuming. Current denoising approaches often require clean reference signals, which are rarely available in practical quantum sensing scenarios.

Method: Self-supervised deep learning framework trained on two sets of noisy signals with identical statistical distributions, eliminating need for clean reference signals. Evaluated U-Net and Transformer architectures for denoising performance.

Result: Outperforms wavelet transform and Kalman filtering, achieves denoising effect equivalent to 10,000-set averaging while reducing computation time by three orders of magnitude. Validated across diverse noise profiles and quantified complexity-performance trade-off between architectures.

Conclusion: The framework enables efficient single-shot noise suppression for Rydberg sensors without clean reference signals, providing actionable guidance for optimizing deep learning-based denoising in quantum sensing systems.

Abstract: We report a self-supervised deep learning framework for Rydberg sensors that enables single-shot noise suppression matching the accuracy of multi-measurement averaging. The framework eliminates the need for clean reference signals (hardly required in quantum sensing) by training on two sets of noisy signals with identical statistical distributions. When evaluated on Rydberg sensing datasets, the framework outperforms wavelet transform and Kalman filtering, achieving a denoising effect equivalent to 10,000-set averaging while reducing computation time by three orders of magnitude. We further validate performance across diverse noise profiles and quantify the complexity-performance trade-off of U-Net and Transformer architectures, providing actionable guidance for optimizing deep learning-based denoising in Rydberg sensor systems.

</details>


### [53] [On the homogeneity of the quantum transition probability](https://arxiv.org/abs/2601.01936)
*Gerd Niestegge*

Main category: quant-ph

TL;DR: The paper connects Wang and Hirzebruch's mathematical classification of two-point homogeneous compact spaces with convex metrics to quantum mechanical transition probability, showing maximum homogeneity in simple Euclidean Jordan algebras and distinguishing quantum logic via topological characterization of extreme state boundaries.


<details>
  <summary>Details</summary>
Motivation: To reveal the physical meaning of Wang and Hirzebruch's mathematical classification (1952, 1965) of two-point homogeneous compact spaces with convex metrics for quantum mechanical transition probability, and to show how this connects to simple Euclidean Jordan algebras which include finite-dimensional Hilbert space quantum theory.

Method: Analyzes the connection between Wang and Hirzebruch's classification (spheres, real/complex/octonion projective spaces, Moufang plane, minimal idempotents in simple Euclidean Jordan algebras) and quantum transition probability. Shows that transition probability features maximum homogeneity in simple Euclidean Jordan algebras. Uses topological characterization of extreme boundaries of state spaces rather than distinguishing entire state spaces among convex compact sets.

Result: Demonstrates that quantum mechanical transition probability exhibits maximum degree of homogeneity in all simple Euclidean Jordan algebras (including finite-dimensional Hilbert space quantum theory). Shows that atomic parts of these algebras/extreme boundaries of their state spaces can be characterized purely topologically. Identifies an interesting case with non-homogeneous transition probability when using the E₆-symmetric bioctonionic projective plane as quantum logic.

Conclusion: The paper establishes a deep connection between Wang and Hirzebruch's mathematical classification and quantum physics, showing that simple Euclidean Jordan algebras provide a framework where transition probability achieves maximum homogeneity. The topological characterization of extreme state boundaries offers a novel approach to distinguishing quantum systems, with the bioctonionic projective plane presenting an interesting non-homogeneous case for quantum logic.

Abstract: In the years 1952 and 1965, H.-C. Wang and U. Hirzebruch showed that the two-point homogeneous compact spaces with convex metrics are isometric to the spheres, the real, complex, octonion projective spaces and the Moufang plane and as well to the sets of the minimal idempotents or pure states in the simple Euclidean Jordan algebras. Here we reveal the physical meaning of these mathematical achievements for the quantum mechanical transition probability. We show that this transition probability features a maximum degree of homogeneity in all simple Euclidean Jordan algebras, which includes common finite-dimensional Hilbert space quantum theory. The atomic parts of these algebras or, equivalently, the extreme boundaries of their state spaces can be characterized by purely topological means. This is an important difference to many other recent approaches that aim to distinguish the entire state spaces among the convex compact sets. An interesting case with non-homogeneous transition probability arises, when the $E_6$-symmetric bioctonionic projective plane is used as quantum logic.

</details>


### [54] [Discrete symmetries in classical and quantum oscillators](https://arxiv.org/abs/2601.01960)
*Alexander D. Popov*

Main category: quant-ph

TL;DR: The paper shows that quantum harmonic oscillator eigenfunctions in Bargmann-Fock-Segal representation correspond to classical oscillator coordinates on conical spaces with discrete rotational symmetries.


<details>
  <summary>Details</summary>
Motivation: To understand the nature of the wave function by examining the relationship between quantum harmonic oscillator eigenfunctions and classical oscillator coordinates, exploring how quantum states emerge from classical phase space with discrete symmetries.

Method: Analyzes harmonic oscillator eigenfunctions ψ_n=z^n in complex Bargmann-Fock-Segal representation, showing they correspond to coordinates of classical oscillator with energy E_n=ħωn. Demonstrates these functions are defined on conical spaces ℂ/ℤ_n with cone angles 2π/n, embedded in classical phase space ℂ.

Result: Quantum eigenfunctions ψ_n are coordinates of classical oscillator on conical spaces with discrete rotational symmetries. Superposition ψ=∑c_nψ_n arises from incomplete knowledge of initial data when discrete group invariance conditions aren't imposed, allowing general solution with all possible initial data parametrized by n∈ℕ.

Conclusion: The wave function structure emerges from classical phase space with discrete symmetries, where quantum superpositions result from incomplete specification of initial conditions rather than fundamental quantum indeterminacy.

Abstract: We consider the nature of the wave function using the example of a harmonic oscillator. We show that the eigenfunctions $ψ_n{=}z^n$ of the quantum Hamiltonian in the complex Bargmann-Fock-Segal representation with $z\in\mathbb C$ are the coordinates of a classical oscillator with energy $E_n=\hbarωn$, $n=0,1,2,...\,$. They are defined on conical spaces ${\mathbb C}/{\mathbb Z}_n$ with cone angles $2π/n$, which are embedded as subspaces in the phase space $\mathbb C$ of the classical oscillator. Here ${\mathbb Z}_n$ is the finite cyclic group of rotations of the space $\mathbb C$ by an angle $2π/n$. The superposition $ψ=\sum_n c_nψ_n$ of the eigenfunctions $ψ_n$ arises only with incomplete knowledge of the initial data for solving the Schrödinger equation, when the conditions of invariance with respect to the discrete groups ${\mathbb Z}_n$ are not imposed and the general solution takes into account all possible initial data parametrized by the numbers $n\in\mathbb N$.

</details>


### [55] [Experimental realization of quantum Zeno dynamics for robust quantum metrology](https://arxiv.org/abs/2601.01987)
*Ran Liu,Xiaodong Yang,Xiang Lv,Xinyue Long,Hongfeng Liu,Dawei Lu,Ying Dong,Jun Li*

Main category: quant-ph

TL;DR: Experimental demonstration of quantum Zeno dynamics for robust quantum metrology using strong inter-particle interactions to overcome previous limitations, achieving near-optimal precision scaling under amplitude damping noise.


<details>
  <summary>Details</summary>
Motivation: Quantum Zeno dynamics offers a promising approach for protecting quantum information from noise, but previous studies focused on single-particle systems and faced challenges where QZD could interfere with parameter encoding. There's a need to harness QZD for practical quantum metrology applications.

Method: Introduce strong inter-particle interactions during parameter encoding stage to overcome typical limitations of previous QZD studies. Experimental validation on nuclear magnetic resonance platform, with numerical simulations to demonstrate scalability and compatibility with other control techniques.

Result: Achieved near-optimal precision scaling under amplitude damping noise in both parallel and sequential settings. Numerical simulations demonstrate scalability of the approach and compatibility with other control techniques for suppressing more general noise types.

Conclusion: Quantum Zeno dynamics is a powerful strategy for noise-resilient quantum metrology, with the proposed scheme overcoming previous limitations and demonstrating practical applicability through experimental validation and numerical simulations.

Abstract: Quantum Zeno dynamics (QZD), which restricts the system's evolution to a protected subspace, provides a promising approach for protecting quantum information from noise. Here, we explore a practical approach to harnessing QZD for robust quantum metrology. By introducing strong inter-particle interactions during the parameter encoding stage, we overcome the typical limitations of previous QZD studies, which have largely focused on single-particle systems and faced challenges where QZD could interfere with the encoding process. We experimentally validate the proposed scheme on a nuclear magnetic resonance platform, achieving near-optimal precision scaling under amplitude damping in both parallel and sequential settings. Numerical simulations further demonstrate the scalability of the approach and its compatibility with other control techniques for suppressing more general types of noise. These findings highlight QZD as a powerful strategy for noise-resilient quantum metrology.

</details>


### [56] [Continuous Unitary Designs for Universally Robust Quantum Control](https://arxiv.org/abs/2601.01988)
*Xiaodong Yang,Jiaqing Leng,Jun Li*

Main category: quant-ph

TL;DR: Continuous unitary designs extend discrete ensembles to continuous paths, enabling robust quantum control and noise mitigation through geometric/topological constructions.


<details>
  <summary>Details</summary>
Motivation: Physical processes like quantum chaos, thermalization, and control involve continuous time-evolution, but existing unitary design research focuses only on discrete ensembles, creating a gap between theory and practical applications.

Method: For single-qubit systems: explicit unitary 1-design paths from spherical 2-design curves and Hopf fibration theory. For arbitrary dimensions: two systematic frameworks - one based on topological bundle theory of the unitary group, another based on the Heisenberg-Weyl group.

Result: Unitary design paths provide analytical solutions for universally robust quantum control, outperforming conventional pulse techniques in mitigating arbitrary unknown static noises in simulations, demonstrating immediate utility for quantum engineering.

Conclusion: Continuous unitary designs introduce powerful geometric/topological tools complementing conventional methods, enhance experimental feasibility over discrete counterparts, and pave the way for exploring complex quantum dynamics and quantum information protocols.

Abstract: Unitary designs are unitary ensembles that emulate Haar-random unitary statistics. They provide a vital tool for studying quantum randomness and have found broad applications in quantum technologies. However, existing research has focused on discrete ensembles, despite that many physical processes, such as in quantum chaos, thermalization, and control, naturally involve continuous ensembles generated from continuous time-evolution. Here we initial the study of continuous unitary designs, addressing fundamental questions about their construction and practical utility. For single-qubit system, we construct explicit unitary 1-design paths from spherical 2-design curves and Hopf fibration theory. For arbitrary dimensions, we develop two systematic construction frameworks, one based on topological bundle theory of the unitary group and the other based on the Heisenberg-Weyl group. On the practical front, our unitary design paths provide analytical solutions to universally robust quantum control. Simulations show they outperform conventional pulse techniques in mitigating arbitrary unknown static noises, demonstrating immediate utility for quantum engineering. Extending unitary designs to the continuous domain not only introduces powerful geometric and topological tools that complement conventional combinatorial and group-theoretic methods, but also enhances experimental feasibility over discrete counterparts which usually involve instantaneous pulses. As an outlook, we anticipate that this work will pave the way for using continuous unitary designs to explore complex quantum dynamics and devise quantum information protocols.

</details>


### [57] [Parallel Quantum Gates via Scalable Subsystem-Optimized Robust Control](https://arxiv.org/abs/2601.01990)
*Xiaodong Yang,Ran Liu,Jun Li*

Main category: quant-ph

TL;DR: A scalable method for parallel quantum gate control that reduces crosstalk-induced errors by optimizing over constant-sized subsystems instead of full Hilbert space, achieving linear noise scaling for single-qubit gates and order-of-magnitude improvements for multi-qubit gates.


<details>
  <summary>Details</summary>
Motivation: Crosstalk between qubits in noisy quantum processors impedes high gate fidelities and makes full Hilbert-space control optimization prohibitively difficult for scalable quantum information processing.

Method: Reduces full-system optimization to crosstalk-robust control over constant-sized subsystems, eliminating leading-order gate operation deviations induced by crosstalk. Constructs analytical pulse solutions for parallel single-qubit gates and numerical pulses for parallel multi-qubit operations.

Result: Validated across multiple platforms (coupled NV centers, nuclear-spin processor, superconducting-qubit arrays up to 200 qubits). Noise scaling reduced from exponential to linear for parallel single-qubit gates, with order-of-magnitude reduction for parallel multi-qubit gates.

Conclusion: Establishes a scalable framework for parallel quantum control that doesn't require precise knowledge of crosstalk strengths or assumptions about qubit connectivity/lattice geometry, enabling practical implementation in large-scale quantum architectures.

Abstract: Accurate and efficient implementation of parallel quantum gates is crucial for scalable quantum information processing. However, the unavoidable crosstalk between qubits in current noisy processors impedes the achievement of high gate fidelities and renders full Hilbert-space control optimization prohibitively difficult. Here, we overcome this challenge by reducing the full-system optimization to crosstalk-robust control over constant-sized subsystems, which dramatically reduces the computational cost. Our method effectively eliminates the leading-order gate operation deviations induced by crosstalk, thereby suppressing error rates. Within this framework, we construct analytical pulse solutions for parallel single-qubit gates and numerical pulses for parallel multi-qubit operations. We validate the proposed approach numerically across multiple platforms, including coupled nitrogen-vacancy centers, a nuclear-spin processor, and superconducting-qubit arrays with up to 200 qubits. As a result, the noise scaling is reduced from exponential to linear for parallel single-qubit gates, and an order-of-magnitude reduction is achieved for parallel multi-qubit gates. Moreover, our method does not require precise knowledge of crosstalk strengths and makes no assumption about the underlying qubit connectivity or lattice geometry, thereby establishing a scalable framework for parallel quantum control in large-scale quantum architectures.

</details>


### [58] [Absolutely Maximal Contextual Correlations](https://arxiv.org/abs/2601.02009)
*Nripendra Majumdar,S. Aravinda*

Main category: quant-ph

TL;DR: The paper defines absolutely maximal contextual correlations (AMCC) as the contextual analogue of absolutely maximally entangled states, using contextual fraction as a metric, constructs infinite families of AMCC via parity check and CSP methods, and applies them to secret sharing and randomness extraction.


<details>
  <summary>Details</summary>
Motivation: To establish a formal correspondence between maximal entanglement in multipartite quantum systems and maximal non-local/contextual correlations, extending the bipartite PR box concept to multipartite settings and developing a rigorous framework for quantifying maximal contextual correlations.

Method: Uses sheaf-theoretic framework for contextuality to define contextual fraction (CF) metric (0 to 1). Defines AMCC as correlations with CF=1 and maximal marginals. Constructs AMCC families using parity check method and constraint satisfiability problem (CSP) scheme. Also identifies non-AMCC correlations (maximally contextual but without maximal marginals).

Result: Successfully defines AMCC as contextual analogue of AME states. Constructs infinite families of various AMCC forms in tripartite case (extending bipartite PR box). Demonstrates existence of both AMCC and non-AMCC correlations. Applies results to secret sharing and randomness extraction protocols.

Conclusion: The paper establishes a rigorous framework connecting maximal entanglement and maximal contextual correlations, provides constructive methods for generating AMCC, and demonstrates practical applications in quantum information processing tasks like secret sharing and randomness extraction.

Abstract: The foundational work by Bell led to an interest in understanding non-local correlations that arise from entangled states shared between distinct, spacelike-separated parties, which formed a foundation for the theory of quantum information processing. We investigate the question of maximal correlations analogous to the maximally entangled states defined in the entanglement theory of multipartite systems. To formalize this, we employ the sheaf-theoretic framework for contextuality, which generalizes non-locality. This provides a new metric for correlations called contextual fraction (CF), which ranges from 0 (non-contextual) to 1 (maximally contextual). Using this, we have defined the absolutely maximal contextual correlations (AMCC), which are maximally contextual and have maximal marginals, which captures the notion of absolutely maximal entangled (AME) states. The Popescu-Rohrlich (PR) box serves as the bipartite example, and we construct various extensions of such correlations in the tripartite case. An infinite family of various forms of AMCC is constructed using the parity check method and the constraint satisfiability problem (CSP) scheme. We also demonstrate the existence of maximally contextual correlations, which do not exhibit maximal marginals, and refer to them as non-AMCC. The results are further applied to secret sharing and randomness extraction using AMCC correlations.

</details>


### [59] [Integrating Quantum Software Tools with(in) MLIR](https://arxiv.org/abs/2601.02062)
*Patrick Hopf,Erick Ochoa Lopez,Yannick Stade,Damian Rovara,Nils Quetschlich,Ioan Albert Florea,Josh Izaac,Robert Wille,Lukas Burgholzer*

Main category: quant-ph

TL;DR: A practical guide for quantum software engineers to overcome MLIR's steep learning curve through a case study integrating PennyLane and MQT, aiming to foster MLIR adoption as a unifying bridge for quantum software interoperability.


<details>
  <summary>Details</summary>
Motivation: Quantum compilation is fragmented with ad hoc solutions lacking interoperability, preventing seamless integration of quantum software tools into cohesive toolchains. MLIR addresses similar challenges in classical computing but has a steep learning curve that hinders adoption in quantum computing where software is often built by experimentalists rather than experienced engineers.

Method: Provides a practical, hands-on guide through a concrete case study linking Xanadu's PennyLane framework with the Munich Quantum Toolkit (MQT). The paper outlines actionable integration steps, highlights best practices, and shares insights from real-world development experience.

Result: The paper delivers a practical framework for quantum tool developers to navigate MLIR's complexities, demonstrating how to integrate disparate quantum software tools and providing concrete guidance for overcoming MLIR's learning curve in quantum computing contexts.

Conclusion: MLIR can serve as a unifying bridge across the growing quantum software ecosystem, enabling more modular, interoperable, and integrated quantum software stacks. The guide aims to support quantum tool developers in adopting MLIR to address fragmentation and interoperability challenges in quantum compilation.

Abstract: Compilers transform code into action. They convert high-level programs into executable hardware instructions - a crucial step in enabling reliable and scalable quantum computation. However, quantum compilation is still in its infancy, and many existing solutions are ad hoc, often developed independently and from scratch. The resulting lack of interoperability leads to significant missed potential, as quantum software tools remain isolated and cannot be seamlessly integrated into cohesive toolchains.
  The Multi-Level Intermediate Representation (MLIR) has addressed analogous challenges in the classical domain. It was developed within the LLVM project, which has long powered robust software stacks and enabled compilation across diverse software and hardware components, with particular importance in high-performance computing environments. However, MLIR's steep learning curve poses a significant barrier to entry, particularly in quantum computing, where much of the software stack is still predominantly built by experimentalists out of necessity rather than by experienced software engineers.
  This paper provides a practical and hands-on guide for quantum software engineers to overcome this steep learning curve. Through a concrete case study linking Xanadu's PennyLane framework with the Munich Quantum Toolkit (MQT), we outline actionable integration steps, highlight best practices, and share hard-earned insights from real-world development. This work aims to support quantum tool developers in navigating MLIR's complexities and to foster its adoption as a unifying bridge across a rapidly growing ecosystem of quantum software tools, ultimately guiding the development of more modular, interoperable, and integrated quantum software stacks.

</details>


### [60] [Cutting Quantum Circuits Beyond Qubits](https://arxiv.org/abs/2601.02064)
*Manav Seksaria,Anil Prabhakar*

Main category: quant-ph

TL;DR: Quantum circuit cutting extended to heterogeneous registers with mixed-dimensional qudits, enabling simulation of high-dimensional circuits on disconnected hardware with exact state reconstruction and significant memory reduction.


<details>
  <summary>Details</summary>
Motivation: To enable simulation and execution of quantum circuits with mixed-dimensional qudits (heterogeneous registers) on disconnected hardware fragments by extending quantum circuit cutting techniques beyond homogeneous qubit systems.

Method: Decompose non-local interactions into tensor products of local generalized Gell-Mann matrices, extending quantum circuit cutting to heterogeneous registers comprising mixed-dimensional qudits, validated on qubit-qutrit (2-3) interfaces.

Result: Achieved exact state reconstruction with Total Variation Distance of 0 within single-precision floating-point tolerance, and demonstrated memory advantage in an 8-particle dimension-8 system, reducing memory usage from 128 MB to 64 KB per circuit.

Conclusion: The framework successfully extends quantum circuit cutting to heterogeneous quantum registers, enabling efficient simulation of high-dimensional circuits on disconnected hardware with significant memory savings and exact reconstruction capabilities.

Abstract: We extend quantum circuit cutting to heterogeneous registers comprising mixed-dimensional qudits. By decomposing non-local interactions into tensor products of local generalised Gell-Mann matrices, we enable the simulation and execution of high-dimensional circuits on disconnected hardware fragments. We validate this framework on qubit--qutrit ($2$--$3$) interfaces, achieving exact state reconstruction with a Total Variation Distance of 0 within single-precision floating-point tolerance. Furthermore, we demonstrate the memory advantage in an 8-particle, dimension-8 system, reducing memory usage from 128 MB to 64 KB per circuit.

</details>


### [61] [Optimization of modulation transfer protocol for Rydberg RF receivers](https://arxiv.org/abs/2601.02070)
*Mickael Branco,K V Adwaith,Duc-Anh Trinh,Sacha Welinski,Perrine Berger,Fabienne Goldfarb,Fabien Bretenaker*

Main category: quant-ph

TL;DR: The paper analyzes a modulation transfer protocol for extending bandwidth in quantum RF receivers using hot Rydberg atoms, showing it outperforms conventional methods for detuned RF signals.


<details>
  <summary>Details</summary>
Motivation: To extend the bandwidth of quantum RF receivers based on hot Rydberg atoms by developing and optimizing a modulation transfer protocol that can better handle detuned RF signals.

Method: Theoretical modeling and experimental validation of a modulation transfer protocol involving phase modulation of the coupling beam, which is transformed by atomic nonlinear response into amplitude modulation of the probe beam. Optimization of modulation frequency and amplitude to maximize atomic response.

Result: The optimized modulation transfer protocol outperforms conventional protocols for RF signals detuned by more than a few MHz, providing enhanced sensitivity and complementary approach to increase detection bandwidth. Experimental results show good agreement with simulations.

Conclusion: The modulation transfer protocol successfully extends the bandwidth of quantum RF receivers using hot Rydberg atoms, offering superior performance for detuned RF signals compared to conventional methods, with experimental validation confirming theoretical predictions.

Abstract: We explore theoretically and experimentally the recently demonstrated modulation transfer protocol [D.-A. Trinh, K. V. Adwaith, M. Branco, A. Rouxel, S. Welinski, P. Berger, F. Goldfarb, and F. Bretenaker, Applied Physics Letters 125, 154001 (2024)] aiming at extending the bandwidth of quantum RF receivers based on hot Rydberg atoms. This protocol is based on a phase modulation of the coupling beam, which is transformed by the nonlinear response of the atoms into an amplitude modulation of the probe beam. We develop a theoretical model to optimize both the modulation frequency and the modulation amplitude of the coupling beam, thereby maximizing the atomic response. Once optimized, the sensitivity to detuned RF fields of this modulation transfer protocol is compared with that of the conventional protocol. This comparison shows that the new protocol outperforms the usual one as soon as the RF signal to be measured is detuned by more than a few MHz and offers a complementary approach to increase the detection bandwidth. In all cases, the experimental results are in good agreement with the simulations.

</details>


### [62] [Adaptive Framework for Failure-Aware Protocols in Fusion-Based Graph-State Generation](https://arxiv.org/abs/2601.02087)
*Korbinian Staudacher,Bhilahari Jeevanesan,Tobias Guggemos*

Main category: quant-ph

TL;DR: Framework for optimizing photonic graph state generation using sequential fusion measurements with adaptive protocols and Markov process analysis to minimize fusion overhead.


<details>
  <summary>Details</summary>
Motivation: To efficiently build large photonic graph states from small linear clusters using non-deterministic fusion measurements, addressing the challenge of fusion failures and high hardware costs in linear optics quantum computing.

Method: Develop adaptive graph state generation protocols for linear cluster resources with Type-I/II fusions that reuse leftover states after failures. Model protocols as finite Markov processes, formulate expected fusion attempts as first passage problems, and deploy polynomial algorithms to optimize graph states, extract fusion networks, and find beneficial fusion orderings.

Result: The optimization strategies reduce fusion overhead by several orders of magnitude compared to simple repeat-until-success protocols, particularly for realistic fusion success probabilities between 50-75%.

Conclusion: The framework provides efficient methods for building large photonic graph states with adaptive fusion protocols and optimization algorithms that significantly lower hardware costs by minimizing required fusion attempts.

Abstract: We consider the generation of photonic graph states in a linear optics setting where sequential non-deterministic fusion measurements are used to build large graph states out of small linear clusters and develop a framework to optimize the building process using graph theoretic characterizations of fusion networks. We present graph state generation protocols for linear cluster resource states and Type-I/Type-II fusions which are adaptive to fusion failure, that is, they reuse leftover graph states in the remaining building process. To estimate hardware costs, we interpret our protocols as finite Markov processes. This viewpoint allows to cast the expected number of fusion measurements until success as a first passage problem. We then deploy a pipeline of polynomial algorithms to optimize arbitrary graph states, extract fusion networks and find beneficial orderings of fusions with the goal of lowering the corresponding mean first passage times. We evaluate our pipeline for different initial resource states and fusion mechanisms with varying success probabilities. Results show that our strategies can reduce the fusion overhead by several orders of magnitude when compared to simple repeat until success protocols, especially for realistic fusion success probabilities between 50-75 %.

</details>


### [63] [Efficient Calculation of the Maximal Rényi Divergence for a Matrix Product State via Generalized Eigenvalue Density Matrix Renormalization Group](https://arxiv.org/abs/2601.02122)
*Uri Levin,Noa Feldman,Moshe Goldstein*

Main category: quant-ph

TL;DR: The paper develops an efficient algorithm to compute maximal Rényi divergence for 1D quantum systems using matrix product states, benchmarking it on the XXZ chain and showing it differs from von Neumann mutual information.


<details>
  <summary>Details</summary>
Motivation: Quantum mutual information based on von Neumann entropy requires exponential resources due to the curse of dimensionality. Rényi divergence-based measures offer theoretical advantages as alternative correlation measures, but efficient computation methods are needed.

Method: Developed a generalized eigenvalue version of the density matrix renormalization group algorithm to efficiently compute maximal Rényi divergence for 1D states represented as matrix product states.

Result: Benchmarked the method on the paradigmatic XXZ chain, demonstrating that maximal Rényi divergence can exhibit different trends than von Neumann mutual information, revealing distinct correlation properties.

Conclusion: The developed algorithm enables efficient computation of maximal Rényi divergence for 1D quantum systems, providing an alternative correlation measure that captures different aspects of quantum correlations than von Neumann mutual information.

Abstract: The study of quantum and classical correlations between subsystems is fundamental to understanding many-body physics. In quantum information theory, the quantum mutual information, $I(A;B)$, is a measure of correlation between the subsystems $A,B$ in a quantum state, and is defined by the means of the von Neumann entropy: $I\left(A;B\right)=S\left(ρ_{A}\right)+S\left(ρ_{B}\right)-S\left(ρ_{AB}\right)$. However, such a computation requires an exponential amount of resources. This is a defining feature of quantum systems, the infamous ``curse of dimensionality'' . Other measures, which are based on Rényi divergences instead of von Neumann entropy, were suggested as alternatives in a recent paper showing them to possess important theoretical features, and making them leading candidates as mutual information measures. In this work, we concentrate on the maximal Rényi divergence. This measure can be shown to be the solution of a generalized eigenvalue problem. To calculate it efficiently for a 1D state represented as a matrix product state, we develop a generalized eigenvalue version of the density matrix renormalization group algorithm. We benchmark our method for the paradigmatic XXZ chain, and show that the maximal Rényi divergence may exhibit different trends than the von Neumann mutual information.

</details>


### [64] [Flux-noise-resilient transmon qubit via a doubly-connected gradiometric design](https://arxiv.org/abs/2601.02137)
*J. B. Fu,Da-Wei Wang,B. Ren,Z. H. Yang,S. Hu,G. Y. Huang,S. H. Cao,D. D. Liu,X. F. Zhang,X. Fu,S. C. Xue,Y. G. Che,Yu-xi Liu,M. T. Deng,J. J. Wu*

Main category: quant-ph

TL;DR: A gradiometric transmon qubit (8-mon) with nano-airbridge interconnect achieves enhanced coherence and stability by suppressing flux noise while maintaining full electrical tunability.


<details>
  <summary>Details</summary>
Motivation: Frequency-tunable superconducting transmon qubits suffer from sensitivity to low-frequency flux noise, which degrades their performance and limits coherence times in quantum processors.

Method: Developed a doubly-connected gradiometric transmon (8-mon) with a nano-airbridge linking two loops, preserving full electrical tunability while suppressing flux noise through geometric design. The airbridge eliminates dielectric loss and maintains compatibility with standard X-mon control/readout.

Result: Achieved T₁ comparable to reference X-mons and nearly threefold enhancement in Ramsey T₂* in small flux-bias regime, reaching same order as T₁ without echo decoupling. Superior long-term frequency stability without magnetic shielding. Experimental coherence trends reproduced by spatially correlated flux-noise model revealing coexistence of short- and long-correlation-length magnetic noise.

Conclusion: The 8-mon unifies high tunability with intrinsic flux-noise suppression through robust geometric design, providing a practical pathway toward more coherent and stable superconducting quantum processors.

Abstract: Frequency-tunable superconducting transmon qubits are a cornerstone of scalable quantum processors, yet their performance is often degraded by sensitivity to low-frequency flux noise. Here we present a doubly-connected gradiometric transmon (the ``8-mon") that incorporates a nano-airbridge to link its two loops. This design preserves full electrical tunability and remains fully compatible with standard X-mon control and readout, requiring no additional measurement overhead. The airbridge interconnect eliminates dielectric loss, which enables the 8-mon to achieve both energy relaxation times $T_{\rm 1}$ comparable to reference X-mons and, in the small flux-bias regime, a nearly threefold enhancement in Ramsey coherence time $T_{\rm 2}^*$. This improved $T_{\rm 2}^*$ reaches the same order as $T_{\rm 1}$ without employing echo decoupling. The device also exhibits superior long-term frequency stability even without any magnetic field shielding. We develop a spatially correlated flux-noise model whose simulations quantitatively reproduce the experimental coherence trends, revealing the coexistence of short- and long-correlation-length magnetic noise in the superconducting chip environment. By unifying high tunability with intrinsic flux-noise suppression through a robust geometric design, the 8-mon provides a practical pathway toward more coherent and stable superconducting quantum processors.

</details>


### [65] [Quantum Extreme Reservoir Computing for Phase Classification of Polymer Alloy Microstructures](https://arxiv.org/abs/2601.02150)
*Arisa Ikeda,Akitada Sakurai,Kae Nemoto,Mayu Muramatsu*

Main category: quant-ph

TL;DR: Quantum extreme reservoir computing (QERC) is applied to classify microstructure images of polymer alloys from self-consistent field theory (SCFT) simulations, demonstrating quantum machine learning on realistic engineering data rather than benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: To demonstrate the applicability of quantum machine learning to realistic engineering and materials science data, moving beyond standard benchmark datasets like MNIST, and to establish foundations for integrating quantum learning techniques into materials informatics.

Method: Quantum extreme reservoir computing (QERC) applied to microstructure image classification of polymer alloys generated using self-consistent field theory (SCFT). Numerical experiments examine key parameters: number of qubits, sampling cost (measurement shots), and reservoir configuration.

Result: Phase classifications are depicted as phase diagrams illustrating polymer morphology transitions, establishing understandable connections between quantum model outputs and material behavior. Results provide practical guidelines for quantum encoder design and model generalization.

Conclusion: This work demonstrates QERC performance on realistic materials datasets and establishes a foundation for integrating quantum learning techniques into materials informatics, showing practical applicability of quantum machine learning to engineering problems.

Abstract: Quantum machine learning (QML) is expected to offer new opportunities to process high-dimensional data efficiently by exploiting the exponentially large state space of quantum systems. In this work, we apply quantum extreme reservoir computing (QERC) to the classification of microstructure images of polymer alloys generated using self-consistent field theory (SCFT). While previous QML efforts have primarily focused on benchmark datasets such as MNIST, our work demonstrates the applicability of QERC to engineering data with direct materials relevance. Through numerical experiments, we examine the influence of key computational parameters-including the number of qubits, sampling cost (the number of measurement shots), and reservoir configuration-on classification performance. The resulting phase classifications are depicted as phase diagrams that illustrate the phase transitions in polymer morphology, establishing an understandable connection between quantum model outputs and material behavior. These results illustrate QERC performance on realistic materials datasets and suggest practical guidelines for quantum encoder design and model generalization. This work establishes a foundation for integrating quantum learning techniques into materials informatics.

</details>


### [66] [Optical nonlinearity of cold atomic ensemble driven by strong coherent field in a saturation regime](https://arxiv.org/abs/2601.02152)
*A. S. Usoltsev,L. V. Gerasimov,A. D. Manukhova,S. P. Kulik,D. V. Kupriyanov*

Main category: quant-ph

TL;DR: The paper analyzes how dielectric susceptibility in a dense medium of two-level atoms can significantly amplify optical nonlinearity, particularly parametric processes, potentially limiting quantum communication protocols using entangled photons.


<details>
  <summary>Details</summary>
Motivation: To understand how collective atomic dynamics in dense media affect optical nonlinearities and parametric processes, which has implications for quantum communication protocols relying on entangled photons.

Method: Microscopic analysis of dielectric susceptibility in a medium of vector-type two-level atoms driven by strong coherent fields, using Mollow-type nonlinear excitation regime for dilute gases and interpolating to dense media.

Result: In dense media, optical nonlinearity (especially parametric processes) can be significantly magnified by manipulating both coherent pump and sample density, potentially limiting quantum communication protocols using entangled photons.

Conclusion: Collective atomic dynamics in dense media can amplify parametric nonlinearities, imposing limitations on quantum communication protocols that utilize entangled photons generated through parametric processes.

Abstract: We present a microscopic analysis and evaluation of the dielectric susceptibility of a dielectric medium consisting of vector-type two-energy-level atoms responding on a weak probe mode when the atoms are driven by a strong coherent field. Each atom, in an environment of others, exists as a quasiparticle further structuring a bulk medium. In a limit of dilute atomic gas, the dynamics of each atom follows the Mollow-type nonlinear excitation regime, and the medium susceptibility collectivizes the individual atomic responses to the probe mode. We outline how the collective dynamics can be interpolated up to a dense medium, and we argue from general positions that in such a medium the optical nonlinearity and, in particular, its parametric part could be significantly magnified by manipulating both the coherent pump and the sample density. That indicates certain limitations for potential capabilities of quantum communication protocols utilizing the entangled photons, created by a parametric process, as a main resource of quantum correlations.

</details>


### [67] [Simulating Non-Markovian Dynamics in Open Quantum Systems](https://arxiv.org/abs/2601.02160)
*Meng Xu,Vasilii Vadimov,J. T. Stockburger,J. Ankerhold*

Main category: quant-ph

TL;DR: A systematic review of open quantum system simulation methods, presenting a unified framework to connect diverse approaches and address fragmentation in the field.


<details>
  <summary>Details</summary>
Motivation: The field of open quantum system dynamics faces fragmentation due to diverse simulation approaches from different communities, hindering cohesive advances and effective application to complex systems. There's a need to understand how different methods relate, their strengths/limitations, and to provide a unified perspective.

Method: The paper provides a systematic overview and concise discussion using a unified framework formulated in an extended state space that includes effective reservoir modes. This framework links different schemes including hierarchical equations of motion, Lindblad-pseudomode formulas, chain-mapping approaches, quantum Brownian motion master equations, stochastic unravelings, and refined quantum master equations.

Result: The unified framework enables comprehensive understanding of existing methods, elucidating their physical interpretations, interconnections, and applicability. It provides a systematic way to relate different approaches and catalyze further progress in the field.

Conclusion: The paper offers a cohesive framework to address fragmentation in open quantum system simulation methods, providing a comprehensive understanding of diverse approaches and their relationships, which should facilitate cross-community application and advance the field.

Abstract: Recent advances in quantum technologies and related experiments have created a need for highly accurate, versatile, and computationally efficient simulation techniques for the dynamics of open quantum systems. Long-lived correlation effects (non-Markovianity), system-environment hybridization, and the necessity for accuracy beyond the Born-Markov approximation form particular challenges. Approaches to meet these challenges have been introduced, originating from different fields, such as hierarchical equations of motion, Lindblad-pseudomode formulas, chain-mapping approaches, quantum Brownian motion master equations, stochastic unravelings, and refined quantum master equations. This diversity, while indicative of the field's relevance, has inadvertently led to a fragmentation that hinders cohesive advances and their effective cross-community application to current problems for complex systems. How are different approaches related to each other? What are their strengths and limitations? Here we give a systematic overview and concise discussion addressing these questions. We make use of a unified framework which very conveniently allows to link different schemes and, this way, may also catalyze further progress. In line with the state of the art, this framework is formulated not in a fully reduced space of the system but in an extended state space which in a minimal fashion includes effective reservoir modes. This in turn offers a comprehensive understanding of existing methods, elucidating their physical interpretations, interconnections, and applicability.

</details>


### [68] [Developments in superconducting erasure qubits for hardware-efficient quantum error correction](https://arxiv.org/abs/2601.02183)
*Maria Violaris,Luciana Henaut,James Wills,Gioele Consani,Jamie Friel,Brian Vlastakis*

Main category: quant-ph

TL;DR: The paper discusses erasure qubits as a hardware-efficient approach to quantum error correction, focusing on superconducting implementations and their potential for early fault-tolerant quantum computing.


<details>
  <summary>Details</summary>
Motivation: Quantum computers are inherently noisy, requiring error correction for large-scale fault-tolerant operation. Hardware with specific noise profiles can enable higher error thresholds with certain quantum error correcting codes, making erasure qubits a promising direction for hardware-efficient quantum error correction.

Method: The approach uses erasure qubits that concatenate an inner code built into the hardware with an outer code. The paper focuses specifically on dual-rail encoded erasure qubits implemented using superconducting qubits, examining theory, simulation, and hardware demonstrators.

Result: Recent developments show progress in theory, simulation, and hardware demonstrators for dual-rail encoded erasure qubits using superconducting qubits. The approach enables hardware-efficient quantum error correction with potential for near-term applications using quantum error detection.

Conclusion: Erasure qubits represent a promising path toward early fault-tolerant quantum computers, though open problems remain for further development of this approach.

Abstract: Quantum computers are inherently noisy, and a crucial challenge for achieving large-scale, fault-tolerant quantum computing is to implement quantum error correction. A promising direction that has made rapid recent progress is to design hardware that has a specific noise profile, leading to a significantly higher threshold for noise with certain quantum error correcting codes. This Perspective focuses on erasure qubits, which enable hardware-efficient quantum error correction, by concatenating an inner code built-in to the hardware with an outer code. We focus on implementations of dual-rail encoded erasure qubits using superconducting qubits, giving an overview of recent developments in theory and simulation, and hardware demonstrators. We also discuss the differences between implementations; near-term applications using quantum error detection; and the open problems for developing this approach towards early fault-tolerant quantum computers.

</details>


### [69] [PauliEngine: High-Performant Symbolic Arithmetic for Quantum Operations](https://arxiv.org/abs/2601.02233)
*Leon Müller,Adelina Bärligea,Alexander Knapp,Jakob S. Kottmann*

Main category: quant-ph

TL;DR: PauliEngine is a high-performance C++ framework for efficient Pauli string operations with Python interface, offering substantial speedups over existing implementations.


<details>
  <summary>Details</summary>
Motivation: Quantum computation requires fast classical manipulation of qubit operators for scalability. Existing tools lack the performance needed for large-scale quantum software development and simulations.

Method: Built on binary symplectic representation with optimized bit-wise operations. Supports both numerical and symbolic coefficients. Provides primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations.

Result: Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. The framework provides a scalable backend for operator-based quantum software tools.

Conclusion: PauliEngine offers an efficient, high-performance solution for Pauli string manipulation that enables scalable quantum software development through its C++ core and Python interface.

Abstract: Quantum computation is inherently hybrid, and fast classical manipulation of qubit operators is necessary to ensure scalability in quantum software. We introduce PauliEngine, a high-performance C++ framework that provides efficient primitives for Pauli string multiplication, commutators, symbolic phase tracking, and structural transformations. Built on a binary symplectic representation and optimized bit-wise operations, PauliEngine supports both numerical and symbolic coefficients and is accessible through a Python interface. Runtime benchmarks demonstrate substantial speedups over state-of-the-art implementations. PauliEngine provides a scalable backend for operator-based quantum software tools and simulations.

</details>


### [70] [A General Class of Functionals for Certifying Quantum Incompatibility](https://arxiv.org/abs/2601.02239)
*Kuan-Yi Lee,Jhen-Dong Lin,Adam Miranowicz,Yueh-Nan Chen*

Main category: quant-ph

TL;DR: A framework for optimization-free nonlinear incompatibility witnesses based on convex functionals, applicable to quantum steering, measurement, and instrument incompatibility, with connections to entanglement measures.


<details>
  <summary>Details</summary>
Motivation: To develop a unified framework for detecting quantum incompatibility (steering, measurement, instrument incompatibility) without optimization procedures, leveraging convex functionals to create efficient witnesses.

Method: Construct nonlinear incompatibility witnesses using convex functionals; prove witnesses are nontrivial when functionals are non-affine on extremal points; apply to pure bipartite states for entanglement bounds; extend to measurement/instrument incompatibility as genuine monotones.

Result: Witnesses outperform linear steering inequalities for pure states; provide lower bounds on entanglement measures; serve as genuine incompatibility monotones; demonstrated with Wigner-Yanase skew information and ℓ₂-coherence functional.

Conclusion: The framework offers versatile, optimization-free detection of quantum incompatibility across multiple manifestations, with operational relevance demonstrated through specific functionals.

Abstract: Quantum steering, measurement incompatibility, and instrument incompatibility have recently been recognized as unified manifestations of quantum incompatibility. Building on this perspective, we develop a general framework for constructing optimization-free, nonlinear incompatibility witnesses based on convex functionals, valid in arbitrary dimensions. We prove that these witnesses are nontrivial precisely when the underlying functional is non-affine on extremal points (e.g., pure states for ensembles). For pure bipartite states, the witnesses yield lower bounds on entanglement measures, thereby outperforming most linear steering inequalities in the pure-state regime. Moreover, the construction extends in full generality to certify measurement and instrument incompatibility, where the witnesses act as genuine incompatibility monotones. We demonstrate the versatility of our approach with two operationally relevant functionals: the Wigner-Yanase skew information and an $\ell_{2}$-type coherence functional.

</details>


### [71] [Topological Obstructions for Quantum Adiabatic Algorithms: Evidence from MaxCut Instances](https://arxiv.org/abs/2601.02255)
*Prathamesh S. Joshi*

Main category: quant-ph

TL;DR: Quantum adiabatic algorithms exhibit complex global spectral flow constraints due to degeneracy, beyond local gap analysis, with persistent spectral congestion and band permutations that cannot be eliminated by longer evolution times.


<details>
  <summary>Details</summary>
Motivation: Current analysis of quantum adiabatic algorithms focuses on local spectral properties like minimum energy gaps, which fails to capture global constraints imposed by degeneracy in optimization problems with solution manifolds, even when algorithms succeed.

Method: Analyze eigenphases of cumulative unitary operators along interpolation paths in digitized quantum adiabatic evolutions, track eigenphase trajectories, and study spectral band interactions using MaxCut instances with controlled degeneracy as test cases.

Result: Demonstrated that degeneracy forces multiple spectral bands to interact, braid, and permute before coalescing into degenerate manifolds, creating persistent spectral congestion and nontrivial band permutations that remain even with increased evolution time or refined digitization.

Conclusion: Successful adiabatic optimization can coexist with complex spectral flow constraints, revealing topological obstructions rooted in global eigenstate connectivity rather than local gap closures, highlighting limitations of gap-based analyses and motivating spectral-flow-based diagnostics.

Abstract: Quantum adiabatic algorithms are commonly analyzed through local spectral properties of an interpolating Hamiltonian, most notably the minimum energy gap. While this perspective captures an important constraint on adiabatic runtimes, it does not fully describe the global structure of spectral evolution in optimization problems with degenerate solution manifolds. In this work, we show that degeneracy alone imposes unavoidable global constraints on spectral flow, even in instances where adiabatic algorithms succeed with high probability. Focusing on digitized quantum adiabatic evolutions, we analyze the eigenphases of the cumulative unitary operator generated along the interpolation path. By explicitly tracking eigenphase trajectories, we demonstrate that multiple spectral bands are forced to interact, braid, and permute before coalescing into a degenerate manifold at the end of the evolution. This global reordering manifests as persistent spectral congestion and nontrivial band permutations that cannot be removed by increasing evolution time or refining the digitization. Using MaxCut instances with controlled degeneracy as a concrete setting, we extract quantitative diagnostics of spectral congestion and explicitly compute the induced band permutations. Our results show that successful adiabatic optimization can coexist with complex and constrained spectral flow, revealing a form of topological obstruction rooted in the global connectivity of eigenstates rather than in local gap closures. These findings highlight intrinsic limitations of gap-based analyses and motivate spectral-flow-based diagnostics for understanding adiabatic algorithms in degenerate optimization landscapes.

</details>


### [72] [Schwarz maps with symmetry](https://arxiv.org/abs/2601.02282)
*Alfonso García-Velo,Alberto Ibort*

Main category: quant-ph

TL;DR: The paper applies symmetry theory to classify and analyze quantum maps (CPTP, PPT, Schwarz) with unitary group symmetries, deriving explicit parameter conditions and proving PPT² properties for various symmetric families.


<details>
  <summary>Details</summary>
Motivation: To understand how group symmetry constrains the structure of important quantum maps (CPTP, PPT, Schwarz maps) and to systematically classify symmetric maps with applications to quantum information theory.

Method: Develop general structure for equivariant maps between C*-algebras, then systematically study unital Hermiticity-preserving maps with unitary group symmetries. Classify U(n)-equivariant maps on M_n(ℂ), determine complete positivity and Schwarz conditions, extend to diagonal unitary and tensor-product symmetries, and analyze PPT properties.

Result: Complete classification of U(n)-equivariant maps on M_n(ℂ) with explicit algebraic inequalities for Schwarz and completely positive parameter regions. Partial classifications for DU(n)-equivariant and tensor-product symmetric maps. Proof that U(n)-equivariant family satisfies PPT ⇔ EB, while DU(2), symmetric DU(3), U(2)⊗U(2) and U(2)⊗U(3) families obey PPT² conjecture via symmetry arguments.

Conclusion: Group symmetry fundamentally controls the structure of non-completely positive quantum maps, providing systematic classification and new concrete examples where PPT² property holds, advancing understanding of symmetric quantum operations in quantum information theory.

Abstract: The theory of symmetry of quantum mechanical systems is applied to study the structure and properties of several classes of relevant maps in quantum information theory: CPTP, PPT and Schwarz maps. First, we develop the general structure that equivariant maps $Φ:\mathcal A \to \mathcal B$ between $C^\ast$-algebras satisfy. Then, we undertake a systematic study of unital, Hermiticity-preserving maps that are equivariant under natural unitary group actions. Schwarz maps satisfy Kadison's inequality $Φ(X^\ast X) \geq Φ(X)^\ast Φ(X)$ and form an intermediate class between positive and completely positive maps. We completely classify $U(n)$-equivariant on $M_n(\mathbb C)$ and determine those that are completely positive and Schwarz. Partial classifications are then obtained for the weaker $DU(n)$-equivariance (diagonal unitary symmetry) and for tensor-product symmetries $U(n_1) \otimes U(n_2)$. In each case, the parameter regions where $Φ$ is Schwarz or completely positive are described by explicit algebraic inequalities, and their geometry is illustrated. Finally, we further show that the $U(n)$-equivariant family satisfies $\mathrm{PPT} \iff \mathrm{EB}$, while the $DU(2)$, symmetric $DU(3)$, $U(2) \otimes U(2)$ and $U(2) \otimes U(3)$, families obey the $\mathrm{PPT}^2$ conjecture through a direct symmetry argument. These results reveal how group symmetry controls the structure of non-completely positive maps and provide new concrete examples where the $\mathrm{PPT}^2$ property holds.

</details>


### [73] [Binarisation-loophole-free observation of high-dimensional quantum nonlocality](https://arxiv.org/abs/2601.02350)
*Jia-le Miao,Elna Svegborn,Zhuo Chen,Yu Guo,Xiao-Min Hu,Yun-Feng Huang,Chuan-Feng Li,Guang-Can Guo,Armin Tavakoli,Bi-Heng Liu*

Main category: quant-ph

TL;DR: Researchers close a loophole in high-dimensional Bell inequality tests by using genuine multi-outcome measurements with four-dimensional photonic path-mode entanglement, demonstrating genuinely high-dimensional nonlocality free of the binarisation loophole.


<details>
  <summary>Details</summary>
Motivation: High-dimensional Bell inequality tests often use binary-outcome measurements that emulate multi-outcome measurements, creating a "binarisation loophole" that can be exploited by local hidden variable models, undermining the validity of high-dimensional nonlocality demonstrations.

Method: Used four-dimensional photonic path-mode entanglement with genuine multi-outcome detection (not emulated via binary measurements). Tested both the Collins-Gisin-Linden-Massar-Popescu (CGLMP) inequality and a related Bell inequality specifically tailored for maximally entangled states in high dimensions.

Result: Observed significant violations of both Bell inequalities. The violations were large enough to rule out not only local hidden variable models but also any quantum model based on lower-dimensional entanglement, thereby demonstrating genuinely high-dimensional nonlocality.

Conclusion: Successfully closed the binarisation loophole in high-dimensional Bell inequality tests by implementing genuine multi-outcome measurements with four-dimensional photonic entanglement, providing a robust demonstration of genuinely high-dimensional nonlocality free from measurement reduction artifacts.

Abstract: Bell inequality tests based on high-dimensional entanglement usually require measurements that can resolve multiple possible outcomes. However, the implementation of high-dimensional multi-outcome measurements is often only emulated via a collection of ``click or no-click'' measurements. This reduction of multi-outcome measurements to binary-outcome measurements opens a loophole in high-dimensional tests Bell inequalities which can be exploited by local hidden variable models [Tavakoli et al., Phys. Rev. A 111, 042433 (2025)]. Here, we close this loophole by using four-dimensional photonic path-mode entanglement and multi-outcome detection. We test both the well-known Collins-Gisin-Linden-Massar-Popescu inequality and a related Bell inequality tailored for maximally entangled states in high-dimension. We observe violations that are large enough to also rule out any quantum model based on entanglement of lower dimension, thereby demonstrating genuinely high-dimensional nonlocality free of the binarisation loophole.

</details>
