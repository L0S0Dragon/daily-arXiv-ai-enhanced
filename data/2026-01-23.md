<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 40]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Precision limit under weak-coupling with ancillary qubit](https://arxiv.org/abs/2601.15354)
*Peng Chen,Jun Jing*

Main category: quant-ph

TL;DR: Measurement-based quantum metrology protocol using spin ensemble coupled to qubit achieves Heisenberg-limited phase sensitivity via unconditional measurement and optimized coupling.


<details>
  <summary>Details</summary>
Motivation: To develop quantum metrology protocols that can exceed the standard quantum limit without requiring complex resources like GHZ states or squeezing Hamiltonians, using simpler measurement-based approaches.

Method: Composite system with spin ensemble probe coupled to ancillary qubit via Heisenberg XXZ interaction; optimized weak coupling and joint evolution; unconditional measurement on qubit creates two-component state with large eigenspace distance; parity detection on qubit or probe system.

Result: Quantum Fisher information shows exact or asymptotic quadratic scaling with probe size N (spin number); phase sensitivity approaches Heisenberg limit; scaling behavior robust to imperfect encoding operator and coupling strength.

Conclusion: Unconditional measurement on qubit can efficiently replace GHZ-like states and squeezing Hamiltonians for surpassing standard quantum limit in metrology precision.

Abstract: We propose a measurement-based quantum metrology protocol in a composite model, where the probe system (a spin ensemble) is coupled to an ancillary two-level system (qubit) with a general Heisenberg XXZ interaction. With an optimized and weak probe-ancilla coupling strength and a proper duration of joint evolution, the two parallel evolution paths of the probe system induced by the unconditional measurement on qubit can transform an eigenstate of the collective angular momentum operator of spin ensemble to be a two-component state with a large distance in eigenspace. The quantum Fisher information about the phase encoded in the probe system of polarized states or their superposition, that could be relaxed to mixed states, can therefore manifest an exact or asymptotic quadratic scaling with respect to the probe size (spin number) $N$. The quadratic scaling behavior is found to be insensitive to the imperfect encoding operator and coupling strength. By virtue of the parity detection on the ancillary qubit or the probe system, the phase sensitivity can approach the Heisenberg limit. We suggest that the unconditional measurement on qubit could become an efficient resource to replace Greenberger-Horne-Zeilinger-like states and squeezing Hamiltonian for exceeding the standard quantum limit in metrology precision.

</details>


### [2] [USDs: A universal stabilizer decoder framework using symmetry](https://arxiv.org/abs/2601.15361)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: quant-ph

TL;DR: Generalizes decoder re-optimization technique from toric code to arbitrary stabilizer codes to address label degeneracy in deep learning-based quantum error correction decoding, achieving accuracy improvements for Color and Golay codes.


<details>
  <summary>Details</summary>
Motivation: Address the challenge of label degeneracy in deep learning-based quantum error correction decoding, where multiple error patterns correspond to the same syndrome measurements, making ground-truth labeling ambiguous.

Method: Generalize prior toric code decoder re-optimization approach to arbitrary stabilizer codes using multilayer perceptrons to approximate continuous functions that complement syndrome measurements, then perform decoder re-optimization for each code.

Result: For Color code: ~0.8% decoding accuracy improvement at 5% physical error rate; for Golay code: ~0.1% accuracy increase. Continuous function approximations that faithfully reproduce code structure significantly impact re-optimization effectiveness.

Conclusion: Decoder re-optimization technique effective for toric code can be generalized to address label degeneracy in deep learning-based decoding of stabilizer codes, with approximations that capture code structure being crucial for learning effectiveness.

Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.

</details>


### [3] [The computational two-way quantum capacity](https://arxiv.org/abs/2601.15393)
*Johannes Jakob Meyer,Jacopo Rizzo,Asad Raza,Lorenzo Leone,Sofiene Jerbi,Jens Eisert*

Main category: quant-ph

TL;DR: Computational quantum capacities differ from standard capacities by requiring computationally efficient encoding/decoding, leading to stark separations where channels with maximal unbounded capacity can have zero computational capacity under standard cryptographic assumptions.


<details>
  <summary>Details</summary>
Motivation: Standard quantum channel capacity definitions don't limit computational resources of sender and receiver, but practical quantum communication requires computationally efficient encoding and decoding operations.

Method: Initiate study of computational quantum capacities, focusing on computational two-way quantum capacity. Show connection to computational distillable entanglement of channel's Choi state. Use cryptographic assumptions to construct polynomial-complexity channels with capacity separation.

Result: Under standard cryptographic assumptions, there exists polynomial-complexity quantum channels whose computational two-way quantum capacity is zero while unbounded capacity is nearly maximal. Sharp transition occurs when channel complexity leaves polynomial realm.

Conclusion: Computational efficiency requirement radically alters quantum communication limits, creating stark separations between computational and unbounded capacities that depend on channel complexity.

Abstract: Quantum channel capacities are fundamental to quantum information theory. Their definition, however, does not limit the computational resources of sender and receiver. In this work, we initiate the study of computational quantum capacities. These quantify how much information can be reliably transmitted when imposing the natural requirement that en- and decoding have to be computationally efficient. We focus on the computational two-way quantum capacity and showcase that it is closely related to the computational distillable entanglement of the Choi state of the channel. This connection allows us to show a stark computational capacity separation. Under standard cryptographic assumptions, there exists a quantum channel of polynomial complexity whose computational two-way quantum capacity vanishes while its unbounded counterpart is nearly maximal. More so, we show that there exists a sharp transition in computational quantum capacity from nearly maximal to zero when the channel complexity leaves the polynomial realm. Our results demonstrate that the natural requirement of computational efficiency can radically alter the limits of quantum communication.

</details>


### [4] [Quadratic tensors as a unification of Clifford, Gaussian, and free-fermion physics](https://arxiv.org/abs/2601.15396)
*Andreas Bauer,Seth Lloyd*

Main category: quant-ph

TL;DR: The paper presents a unified algebraic framework using quadratic functions over abelian groups/Hopf algebras to describe and efficiently simulate various solvable quantum models including Clifford circuits, stabilizer codes, free bosons/fermions, and rotor/GKP codes.


<details>
  <summary>Details</summary>
Motivation: To provide a unified mathematical framework that captures diverse families of solvable quantum models (Clifford circuits, stabilizer codes, free particles, rotor codes) which are currently treated separately, enabling efficient classical simulation and generalization to mixed degrees of freedom.

Method: Develops a formalism based on quadratic functions over abelian groups and (super) Hopf algebras, where different quantum degrees of freedom correspond to different elementary groups/algebras. Represents quantum objects as quadratic tensors that can be efficiently specified (O(n²) coefficients) and contracted using Schur complement-like operations.

Result: Shows that all mentioned solvable quantum models can be described as instances of the same quadratic function framework. Demonstrates efficient tensor contraction algorithms for quadratic tensors, generalization to mixed degrees of freedom, and extension to generalized stabilizer codes and Clifford gates for arbitrary abelian groups.

Conclusion: Quadratic functions over abelian groups/Hopf algebras provide a unifying algebraic structure for diverse solvable quantum models, enabling efficient classical simulation, generalization to mixed systems, and extension to higher-order tensors (though with less efficient contraction).

Abstract: Certain families of quantum mechanical models can be described and solved efficiently on a classical computer, including qubit or qudit Clifford circuits and stabilizer codes, free-boson or free-fermion models, and certain rotor and GKP codes. We show that all of these families can be described as instances of the same algebraic structure, namely quadratic functions over abelian groups, or more generally over (super) Hopf algebras. Different kinds of degrees of freedom correspond to different "elementary" abelian groups or Hopf algebras: $\mathbb{Z}_2$ for qubits, $\mathbb{Z}_d$ for qudits, $\mathbb{R}$ for continuous variables, both $\mathbb{Z}$ and $\mathbb{R}/\mathbb{Z}$ for rotors, and a super Hopf algebra $\mathcal F$ for fermionic modes. Objects such as states, operators, superoperators, or projection-operator valued measures, etc, are tensors. For the solvable models above, these tensors are quadratic tensors based on quadratic functions. Quadratic tensors with $n$ degrees of freedom are fully specified by only $O(n^2)$ coefficients. Tensor networks of quadratic tensors can be contracted efficiently on the level of these coefficients, using an operation reminiscent of the Schur complement. Our formalism naturally includes models with mixed degrees of freedom, such as qudits of different dimensions. We also use quadratic functions to define generalized stabilizer codes and Clifford gates for arbitrary abelian groups. Finally, we give a generalization from quadratic (or 2nd order) to $i$th order tensors, which are specified by $O(n^i)$ coefficients but cannot be contracted efficiently in general.

</details>


### [5] [Dissipative Quantum Dynamics in Static Network with Different Topologies](https://arxiv.org/abs/2601.15439)
*Wei-Yang Liu,Hsuan-Wei Lee*

Main category: quant-ph

TL;DR: The paper investigates how network topology affects quantum dissipative dynamics in spin networks coupled to thermal baths, using Lindblad master equations and mean-field approaches to connect structure to coherence control.


<details>
  <summary>Details</summary>
Motivation: To understand how network topology shapes quantum dissipative dynamics and coherence in quantum networks, with potential applications to complex systems like social models, epidemiology, and biological systems.

Method: Two-part approach: (1) Lindblad master equation analysis of small Ising spin networks coupled to thermal bosonic reservoirs, (2) mean-field approach for extending to large-scale networks to capture dissipative dynamics.

Result: Network topology significantly shapes quantum dissipative dynamics, revealing sensitivity of quantum coherence to network structure and providing basis for coherence control through tailored network designs.

Conclusion: Dissipative quantum dynamics strongly depend on network topology, offering insights into coherent dynamics of entangled states in networks with potential extensions to complex systems across multiple domains.

Abstract: We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems.

</details>


### [6] [Check-weight-constrained quantum codes: Bounds and examples](https://arxiv.org/abs/2601.15446)
*Lily Wang,Andy Zeyi Liu,Ray Li,Aleksander Kubica,Shouzhen Gu*

Main category: quant-ph

TL;DR: The paper establishes fundamental limitations on quantum LDPC code parameters when check weights are constrained, proving no nontrivial distance for weight-3 stabilizer codes and tight rate-distance tradeoffs for weight-4 CSS and weight-2 subsystem codes, with numerical bounds for finite-size codes.


<details>
  <summary>Details</summary>
Motivation: To understand how constraints on check weight limit achievable parameters of qLDPC codes, which are crucial for building noise-resilient quantum computers due to their compatibility with noisy hardware through low-weight check measurements.

Method: Combines analytical arguments with numerical optimization, using linear programming techniques for finite-size bounds, and studies stabilizer and subsystem codes with constrained check weight.

Result: Proves stabilizer codes with weight-3 checks cannot have nontrivial distance; establishes tight rate-distance tradeoffs for CSS codes with weight-4 checks and subsystem codes with weight-2 checks; derives numerical upper bounds for finite-size codes and identifies constructions approaching these limits.

Conclusion: The work provides fundamental bounds on qLDPC code parameters under check-weight constraints, delineating the landscape of practically relevant codes for quantum computing applications with tens to hundreds of physical qubits.

Abstract: Quantum low-density parity-check (qLDPC) codes can be implemented by measuring only low-weight checks, making them compatible with noisy quantum hardware and central to the quest to build noise-resilient quantum computers. A fundamental open question is how constraints on check weight limit the achievable parameters of qLDPC codes. Here, we study stabilizer and subsystem codes with constrained check weight, combining analytical arguments with numerical optimization to establish strong upper bounds on their parameters. We show that stabilizer codes with checks of weight at most three cannot have nontrivial distance. We also prove tight tradeoffs between rate and distance for broad families of CSS stabilizer and subsystem codes with checks of weight at most four and two, respectively. Notably, our bounds are applicable to general qLDPC codes, as they rely only on check-weight constraints without assuming geometric locality or special graph connectivity. In the finite-size regime, we derive numerical upper bounds using linear programming techniques and identify explicit code constructions that approach these limits, delineating the landscape of practically relevant qLDPC codes with tens or hundreds of physical qubits.

</details>


### [7] [Studying energy-resolved transport with wavepacket dynamics on quantum computers](https://arxiv.org/abs/2601.16180)
*Melody Lee,Roland C. Farrell*

Main category: quant-ph

TL;DR: Wavepackets enable energy-resolved transport studies on quantum computers, revealing a mobility edge in Anderson model and offering scalable methods for many-body systems with improved error mitigation.


<details>
  <summary>Details</summary>
Motivation: Existing quantum simulation approaches using simple initial states (computational basis states) have poor energy resolution, limiting the study of energy-dependent transport phenomena. There's a need for methods that can prepare states with tunable energy and small energy variance to probe transport properties with better energy resolution.

Method: Use wavepackets as initial states to probe transport with improved energy resolution. Demonstrate on Quantinuum's H2-2 quantum computer with Anderson model on 8x7 lattice. Implement error mitigation using maximum-likelihood estimation to infer noiseless output distributions. Develop quantum algorithm for preparing quasiparticle wavepackets in interacting fermion models with modest resource requirements.

Result: Observed energy-dependent localization transition (finite-size mobility edge) in Anderson model: low-energy wavepackets remain localized while high-energy wavepackets delocalize. Error mitigation strategy reduced statistical uncertainty by up to factor of 5 compared to post-selection. Extended methods to many-particle regime with scalable wavepacket preparation algorithm.

Conclusion: Wavepacket-based approaches provide superior energy resolution for studying transport in quantum simulators, enabling observation of mobility edges and offering promising near-term applications for many-body systems with efficient error mitigation and modest quantum resource requirements.

Abstract: Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.

</details>


### [8] [A Sublinear-Time Quantum Algorithm for High-Dimensional Reaction Rates](https://arxiv.org/abs/2601.15523)
*Tyler Kharazi,Ahmad M. Alkadri,Kranthi K. Mandadapu,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: Quantum algorithm for Fokker-Planck equation achieves exponential speedup in particle number, quartic speedup in error tolerance, and quadratic speedup in time compared to classical worst-case bounds.


<details>
  <summary>Details</summary>
Motivation: The Fokker-Planck equation models rare events in high-dimensional systems, but classical computers struggle with its dimensionality. Existing quantum algorithms suffer from exponential decay in success probability when simulating non-unitary dynamics.

Method: Developed Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) using sum-of-squares representation to represent non-unitary propagator. Paired with novel technique to directly estimate matrix elements without exponential decay. Uses block encoding with O(√(t‖H‖log(1/ε))) queries.

Result: For η pairwise interacting particles with N plane waves per degree of freedom, reactive flux estimation to error ε requires Õ((η^{5/2}√(tβ)α_V + η^{3/2}√(t/β)N)/ε) quantum gates. Achieves exponential separation in η, quartic speedup in ε, and quadratic speedup in t compared to classical worst-case bounds O(te^{Ω(η)}/ε^4).

Conclusion: The algorithm provides a rigorous route toward quantum advantage for high-dimensional dissipative dynamics, overcoming exponential decay issues in previous quantum approaches and demonstrating significant speedups over classical worst-case analytical bounds.

Abstract: The Fokker-Planck equation models rare events across sciences, but its high-dimensional nature challenges classical computers. Quantum algorithms for such non-unitary dynamics often suffer from exponential {decay in} success probability. We introduce a quantum algorithm that overcomes this for computing reaction rates. Using a sum-of-squares representation, we develop a Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) to represent the non-unitary propagator with $O\left(\sqrt{t\|H\|\log(1/ε)}\right)$ queries to its block encoding. Crucially, we pair this with {a} novel technique to directly estimate matrix elements without exponential decay. For $η$ pairwise interacting particles discretized with $N$ plane waves per degree of freedom, we estimate reactive flux to error $ε$ using $\widetilde{O}\left((η^{5/2}\sqrt{tβ}α_V + η^{3/2}\sqrt{t/β}N)/ε\right)$ quantum gates, where $α_V = \max_{r}|V'(r)/r|$. For non-convex potentials, the {sharpest classical} worst-case analytical bounds to simulate the related overdamped Langevin {equation} scale as $O(te^{Ω(η)}/ε^4)$. This {implies} an exponential separation in particle number $η$, a quartic speedup in $ε$, and quadratic speedup in $t$. While specialized classical heuristics may outperform these bounds in practice, this demonstrates a rigorous route toward quantum advantage for high-dimensional dissipative dynamics.

</details>


### [9] [Bidirectional teleportation using scrambling dynamics: a practical protocol](https://arxiv.org/abs/2601.15536)
*Amit Vikram,Edwin Chaparro,Muhammad Miskeen Khan,Andrew Lucas,Chris Akers,Ana Maria Rey*

Main category: quant-ph

TL;DR: Quantum scrambling enables SWAP gate between collective degrees of freedom without local control via Hayden-Preskill recovery and teleportation running in parallel opposite directions.


<details>
  <summary>Details</summary>
Motivation: To enable generic quantum gates (specifically SWAP gates) between collective degrees of freedom in systems lacking universal local control, leveraging quantum information scrambling phenomena.

Method: Combines Hayden-Preskill recovery scheme (from black hole information paradox) with quantum teleportation, running them in parallel and opposite directions to enable bidirectional state exchange through global interactions alone. Uses Dicke model for experimental realization in cavity-QED and trapped-ion platforms.

Result: Demonstrates that quantum scrambling can enable coherent state transfer and recovery between collective degrees of freedom without requiring local control, distinguishing the roles of information spreading, entanglement, and chaos.

Conclusion: Quantum information scrambling provides a pathway to implement practical quantum gates in systems with limited control, highlighting the utility of holography concepts for designing quantum information processing protocols.

Abstract: We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates.

</details>


### [10] [Spectator-transition crosstalk in a spin-3/2 silicon vacancy qudit in silicon carbide revealed by broadband Ramsey interferometry](https://arxiv.org/abs/2601.15559)
*Jun-Jae Choi,Seung-Jae Hwang,Seoyoung Paik,Juhwan Kim,Jawad UI-Hassan,Nguyen Tien Son,Hiroshi Abe,Takeshi Oshima,Jaekwon Suk,Hyeon-Ho Jeong,Dong-Hee Kim,Sang-Yun Lee*

Main category: quant-ph

TL;DR: Broadband Ramsey interferometry reveals and quantifies spectator-transition crosstalk in silicon vacancy qudits in SiC, providing a practical framework for multilevel control.


<details>
  <summary>Details</summary>
Motivation: Silicon vacancy centers in 4H-SiC offer wafer-scale materials maturity with long spin coherence and chip-level photonics for scalable quantum technologies. The S=3/2 ground state provides a native qudit for compact encodings and subspace-selective control, but introduces spectator transitions where short, detuned pulses can coherently drive non-addressed level pairs and create crosstalk.

Method: Used broadband Ramsey interferometry to reveal and quantify spectator-transition crosstalk. Analytically mapped each spectral line to pairwise energy differences between qudit levels of the rotating-frame Hamiltonian and assigned weights via compact amplitudes set by prepared state and microwave pulse parameters. Performed numerical time-domain propagation with experimental sampling to reproduce detuning maps.

Result: Ramsey Fourier spectra displayed multiple lines beyond the addressed single-quantum transition, revealing a deterministic six-branch structure. Measured peak positions coincided with analytic branch lines without frequency fitting. The approach successfully quantified spectator-transition crosstalk and provided a practical framework for multilevel control.

Conclusion: The results provide a practical, spectator-aware framework for multilevel control in silicon vacancy qudits. The approach offers clear guidance to suppress crosstalk or exploit spectator lines for additional constraints in pulse calibration and phase-sensitive quantum state/process estimation.

Abstract: Color center spins in 4H-SiC offer a rare combination of wafer-scale materials maturity with long spin coherence and chip-level photonics, making them promising building blocks for scalable quantum technologies. In particular, the silicon vacancy hosts an S=3/2 ground state, a native qudit that enables compact encodings and subspace-selective control, but also introduces spectator transitions: short, detuned pulses can coherently drive non-addressed level pairs and create crosstalk. Here we use broadband Ramsey interferometry to reveal and quantify such spectator-transition crosstalk. Experimentally, the Ramsey Fourier spectra display multiple lines beyond the addressed single-quantum transition. Analytically, we map each line to a pairwise energy difference between qudit levels of the rotating-frame Hamiltonian and assign its weight via compact amplitudes set by the prepared state and the microwave pulse parameters, predicting a deterministic six-branch structure. Numerical time-domain propagation with the experimental sampling reproduces the detuning map, and the measured peak positions coincide with the analytic branch lines without frequency fitting. Together these results provide a practical, spectator-aware framework for multilevel control in the silicon vacancy qudit. The approach offers clear guidance to suppress crosstalk or, conversely, to exploit spectator lines, for example as additional constraints for in situ pulse calibration and for phase-sensitive quantum state and process estimation.

</details>


### [11] [Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy](https://arxiv.org/abs/2601.15565)
*Alex Terrasson,Lars Madsen,Joel Grim,Warwick Bowen*

Main category: quant-ph

TL;DR: Researchers developed a waveguide-based technique to generate record-high levels of bright picosecond pulsed squeezed light for quantum-enhanced nonlinear microscopy.


<details>
  <summary>Details</summary>
Motivation: Squeezed light enables enhanced measurement precision below the standard quantum limit, but generating bright pulsed squeezing at high levels for nonlinear microscopy applications remains challenging due to photodamage and quantum-limited noise constraints.

Method: Used a χ² optical parametric amplification process in a waveguide to efficiently generate bright picosecond pulsed squeezed light, measuring both bright squeezing and vacuum squeezing levels.

Result: Achieved -3.2 dB of bright squeezing with optical power compatible with nonlinear microscopy and -3.6 dB of vacuum squeezing. Corrected for losses, these correspond to -15.4^{+2.7}_{-8.7} dB of squeezing generated in the waveguide, representing the highest reported level of bright amplitude pulsed squeezing to date.

Conclusion: This efficient technique for generating high levels of bright pulsed squeezing will facilitate broader adoption of quantum-enhanced nonlinear microscopy in biological studies by overcoming previous limitations in squeezing generation and detection.

Abstract: Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies.

</details>


### [12] [Optimized Slice-Phase Control of Mirror Pulse in Cold-Atom Interferometry with Finite Response Time](https://arxiv.org/abs/2601.15586)
*Xueting Fang,Doudou Wang,Kun Yuan,Jie Deng,Qin Luo,Xiaochun Duan,Minkang Zhou,Lushuai Cao,Zhongkun Hu*

Main category: quant-ph

TL;DR: Quantum optimal control using adaptive sliced structure enhances atom interferometer mirror pulses, improving robustness to experimental inhomogeneities while maintaining high efficiency.


<details>
  <summary>Details</summary>
Motivation: Atom interferometers require high efficiency and robust performance in mirror pulses under experimental inhomogeneities like detuning variations, Rabi frequency fluctuations, and response-time delays.

Method: Used gradient ascent pulse engineering (GRAPE) to design optimized mirror pulses with adaptive non-uniform phase slicing for a Mach-Zehnder light-pulse atom interferometer.

Result: Optimized pulses showed broad tolerance to detuning variations [-Ω₀,Ω₀], Rabi frequency variations [0.1×Ω₀,1.9×Ω₀] (Ω₀=2π×25 kHz), maintained high efficiency with response-time delays up to 1.6 μs, and were robust to coupling inhomogeneity and velocity spread.

Conclusion: The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative quantum optimal control scheme for high-precision atom interferometry.

Abstract: Atom interferometers require both high efficiency and robust performance in their mirror pulses under experimental inhomogeneities. In this work, we demonstrated that quantum optimal control designed mirror pulse significantly enhance interferometer performance by using novel adaptive sliced structure. Using gradient ascent pulse engineering (GRAPE), optimized mirror pulse for a Mach-Zehnder light-pulse atom interferometer was designed by discretizing the control into non-uniform phase slices. This design broadened the tolerence to experimentally relevant variations in detuning $[-Ω_0,Ω_0]$ and Rabi frequency $[0.1\timesΩ_0,1.9\timesΩ_0]$ ($Ω_0=2π\times25$ kHz), while maintaining high transfer efficiency even when the response-time delays up to 1.6 $\rm{μs}$. The optimized pulse was found to be robust to coupling inhomogeneity and velocity spread, offering a significant improvement in robustness over conventional pulse. The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative scheme for quantum optimal control in high precision atom interferometry.

</details>


### [13] [Tensor-based phase difference estimation on time series analysis](https://arxiv.org/abs/2601.15616)
*Shu Kanno,Kenji Sugisaki,Rei Sakuma,Jumpei Kato,Hajime Nakamura,Naoki Yamamoto*

Main category: quant-ph

TL;DR: Tensor-network circuit compression enables scalable quantum phase estimation with improved accuracy using algorithmic error mitigation and iterative optimization, demonstrated on up to 52-qubit systems.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable quantum phase estimation algorithm that overcomes limitations of conventional QPE by achieving higher accuracy and scalability for near-term quantum devices.

Method: Uses tensor-network circuit compression to construct nearest-neighbor gate circuits, extracts time-evolution data via four-type circuit measurements, and employs algorithmic error mitigation and iterative circuit optimization with matrix product state merging.

Result: Achieves 0.4-4.7% error from true energy gap on 8-qubit Hubbard model, demonstrates accuracy improvements with error mitigation, and successfully runs on IBM Heron devices with up to 52 qubits using over 5,000 2-qubit gates.

Conclusion: The proposed algorithm represents significant progress toward practical near-term quantum computing applications and preparation for error-corrected quantum devices, demonstrating largest-scale QPE-type algorithm implementations to date.

Abstract: We propose a phase-difference estimation algorithm based on the tensor-network circuit compression, leveraging time-evolution data to pursue scalability and higher accuracy on a quantum phase estimation (QPE)-type algorithm. Using tensor networks, we construct circuits composed solely of nearest-neighbor gates and extract time-evolution data by four-type circuit measurements. In addition, to enhance the accuracy of time-evolution and state-preparation circuits, we propose techniques based on algorithmic error mitigation and on iterative circuit optimization combined with merging into matrix product states, respectively. Verifications using a noiseless simulator for the 8-qubit one-dimensional Hubbard model using an ancilla qubit show that the proposed algorithm achieves accuracies with 0.4--4.7\% error from a true energy gap on an appropriate time-step size, and that accuracy improvements due to the algorithmic error mitigation are observed. We also confirm the enhancement of the overlap with matrix product states through iterative optimization. Finally, the proposed algorithm is demonstrated on IBM Heron devices with Q-CTRL error suppression for 8-, 36-, and 52-qubit models using more than 5,000 2-qubit gates. These largest-scale demonstrations for the QPE-type algorithm represent significant progress not only toward practical applications of near-term quantum computing but also toward preparation for the era of error-corrected quantum devices.

</details>


### [14] [Machine Failure Detection Based on Projected Quantum Models](https://arxiv.org/abs/2601.15641)
*Larry Bowden,Qi Chu,Bernard Cena,Kentaro Ohno,Bob Parney,Deepak Sharma,Mitsuharu Takeori*

Main category: quant-ph

TL;DR: Quantum computing-based failure detection algorithm using projected quantum feature maps and statistical change-point detection for industrial machine monitoring, validated on benchmark and real-world IoT sensor data.


<details>
  <summary>Details</summary>
Motivation: Prompt detection of machine failures is critical for industrial efficiency and minimizing downtime. Current methods may lack precision in noisy environments, creating a need for more accurate anomaly detection approaches.

Method: Developed a failure detection algorithm combining quantum computing with statistical change-point detection. Utilizes projected quantum feature maps to enhance anomaly detection precision. Implemented and executed on IBM's 133-qubit Heron quantum processor.

Result: Empirically validated on benchmark multi-dimensional time series datasets and real-world IoT sensor readings from operational machines. Demonstrated effective anomaly detection in noisy time series data and feasibility of quantum computing integration in industrial maintenance.

Conclusion: Quantum-based failure detection system shows promising effectiveness for industrial diagnostics. Work highlights quantum computing potential in predictive maintenance and paves way for more sophisticated quantum algorithms in this domain.

Abstract: Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.

</details>


### [15] [Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations](https://arxiv.org/abs/2601.15654)
*Arman,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: Photon-added cat and kitten states show metrological advantage over original forms due to phase-space broadening from increased amplitude, though with higher energy cost. Squeezed cat states and symmetrically squeezed states constructed from weak squeezing and displacement show regimes of high fidelity and large amplitude suitable for preparation via Gaussian operations and photon addition.


<details>
  <summary>Details</summary>
Motivation: To investigate whether photon addition to non-classical states (cat states and kitten states) can enhance their metrological performance in phase-space sensitivity, and to identify regimes where such enhanced states can be practically prepared using accessible Gaussian operations.

Method: Construct squeezed cat states and symmetrically squeezed states using weak squeezing and displacement operations. Create photon-added variants of these states and compare them with parity-matched cat states and kitten states using quantum Fisher information (QFI) and fidelity metrics. Analyze QFI isocontours to identify regimes of high fidelity and large amplitude.

Result: Photon-added cat and kitten states demonstrate improved metrological advantage over original forms due to phase-space broadening from increased amplitude. QFI isocontours reveal specific regimes where kitten states exhibit both high fidelity and large amplitude, making them suitable for preparation via Gaussian operations and photon addition. Similar regimes exist for cat states enhanced by squeezing and photon addition, showing improved metrological performance.

Conclusion: Photon addition to non-classical states enhances their metrological performance by increasing amplitude and broadening phase-space area, which reduces interferometric fringe size and improves quantum error correction effectiveness in cat codes. The identified regimes enable practical preparation of these enhanced states using accessible Gaussian operations.

Abstract: We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes.

</details>


### [16] [Quantum-HPC hybrid computation of biomolecular excited-state energies](https://arxiv.org/abs/2601.15677)
*Kentaro Yamamoto,Riku Masui,Takahito Nakajima,Miwako Tsuji,Mitsuhisa Sato,Peter Schow,Lukas Heidemann,Matthew Burke,Philipp Seitz,Oliver J. Backhouse,Juan W. Pedersen,John Children,Craig Holliman,Nathan Lysne,Daichi Okuno,Seyon Sivarajah,David Muñoz Ramo,Alex Chernoguzov,Ross Duncan*

Main category: quant-ph

TL;DR: Hybrid quantum-classical workflow using ONIOM framework with Fugaku supercomputer and Quantinuum Reimei quantum computer for scalable biomolecular reaction simulations


<details>
  <summary>Details</summary>
Motivation: To enable accurate simulation of complex biomolecular reactions by combining quantum computing for active site treatment with classical computing for molecular environment

Method: Developed workflow within ONIOM framework using hybrid Fugaku supercomputer (classical) and Quantinuum Reimei trapped-ion quantum computer (quantum) with layered approach for biomolecular systems

Result: Demonstrated successful implementation on hybrid platform, enabling accurate treatment of active site and large molecular environment

Conclusion: Represents significant milestone in scalable and accurate simulation of complex biomolecular reactions using quantum-classical hybrid computing

Abstract: We develop a workflow within the ONIOM framework and demonstrate it on the hybrid computing system consisting of the supercomputer Fugaku and the Quantinuum Reimei trapped-ion quantum computer. This hybrid platform extends the layered approach for biomolecular chemical reactions to accurately treat the active site, such as a protein, and the large and often weakly correlated molecular environment. Our result marks a significant milestone in enabling scalable and accurate simulation of complex biomolecular reactions

</details>


### [17] [Fractional squeezing: spectra and dynamics from generalized squeezing Hamiltonian with fractional orders](https://arxiv.org/abs/2601.15693)
*Sahel Ashhab*

Main category: quant-ph

TL;DR: Generalization of squeezing problem to fractional squeezing orders n, enabling identification of critical points and behavior prediction where conventional methods fail.


<details>
  <summary>Details</summary>
Motivation: To extend squeezing analysis to fractional orders, allowing determination of critical points where qualitative behavior changes occur, which are difficult for standard computational approaches.

Method: Generalize squeezing problem to include fractional values of squeezing order n; use numerical calculations to identify critical points and analyze behavior.

Result: Identified with high confidence: point where spectrum changes from continuous to discrete, and point where oscillations transition from asymptotically infinite to finite amplitudes; investigated large n regime with intuitive explanation matching numerical results.

Conclusion: Fractional generalization enables accurate prediction of critical behavior and provides insights into squeezing dynamics that conventional methods cannot capture.

Abstract: We generalize the generalized-squeezing problem to include fractional values of the squeezing order $n$. This approach allows us to determine the locations of critical points at which qualitative changes in behaviour occur and accurately predict the behaviour at these critical points, which are challenging for conventional computational methods. Based on our numerical calculations, we identify with a high degree of confidence the point at which the spectrum turns from continuous to discrete and the point at which oscillations turn from having asymptotically infinite amplitudes to finite amplitudes. Furthermore, we numerically investigate the behaviour in the large $n$ regime and provide an intuitive explanation that coincides with the numerical results.

</details>


### [18] [Unsplit Spreading: An Overlooked Signature of Long-Range Interaction](https://arxiv.org/abs/2601.15752)
*Jian-Feng Wu,Yi Huang,Yu-Xiang Zhang*

Main category: quant-ph

TL;DR: Unsplit spreading of localized excitations requires singular dispersion relations, which long-range interactions enable, and serves as a signature of singular band structure in quantum systems.


<details>
  <summary>Details</summary>
Motivation: To understand why conventional smooth dispersion relations cause splitting of localized excitations into counter-propagating wave packets, and to identify conditions where unsplit spreading can occur as a distinct physical effect.

Method: Proving mathematically that smooth dispersion relations imply splitting, showing that unsplit spreading requires singular features in ω(k), and demonstrating this phenomenon in realistic open quantum systems like 1D and 2D subwavelength atomic arrays with long-range interactions.

Result: Unsplit spreading emerges in systems with long-range interactions that create singular dispersion relations, as observed in published quantum simulation experiments dating back to 2014, and can be realized in subwavelength atomic arrays where subradiant states host effective dispersion with required singularities.

Conclusion: Unsplit spreading serves as an experimentally accessible signature of singular band structure induced by long-range physics, representing a previously unrecognized distinct physical effect that can be observed in realistic quantum systems.

Abstract: In conventional lattice models, the dispersion relation $ω(k)$ is assumed to be a smooth function. We prove that this smoothness implies the splitting of an initially localized excitation into counter-propagating wave packets. Consequently, unsplit spreading can occur only when $ω(k)$ develops singular features, precisely what long-range interactions enable. Remarkably, this phenomenon was clearly visible in published quantum simulation experiments as early as 2014, yet it has remained unrecognized or discussed as a distinct physical effect. We show that unsplit spreading emerges in realistic open quantum systems, such as 1D and 2D subwavelength atomic arrays, where the long-lived subradiant states host effective dispersion with the required singularities. Our work establishes unsplit spreading as an experimentally accessible, smoking-gun signature of singular band structure induced by long-range physics.

</details>


### [19] [Improving the efficiency of QAOA using efficient parameter transfer initialization and targeted-single-layer regularized optimization with minimal performance degradation](https://arxiv.org/abs/2601.15760)
*Shubham Patel,Utkarsh Mishra*

Main category: quant-ph

TL;DR: Parameter transfer initialization with targeted single-layer QAOA optimization achieves 98.88% optimal performance with 8.06x speedup for unweighted graphs, but performs poorly for weighted graphs. Ridge regularization reduces inconsistent optimization cases from 8.92% to 3.81%.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency of QAOA for combinatorial optimization problems by developing parameter initialization and optimization strategies that reduce computational cost while maintaining high solution quality.

Method: Parameter transfer initialization followed by targeted single-layer optimization for QAOA applied to MaxCut on 3-regular, Erdos-Renyi, and Barabasi-Albert graphs. Ridge (L2) regularization used to smooth the parameter landscape during full optimization.

Result: For unweighted graphs: mean approximation ratio of 0.9443 vs 0.9551 for full optimization (98.88% optimal performance) with 8.06x speedup. For weighted graphs: performance drops below 90% for larger graphs. Ridge regularization reduces inconsistent optimization cases from 8.92% to 3.81%.

Conclusion: Efficient parameter initialization and targeted single-layer optimization can significantly improve QAOA efficiency with minimal performance degradation for unweighted graphs, but weighted graphs require different approaches. Ridge regularization helps mitigate optimization inconsistencies.

Abstract: Quantum approximate optimization algorithm (QAOA) have promising applications in combinatorial optimization problems (COPs). We investigated the MaxCut problem in three different families of graphs using QAOA ansats with parameter transfer initialization followed by targeted single layer optimization. For 3 regular (3R), Erdos Renyi (ER), and Barabasi Albert (BA) graphs, the parameter transfer approach achieved mean approximation ratios of 0.9443 for targeted-single layer optimization as compared to 0.9551 of full optimization. It represents 98.88 percent optimal performance, with 8.06 times computational speedup in unweighted graphs. But, in weighted graph families, optimal performance is relatively low (less than 90 percent) for higher nodes graph, suggesting parameter transfer followed by targeted-single-layer optimization is not ideal for weighted graph families, however, we find that for some weighted families (weighted 3-regular) this approach works perfectly. In 8.92 percent test cases, targeted single layer optimization outperformed the full optimization, indicating that complex parameter landscape can trap full optimization in sub-optimal local minima. To mitigate this inconsistency, ridge (L2) regularization is used to smoothen the solution landscape, which helps the optimizer to find better optimum parameters during full optimization and reduces these inconsistent test cases from 8.92 percent to 3.81 percent. This work demonstrates that efficient parameter initialization and targeted-single-layer optimization can improve the efficiency of QAOA with minimal performance degradation.

</details>


### [20] [Classical Simulation of Noiseless Quantum Dynamics without Randomness](https://arxiv.org/abs/2601.15770)
*Jue Xu,Chu Zhao,Xiangran Zhang,Shuchen Zhu,Qi Zhao*

Main category: quant-ph

TL;DR: LPD algorithm efficiently approximates local observables for short-time quantum dynamics without noise, using entanglement to reduce classical simulation error.


<details>
  <summary>Details</summary>
Motivation: Classical simulation of noiseless quantum dynamics faces limitations: tensor networks become inefficient with high entanglement, while Pauli-truncation methods typically require noise or randomness. There's a need for efficient classical methods that work without these assumptions.

Method: Proposes Low-weight Pauli Dynamics (LPD) algorithm that approximates local observables for short-time dynamics. Uses entanglement to bound truncation error without assuming randomness. Shows entangled states can be generated by tensor-network classical simulation or near-term quantum devices.

Result: Proves average-case bound for truncation error without randomness assumption when state is sufficiently entangled. Demonstrates counterintuitive result that entanglement reduces classical simulation error. Establishes synergy between classical simulation methods and provides complementary route to quantum simulation.

Conclusion: LPD algorithm extends accessible regime of quantum dynamics by reducing circuit depth requirements for long-time dynamics, creating synergy between classical and quantum simulation approaches.

Abstract: Simulating noiseless quantum dynamics classically faces a fundamental dilemma: tensor-network methods become inefficient as entanglement saturates, while Pauli-truncation approaches typically rely on noise or randomness. To close the gap, we propose the Low-weight Pauli Dynamics (LPD) algorithm that efficiently approximates local observables for short-time dynamics in the absence of noise. We prove that the truncation error admits an average-case bound without assuming randomness, provided that the state is sufficiently entangled. Counterintuitively, entanglement--usually an obstacle for classical simulation--alleviates classical simulation error. We further show that such entangled states can be generated either by tensor-network classical simulation or near-term quantum devices. Our results establish a rigorous synergy between existing classical simulation methods and provide a complementary route to quantum simulation that reduces circuit depth for long-time dynamics, thereby extending the accessible regime of quantum dynamics.

</details>


### [21] [Fermion Doubling in Dirac Quantum Walks](https://arxiv.org/abs/2601.15885)
*Chaitanya Gupta,Anthony J. Short*

Main category: quant-ph

TL;DR: A family of quantum walks is proposed to eliminate fermion doublers and pseudo-doublers that plague conventional Dirac quantum walks, while still simulating the Dirac equation in the continuum limit.


<details>
  <summary>Details</summary>
Motivation: Fermion doubling in quantum walks leads to spurious solutions when introducing interactions in quantum cellular automata, and pseudo-doublers cause potential vacuum stability problems, necessitating a solution that eliminates these artifacts while preserving Dirac equation simulation.

Method: Propose a family of quantum walks that allow non-zero probability for the walker staying at the same point (unlike conventional Dirac walks which always have zero probability for staying), thereby eliminating doublers and pseudo-doublers while maintaining the Dirac equation in the continuum limit.

Result: The proposed family of quantum walks successfully eliminates fermion doublers and pseudo-doublers, though a small number of additional low energy solutions remain that don't directly correspond to Dirac particles.

Conclusion: By modifying the quantum walk structure to allow non-zero staying probability, it's possible to create models free from problematic doublers and pseudo-doublers while still simulating Dirac physics in the continuum limit, addressing key issues in quantum walk-based particle simulations.

Abstract: We consider discrete spacetime models known as quantum walks, which can be used to simulate Dirac particles. In particular we look at fermion doubling in these models, in which high momentum states yield additional low energy solutions which behave like Dirac particles. The presence of doublers carries over to the `second quantised' version of the walks represented by quantum cellular automata, which may lead to spurious solutions when introducing interactions. Moreover, we also consider pseudo-doublers, which have high energy but behave like low energy Dirac particles, and cause potential problems regarding the stability of the vacuum. To address these issues, we propose a family of quantum walks, that are free of these doublers and pseudo-doublers, but still simulate the Dirac equation in the continuum limit. However, there remain a small number of additional low energy solutions which do not directly correspond to Dirac particles. While the conventional Dirac walk always has a zero probability for the walker staying at the same point, we obtain the family of walks by allowing this probability to be non-zero.

</details>


### [22] [Improved cryptographic security in teleportation with q-deformed non-maximal entangled states](https://arxiv.org/abs/2601.15902)
*Prabal Dasgupta,Debashis Gangopadhyay*

Main category: quant-ph

TL;DR: A novel quantum teleportation protocol using q-deformed harmonic oscillator states to enhance cryptographic security through additional deformation parameters.


<details>
  <summary>Details</summary>
Motivation: To improve cryptographic security in quantum teleportation by leveraging the mathematical framework of q-deformed algebras, which introduce additional parameters that must be shared for decryption.

Method: Construct q-deformed Bell-like states from q-deformed harmonic oscillator states, generalize standard teleportation protocol to non-maximally entangled states, and develop two new protocols using q-deformed non-maximally entangled states with arbitrary functions of deformation parameter q.

Result: Created q-deformed Bell-like states that reduce to standard Bell states when q→1, formed orthonormal basis for q-deformed entangled bipartite states under constraint conditions, and developed two new teleportation protocols with enhanced security through additional parameters requiring sharing for decryption.

Conclusion: The q-deformed algebraic framework provides a powerful method to enhance cryptographic security in quantum teleportation by introducing additional parameters that must be shared for successful decryption, offering improved protection compared to standard teleportation protocols.

Abstract: In this work the machinery of q-deformed algebras are used to enhance cryptographic security during teleportation. We use q-deformed harmonic oscillator states to develop a novel method of teleportation. The deformed states can be expressed in terms of standard oscillator states and the expressions contain certain arbitrary functions of $q$. It is the presence of these arbitrary functions that allows an enhancement of cryptographic security. The specifics are :
  (a) q-deformed Bell-like states are constructed which reduce to the usual Bell states when the deformation parameter $q\rightarrow 1$. These deformed states form an orthonormal basis for q-deformed entangled bipartite states when certain arbitrary functions of $q$ satisfy a constraint.
  (b) We discuss the generalisation of the usual teleportation protocol with non-maximally entangled states. This generalisation is then employed to construct two new protocols using q-deformed non-maximally entangled states. These states have additional parameters and these have to be shared for decryption after teleportation. Consequently, the cryptographic security is improved.

</details>


### [23] [Automated quantum circuit optimization with randomized replacements](https://arxiv.org/abs/2601.15934)
*Marcin Szyniszewski,Aleks Kissinger,Noah Linden,Paul Skrzypczyk*

Main category: quant-ph

TL;DR: Automated quantum circuit optimization using ZX-calculus with greedy stochastic approximations that replace small-angle operations with mixtures of identity and over-rotations to reduce gate count within error budgets.


<details>
  <summary>Details</summary>
Motivation: Current quantum circuit optimization focuses on exact unitary transformations, but substantial resource reduction opportunities exist by allowing approximate local transformations and employing mixed quantum channels to approximate pure circuits, converting experimental noise into deliberately engineered random noise.

Method: Refined ZX-calculus-based automated optimization with greedy strategy that selectively replaces ZX-diagrams with small phase angles using stochastic mixtures of identity and carefully chosen over-rotations, designed to reduce overall gate count in expectation while staying within strict error budget.

Result: Modest two-qubit gate count reduction in random quantum circuits, substantial reduction in structured circuits like quantum Fourier transform, outperforms many other approximation methods on average by converting experimental noise into deliberately engineered random noise.

Conclusion: Mixed-channel approximations show potential to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels.

Abstract: Quantum circuit optimization - the process of transforming a quantum circuit into an equivalent one with reduced time and space requirements - is crucial for maximizing the utility of current and near-future quantum devices. While most automated optimization techniques focus on transforming circuits into equivalent ones that implement the same unitary, we show that substantial new opportunities for resource reduction can be achieved by (1) allowing approximate local transformations and (2) employing mixed quantum channels to approximate pure circuits. Our novel automated protocol for approximate circuit rewriting is a refined evolution of automated optimization techniques based on the ZX-calculus, where we add a greedy strategy that selectively replaces ZX-diagrams with small phase angles with stochastic mixtures of the identity and carefully chosen over-rotations, which are designed to reduce the overall gate count in expectation while staying within a strict error budget. This approach yields modest two-qubit gate count reduction in random quantum circuits, and achieves a substantial reduction in structured circuits such as the quantum Fourier transform. Fundamentally, our protocol converts experimental noise due to gate applications into deliberately engineered random noise, outperforming many other approximation methods on average. These results highlight the potential of mixed-channel approximations to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels.

</details>


### [24] [Frictional work and entropy production in integrable and non-integrable spin chains](https://arxiv.org/abs/2601.15941)
*Vishnu Muraleedharan Sajitha,Matthew J. Davis,L. A. Williamson*

Main category: quant-ph

TL;DR: Frictional work in quantum systems is linked to diagonal entropy production from quantum coherence for slow/moderate driving, and to quantum relative entropy for fast driving, with integrability breaking affecting work extraction differently across regimes.


<details>
  <summary>Details</summary>
Motivation: To understand how frictional work (difference between adiabatic and non-adiabatic work extraction) in quantum systems relates to entropy production and quantum coherence, and how integrability affects these relationships.

Method: Analyze frictional work in non-integrable spin chains using diagonal entropy production (associated with quantum coherence buildup) characterized by effective temperature of final adiabatic state for slow/moderate driving, and quantum relative entropy between final non-adiabatic and adiabatic states for fast driving. Compare with integrable spin chains where adiabatic state has multiple effective temperatures.

Result: Frictional work in non-integrable systems is well-described by diagonal entropy production for slow/moderate driving and by quantum relative entropy for fast driving. Integrability breaking enhances work extraction in adiabatic limit but degrades it in sufficiently non-adiabatic regimes.

Conclusion: The relationship between frictional work and entropy production depends on driving speed and system integrability, with integrability breaking having opposite effects on work extraction in adiabatic vs. non-adiabatic regimes.

Abstract: The maximum work extractable from a quantum system is achieved when the system is driven adiabatically. Frictional work then quantifies the difference in work output between adiabatic and non-adiabatic driving. Here we show that frictional work in a non-integrable spin chain is well-described by the diagonal entropy production associated with the build up of quantum coherence. The relationship is characterized by an effective temperature of the final adiabatic state and holds for slow to moderate driving protocols. For fast protocols, the frictional work is instead described by the quantum relative entropy between the final non-adiabatic and adiabatic states. We compare our results to those obtained from an integrable spin chain, in which case the adiabatic state is no longer described by a single temperature. In this case, the frictional work is described by a sum of terms for each independent subspace of the spin chain, which are at different effective temperatures. We show how integrability breaking can enhance work extraction in the adiabatic limit, but degrade work extraction in sufficiently non-adiabatic regimes.

</details>


### [25] [Renormalization Treatment of IR and UV Cutoffs in Waveguide QED and Implications to Numerical Model Simulation](https://arxiv.org/abs/2601.15945)
*Romain Piron,Akihito Soeda*

Main category: quant-ph

TL;DR: Non-perturbative derivation of renormalization relations for waveguide-QED models with explicit IR/UV cutoff treatment, enabling efficient multi-photon simulations.


<details>
  <summary>Details</summary>
Motivation: Numerical simulations of waveguide-QED models require introducing infrared and ultraviolet cutoffs, necessitating proper renormalization to connect bare parameters to physical observables and enable efficient computational approaches.

Method: Time-domain formulation of atomic dynamics to derive explicit renormalization relations linking bare parameters to observable atomic frequency and decay rate, verified against scattering theory and connected to Feynman diagrams for physical interpretation.

Result: Obtained explicit renormalization relations that enable parameterization of simulations with minimal frequency bandwidth while preserving physical accuracy, reducing computational cost for multi-photon light-matter simulations.

Conclusion: The derived renormalization relations provide a foundation for efficient and reliable waveguide-QED simulations by properly handling cutoffs and enabling minimal-bandwidth parameterization without sacrificing physical accuracy.

Abstract: We present a non-perturbative, first-principles derivation of renormalization relations for waveguide-QED models, explicitly accounting for the infrared (IR) and ultraviolet (UV) cutoffs that are necessarily introduced in numerical simulations. By formulating the atomic dynamics in the time domain, we obtain explicit expressions linking the bare model parameters to the physically observable atomic frequency and decay rate, and verify their consistency with scattering theory. We further connect these results to standard Feynman diagrams, providing a transparent physical interpretation and ensuring the generality of the approach. Finally, we show how these renormalization relations can be used to parameterize simulations with a minimal frequency bandwidth, simultaneously preserving physical accuracy and reducing computational cost, thereby paving the way for efficient and reliable multi-photon light-matter simulations.

</details>


### [26] [Universal Digitized Counterdiabatic Driving](https://arxiv.org/abs/2601.15972)
*Takuya Hatomura*

Main category: quant-ph

TL;DR: Proposes digitized counterdiabatic driving method that constructs adiabatic gauge potential digitally, avoiding many-body/nonlocal interactions while incorporating infinite nested commutators with explicit rotation angles.


<details>
  <summary>Details</summary>
Motivation: To develop a universal digitized counterdiabatic driving method that overcomes limitations of existing approaches: avoiding introduction of many-body/nonlocal interactions, incorporating infinite nested commutators, and providing explicit rotation angles for digital implementation.

Method: Constructs adiabatic gauge potential in a digital way using universal counterdiabatic driving principles. The method digitally implements the gauge potential without modifying the original target Hamiltonian's interaction structure, incorporates infinite nested commutators, and provides explicit expressions for rotation angles in digital quantum circuits.

Result: The method shows consistency with exact theory through analytical demonstration and effectiveness through numerical simulations. It successfully implements counterdiabatic driving digitally while preserving the original Hamiltonian's interaction structure.

Conclusion: The proposed universal digitized counterdiabatic driving method provides a practical approach for quantum control that avoids problematic interactions, incorporates full commutator expansions, and offers explicit digital implementation parameters, advancing quantum adiabatic protocols.

Abstract: Counterdiabatic driving realizes parameter displacement of an energy eigenstate of a given parametrized Hamiltonian using the adiabatic gauge potential. In this paper, we propose a universal method of digitized counterdiabatic driving, constructing the adiabatic gauge potential in a digital way with the idea of universal counterdiabatic driving. This method has three advantages over existing universal counterdiabatic driving and/or digitized counterdiabatic driving: it does not introduce any many-body and/or nonlocal interactions to an original target Hamiltonian; it can incorporate infinite nested commutators, which constitute the adiabatic gauge potential; and it gives explicit expression of rotation angles for digital implementation. We show the consistency of our method to the exact theory in an analytical way and the effectiveness of our method with the aid of numerical simulations.

</details>


### [27] [Semiclassical entanglement entropy for spin-field interaction](https://arxiv.org/abs/2601.15986)
*Matheus V. Scherer,Lea F. Santos,Alexandre D. Ribeiro*

Main category: quant-ph

TL;DR: A semiclassical framework for entanglement dynamics in spin-boson systems using real and complex classical trajectories to compute entanglement entropy beyond Ehrenfest time.


<details>
  <summary>Details</summary>
Motivation: To develop a semiclassical description of entanglement dynamics between spin and bosonic subsystems that goes beyond the limitations of conventional semiclassical methods, particularly extending beyond the Ehrenfest time.

Method: Using a spin-boson system with initial product state of spin coherent state and canonical coherent state; deriving semiclassical entanglement entropy expression dependent on classical trajectories; analytically extending phase space to complex domain to identify additional complex trajectories that improve accuracy.

Result: The inclusion of complex trajectories significantly improves accuracy of semiclassical entanglement description, allowing precise capture of entanglement dynamics well beyond Ehrenfest time; demonstrated with representative example showing explicit role of real and complex trajectories.

Conclusion: Complex trajectory extension of semiclassical framework provides powerful method for describing quantum entanglement dynamics in spin-boson systems, overcoming limitations of conventional real-trajectory approaches and enabling accurate description beyond Ehrenfest time.

Abstract: We study a general bipartite quantum system consisting of a spin interacting with a bosonic field, with the initial state prepared as the product of a spin coherent state and a canonical coherent state. Our goal is to develop a semiclassical framework to describe the entanglement dynamics between these two subsystems. Using appropriate approximations, we derive a semiclassical expression for the entanglement entropy that depends exclusively on the trajectories of the underlying classical description. By analytically extending the classical phase space into the complex domain, we identify additional complex trajectories that significantly improve the accuracy of the semiclassical description. The inclusion of these complex trajectories allows us to capture the entanglement dynamics with remarkable precision, even well beyond the Ehrenfest time. The approach is illustrated with a representative example, where the role of real and complex trajectories in reproducing the quantum entanglement entropy is explicitly demonstrated.

</details>


### [28] [Engineering quantum Mpemba effect by Liouvillian skin effect](https://arxiv.org/abs/2601.16002)
*Xiang Zhang Chen Sun,Fuxiang Li*

Main category: quant-ph

TL;DR: The paper proposes using the Liouvillian skin effect to engineer the quantum Mpemba effect in open quantum systems, discovering a new type of QME with two distance reversals.


<details>
  <summary>Details</summary>
Motivation: To develop a new approach for engineering the quantum Mpemba effect (where distant initial states relax faster than closer ones) using the Liouvillian skin effect as an ideal platform, and to provide more intuitive physical understanding of QME.

Method: Focus on quadratic Lindbladians in open quantum systems, use Liouvillian skin effect to design initial states, consider two concrete cases for state preparation, analyze Hilbert-Schmidt distance dynamics.

Result: Discovery of a new type of quantum Mpemba effect (QME-III) characterized by two reversals in Hilbert-Schmidt distance at two different times, distinct from typical QME scenarios. The LSE provides accessible experimental preparation and more intuitive physical understanding.

Conclusion: The Liouvillian skin effect serves as an effective platform for engineering the quantum Mpemba effect, enabling both theoretical understanding and experimental realization of novel QME phenomena including the newly discovered QME-III.

Abstract: We propose a new approach to engineer the quantum Mpemba effect (QME) -- wherein an initial state farther from system relaxes faster than a close one -- by the Liouvillian skin effect (LSE) in open quantum systems. Moreover, the LSE serves as an ideal platform for realizing the QME and the spatial profile of the LSE provides a straightforward pathway for the initial state preparation, thereby enabling readily accessible experimental preparation. Focusing on the quadratic Lindbladians, we consider two concrete cases to design the initial states, thereby realizing the QME. Interestingly, we uncover a new kind of QME (QME-III) that is distinct from the two typical scenarios, manifested as two reversals in the Hilbert-Schmidt distance at two different times. In particular, the LSE provides a physically more intuitive understanding of the QME.

</details>


### [29] [Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware](https://arxiv.org/abs/2601.16004)
*Christopher Altman*

Main category: quant-ph

TL;DR: Experimental implementation and benchmarking of Violaris' circuit family on IBM Quantum hardware for estimating operational inter-branch communication witnesses using Wigner's-friend-style circuits with five qubits.


<details>
  <summary>Details</summary>
Motivation: To provide a reproducible operational constraint pipeline for evaluating detectability of non-ideal quantum channels relative to calibrated device noise, rather than testing interpretations of quantum mechanics.

Method: Implemented Violaris' circuit family on IBM Quantum hardware (ibm_fez backend) with five qubits, encoding branch-conditioned evolution of an observer subsystem with control qubit dependence, followed by controlled transfer operation to probe correlations between conditional measurement contexts. Used 20000 shots for execution.

Result: Observed population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and phase-sensitive magnitude of approximately 1.17. Visibility metric is insensitive to some dephasing classes while coherence witnesses provide complementary sensitivity to off-diagonal noise.

Conclusion: The work demonstrates a practical implementation of operational inter-branch communication witness estimation on quantum hardware, providing a benchmark framework for evaluating quantum channel detectability against realistic device noise and compilation constraints.

Abstract: We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.
  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.
  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise.

</details>


### [30] [Echoed Random Quantum Metrology](https://arxiv.org/abs/2601.16026)
*Dong-Sheng Liu,Zi-Jie Chen,Ziyue Hua,Yilong Zhou,Qing-Xuan Jie,Weizhou Cai,Ming Li,Luyan Sun,Chang-Ling Zou,Xi-Feng Ren,Guang-Can Guo*

Main category: quant-ph

TL;DR: Random pulse-driven Kerr nonlinear mode achieves Heisenberg-limit sensitivity without complex quantum control or calibrated probe states.


<details>
  <summary>Details</summary>
Motivation: Quantum metrology traditionally requires exotic quantum states (entangled/squeezed) with carefully calibrated parameters and optimized controls, limiting scalability and robustness.

Method: Introduces an echoed random process using random pulses to drive a Kerr nonlinear mode, generating sub-Planck phase-space structures that enable high sensitivity without complex quantum control.

Result: Achieves sensitivity approaching the Heisenberg limit while remaining blind to random probe states; protocol is statistically robust across broad parameter ranges and resilient to control fluctuations and photon loss.

Conclusion: Provides a practical, hardware-efficient, scalable, optimization-free route to quantum-enhanced metrology applicable to both bosonic and qubit platforms in high-dimensional Hilbert spaces.

Abstract: Quantum metrology typically demands the preparation of exotic quantum probe states, such as entangled or squeezed states, to surpass classical limits. However, the need for carefully calibrated system parameters and finely optimized quantum controls imposes limitations on scalability and robustness. Here, we circumvent these limitations by introducing an echoed random process that achieves sensitivity approaching the Heisenberg limit while remaining blind to the random probe state. We demonstrate that by simply driving a Kerr nonlinear mode with random pulses, the emergence of sub-Planck phase-space structures grants high sensitivity, eliminating the need for complex quantum control. The protocol is statistically robust, yielding high performance across broad driving parameter ranges while exhibiting resilience to control fluctuations and photon loss. Broadly applicable to both bosonic and qubit platforms, our work reveals a practical, hardware-efficient, scalable, and optimization-free route to quantum-enhanced metrology in high-dimensional Hilbert spaces.

</details>


### [31] [Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals](https://arxiv.org/abs/2601.16081)
*Aishwarya Majumdar,Yuan Liu*

Main category: quant-ph

TL;DR: GQSPI framework for binary hypothesis testing of displacement signals in bosonic systems achieves O(1/d log d) error probability with circuit depth d, robust to noise, and extensible to multi-threshold cases.


<details>
  <summary>Details</summary>
Motivation: Need to determine if a displacement parameter β lies within asymmetric thresholds [β_{-th}, β_{+th}] in bosonic quantum systems, which is a binary decision problem relevant for quantum sensing and signal detection.

Method: Generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems, recasting active binary hypothesis testing as polynomial approximation problem.

Result: Achieves small decision error probability p_err ~ O(1/d log d) with circuit depth d; works for both deterministic β and random β with known prior; robust under dephasing noise; extensible to multi-threshold cases.

Conclusion: The GQSPI framework enables efficient decision-making over arbitrary thresholds for general displacement signals in single or few shots, providing a robust quantum sensing protocol.

Abstract: A relevant signal in the quantum domain may manifest as a displacement or a phase shift operator in the bosonic phase space. For a real parameter $β$ embedded in such a displacement operator, the task of determining if $β\in [β_{-th}, β_{+th}]$ for real asymmetric thresholds $(β_{-th} \ne -β_{+th})$ is a binary decision problem. We propose a framework based on generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems that addresses this parameter detection problem by recasting the practical task of active binary hypothesis testing on quantum systems to that of a polynomial approximation. We achieve a small decision error probability $p_{err}$ on the order of $O(\frac{1}{d}\log{(d)})$, with $d$ as the circuit depth. We analyze the protocol when (i) $β$ is a deterministic parameter, and (ii) when $β$ is drawn randomly from a known prior distribution. The performance of the sensing protocol under dephasing noise is also shown to be robust. We further extend our protocol from two thresholds to more general multi-threshold cases as well. Overall, the proposed framework enables decision-making over arbitrary thresholds for any general displacement signal in a single or a few shots.

</details>


### [32] [Quantum Metrology under Coarse-Grained Measurement](https://arxiv.org/abs/2601.16106)
*Byeong-Yoon Go,Geunhee Gwak,Young-Do Yoon,Sungho Lee,Nicolas Treps,Jiyong Park,Young-Sik Ra*

Main category: quant-ph

TL;DR: Quantum metrology with coarse-grained measurements achieves Heisenberg scaling even with only two measurement bins, demonstrating practical quantum enhancement despite experimental imperfections.


<details>
  <summary>Details</summary>
Motivation: While quantum metrology offers precision beyond classical limits, its performance is typically vulnerable to experimental imperfections. Most prior research focused on imperfections in quantum states and operations, but this paper investigates the impact of coarse graining in quantum measurement itself.

Method: Theoretical analysis and experimental demonstration using an interferometer with squeezed vacuum and laser input. Analyzed how coarse graining in homodyne detection affects phase estimation precision. Evaluated Fisher information under various coarse-graining conditions and determined optimal estimation strategies that saturate the Cramér-Rao bound. Experimentally employed method of moments with calibration procedures for general experimental settings.

Result: Even extremely coarse-grained measurement with only two bins enables phase estimation beyond the standard quantum limit and achieves Heisenberg scaling. Experimental demonstration showed quantum enhancement of 1.2 dB compared to classical method using ideal measurement with two bins, improving to 3.8 dB as bin number increases.

Conclusion: Coarse-grained measurements can still achieve quantum-enhanced precision, providing a practical pathway to quantum metrology under severe experimental imperfections. The results demonstrate that quantum enhancement is robust to measurement imperfections when optimal estimation strategies are employed.

Abstract: While quantum metrology enables measurement precision beyond classical limits, its performance is often susceptible to experimental imperfections. Most prior studies have focused on imperfections in quantum states and operations. Here, we investigate the effect of coarse graining in quantum measurement through both theoretical analysis and experimental demonstration. Using an interferometer with a squeezed vacuum and a laser input, we analyze how coarse graining in homodyne detection affects the precision of phase estimation. We evaluate the Fisher information under various coarse-graining conditions and determine, in each case, an optimal estimation strategy that saturates the Cramér-Rao bound. Remarkably, even extremely coarse-grained measurement -- with only two bins -- enables phase estimation beyond the standard quantum limit and even achieves a precision that follows the Heisenberg scaling. We experimentally demonstrate quantum-enhanced phase estimation under coarse-grained homodyne detection. To determine an optimal estimation strategy, we employ the method of moments and present calibration procedures that enable its application to general experimental settings. Using only two bins, we observe a quantum enhancement of 1.2 dB compared to the classical method using the ideal measurement, improving towards 3.8 dB as the bin number increases. These results highlight a practical pathway to achieving quantum enhancement under the presence of severe experimental imperfections.

</details>


### [33] [Experimental prime factorization via a feedback quantum control](https://arxiv.org/abs/2601.16116)
*Hari Krishnan KB,Vishal Varma,T. S. Mahesh*

Main category: quant-ph

TL;DR: Measurement-based feedback approach for quantum prime factorization that iteratively steers quantum system toward target ground state without classical computation of drive parameters.


<details>
  <summary>Details</summary>
Motivation: Existing quantum factorization methods have limitations: Shor's algorithm requires high-fidelity gates, while Hamiltonian optimization methods need substantial classical post-processing. There's a need for an all-quantum approach that eliminates classical computation overhead once the problem Hamiltonian is established.

Method: All-quantum, measurement-based feedback approach that iteratively steers a quantum system toward the target ground state. The method eliminates classical computation of drive parameters after problem Hamiltonian determination. Uses FALQON (Feedback-based Algorithm for Quantum Optimization) factorization approach.

Result: Experimentally factored biprime 551 using a three-qubit NMR quantum register. Numerically demonstrated robustness against control field errors. Scaled to larger biprimes: 9,167 (5 qubits) and 2,106,287 (9 qubits) through numerical implementation.

Conclusion: The proposed measurement-based feedback approach provides a viable all-quantum alternative to existing factorization methods, eliminating classical computation overhead while demonstrating experimental feasibility and scalability to larger problems.

Abstract: Prime factorization on quantum processors is typically implemented either via circuit-based approaches such as Shor's algorithm or through Hamiltonian optimization methods based on adiabatic, annealing, or variational techniques. While Shor's algorithm demands high-fidelity quantum gates, Hamiltonian optimization schemes, with prime factors encoded as degenerate ground states of a problem Hamiltonian, generally require substantial classical post-processing to determine control parameters. We propose an all-quantum, measurement-based feedback approach that iteratively steers a quantum system toward the target ground state, eliminating the need for classical computation of drive parameters once the problem Hamiltonian is determined and realized. As a proof of principle, we experimentally factor the biprime 551 using a three-qubit NMR quantum register and numerically analyze the robustness of the method against control field-errors. We further demonstrate scalability by numerically implementing the FALQON factorization of larger biprimes, 9,167 and 2,106,287, using 5 and 9 qubits, respectively.

</details>


### [34] [Exceptional points in Gaussian channels: diffusion gauging and drift-governed spectrum](https://arxiv.org/abs/2601.16121)
*Frank Ernesto Quintela Rodríguez*

Main category: quant-ph

TL;DR: The paper establishes a noise-independence principle for bosonic Gaussian quantum systems, showing that Liouvillian spectra are independent of noise strength in both continuous-time Markov semigroups and discrete-time Gaussian channels.


<details>
  <summary>Details</summary>
Motivation: To extend and formalize McDonald and Clerk's finding that Liouvillian spectra are noise-independent in linear open quantum systems, specifically for bosonic Gaussian systems in both continuous and discrete time settings.

Method: For continuous-time: use Gaussian similarity transformation fixed by Lyapunov equation to gauge away diffusion. For discrete-time: construct explicit Gaussian similarity transformation at channel parametrization level to eliminate diffusion effects.

Result: Demonstrated that eigenvalues and non-diagonalizability are controlled entirely by drift, while diffusion determines steady states and eigenoperator structure. Applied to single-mode squeezed-reservoir Lindbladian and non-Markovian Gaussian channels with analytical exceptional-point manifolds.

Conclusion: Established a fundamental separation principle: drift governs spectral properties while diffusion governs stationary properties in bosonic Gaussian quantum systems, unifying continuous and discrete time formulations.

Abstract: McDonald and Clerk [Phys.\ Rev.\ Research 5, 033107 (2023)] showed that for linear open quantum systems the Liouvillian spectrum is independent of the noise strength. We first make this noise-independence principle precise in continuous time for multimode bosonic Gaussian Markov semigroups: for Hurwitz drift, a time-independent Gaussian similarity fixed by the Lyapunov equation gauges away diffusion for all times, so eigenvalues and non-diagonalizability are controlled entirely by the drift, while diffusion determines steady states and the structure of eigenoperators. We then extend the same separation to discrete time for general stable multimode bosonic Gaussian channels: for any stable Gaussian channel, we construct an explicit Gaussian similarity transformation that gauges away diffusion at the level of the channel parametrization. We illustrate the method with a single-mode squeezed-reservoir Lindbladian and with a non-Markovian family of single-mode Gaussian channels, where the exceptional-point manifolds and the associated gauging covariances can be obtained analytically.

</details>


### [35] [Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments](https://arxiv.org/abs/2601.16123)
*Samuel Stein,Shuwen Kan,Chenxu Liu,Adrian Harkness,Sean Garner,Zefan Du,Yufei Ding,Ying Mao,Ang Li*

Main category: quant-ph

TL;DR: Hardware-conditioned neural decoder for quantum error correction achieves 11.1x reduction in logical error rate by decoupling slow calibration processing from fast syndrome decoding using FiLM conditioning.


<details>
  <summary>Details</summary>
Motivation: Real-time quantum error correction decoding requires high accuracy, low latency, and robustness to hardware noise variations. Superconducting processors have natural timescale separation: calibration drifts occur over hours while error correction requires microsecond responses.

Method: Hardware-conditioned neural decoder framework with graph-based encoder for calibration data and lightweight convolutional backbone conditioned via feature-wise linear modulation (FiLM). This decouples heavy device statistics processing from low-latency syndrome decoding.

Result: Evaluation on IBM processors (Fez, Kingston, Pittsburgh) with over 2.7 million experimental shots up to distance d=11. Single trained model generalizes to unseen qubit chains and new calibration data days later without retraining. Achieves up to 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching.

Conclusion: Hardware-conditioned neural decoding demonstrates promising adaptive performance with negligible latency overhead by exploiting asynchronous nature of system calibration and decoding, enabling practical fault-tolerant quantum computation.

Abstract: Real-time decoding of quantum error correction (QEC) is essential for enabling fault-tolerant quantum computation. A practical decoder must operate with high accuracy at low latency, while remaining robust to spatial and temporal variations in hardware noise. We introduce a hardware-conditioned neural decoder framework designed to exploit the natural separation of timescales in superconducting processors, where calibration drifts occur over hours while error correction requires microsecond-scale responses. By processing calibration data through a graph-based encoder and conditioning a lightweight convolutional backbone via feature-wise linear modulation (FiLM), we decouple the heavy processing of device statistics from the low-latency syndrome decoding.
  We evaluate this approach using the 1D repetition code as a testbed on IBM Fez, Kingston, and Pittsburgh processors, collecting over 2.7 million experimental shots spanning distances up to d = 11. We demonstrate that a single trained model generalizes to unseen qubit chains and new calibration data acquired days later without retraining. On these unseen experiments, the FiLM-conditioned decoder achieves up to an 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching. We observe that by employing a network architecture that exploits the highly asynchronous nature of system calibration and decoding, hardware-conditioned neural decoding demonstrates promising, adaptive performance with negligible latency overhead relative to unconditioned baselines.

</details>


### [36] [Quantum Dimension Reduction of Hidden Markov Models](https://arxiv.org/abs/2601.16126)
*Rishi Sundar,Thomas Elliott*

Main category: quant-ph

TL;DR: Quantum HMM compression pipeline enables dimension reduction for any finite ergodic HMM, outperforming classical methods in memory-accuracy trade-offs.


<details>
  <summary>Details</summary>
Motivation: Classical HMMs are large and high-dimensional, while existing quantum HMM compression techniques only work for deterministic transition HMMs, limiting their applicability.

Method: Introduces a pipeline for compressing any finite ergodic HMM using quantum dimension reduction techniques, extending beyond deterministic transition limitations.

Result: Demonstrated on toy model and speech-derived HMM, showing favorable memory-accuracy trade-offs compared to classical compression approaches.

Conclusion: Provides a general route for effective quantum dimension reduction of arbitrary HMMs, expanding quantum advantage in stochastic process modeling.

Abstract: Hidden Markov models (HMMs) are ubiquitous in time-series modelling, with applications ranging from chemical reaction modelling to speech recognition. These HMMs are often large, with high-dimensional memories. A recently-proposed application of quantum technologies is to execute quantum analogues of HMMs. Such quantum HMMs (QHMMs) are strictly more expressive than their classical counterparts, enabling the construction of more parsimonious models of stochastic processes. However, state-of-the-art techniques for QHMM compression, based on tensor networks, are only applicable for a restricted subset of HMMs, where the transitions are deterministic. In this work we introduce a pipeline by which \emph{any} finite, ergodic HMM can be compressed in this manner, providing a route for effective quantum dimension reduction of general HMMs. We demonstrate the method on both a simple toy model, and on a speech-derived HMM trained from data, obtaining favourable memory--accuracy trade-offs compared to classical compression approaches.

</details>


### [37] [Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory](https://arxiv.org/abs/2601.16144)
*Tetsuro Abe,Shu Tanaka*

Main category: quant-ph

TL;DR: SBO-QAOA addresses bias in degenerate ground state sampling in QAOA by using temperature-dependent Hamiltonians to achieve fair sampling and temperature-targeting properties.


<details>
  <summary>Details</summary>
Motivation: Standard QAOA with transverse-field mixer introduces biases among degenerate ground states as circuit depth increases, preventing fair sampling of degenerate solutions in combinatorial optimization problems.

Method: Proposes SBO-QAOA based on quantum-classical correspondence theory, using a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state to achieve uniform sampling among degenerate states.

Result: Numerical simulations show SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states, unlike standard QAOA. These properties are preserved even with only four variational parameters under a linear schedule.

Conclusion: SBO-QAOA successfully addresses the bias problem in degenerate ground state sampling for QAOA, achieving fair sampling and temperature-targeting capabilities with minimal variational parameters.

Abstract: In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule.

</details>


### [38] [Polynomial-time thermalization and Gibbs sampling from system-bath couplings](https://arxiv.org/abs/2601.16154)
*Samuel Slezak,Matteo Scandi,Álvaro M. Alhambra,Daniel Stilck França,Cambyse Rouzé*

Main category: quant-ph

TL;DR: The paper proves polynomial-time convergence for two families of Lindblad dynamics modeling quantum Gibbs sampling and open many-body thermalization in non-commuting systems.


<details>
  <summary>Details</summary>
Motivation: Understanding convergence speed of Lindbladians to steady states is crucial for bounding algorithmic runtimes and thermalization timescales in quantum systems weakly coupled to baths.

Method: The authors study two families of processes: repeated-interaction Gibbs sampling algorithm and open many-body quantum thermalization models. They prove convergence using a novel technical result that extrapolates spectral gap lower bounds from quasi-local Lindbladians to non-local generators.

Result: Both processes converge in polynomial time for several non-commuting systems including high-temperature local lattices, weakly interacting fermions, and 1D spin chains.

Conclusion: Simple dissipative quantum algorithms can prepare complex Gibbs states and Lindblad dynamics accurately capture thermal relaxation in various physically relevant systems.

Abstract: Many physical phenomena, including thermalization in open quantum systems and quantum Gibbs sampling, are modeled by Lindbladians approximating a system weakly coupled to a bath. Understanding the convergence speed of these Lindbladians to their steady states is crucial for bounding algorithmic runtimes and thermalization timescales. We study two such families of processes: one characterizing a repeated-interaction Gibbs sampling algorithm, and another modeling open many-body quantum thermalization. We prove that both converge in polynomial time for several non-commuting systems, including high-temperature local lattices, weakly interacting fermions, and 1D spin chains. These results demonstrate that simple dissipative quantum algorithms can prepare complex Gibbs states and that Lindblad dynamics accurately capture thermal relaxation. Our proofs rely on a novel technical result that extrapolates spectral gap lower bounds from quasi-local Lindbladians to the non-local generators governing these dynamics.

</details>


### [39] [Stabilizer Thermal Eigenstates at Infinite Temperature](https://arxiv.org/abs/2601.16177)
*Akihiro Hokkyo*

Main category: quant-ph

TL;DR: The paper introduces a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians, proves a no-go theorem that stabilizer eigenstates of two-body Hamiltonians cannot satisfy k-body microscopic thermal equilibrium for k≥4, and shows this bound is tight with explicit constructions.


<details>
  <summary>Details</summary>
Motivation: Understanding highly entangled thermal eigenstates is a central challenge in quantum many-body systems. The authors aim to develop analytical approaches to study such states, particularly focusing on the limitations imposed by few-body interactions on achieving microscopic thermal equilibrium.

Method: The authors introduce a stabilizer-based approach to construct analytically tractable energy eigenstates. They prove a sharp no-go theorem using mathematical analysis of stabilizer eigenstates of two-body Hamiltonians, and demonstrate tightness of the bound by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and three-body observables.

Result: The main results are: (1) A proven no-go theorem showing stabilizer eigenstates of two-body Hamiltonians cannot satisfy k-body microscopic thermal equilibrium for any k≥4; (2) Demonstration that this bound is tight through explicit constructions of Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and three-body observables; (3) Identification of the structural origin of this limitation by characterizing conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian.

Conclusion: The work reveals a fundamental constraint imposed by the few-body nature of interactions on achieving microscopic thermal equilibrium in stabilizer eigenstates, providing important insights into the structure of thermal eigenstates in quantum many-body systems and establishing analytical tools for studying nonintegrable Hamiltonians.

Abstract: Understanding how to analyze highly entangled thermal eigenstates is a central challenge in the study of quantum many-body systems. In this Letter, we introduce a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians. Focusing on zero-energy eigenstates at infinite temperature, we prove a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy $k$-body microscopic thermal equilibrium for any $k\ge4$. We further show that this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables. Finally, we identify the structural origin of this limitation by characterizing the conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian, thereby revealing a fundamental constraint imposed by the few-body nature of interactions.

</details>


### [40] [Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States](https://arxiv.org/abs/2601.16189)
*Xiaotian Yang,Santiago Zamora,Rafael Chaves,Ulrik L. Andersen,Jonatan Bohr Brask,A. de Oliveira Junior*

Main category: quant-ph

TL;DR: GKP encoding enables homodyne detection to reveal multipartite Bell nonlocality in continuous-variable systems, overcoming bipartite limitations.


<details>
  <summary>Details</summary>
Motivation: Homodyne detection in continuous-variable systems faces strong constraints for Bell tests. The paper investigates whether Gottesman-Kitaev-Preskill (GKP) encoding can transform homodyne detection into a practical tool for revealing Bell nonlocality.

Method: The authors consider a physically motivated model where each party performs homodyne detection and digitizes continuous outcomes via fixed periodic binning (corresponding to logical Pauli measurements). They analyze bipartite and multipartite scenarios, deriving no-go theorems for bipartite CHSH violation and demonstrating multipartite nonlocality for GKP-encoded GHZ and W states.

Result: Bipartite no-go: CHSH cannot be violated for Bell-pair states. However, finitely squeezed GKP-encoded GHZ and W states exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. The paper quantifies required squeezing thresholds and robustness to loss.

Conclusion: GKP encoding provides a viable route toward homodyne-based Bell tests in continuous-variable systems, overcoming bipartite limitations and enabling practical multipartite nonlocality demonstrations with homodyne detection.

Abstract: Bell tests based on homodyne detection are strongly constrained in continuous-variable systems. Can Gottesman-Kitaev-Preskill (GKP) encoding turn homodyne detection into a practical tool for revealing Bell nonlocality? We consider a physically motivated model in which each party performs homodyne detection and digitizes the continuous outcome via a fixed periodic binning, corresponding to logical Pauli measurements. Within this framework, we derive a bipartite no-go: CHSH cannot be violated for Bell-pair states. Moving beyond two parties, we show that finitely squeezed GKP-encoded GHZ and W states nevertheless exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. We quantify the required squeezing thresholds and robustness to loss, providing a route toward homodyne-based Bell tests in continuous-variable systems.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [41] [Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.15340)
*Fabiana Taglietti,Andrea Pulici,Maxwell Roxburgh,Gabriele Seguini,Ian Vidamour,Stephan Menzel,Edoardo Franco,Michele Laus,Eleni Vasilaki,Michele Perego,Thomas J. Hayward,Marco Fanciulli,Jack C. Gartside*

Main category: cond-mat.dis-nn

TL;DR: Physical KANs using trainable synaptic nonlinearities outperform conventional linear-weight networks with far fewer parameters/devices, demonstrated experimentally with silicon SYNE devices.


<details>
  <summary>Details</summary>
Motivation: Current physical neural networks train only linear synaptic weights while treating device nonlinearities as fixed, missing opportunities to leverage physical nonlinear dynamics for more efficient computation.

Method: Train synaptic nonlinearity itself using Kolmogorov-Arnold Network (KAN) architectures implemented physically in silicon-on-insulator devices called Synaptic Nonlinear Elements (SYNEs), operating at room temperature with 0.1-1 μA currents and 2 MHz speeds.

Result: Physical KANs outperform equivalently-parameterized software MLPs across nonlinear function regression, classification, and Li-Ion battery prediction tasks, achieving up to 100× fewer parameters and 100× fewer devices than linear-weight physical networks with no degradation over 10^13 measurements.

Conclusion: Learned physical nonlinearity serves as a hardware-native computational primitive for compact, efficient learning systems, with SYNE devices providing effective substrates for heterogeneous nonlinear computing.

Abstract: Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.
  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.
  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing.

</details>


### [42] [Non-zero Momentum Implies Long-Range Entanglement When Translation Symmetry is Broken in 1D](https://arxiv.org/abs/2601.15345)
*Amanda Gatto Lamas,Taylor L. Hughes*

Main category: cond-mat.dis-nn

TL;DR: The paper extends Gioia and Wang's momentum-LRE connection to non-translation symmetric states in 1D systems, showing that the expectation value of the translation operator |⟨T⟩| approaches 1 for delocalized states, serving as a momentum-space analog to Resta's formula for localization length.


<details>
  <summary>Details</summary>
Motivation: Gioia and Wang showed translationally symmetric states with nonzero momentum are necessarily long-range entangled (LRE), but this requires finding finite-depth quantum circuits connecting states to translation-symmetric ones, which is impractical for translation-symmetry-breaking states. The authors aim to develop a momentum-based entanglement probe that works directly for non-translation symmetric states.

Method: Instead of translation eigenstates, the authors analyze the many-body momentum distribution and expectation value of the translation operator ⟨T⟩ in systems with broken translation symmetry. They show that in the continuum limit, |⟨T⟩| → 1 for delocalized states (proxy for LRE in 1D). They introduce two lattice models: a deterministic random dimer model to study thermodynamic and continuum limits, and a simplified Aubry-André model with commensurate hopping. They test their approach using the random dimer model as a case study.

Result: For 1D systems, the magnitude of the translation operator expectation value |⟨T⟩| necessarily approaches 1 for delocalized states in the continuum limit, providing a momentum-space analog to Resta's localization length formula. This serves as a direct entanglement probe for non-translation symmetric states. The approach works for 1D systems but requires further development for higher dimensions and topologically ordered systems.

Conclusion: The expectation value of the translation operator |⟨T⟩| can directly encode entanglement nature for non-translation symmetric states in 1D systems, providing a practical momentum-space entanglement probe that avoids the need to find finite-depth quantum circuits connecting to translation-symmetric states. The method generalizes Gioia and Wang's result beyond translation symmetry and offers a momentum-space perspective on localization and entanglement.

Abstract: A result by Gioia and Wang [Phys Rev X 12, 031007 (2022)] showed that translationally symmetric states having nonzero momentum are necessarily long range entangled (LRE). Here, we consider the question: can a notion of momentum for non-translation symmetric states directly encode the nature of their entanglement, as it does for translation symmetric states? We show the answer is affirmative for 1D systems, while higher dimensional extensions and topologically ordered systems require further work. While Gioia and Wang's result applies to states connected via finite depth quantum circuits to a translation symmetric state, it is often impractical to find such a circuit to determine the nature of the entanglement of states that break translation symmetry. Here, instead of translation eigenstates, we focus on the many-body momentum distribution and the expectation value of the translation operator in many-body states of systems having broken translation symmetry. We show that in the continuum limit the magnitude of the expectation value of the translation operator $|<T>|$ necessarily goes to $1$ for delocalized states, a proxy for LRE states in 1D systems. This result can be seen as a momentum-space version of Resta's formula for the localization length. We investigate how accurate our results are in different lattice models with and without well-defined continuum limits. To that end, we introduce two models: a deterministic version of the random dimer model, illustrating the role of the thermodynamic and continuum limits for our result at a lattice level, and a simplified version of the Aubry-Andre model, with commensurate hopping for both momentum and position space. Finally, we use the random dimer model as a test case for the accuracy of $|<T>|$ as a localization (and thus entanglement) probe for 1D periodic lattice models without a well-defined continuum limit.

</details>


### [43] [Structural constraints on mobility edges in one-dimensional quasiperiodic systems](https://arxiv.org/abs/2601.15799)
*Sanghoon Lee,Tilen Cadez,Kyoung-Min Kim*

Main category: cond-mat.dis-nn

TL;DR: Mobility edges in quasiperiodic systems are structurally constrained across isospectral dual Hamiltonians, restricting mobility edge positions to a reduced set of energies and enforcing linear critical scaling near self-dual points.


<details>
  <summary>Details</summary>
Motivation: To understand that mobility edge positions are not independent spectral features of individual Hamiltonians but are structurally constrained across quasiperiodic Hamiltonians related by isospectral duality, moving beyond the typical understanding at the level of individual Hamiltonians.

Method: Using a bichromatic Aubry-André model as a minimal setting, demonstrating the constraint is encoded in an exact identity for Lyapunov exponents derived from the Thouless formula, and analyzing the structural consequences for mobility edge positions.

Result: Mobility edge positions are restricted to a reduced set of energies, and in the self-dual limit they coincide at a single localization-delocalization transition. The structural constraint enforces linear critical scaling of the physical Lyapunov spectrum near the self-dual point, with numerical results confirming a critical exponent ν=1 and revealing a novel, non-universal energy-dependent prefactor.

Conclusion: Mobility edges in quasiperiodic systems are fundamentally constrained by isospectral duality relations, leading to reduced sets of allowed mobility edge positions and specific critical scaling behavior near self-dual points, with implications for understanding localization transitions in disordered systems.

Abstract: Mobility edges commonly arise in one-dimensional quasiperiodic systems once exact self-duality is broken, yet their origin is typically understood only at the level of individual Hamiltonians. Here we show that mobility edge positions are not independent spectral features of individual Hamiltonians, but are structurally constrained across quasiperiodic Hamiltonians related by an isospectral duality. Using a bichromatic Aubry--André model as a minimal setting, we demonstrate that this constraint is encoded in an exact identity for Lyapunov exponents derived from the Thouless formula. As a consequence, the mobility edge positions are restricted to a reduced set of energies. In the self-dual limit, these mobility edge positions coincide at a single localization--delocalization transition. This structural constraint enforces a linear critical scaling of the physical Lyapunov spectrum near the self-dual point. Numerical results confirm a critical exponent consistent with the standard Aubry--André value of $ν= 1$, while simultaneously revealing a novel, non-universal energy-dependent prefactor.

</details>
