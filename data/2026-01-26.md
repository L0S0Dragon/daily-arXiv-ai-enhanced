<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 38]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [LiDMaS: Architecture-Level Modeling of Fault-Tolerant Magic-State Injection in GKP Photonic Qubits](https://arxiv.org/abs/2601.16244)
*Dennis Delali Kwesi Wayo*

Main category: quant-ph

TL;DR: Study of logical T-gate magic-state preparation in GKP-encoded photonic qubits using repeat-until-success injection with outer surface-code protection, analyzing trade-offs between squeezing, photon loss, and logical fidelity.


<details>
  <summary>Details</summary>
Motivation: Fault-tolerant quantum computation in photonic architectures requires efficient preparation of high-fidelity logical magic states under realistic constraints of finite squeezing and photon loss.

Method: Developed architecture-level modeling framework using lightweight density-matrix simulator with standard numerical linear algebra. Finite squeezing mapped to logical dephasing, depolarizing noise included at logical level, photon loss treated as heralded erasure. Systematic parameter sweeps over squeezing (8-16 dB), loss probabilities (0.01-0.03), and surface-code distances (d=1,3,5,7).

Result: Success probabilities exceed 0.94 across all parameters with average overhead close to unity. Logical fidelities reach approximately 0.77-0.80 after outer-code protection, showing weak sensitivity to moderate photon loss but strong dependence on squeezing. Phase-boundary analysis identifies minimum squeezing requirements for high success probability and logical fidelity.

Conclusion: The results provide quantitative design guidance for scalable photonic fault-tolerant quantum architectures, demonstrating that repeat-until-success injection with outer surface-code protection can achieve practical logical magic-state fidelities under realistic experimental constraints.

Abstract: Fault-tolerant quantum computation in photonic architectures relies on the efficient preparation of high-fidelity logical magic states under realistic constraints imposed by finite squeezing and photon loss. In this work, we study logical T-gate magic-state preparation in GKP-encoded photonic qubits using a repeat-until-success injection protocol combined with outer surface-code protection. We develop an architecture-level modeling framework based on a lightweight density-matrix simulator implemented with standard numerical linear algebra. Finite squeezing is mapped to effective logical dephasing, depolarizing noise is included at the logical level, and photon loss is treated as a heralded erasure process. This approach avoids explicit continuous-variable wavefunction simulation, hardware-specific photonic models, and quantum software frameworks, enabling transparent and computationally efficient exploration of architectural trade-offs. We perform systematic parameter sweeps over squeezing values from 8 to 16 dB, baseline loss probabilities between 0.01 and 0.03, and surface-code distances d = 1, 3, 5, and 7. Across this regime, we evaluate repeat-until-success probability, average injection overhead, and logical magic-state fidelity. We find that success probabilities exceed 0.94 across all studied parameters, with an average overhead close to unity. After outer-code protection, logical fidelities reach approximately 0.77 to 0.80 and show weak sensitivity to moderate photon loss but a strong dependence on squeezing. Phase-boundary analysis identifies minimum squeezing requirements needed to simultaneously achieve high success probability and logical fidelity. These results provide quantitative design guidance for scalable photonic fault-tolerant quantum architectures.

</details>


### [2] [Quantum Cellular Automata on a Dual-Species Rydberg Processor](https://arxiv.org/abs/2601.16257)
*Ryan White,Vikram Ramesh,Alexander Impertro,Shraddha Anand,Francesco Cesa,Giuliano Giudici,Thomas Iadecola,Hannes Pichler,Hannes Bernien*

Main category: quant-ph

TL;DR: Quantum cellular automata (QCAs) implemented on dual-species Rydberg arrays enable universal quantum dynamics using only global controls, bypassing the scaling challenge of individual qubit addressing.


<details>
  <summary>Details</summary>
Motivation: As quantum devices scale up, the challenge of scaling coherent controls for individual qubits becomes significant. QCAs offer a framework to bypass this control problem by enabling universal dynamics using only static qubit arrays and global control operations.

Method: Implemented QCAs on a dual-species Rydberg array of rubidium and cesium atoms, leveraging independent global control of each species. Used simple pulse sequences to perform various quantum protocols and explore many-body dynamics.

Result: Generated a variety of entangled states including GHZ states, 96.7(1.7)%-fidelity Bell states, 17-qubit cluster states, and high-connectivity graph states. Demonstrated the versatility of QCAs for quantum information processing.

Conclusion: QCAs offer compelling routes for scaling quantum information systems with global controls and provide new perspectives on quantum many-body dynamics, addressing the control scaling challenge in large quantum devices.

Abstract: As quantum devices scale to larger and larger sizes, a significant challenge emerges in scaling their coherent controls accordingly. Quantum cellular automata (QCAs) constitute a promising framework that bypasses this control problem: universal dynamics can be achieved using only a static qubit array and global control operations. We realize QCAs on a dual-species Rydberg array of rubidium and cesium atoms, leveraging independent global control of each species to perform a myriad of quantum protocols. With simple pulse sequences, we explore many-body dynamics and generate a variety of entangled states, including GHZ states, 96.7(1.7)%-fidelity Bell states, 17-qubit cluster states, and high-connectivity graph states. The versatility and scalability of QCAs offers compelling routes for scaling quantum information systems with global controls, as well as new perspectives on quantum many-body dynamics.

</details>


### [3] [Multi-invariants in stabilizer states](https://arxiv.org/abs/2601.16258)
*Sriram Akella,Abhijit Gadde,Jay Pandey*

Main category: quant-ph

TL;DR: Efficient computation methods for multipartite entanglement measures (multi-invariants) in stabilizer states, with explicit formulas for tripartite cases and topological connections.


<details>
  <summary>Details</summary>
Motivation: Multipartite entanglement is poorly understood compared to bipartite entanglement, requiring better tools to calculate entanglement measures for stabilizer states, which are important in quantum information and many-body physics.

Method: Developed efficient numerical algorithm for computing multi-invariants for stabilizer states; derived explicit formula for tripartite stabilizer states using GHZ-extraction theorem; presented counting argument for Coxeter multi-invariants of q-partite stabilizer states; simplified formulas for restricted stabilizer states appearing in models like toric code and X-cube.

Result: Efficient algorithm for multi-invariant computation; explicit tripartite formula; counting argument for Coxeter multi-invariants; conjectured closed form expression; discovered connections between multi-invariants, stabilizer states and topology; simplified formulas for specific model ground states.

Conclusion: The paper provides powerful tools for analyzing multipartite entanglement in stabilizer states, revealing mathematical structure and topological connections, with practical applications to quantum many-body systems like toric code and X-cube models.

Abstract: Multipartite entanglement is a natural generalization of bipartite entanglement, but is relatively poorly understood. In this paper, we develop tools to calculate a class of multipartite entanglement measures - known as multi-invariants - for stabilizer states. We give an efficient numerical algorithm that computes multi-invariants for stabilizer states. For tripartite stabilizer states, we also obtain an explicit formula for any multi-invariant using the GHZ-extraction theorem. We then present a counting argument that calculates any Coxeter multi-invariant of a q-partite stabilizer state. We conjecture a closed form expression for the same. We uncover hints of an interesting connection between multi-invariants, stabilizer states and topology. We show how our formulas are further simplified for a restricted class of stabilizer states that appear as ground states of interesting models like the toric code and the X-cube model.

</details>


### [4] [Quantum algorithm for simulating non-adiabatic dynamics at metallic surfaces](https://arxiv.org/abs/2601.16264)
*Robert A. Lang,Paarth Jain,Juan Miguel Arrazola,Danial Motlagh*

Main category: quant-ph

TL;DR: A quantum algorithm for simulating non-adiabatic dynamics at molecule-metal interfaces with low resource requirements, suitable for near-term fault-tolerant quantum computers.


<details>
  <summary>Details</summary>
Motivation: Non-adiabatic dynamics at molecule-metal interfaces are crucial for applications like heterogeneous catalysis, solar energy conversion, and molecular electronics, but classical computational methods are prohibitively expensive due to the large number of electronic states and nuclear degrees of freedom involved.

Method: Developed a generalization of the Anderson-Newns Hamiltonian and created a highly optimized quantum algorithm using the PennyLane software platform, with resource estimation for realistic model systems.

Result: The algorithm requires only 271 qubits and 7.9 × 10⁷ Toffoli gates for 1000 Trotter steps, simulating systems with 100 metal orbitals, 8 molecular orbitals, and 20 nuclear degrees of freedom.

Conclusion: Non-adiabatic molecule-metal dynamics represents a promising application for first-generation fault-tolerant quantum computers due to the algorithm's remarkably low resource requirements compared to classical methods.

Abstract: Non-adiabatic dynamics at molecule-metal interfaces govern diverse and technologically important phenomena, from heterogeneous catalysis to dye-sensitized solar energy conversion and charge transport across molecular junctions. Realistic modeling of such dynamics necessitates taking into account various charge and energy transfer channels involving the coupling of nuclear motion with a very large number of electronic states, leading to prohibitive cost using classical computational methods. In this work we introduce a generalization of the Anderson-Newns Hamiltonian and develop a highly optimized quantum algorithm for simulating the non-adiabatic dynamics of realistic molecule-metal interfaces. Using the PennyLane software platform, we perform resource estimations of our algorithm, showing its remarkably low implementation cost for model systems representative of various scientifically and industrially relevant molecule-metal systems. Specifically, we find that time evolution for models including $100$ metal orbitals, $8$ molecular orbitals, and $20$ nuclear degrees of freedom, requires only $271$ qubits and $7.9 \times 10^7$ Toffoli gates for $1000$ Trotter steps, suggesting non-adiabatic molecule-metal dynamics as a fruitful application of first-generation fault-tolerant quantum computers.

</details>


### [5] [Post-processing optimization and optimal bounds for non-adaptive shadow tomography](https://arxiv.org/abs/2601.16266)
*Andrea Caprotti,Joshua Morris,Borivoje Dakić*

Main category: quant-ph

TL;DR: Optimizing post-processing of overcomplete POVM measurements to minimize variance bounds in shadow tomography, enabling dramatic reduction in sampling complexity.


<details>
  <summary>Details</summary>
Motivation: Informationally overcomplete POVMs outperform minimally complete measurements in tomography tasks but leave classical freedom in shadow tomography - the same observable admits infinitely many unbiased linear reconstructions from identical measurement data. This freedom can be exploited to reduce variance.

Method: Formulate the choice of reconstruction coefficients as a convex minimax problem. Develop an algorithm with guaranteed convergence that returns the tightest state-independent variance bound achievable by post-processing for a fixed POVM and observable.

Result: Numerical examples show the resulting estimators dramatically reduce sampling complexity relative to standard (canonical) reconstructions. They can even improve the qualitative scaling with system size for structured noncommuting targets.

Conclusion: Optimizing post-processing coefficients for overcomplete POVMs provides significant practical advantages in shadow tomography, enabling more efficient estimation with reduced sampling requirements and improved scaling properties.

Abstract: Informationally overcomplete POVMs are known to outperform minimally complete measurements in many tomography and estimation tasks, and they also leave a purely classical freedom in shadow tomography: the same observable admits infinitely many unbiased linear reconstructions from identical measurement data. We formulate the choice of reconstruction coefficients as a convex minimax problem and give an algorithm with guaranteed convergence that returns the tightest state-independent variance bound achievable by post-processing for a fixed POVM and observable. Numerical examples show that the resulting estimators can dramatically reduce sampling complexity relative to standard (canonical) reconstructions, and can even improve the qualitative scaling with system size for structured noncommuting targets.

</details>


### [6] [Engineering Near-Infrared Two-Level Systems in Confined Alkali Vapors](https://arxiv.org/abs/2601.16269)
*Gilad Orr,Golan Ben-Ari,Eliran Talker*

Main category: quant-ph

TL;DR: Experimental demonstration of telecom-wavelength two-level atomic system using rubidium vapor in sub-micron cell, where wall collisions suppress optical pumping and enable robust light-matter interaction.


<details>
  <summary>Details</summary>
Motivation: To develop compact atomic platforms operating at telecom wavelengths for integrated quantum photonic technologies, overcoming challenges of optical pumping into uncoupled states in conventional atomic systems.

Method: Combined experimental and theoretical investigation using hot rubidium vapor confined in sub-micron-thick cell, analyzing absorption and fluorescence spectra to study atomic coherence influenced by wall-induced relaxation from atom-surface collisions.

Result: Demonstrated optical response dominated by closed cycling transition that effectively isolates atomic dynamics to two-level configuration despite multiple hyperfine states, with confinement-induced selection suppressing optical pumping into uncoupled states.

Conclusion: Established practical route to realizing near-infrared atomic two-level systems in compact vapor-cell devices, opening opportunities for integrated quantum photonic technologies including on-chip quantum memories, telecom-band frequency references, and scalable quantum information processing.

Abstract: We combined experimental and theoretical investigations of an effective two-level atomic system operating in the near-infrared telecom wavelength regime, realized using hot rubidium vapor confined within a sub-micron-thick cell. In this strongly confined geometry, atomic coherence is profoundly influenced by wall-induced relaxation arising from frequent atom-surface collisions. By analyzing both absorption and fluorescence spectra, we demonstrate that the optical response is dominated by a closed cycling transition, which effectively isolates the atomic dynamics to a two-level configuration despite the presence of multiple hyperfine states. This confinement-induced selection suppresses optical pumping into uncoupled states and enables robust, controllable light-matter interaction at telecom wavelengths within a miniature atomic platform. Our results establish a practical route to realizing near-infrared atomic two-level systems in compact vapor-cell devices, opening new opportunities for integrated quantum photonic technologies, including on-chip quantum memories, telecom-band frequency references, and scalable quantum information processing.

</details>


### [7] [Experimental observation of conformal field theory spectra](https://arxiv.org/abs/2601.16275)
*Xiangkai Sun,Yuan Le,Stephen Naus,Richard Bing-Shiun Tsai,Lewis R. B. Picard,Sara Murciano,Michael Knap,Jason Alicea,Manuel Endres*

Main category: quant-ph

TL;DR: Experimental observation of universal energy spectra in quantum phase transitions using Rydberg chains and modulation techniques to probe conformal field theory predictions.


<details>
  <summary>Details</summary>
Motivation: Conformal field theories predict rich universal properties at quantum phase transitions, but much of this structure remains experimentally unobserved despite theoretical importance in high-energy physics, statistical mechanics, and condensed matter.

Method: Developed modulation technique to resolve finite-size spectra of Rydberg chains tuned to quantum phase transitions; used local control to distinguish excitation parities and induce transitions between CFT spectra; employed variant of modulation technique to study dynamical structure factor.

Result: Directly observed energy excitation spectra of emergent CFTs at quantum phase transitions, recovering universal energy ratios characteristic of underlying field theories; distinguished Ising and tricritical Ising CFT spectra; studied dynamical structure factor related to Ising conformal field correlations.

Conclusion: Work demonstrates experimental probing of CFT emergence in quantum simulators and provides diagnostic technique for identifying unknown universality classes in future experiments.

Abstract: Conformal field theories (CFTs) feature prominently in high-energy physics, statistical mechanics, and condensed matter. For example, CFTs govern emergent universal properties of systems tuned to quantum phase transitions, including their entanglement, correlations, and low-energy excitation spectra. Much of the rich structure predicted by CFTs nevertheless remains unobserved in experiment. Here we directly observe the energy excitation spectra of emergent CFTs at quantum phase transitions -- recovering universal energy ratios characteristic of the underlying field theories. Specifically, we develop and implement a modulation technique to resolve a Rydberg chain's finite-size spectra, variably tuned to quantum phase transitions described by either Ising or tricritical Ising CFTs. We also employ local control to distinguish parities of excitations under reflection and, in the tricritical Ising chain, to induce transitions between distinct CFT spectra associated with changing boundary conditions. By utilizing a variant of the modulation technique, we furthermore study the dynamical structure factor of the critical system, which is closely related to the correlation of an underlying Ising conformal field. Our work not only probes the emergence of CFT features in a quantum simulator, but also provides a technique for diagnosing a priori unknown universality classes in future experiments.

</details>


### [8] [Exploring Noisy Quantum Thermodynamical Processes via the Depolarizing-Channel Approximation](https://arxiv.org/abs/2601.16317)
*Jian Li,Xiaoyang Wang,Marcus Huber,Nicolai Friis,Pharnam Bakhshinezhad*

Main category: quant-ph

TL;DR: A framework approximating gate-dependent noise as global depolarizing channel enables analytical derivation of asymptotic cooling limits for noisy quantum thermodynamic protocols, revealing optimal finite qubit numbers and fundamental performance bounds.


<details>
  <summary>Details</summary>
Motivation: Noise and errors are unavoidable in realistic quantum processes, including thermodynamic cooling protocols, and can significantly alter their performance and efficiency. Analytical characterization becomes increasingly challenging with growing system size and deep quantum circuits where noise accumulates complexly.

Method: Introduce a general framework for approximating cumulative effect of gate-dependent noise using a global depolarizing channel. Specify the regime where this approximation provides reliable description of noisy dynamics. Apply framework to thermodynamical two-sort algorithmic cooling (TSAC) protocol.

Result: Analytically derive asymptotic cooling limit for noisy TSAC protocol. Show optimal cooling performance is achieved by finite number of qubits (vs. infinite in noiseless case). Derive fundamental bounds on achievable ground-state population.

Conclusion: The framework enables analytical exploration of noisy quantum thermodynamic processes, revealing noise-induced limitations and optimal operating points, opening new avenues for studying noisy quantum thermodynamics.

Abstract: Noise and errors are unavoidable in any realistic quantum process, including processes designed to reduce noise and errors in the first place. In particular, quantum thermodynamical protocols for cooling can be significantly affected, potentially altering both their performance and efficiency. Analytically characterizing the impact of such errors becomes increasingly challenging as the system size grows, particularly in deep quantum circuits where noise can accumulate in complex ways. To address this, we introduce a general framework for approximating the cumulative effect of gate-dependent noise using a global depolarizing channel. We specify the regime in which this approximation provides a reliable description of the noisy dynamics. Applying our framework to the thermodynamical two-sort algorithmic cooling (TSAC) protocol, we analytically derive its asymptotic cooling limit in the presence of noise. Using the cooling limit, the optimal cooling performance is achieved by a finite number of qubits--distinguished from the conventional noiseless TSAC protocol by an infinite number of qubits--and fundamental bounds on the achievable ground-state population are derived. This approach opens new avenues for exploring noisy quantum thermodynamical processes.

</details>


### [9] [Unambiguous randomness from a quantum state](https://arxiv.org/abs/2601.16343)
*Fionnuala Curran*

Main category: quant-ph

TL;DR: The paper introduces unambiguous randomness as a measure of intrinsic randomness in quantum measurements when an eavesdropper can return inconclusive outcomes, solving the problem for 2D states/projective measurements and isotropically noisy states in unbiased bases.


<details>
  <summary>Details</summary>
Motivation: To quantify intrinsic randomness in quantum measurements when an eavesdropper is never wrong but can sometimes return inconclusive outcomes, analogous to concepts in quantum state discrimination.

Method: Introduce unambiguous randomness and randomness with fixed inconclusive rates; solve for any state and projective measurement in dimension two, and for isotropically noisy states measured in unbiased bases of any dimension.

Result: For isotropically noisy states, an eavesdropper correlated only to the noisy state is always outperformed by one with joint correlations to both noisy state and measurement. A critical error parameter is identified beyond which joint eavesdropper achieves perfect guessing probability, eliminating private randomness.

Conclusion: Unambiguous randomness provides a refined measure of quantum randomness when eavesdroppers can return inconclusive outcomes, revealing that joint correlations to both state and measurement noise can completely compromise private randomness beyond a critical noise threshold.

Abstract: Intrinsic randomness is generated when a quantum state is measured in any basis in which it is not diagonal. In an adversarial scenario, we quantify this randomness by the probability that a correlated eavesdropper could correctly guess the measurement outcomes. What if the eavesdropper is never wrong, but can sometimes return an inconclusive outcome? Inspired by analogous concepts in quantum state discrimination, we introduce the unambiguous randomness of a quantum state and measurement, and, relaxing the assumption of perfect accuracy, randomness with a fixed rate of inconclusive outcomes. We solve these problems for any state and projective measurement in dimension two, as well as for an isotropically noisy state measured in an unbiased basis of any dimension. In the latter case, we find that, given a fixed amount of total noise, an eavesdropper correlated only to the noisy state is always outperformed by an eavesdropper with joint correlations to both a noisy state and a noisy measurement. In fact, we identify a critical error parameter beyond which the joint eavesdropper achieves perfect guessing probability, ruling out any possibility of private randomness.

</details>


### [10] [Reducing TLS loss in tantalum CPW resonators using titanium sacrificial layers](https://arxiv.org/abs/2601.16369)
*Zachary Degnan,Chun-Ching Chiu,Yi-Hsun Chen,David Sommers,Leonid Abdurakhimov,Lihuang Zhu,Arkady Fedorov,Peter Jacobson*

Main category: quant-ph

TL;DR: Using an ultrathin titanium sacrificial layer as an oxygen getter to chemically reduce tantalum oxide at metal-air interfaces significantly reduces two-level system loss in superconducting resonators, achieving over 3x improvement in quality factors.


<details>
  <summary>Details</summary>
Motivation: Two-level system (TLS) loss at metal-air interfaces is a major limitation for coherence in superconducting quantum circuits, particularly in tantalum-based systems where native oxide formation contributes to TLS loss. The motivation is to develop a practical surface engineering approach to suppress TLS loss by modifying the interfacial oxide chemistry.

Method: Deposit a 0.2nm titanium sacrificial layer atop pre-sputtered α-tantalum films on high-resistivity silicon substrates. The titanium acts as a solid-state oxygen getter that chemically modifies the native tantalum oxide at the metal-air interface. After device fabrication, remove the titanium layer using buffered oxide etchant, leaving behind a chemically reduced tantalum oxide surface. Apply subsequent high-vacuum annealing to further suppress TLS loss.

Result: Resonators treated with this process exhibit internal quality factors Qi exceeding an average of 1.5 million in the single-photon regime across ten devices. This represents over three times higher quality factors compared to otherwise identical devices lacking the titanium layer treatment.

Conclusion: Interfacial oxide chemistry plays a critical role in superconducting loss, and atomic-scale surface engineering through sacrificial titanium gettering is an effective approach to improving coherence in tantalum-based quantum circuits. The method is compatible with existing fabrication workflows and offers a practical route to extending T1 lifetimes in superconducting qubits.

Abstract: We demonstrate a substantial reduction in two-level system loss in tantalum coplanar waveguide resonators fabricated on high-resistivity silicon substrates through the use of an ultrathin titanium sacrificial layer. A 0.2nm titanium film, deposited atop pre-sputtered α-tantalum, acts as a solid-state oxygen getter that chemically modifies the native Ta oxide at the metal-air interface. After device fabrication, the titanium layer is removed using buffered oxide etchant, leaving behind a chemically reduced Ta oxide surface. Subsequent high-vacuum annealing further suppresses two-level system loss. Resonators treated with this process exhibit internal quality factors Qi exceeding an average of 1.5 million in the single-photon regime across ten devices, over three times higher than otherwise identical devices lacking the titanium layer. These results highlight the critical role of interfacial oxide chemistry in superconducting loss and reinforce atomic-scale surface engineering as an effective approach to improving coherence in tantalum-based quantum circuits. The method is compatible with existing fabrication workflows applicable to tantalum films, offering a practical route to further extending T1 lifetimes in superconducting qubits.

</details>


### [11] [Subspace-Confined QAOA with Generalized Dicke States for Multi-Channel Allocation in 5G CBRS Networks](https://arxiv.org/abs/2601.16396)
*Gunsik Min,Youngjin Seo,Jun Heo*

Main category: quant-ph

TL;DR: Subspace-confined QAOA for CBRS multi-channel allocation that uses Generalized Dicke states and XY mixers to exactly encode per-node Hamming-weight constraints, reducing search space from 2²⁴ to 2916 feasible configurations and outperforming penalty-based QAOA.


<details>
  <summary>Details</summary>
Motivation: Standard QAOA formulations for CBRS spectrum sharing use penalty terms for multi-channel constraints, making most of the Hilbert space correspond to invalid assignments, which is inefficient for 5G network capacity maximization.

Method: Propose subspace-confined QAOA where each node-wise channel register is initialized in a Generalized Dicke state and evolved under an intra-register XY mixer, confining dynamics to a tensor product of Johnson graphs that exactly encode per-node Hamming-weight constraints.

Result: For 8-node CBRS interference graph with 24 qubits, search space reduced from 2²⁴ to 2916 feasible configurations; algorithm converges rapidly to low-conflict assignments without large penalty coefficients, achieving near-optimal conflict levels and outperforming standard penalty-based QAOA and greedy classical heuristic in feasibility.

Conclusion: Constraint-preserving QAOA structure enables efficient CBRS multi-channel allocation with reduced search space, faster convergence, and maintains high feasibility ratio under NISQ-relevant noise regimes, offering practical advantages for 5G spectrum sharing optimization.

Abstract: Efficient spectrum sharing in the Citizens Broadband Radio Service (CBRS) band is essential for maximizing 5G network capacity, particularly when high-traffic base stations require simultaneous access to multiple channels. Standard formulations of the Quantum Approximate Optimization Algorithm (QAOA) impose such multi-channel constraints using penalty terms, so most of the explored Hilbert space corresponds to invalid assignments. We propose a subspace-confined QAOA tailored to CBRS multi-channel allocation, in which each node-wise channel register is initialized in a Generalized Dicke state and evolved under an intra-register XY mixer. This ansatz confines the dynamics to a tensor product of Johnson graphs that exactly encode per-node Hamming-weight constraints. For an 8-node CBRS interference graph with 24 qubits, the effective search space is reduced from the full Hilbert space of size $2^{24}$ to 2916 feasible configurations. Within this subspace, the algorithm converges rapidly to low-conflict assignments without large penalty coefficients. Simulations on instances with up to eight nodes show that the proposed ansatz achieves near-optimal conflict levels and consistently outperforms standard penalty-based QAOA and a greedy classical heuristic in terms of feasibility. Noise simulations with depolarizing channels further indicate that the constraint-preserving structure maintains a high feasibility ratio in NISQ-relevant error regimes.

</details>


### [12] [Low-Loss, High-Coherence Airbridge Interconnects Fabricated by Single-Step Lithography](https://arxiv.org/abs/2601.16416)
*Jibang Fu,Bo Ren,Jiandong Ouyang,Cong Li,Kechengqi Zhu,Yonggang Che,Xiang Fu,Shichuan Xue,Zhaohua Yang,Mingtang Deng,Junjie Wu*

Main category: quant-ph

TL;DR: Single-step electron-beam lithography process for fabricating nanoscale airbridges with sub-200-nm features, achieving robust mechanical stability and improved quantum device performance.


<details>
  <summary>Details</summary>
Motivation: Conventional multi-step fabrication methods for airbridges hinder miniaturization and introduce process-related defects, limiting performance in integrated circuits and quantum devices.

Method: Simplified process using only a single electron-beam lithography step with optimized multilayer resist stack, triple-exposure-dose scheme, and thermal reflow step.

Result: Fabricated smooth, suspended metallic bridges with sub-200-nm features and robust mechanical stability. In gradiometric SQUID design for transmon qubits, airbridges introduced no measurable additional loss in T₁ while enabling 2.5-fold enhancement of T₂*.

Conclusion: This efficient single-step method offers a practical route toward integrating high-performance three-dimensional interconnects in advanced quantum and nano-electronic devices.

Abstract: Airbridges are essential for creating high-performance, low-parasitic interconnects in integrated circuits and quantum devices. Conventional multi-step fabrication methods hinder miniaturization and introduce process-related defects. We report a simplified process for fabricating nanoscale airbridges using only a single electron-beam lithography step. By optimizing a multilayer resist stack with a triple-exposure-dose scheme and a thermal reflow step, we achieve smooth, suspended metallic bridges with sub-200-nm features that exhibit robust mechanical stability. Fabricated within a gradiometric SQUID design for superconducting transmon qubits, these airbridges introduce no measurable additional loss in the relaxation time $T_1$, while enabling a 2.5-fold enhancement of the dephasing time $T_2^*$. This efficient method offers a practical route toward integrating high-performance three-dimensional interconnects in advanced quantum and nano-electronic devices.

</details>


### [13] [Circulant quantum channels and its applications](https://arxiv.org/abs/2601.16435)
*Bing Xie,Lin Zhang*

Main category: quant-ph

TL;DR: Introduces circulant quantum channels as a subclass of mixed-permutation channels, showing they map to circulant matrices, are entanglement-breaking, and have applications in Bargmann invariants and coherence bounds.


<details>
  <summary>Details</summary>
Motivation: To study a specific family of circulant quantum channels within the broader class of mixed-permutation channels, aiming to characterize their structural properties and operational advantages for quantum information processing.

Method: Introduces circulant quantum channels as a subclass of mixed-permutation channels, analyzes their image as circulant matrices, proves entanglement-breaking property, and applies these results to Bargmann invariants and coherence measures.

Result: The image of circulant quantum channels is precisely the set of circulant matrices; the channels are entanglement-breaking; applications include analysis of arbitrary n-th order Bargmann invariants, tighter lower bounds for ℓ_p-norm coherence, and characterization of action in bipartite systems.

Conclusion: Circulant quantum channels offer significant advantages over general mixed-permutation channels, including reduced resource costs for erasing quantum correlations and practical applications in quantum information theory through their well-characterized structural properties.

Abstract: This note introduces a family of circulant quantum channels -- a subclass of the mixed-permutation channels -- and investigates its key structural and operational properties. We show that the image of the circulant quantum channel is precisely the set of circulant matrices. This characterization facilitates the analysis of arbitrary $n$-th order Bargmann invariants. Furthermore, we prove that the channel is entanglement-breaking, implying a substantially reduced resource cost for erasing quantum correlations compared to a general mixed-permutation channel. Applications of this channel are also discussed, including the derivation of tighter lower bounds for $\ell_p$-norm coherence and a characterization of its action in bipartite systems.

</details>


### [14] [Gluing Randomness via Entanglement: Tight Bound from Second Rényi Entropy](https://arxiv.org/abs/2601.16454)
*Wonjun Lee,Hyukjoon Kwon,Gil Young Cho*

Main category: quant-ph

TL;DR: Local random unitaries applied to entangled states generate approximate random states, with error scaling as Θ(e^{-N₂(ψ)}) where N₂(ψ) is the second Rényi entanglement entropy.


<details>
  <summary>Details</summary>
Motivation: Efficient generation of random quantum states is challenging but important for quantum information processing tasks. The paper aims to understand how entanglement enables local operations to generate global randomness.

Method: Apply local random unitaries to entangled states and analyze the resulting ensemble as approximate state designs. Extend to coherence-free operations and pseudorandom state generation using pseudorandom unitaries on locally entangled multipartite systems.

Result: The ensemble forms approximate state designs with error Θ(e^{-N₂(ψ)}), where N₂(ψ) is the second Rényi entanglement entropy. This bound is tight and also applies to second Rényi entropy of coherence for coherence-free operations. Second Rényi entropy gives the tightest bounds among all α-Rényi entropies.

Conclusion: Entanglement enables local random unitaries to generate global random states through "gluing" randomness. The quality of generated random states under resource-free operations is determined entirely by the resource content (entanglement or coherence) of the initial state, with second Rényi entropies representing maximal randomness generation capacities.

Abstract: The efficient generation of random quantum states is a long-standing challenge, motivated by their diverse applications in quantum information processing tasks. In this work, we identify entanglement as the key resource that enables local random unitaries to generate global random states by effectively gluing randomness across the system. Specifically, we demonstrate that approximate random states can be produced from an entangled state $|ψ\rangle$ through the application of local random unitaries. We show that the resulting ensemble forms an approximate state design with an error saturating as $Θ(e^{-\mathcal{N}_2(ψ)})$, where $\mathcal{N}_2(ψ)$ is the second Rényi entanglement entropy of $|ψ\rangle$. Furthermore, we prove that this tight bound also applies to the second Rényi entropy of coherence when the ensemble is constructed using coherence-free operations. These results imply that, when restricted to resource-free gates, the quality of the generated random states is determined entirely by the resource content of the initial state. Notably, we find that among all $α$-Rényi entropeis, the second Rényi entropy yields the tightest bounds. Consequently, these second Rényi entropies can be interpreted as the maximal capacities for generating randomness using resource-free operations. Finally, moving beyond approximate state designs, we utilize this entanglement-assisted gluing mechanism to present a novel method for generating pseudorandom states in multipartite systems from a locally entangled state via pseudorandom unitaries in each of parties.

</details>


### [15] [Quantum phase estimation with optimal confidence interval using three control qubits](https://arxiv.org/abs/2601.16474)
*Kaur Kristjuhan,Dominic W. Berry*

Main category: quant-ph

TL;DR: Efficient preparation of optimal quantum phase estimation states using matrix product states with bond dimension 4, enabling high-accuracy approximations up to 2^24 dimensions and requiring only 3 control qubits for power-of-2 dimensions.


<details>
  <summary>Details</summary>
Motivation: Quantum phase estimation is crucial for quantum algorithms, especially in quantum chemistry simulations for estimating ground state energies. Current methods for preparing optimal confidence interval states (discrete prolate spheroidal sequences) are inefficient, limiting practical implementation on early fault-tolerant quantum computers with limited logical qubits.

Method: The paper proposes using matrix product state (MPS) representation with bond dimension 4 to approximate the optimal discrete prolate spheroidal sequence states. This MPS can be efficiently prepared using a sequence of simple three-qubit operations. For dimensions that are powers of 2, the phase estimation requires only three qubits in the control register.

Result: The MPS representation with bond dimension 4 provides highly accurate approximations for all dimensions tested up to 2^24. The method enables efficient state preparation with simple three-qubit operations and reduces control register requirements to only 3 qubits for power-of-2 dimensions.

Conclusion: This approach significantly improves the efficiency of preparing optimal quantum phase estimation states, making it suitable for early-generation fault-tolerant quantum computers with limited logical qubit resources while maintaining high accuracy for large-scale quantum simulations.

Abstract: Quantum phase estimation is an important routine in many quantum algorithms, particularly for estimating the ground state energy in quantum chemistry simulations. This estimation involves applying powers of a unitary to the ground state, controlled by an auxiliary state prepared on a control register. In many applications the goal is to provide a confidence interval for the phase estimate, and optimal performance is provided by a discrete prolate spheroidal sequence. We show how to prepare the corresponding state in a far more efficient way than prior work. We find that a matrix product state representation with a bond dimension of 4 is sufficient to give a highly accurate approximation for all dimensions tested, up to $2^{24}$. This matrix product state can be efficiently prepared using a sequence of simple three-qubit operations. When the dimension is a power of 2, the phase estimation can be performed with only three qubits for the control register, making it suitable for early-generation fault-tolerant quantum computers with a limited number of logical qubits.

</details>


### [16] [Indefinite Causal Order from Failure-to-Glue: Contextual Semantics and Parametric Time](https://arxiv.org/abs/2601.16494)
*Partha Ghose*

Main category: quant-ph

TL;DR: A two-part framework: Part I develops category-theoretic formulation of definite-order explainability as gluing problem with contextual classifier; Part II applies to quantum gravity where ICO emerges as indeterminacy of parametric order despite microscopic time ordering.


<details>
  <summary>Details</summary>
Motivation: To clarify the meaning of "indefiniteness" in indefinite causal order (ICO) and its relation to definite-order explanations, which often remain opaque despite studies via quantum processes, process matrices, and quantum-gravity proposals.

Method: Part I: Category-theoretic formulation treating definite causal orderings as contexts, with causal separability as consistent global section (after convex mixing) and causal nonseparability as failure-to-glue; introduces seven-valued contextual classifier. Part II: Applies framework to quantum-gravity setting with parametric ordering variable τ distinct from spacetime time, using stochastic-quantization perspective on spin-network dynamics and interpreting Wheeler-DeWitt condition as equilibrium constraint.

Result: Provides a common language for comparing ICO criteria and precisely stating what "no hidden definite order" means; interprets ICO as indeterminacy of parametric order of coarse-grained relational interventions even when microscopic update process is globally ordered by τ.

Conclusion: The two-part framework unifies understanding of indefinite causal order across different approaches, clarifying the distinction between variation across contexts and genuine indeterminacy, with applications to quantum gravity where ICO emerges from coarse-graining despite fundamental parametric ordering.

Abstract: Indefinite causal order (ICO) has been studied via higher-order quantum processes (e.g.\ the quantum switch), process matrices, and quantum-gravity proposals involving superposed causal structure, yet the meaning of ``indefiniteness'' and its relation to definite-order explanations often remain opaque.
  Part~I develops a category-theoretic formulation of definite-order explainability as a gluing problem: each definite causal ordering (a partial order/DAG type) is treated as a context, and causal separability amounts to a consistent global section (possibly after convex mixing), whereas causal nonseparability is a failure-to-glue. We also introduce a compact seven-valued contextual classifier -- an intuitionistic elaboration -- that separates variation across contexts from genuine indeterminacy.
  Part~II applies this framework to a quantum-gravity motivated setting where the fundamental time is a parametric ordering variable $τ$, distinct from geometric (spacetime) time. Adopting a stochastic-quantization perspective on spin-network dynamics (Hilbert space not assumed fundamental) and reading the Wheeler--DeWitt condition as an equilibrium/stationarity constraint, we interpret ICO as indeterminacy of the parametric order of coarse-grained relational interventions, even when the microscopic update process is globally ordered by $τ$. Together, the two parts provide a common language for comparing ICO criteria and for stating precisely what ``no hidden definite order'' means.

</details>


### [17] [The optimal strategy of two-photon interferometric sensing in diverse noise environments](https://arxiv.org/abs/2601.16517)
*Teng-fei Yan,Zhuo-zhuo Wang,Qi-qi Li,Peng-long Wang,Bai-hong Li,Rui-Bo Jin*

Main category: quant-ph

TL;DR: HOM interferometry is insensitive to phase noise while N00N state interferometry is sensitive, with spectrally resolved detection outperforming non-resolved detection, especially beyond biphoton coherence time.


<details>
  <summary>Details</summary>
Motivation: Quantum sensing using two-photon interferometry offers quantum advantages but faces noise limitations. The paper aims to analyze how different two-photon interferometry schemes (HOM and N00N state) respond to noise to identify optimal strategies for practical applications in noisy environments.

Method: Analyzed sensitivity of two typical two-photon interferometries (Hong-Ou-Mandel and N00N state) to phase noise. Compared both spectrally non-resolved and spectrally resolved detection methods. Examined dependence on biphoton frequency difference (HOM) versus frequency sum (N00N state).

Result: HOM interferometry (depends on biphoton frequency difference) is insensitive to phase noise, while N00N state interferometry (depends on frequency sum) is sensitive to phase noise. This holds for both spectrally non-resolved and resolved detection. Spectrally resolved detection outperforms non-resolved detection, particularly beyond the coherence time of biphotons.

Conclusion: The findings provide optimal strategies for practical two-photon interferometric sensing in diverse noise environments: HOM interferometry for noise-insensitive applications and N00N state interferometry for noise-sensitive scenarios, with spectrally resolved detection as the superior detection method.

Abstract: Quantum sensing based on two-photon interferometry manifests quantum superiority beyond the classical precision limit. However, this superiority is usually diminished inevitably by the noise. Here, we analyze the sensitivity of two typical two-photon interferometries to the noise, that is, Hong-Ou-Mandel (HOM) and N00N state interferometry. It is found that HOM (N00N state) interference, which depends on the biphoton frequency difference (sum), is insensitive (sensitive) to the phase noise in both the manners of spectrally non-resolved and resolved detections in practice, suggesting their potential applications of sensing for different noise scenarios. Furthermore, spectrally resolved detection outperforms spectrally non-resolved one for the two interferometries, especially for the scope that exceeds the coherence time of biphotons. The findings provide an optimal strategy for the practical applications of two-photon interferometric sensing in diverse noise environments.

</details>


### [18] [Drive-Through Quantum Gate: Non-Stop Entangling a Mobile Ion Qubit with a Stationary One](https://arxiv.org/abs/2601.16537)
*Ting Hsu,Wen-Han Png,Kuan-Ting Lin,Ming-Shien Chang,Guin-Dar Lin*

Main category: quant-ph

TL;DR: A novel trapped-ion quantum computing architecture using continuously transported mobile ions for entanglement generation, avoiding heating issues of traditional QCCD shuttling while enabling efficient long-distance entanglement distribution.


<details>
  <summary>Details</summary>
Motivation: Traditional quantum charge-coupled device (QCCD) architectures based on ion shuttling suffer from severe motional heating during detachment, reintegration, and non-uniform motion, requiring extensive cooling and stabilization resources that hinder scalability.

Method: Proposed entangling scheme between stationary ion qubits and continuously transported mobile ions that remain in uniform motion, minimizing motional heating. Theoretical demonstration of gate operations with mobile ions passing beside stationary arrays.

Result: Theoretical demonstration of gate error on the order of 0.01%, achievable with current technology. Enables resource-efficient quantum operations and long-distance entanglement distribution where stationary arrays serve as memory and mobile ions as communication qubits.

Conclusion: This approach provides an alternative trapped-ion architecture beyond the QCCD paradigm, paving the way for scalable quantum computing with reduced heating issues and efficient entanglement distribution.

Abstract: Towards the scalable realization of a quantum computer, a quantum charge-coupled device (QCCD) based on ion shuttling has been considered a promising approach. However, the processes of detaching an ion from an array, reintegrating it, and driving non-uniform motion introduce severe heating, requiring significant time and laser power for re-cooling and stabilization. To mitigate these challenges, we propose a novel entangling scheme between a stationary ion qubit and a continuously transported mobile ion, which remains in uniform motion and minimizes motional heating. We theoretically demonstrate a gate error on the order of 0.01%, within reach of current technology. This approach enables resource-efficient quantum operations and facilitates long-distance entanglement distribution, where stationary trapped-ion arrays serve as memory units and mobile ions act as communication qubits passing beside them. Our results pave the way for an alternative trapped-ion architecture beyond the QCCD paradigm.

</details>


### [19] [Quantum graph resonances by cut-off technique](https://arxiv.org/abs/2601.16545)
*Pavel Exner,Jiří Lipovský,Jan Pekař*

Main category: quant-ph

TL;DR: Quantum graph resonances identified from eigenvalue behavior of cut-off systems with compact core and semi-infinite leads


<details>
  <summary>Details</summary>
Motivation: To develop a method for identifying resonances in quantum graphs with semi-infinite leads by analyzing the eigenvalue behavior of truncated systems

Method: Study eigenvalue behavior of cut-off quantum graph systems (truncated leads) to identify resonances in the full system with semi-infinite leads

Result: Demonstrated that resonances can be identified from the eigenvalue patterns of the cut-off system

Conclusion: Resonances in quantum graphs with semi-infinite leads can be effectively determined by analyzing the eigenvalue behavior of corresponding cut-off systems

Abstract: We demonstrate how resonances in a quantum graph consisting of a compact core and semi-infinite leads can be identified from the eigenvalue behavior of the cut-off system.

</details>


### [20] [Certification of quantum properties with imperfect measurements](https://arxiv.org/abs/2601.16570)
*Leonardo Zambrano,Teodor Parella-Dilmé,Antonio Acín,Donato Farina*

Main category: quant-ph

TL;DR: A robust certification method for quantum states that accounts for both statistical shot noise and systematic measurement imperfections, using convex optimization to bound function values with confidence regions.


<details>
  <summary>Details</summary>
Motivation: Accurate characterization of quantum systems is crucial for quantum technology advancement, and certifying convex functions of quantum states plays a central role in many applications. Existing methods need improvement to handle both statistical noise and systematic measurement imperfections simultaneously.

Method: Extends confidence region methods to accommodate imperfect measurement control, provides explicit prescriptions for quantifying finite statistics noise and estimating measurement imperfection effects, and uses convex optimization techniques to bound function values while jointly incorporating statistical and systematic errors.

Result: A robust certification framework for quantum experiments that accounts for both shot noise (statistical errors) and measurement imperfections (systematic errors) in the data-acquisition stage.

Conclusion: The method provides a comprehensive certification framework that jointly handles statistical and systematic uncertainties, offering robust certification for quantum experiments with imperfect measurements.

Abstract: The accurate characterization of quantum systems is essential for the advancement of quantum technologies. In particular, certifying convex functions of quantum states plays a central role in many applications. We present a certification method for experimentally prepared quantum states that accounts for both shot noise and measurement imperfections in the data-acquisition stage. Building upon previous work, our method extends confidence regions to accommodate imperfect control over measurements. The values of the functions can then be bounded using convex optimization techniques. We provide explicit prescriptions for quantifying the noise contribution from finite statistics and for estimating the effect of measurement imperfections. By jointly incorporating statistical and systematic errors, the method yields a robust certification framework for quantum experiments.

</details>


### [21] [Efficient quantum machine learning with inverse-probability algebraic corrections](https://arxiv.org/abs/2601.16665)
*Jaemin Seo*

Main category: quant-ph

TL;DR: Proposes inverse-probability algebraic learning for QNNs, replacing gradient descent with algebraic parameter updates via pseudo-inverse Jacobian, achieving faster convergence and noise robustness.


<details>
  <summary>Details</summary>
Motivation: QNN training faces challenges: oscillatory loss landscapes, quantum device noise, slow gradient-based convergence, hyperparameter sensitivity, and instability near sharp minima. Need more efficient, robust training methods for near-term quantum devices.

Method: Inverse-probability algebraic learning framework: treats learning as local inverse problem in probability space, directly maps Born-rule probability discrepancies to parameter corrections via pseudo-inverse of Jacobian. Covariant update, no learning-rate tuning, single-step movement toward loss minimum vicinity.

Result: Algebraic learning converges significantly faster than gradient descent/Adam, escapes loss plateaus, achieves lower final errors. Near-optimal error scaling under finite-shot sampling, robust against hardware noise (dephasing). Demonstrated in regression/classification tasks using teacher-student QNN benchmark.

Conclusion: Inverse-probability algebraic learning offers principled, practical alternative to procedural optimization for QNN training, particularly beneficial for resource-constrained near-term quantum devices.

Abstract: Quantum neural networks (QNNs) provide expressive probabilistic models by leveraging quantum superposition and entanglement, yet their practical training remains challenging due to highly oscillatory loss landscapes and noise inherent to near-term quantum devices. Existing training approaches largely rely on gradient-based procedural optimization, which often suffers from slow convergence, sensitivity to hyperparameters, and instability near sharp minima. In this work, we propose an alternative inverse-probability algebraic learning framework for QNNs. Instead of updating parameters through incremental gradient descent, our method treats learning as a local inverse problem in probability space, directly mapping discrepancies between predicted and target Born-rule probabilities to parameter corrections via a pseudo-inverse of the Jacobian. This algebraic update is covariant, does not require learning-rate tuning, and enables rapid movement toward the vicinity of a loss minimum in a single step. We systematically compare the proposed method with gradient descent and Adam optimization in both regression and classification tasks using a teacher-student QNN benchmark. Our results show that algebraic learning converges significantly faster, escapes loss plateaus, and achieves lower final errors. Under finite-shot sampling, the method exhibits near-optimal error scaling, while remaining robust against intrinsic hardware noise such as dephasing. These findings suggest that inverse-probability algebraic learning offers a principled and practical alternative to procedural optimization for QNN training, particularly in resource-constrained near-term quantum devices.

</details>


### [22] [Charging of a Quantum Battery by a Single-Photon Quantum Pulse](https://arxiv.org/abs/2601.16671)
*Elnaz Darsheshdar,Seyed Mostafa Moniri*

Main category: quant-ph

TL;DR: Optimal quantum battery charging using a two-level system excited by single-photon pulses, achieving universal energy bounds and quantum speed limits at exceptional points.


<details>
  <summary>Details</summary>
Motivation: To develop a minimal model for quantum battery charging that maximizes stored energy and charging power while establishing fundamental quantum limits on the charging process.

Method: A two-level system (TLS) charger coupled to a harmonic oscillator battery, excited by single-photon quantum pulses. Analytical solutions for dynamics, optimal pulse shape derivation, and analysis of exceptional point transitions.

Result: Optimal pulse saturates universal bound for stored energy determined by TLS decay rates; minimum charging time established with quantum speed limit at exceptional point; analytical expressions for charging power and optimal pulse duration derived.

Conclusion: The minimal quantum battery model reveals fundamental limits on energy storage and charging speed, with optimal pulses achieving theoretical bounds and exceptional points providing critical transitions for quantum speed limits.

Abstract: We study a minimal model for charging a quantum battery consisting of a two-level system (TLS) acting as a charger, coupled to a harmonic oscillator that serves as the quantum battery. A single-photon quantum pulse of light excites the TLS, which subsequently transfers its excitation to the isolated battery. The TLS may also decay into the electromagnetic environment. We obtain analytical solutions for the dynamics of the battery and determine the optimal pulse shape that maximizes the stored energy. The optimal pulse saturates a universal bound for the stored energy, determined by the TLS decay rates into the pulse and the environment. Furthermore, we derive the minimum charging time and establish a quantum speed limit at the exceptional point, where a critical transition occurs in the system's dynamics. We also present analytical expressions for the charging power and investigate the pulse duration that maximizes it.

</details>


### [23] [Classical Regularization in Variational Quantum Eigensolvers](https://arxiv.org/abs/2601.16679)
*Yury Chernyak,Ijaz Ahamed Mohammad,Martin Plesch*

Main category: quant-ph

TL;DR: Classical L2 regularization stabilizes Variational Quantum Eigensolver optimization by mitigating barren plateaus and ill-conditioned landscapes without modifying quantum circuits.


<details>
  <summary>Details</summary>
Motivation: Current quantum computers are limited in size and quality, leading to hybrid quantum-classical algorithms like VQAs. However, VQAs suffer from barren plateaus and ill-conditioned optimization landscapes that cause unstable convergence and high sensitivity to initialization.

Method: Augment the VQE objective with standard L2 squared-norm regularization (quadratic penalty proportional to squared norm of parameters) without modifying the quantum circuit or measurement process. Tested on H2, LiH, and Random Field Ising Model Hamiltonians across a broad window of regularization strengths.

Result: Across all tested Hamiltonians (H2, LiH, RFIM), improved performance was observed over a broad window of regularization strengths. Large-scale numerical results demonstrate that classical regularization provides robust, system-independent mechanism for mitigating VQE instability.

Conclusion: Classical L2 regularization enhances reliability and reproducibility of variational quantum optimization without altering the underlying quantum circuit, offering a practical remedy for VQA stability issues.

Abstract: While quantum computers are a very promising tool for the far future, in their current state of the art they remain limited both in size and quality. This has given rise to hybrid quantum-classical algorithms, where the quantum device performs only a small but vital part of the overall computation. Among these, variational quantum algorithms (VQAs), which combine a classical optimization procedure with quantum evaluation of a cost function, have emerged as particularly promising. However, barren plateaus and ill-conditioned optimization landscapes remain among the primary obstacles faced by VQAs, often leading to unstable convergence and high sensitivity to initialization. Motivated by this challenge, we investigate whether a purely classical remedy, standard L2 squared-norm regularization, can systematically stabilize hybrid quantum-classical optimization. Specifically, we augment the Variational Quantum Eigensolver (VQE) objective with a quadratic penalty proportional to the squared norm of the parameters, without modifying the quantum circuit or measurement process. Across all tested Hamiltonians, H2, LiH, and the Random Field Ising Model (RFIM), we observe improved performance over a broad window of the regularization strength. Our large-scale numerical results demonstrate that classical regularization provides a robust, system-independent mechanism for mitigating VQE instability, enhancing the reliability and reproducibility of variational quantum optimization without altering the underlying quantum circuit.

</details>


### [24] [Sparsity-dependent Complexity Lower Bound of Quantum Linear System Solvers](https://arxiv.org/abs/2601.16697)
*Hitomi Mori,Yuta Kikuchi,Marcello Benedetti,Matthias Rosenkranz*

Main category: quant-ph

TL;DR: The paper establishes a rigorous lower bound of Ω(κ√s) for quantum linear system solvers, capturing sparsity dependence that was previously folklore but unproven.


<details>
  <summary>Details</summary>
Motivation: Quantum linear system (QLS) solvers are fundamental quantum algorithms with applications in machine learning and differential equations. While the best known query complexity lower bound was Ω(κ log(1/ε)), a more general bound including sparsity s (Ω(κ√s log(1/ε))) had become folklore but lacked rigorous proof. The authors aim to establish the sparsity-dependent lower bound formally.

Method: The authors prove the lower bound through rigorous mathematical analysis, establishing Ω(κ√s) for any quantum algorithm solving QLS with constant error. The work addresses the gap between folklore knowledge and formal proof regarding sparsity dependence.

Result: The paper proves a lower bound of Ω(κ√s) for quantum linear system solvers with constant error, providing the first rigorous proof of sparsity dependence that was previously only folklore. This result serves as a crucial step toward complete characterization of QLS complexity.

Conclusion: The work establishes an important rigorous lower bound for quantum linear system solvers that captures sparsity dependence, addressing a significant gap in the literature. While the complete dependence on all parameters (κ, s, ε) remains an open problem, this result provides a foundational stepping stone for future research on QLS complexity characterization.

Abstract: Quantum linear system (QLS) solvers are a fundamental class of quantum algorithms used in many potential quantum computing applications, including machine learning and solving differential equations. The performance of quantum algorithms is often measured by their query complexity, which quantifies the number of oracle calls required to access the input. The main parameters determining the complexity of QLS solvers are the condition number $κ$ and sparsity $s$ of the linear system, and the target error $ε$. To date, the best known query-complexity lower bound is $Ω(κ\log(1/ε))$, which establishes the optimality of the most recent QLS solvers. The original proof of this lower bound is attributed to Harrow and Kothari, but their result is unpublished. Furthermore, when discussing a more general lower bound including the sparsity $s$ of the linear system, it has become folklore that it should read as $Ω( κ\sqrt{s}\log(1/ε))$. In this work, we establish the rigorous lower bound capturing the sparsity dependence of QLS. We prove the lower bound of $Ω(κ\sqrt{s})$ for any quantum algorithm that solves QLS with constant error. While the dependence on all parameters $κ,s,ε$ remains an open problem, our result provides a crucial stepping stone toward the complete characterization of QLS complexity.

</details>


### [25] [Entanglement harvesting in the presence of cavities](https://arxiv.org/abs/2601.16698)
*Jannik Ströhle,Nikolija Momcilovic*

Main category: quant-ph

TL;DR: Analytical and numerical study of entanglement harvesting in cylindrical cavities using Gaussian detectors, revealing strong dependence on cavity length, invariance to radius, different parameter scalings inside/outside light cone, and sensitivity to cavity-induced field parity.


<details>
  <summary>Details</summary>
Motivation: Previous entanglement harvesting studies focused on free space setups, but cavities offer controlled environments that can enhance or modify entanglement harvesting processes. Understanding how cavity confinement affects entanglement harvesting is important for quantum information applications and fundamental studies of quantum field theory in bounded spaces.

Method: Adiabatically couple quantized electromagnetic field to two identical Gaussian detectors positioned on symmetry axis of cylindrical cavity. Use detailed analytical and numerical analysis to study entanglement harvesting. Investigate dependence on cavity length, radius, detector parameters, and cavity-induced field parity.

Result: Numerical results show strong dependence on cavity length but invariance to cavity radius in regimes of maximal entanglement. Different scalings of detector system parameters identified for entanglement inside vs outside light cone. Strong dependence of harvested correlations on cavity-induced parity of electromagnetic field revealed.

Conclusion: Cavity confinement significantly modifies entanglement harvesting compared to free space, with cavity length and field parity playing crucial roles. These findings provide insights for optimizing entanglement harvesting in confined geometries and understanding quantum field correlations in bounded spaces.

Abstract: So far, entanglement harvesting has been extensively studied in free space setups. Here, we provide a detailed analytical and numerical analysis of entanglement harvesting in cavities. Specifically, we adiabatically couple the quantized electromagnetic field to two identical Gaussian detectors located on the symmetry axis of a cylindrical cavity. Our numerical investigations reveal a strong dependence on the cavity length, while showing invariance under changes in the cavity radius in regimes of maximal entanglement. Moreover, we identify different scalings of the detector system parameters for entanglement inside and outside the light cone. Finally, we uncover a strong dependence of the harvested correlations on the cavity induced parity of the electromagnetic field.

</details>


### [26] [SeeMPS: A Python-based Matrix Product State and Tensor Train Library](https://arxiv.org/abs/2601.16734)
*Paula García-Molina,Juan José Rodríguez-Aldavero,Jorge Gidi,Juan José García-Ripoll*

Main category: quant-ph

TL;DR: SeeMPS is a Python library implementing tensor network algorithms using Matrix Product States and Quantized Tensor Train formalisms for compressing exponentially large vector spaces and enabling both low-level tensor operations and high-level algorithms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to provide a comprehensive Python library for tensor network computations that bridges quantum many-body physics applications with quantum-inspired numerical analysis problems, offering efficient compression of exponentially large vector spaces through MPS/TT formalisms.

Method: The library implements tensor network algorithms based on Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms, providing a complete finite precision linear algebra package where exponentially large vector spaces are compressed using MPS/TT representation.

Result: SeeMPS enables both low-level operations (vector addition, linear transformations, Hadamard products) and high-level algorithms (approximation of linear equations, eigenvalue computations, exponentially efficient Fourier transforms) for quantum many-body physics and quantum-inspired numerical analysis.

Conclusion: SeeMPS serves as a versatile Python library that applies tensor network methods to both traditional quantum physics problems and broader numerical analysis applications, providing efficient computational tools for handling exponentially large state spaces.

Abstract: We introduce SeeMPS, a Python library dedicated to implementing tensor network algorithms based on the well-known Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms. SeeMPS is implemented as a complete finite precision linear algebra package where exponentially large vector spaces are compressed using the MPS/TT formalism. It enables both low-level operations, such as vector addition, linear transformations, and Hadamard products, as well as high-level algorithms, including the approximation of linear equations, eigenvalue computations, and exponentially efficient Fourier transforms. This library can be used for traditional quantum many-body physics applications and also for quantum-inspired numerical analysis problems, such as solving PDEs, interpolating and integrating multidimensional functions, sampling multivariate probability distributions, etc.

</details>


### [27] [Noise Resilience and Robust Convergence Guarantees for the Variational Quantum Eigensolver](https://arxiv.org/abs/2601.16758)
*Mirko Legnini,Julian Berberich*

Main category: quant-ph

TL;DR: The paper analyzes how coherent and incoherent noise affects Variational Quantum Eigensolver (VQE) convergence, providing theoretical insights and numerical simulations via Pennylane.


<details>
  <summary>Details</summary>
Motivation: While global convergence guarantees exist for VQEs under ideal conditions, little is known about convergence when quantum circuits are affected by noise. The paper aims to characterize how different noise processes impact VQE performance and convergence.

Method: The authors characterize the effect of coherent and incoherent noise processes on VQE optimal parameters and cost. They study noise influence on convergence guarantees and accompany theoretical analysis with numerical simulations implemented via Pennylane.

Result: The work provides novel theoretical insights into how noise affects parameterized quantum circuits, specifically analyzing noise impact on VQE optimal parameters, optimal cost, and convergence behavior.

Conclusion: The paper advances understanding of VQE behavior under realistic noisy conditions, bridging the gap between ideal theoretical convergence guarantees and practical implementations affected by quantum noise.

Abstract: Variational Quantum Algorithms (VQAs) are a class of hybrid quantum-classical algorithms that leverage on classical optimization tools to find the optimal parameters for a parameterized quantum circuit. One relevant application of VQAs is the Variational Quantum Eigensolver (VQE), which aims at steering the output of the quantum circuit to the ground state of a certain Hamiltonian. Recent works have provided global convergence guarantees for VQEs under suitable local surjectivity and smoothness hypotheses, but little has been done in characterizing convergence of these algorithms when the underlying quantum circuit is affected by noise. In this work, we characterize the effect of different coherent and incoherent noise processes on the optimal parameters and the optimal cost of the VQE, and we study their influence on the convergence guarantees of the algorithm. Our work provides novel theoretical insight into the behavior of parameterized quantum circuits. Furthermore, we accompany our results with numerical simulations implemented via Pennylane.

</details>


### [28] [Investigating Retargetability Claims for Quantum Compilers](https://arxiv.org/abs/2601.16779)
*Luke Southall,Joshua Ammermann,Rinor Kelmendi,Domenik Eichhorn,Ina Schaefer*

Main category: quant-ph

TL;DR: Researchers develop and apply a metric to assess retargetability of quantum compilers (Tket, Qiskit, ProjectQ) across diverse NISQ-era hardware platforms, finding Tket most retargetable followed by Qiskit.


<details>
  <summary>Details</summary>
Motivation: The proliferation of diverse quantum hardware architectures from different manufacturers creates challenges for quantum software retargetability, necessitating evaluation of quantum compilers' ability to compile software across different hardware platforms.

Method: Develop a metric for assessing retargetability of quantum compilers, then conduct a study applying this metric to analyze three prominent quantum compilers: Tket, Qiskit, and ProjectQ.

Result: Tket demonstrates the highest level of retargetability, closely followed by Qiskit, while ProjectQ lags behind in retargetability capabilities.

Conclusion: The study provides quantum software developers with insights for compiler selection and highlights areas for improvement in quantum compiler retargetability to address hardware diversity challenges in the NISQ era.

Abstract: In the NISQ-era, there is a wide variety of hardware manufacturers building quantum computers. Each of these companies may choose different approaches and hardware architectures for their machines. This poses a problem for quantum software engineering, as the retargetability of quantum programs across different hardware platforms becomes a non-trivial challenge. In response to this problem, various retargetable quantum compilers have been presented in the scientific literature. These promise the ability to compile software for different hardware platforms, enabling retargetability for quantum software. In this paper, we develop and apply a metric by which the retargetability of the quantum compilers can be assessed. We develop and run a study to analyze key aspects regarding the retargetability of the compilers Tket, Qiskit, and ProjectQ. Our findings indicate that Tket demonstrates the highest level of retargetability, closely followed by Qiskit, while ProjectQ lags behind. These results provide insights for quantum software developers in selecting appropriate compilers for their use-cases, and highlight areas for improvement in quantum compilers.

</details>


### [29] [Harnessing Quantum Computing for Energy Materials: Opportunities and Challenges](https://arxiv.org/abs/2601.16816)
*Seongmin Kim,In-Saeng Suh,Travis S. Humble,Thomas Beck,Eungkyu Lee,Tengfei Luo*

Main category: quant-ph

TL;DR: Quantum computing offers transformative potential for energy materials research by addressing computational challenges intractable for classical methods, though practical implementation requires hybrid quantum-classical approaches and future fault-tolerant systems.


<details>
  <summary>Details</summary>
Motivation: Classical computational methods face scaling and time-complexity limitations for high-dimensional or strongly correlated material systems in energy applications, creating a need for quantum computing's potential paradigm shift.

Method: The paper presents a perspective on leveraging quantum computing combined with classical computing methods for energy materials design and simulation, discussing hybrid approaches and outlining future error-corrected, fault-tolerant quantum computing systems.

Result: The perspective identifies opportunities for quantum computing in energy materials research while acknowledging current challenges, presenting cases where quantum-classical hybrid approaches can advance practical energy materials development.

Conclusion: Quantum computing holds promise for transformative advances in energy materials research, but achieving predictive accuracy and quantum advantage will require future error-corrected, fault-tolerant quantum computing systems capable of handling complex material systems.

Abstract: Developing high-performance materials is critical for diverse energy applications to increase efficiency, improve sustainability and reduce costs. Classical computational methods have enabled important breakthroughs in energy materials development, but they face scaling and time-complexity limitations, particularly for high-dimensional or strongly correlated material systems. Quantum computing (QC) promises to offer a paradigm shift by exploiting quantum bits with their superposition and entanglement to address challenging problems intractable for classical approaches. This perspective discusses the opportunities in leveraging QC to advance energy materials research and the challenges QC faces in solving complex and high-dimensional problems. We present cases on how QC, when combined with classical computing methods, can be used for the design and simulation of practical energy materials. We also outline the outlook for error-corrected, fault-tolerant QC capable of achieving predictive accuracy and quantum advantage for complex material systems.

</details>


### [30] [Protocols to share genuine multipartite entanglement employing copies of biseparable states](https://arxiv.org/abs/2601.16840)
*Swati Choudhary,Ujjwal Sen,Saronath Halder*

Main category: quant-ph

TL;DR: Two copies of biseparable three-qutrit states can generate genuine multipartite entanglement, unlike qubit systems requiring many copies, with protocol generalizable to arbitrary parties and activating stronger nonlocal correlations.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that genuine multipartite entanglement can be activated from biseparable states using fewer copies in higher-dimensional systems (qutrits vs qubits), and to show this activation can be achieved without joint measurements while also activating stronger nonlocal correlations.

Method: Developed a protocol for three-qutrit systems using two copies of rank-two biseparable states (entangled across all bipartitions) to probabilistically generate genuine multipartite entanglement through local operations and classical communication without joint measurements, then generalized to arbitrary number of parties.

Result: Successfully activated genuine multipartite entanglement from two copies of biseparable three-qutrit states with nonzero probability, contrasting with qubit systems requiring many copies, and showed the protocol naturally activates genuinely nonlocal correlations stronger than entanglement activation alone.

Conclusion: Genuine multipartite entanglement activation is more efficient in higher-dimensional systems (qutrits) than qubits, requiring only two copies, and the protocol demonstrates that such activation can simultaneously generate stronger nonlocal correlations without requiring joint measurements.

Abstract: Sharing genuine multipartite entanglement by considering collective use of copies of biseparable states, which are entangled across all bipartitions but lack genuine multipartite entanglement at the single-copy level, plays a central role in several quantum information processing protocols, and has been referred as genuine multipartite entanglement activation. We present a protocol for three-qutrit systems showing that two copies of rank-two biseparable states, entangled across every bipartition, are sufficient to generate a genuinely multipartite entangled state with nonzero probability. This contrasts with the three-qubit scenario where many copies of biseparable states might be required for sharing genuine multipartite entanglement. We subsequently generalize our protocols to the case of an arbitrary number of parties. Our protocol does not rely on the implementation of joint measurements on the copies of states. Interestingly, the proposed construction naturally leads to the activation of genuinely nonlocal correlations, yielding a result that is stronger than genuine multipartite entanglement activation alone.

</details>


### [31] [Generation of fully phase controlled two-photon entangled states](https://arxiv.org/abs/2601.16875)
*Ian Ford,Adrien Amour,Matthias Keller*

Main category: quant-ph

TL;DR: Researchers demonstrate generation of two-photon entangled states with full phase control using a single trapped calcium ion coupled to an optical cavity, achieving 82% fidelity.


<details>
  <summary>Details</summary>
Motivation: Trapped ions offer excellent control over internal states for generating single and two-photon states, but achieving full phase control over entangled photon states remains challenging. The goal is to leverage ion-cavity coupling to create precisely controlled two-photon entanglement.

Method: Use a single ⁴⁰Ca⁺ ion coupled to an optical cavity. Generate ion-photon entanglement first, then produce a second photon that maps the ion's state onto it. Employ coherence protection schemes for the ion-cavity interaction and adjust drive fields to control the entangled state's phase.

Result: Successfully generated two-photon entangled states with full phase control, achieving up to 82% fidelity. Demonstrated efficient emission into single spatial mode with control over temporal shape, phase, and frequency.

Conclusion: The approach enables resource-efficient generation of phase-controlled two-photon entanglement using a single trapped ion coupled to a cavity, advancing capabilities for quantum information processing and quantum communication applications.

Abstract: Control over the internal states of trapped ions makes them the ideal system to generate single and two-photon states. Coupling a single ion to an optical cavity enables efficient emission of single photons into a single spatial mode and grants control over their temporal shape, phase and frequency. Using the long coherence time of the ion's internal states and employing a scheme to protect the coherence of the ion-cavity interaction, we demonstrate the generation of a two-photon entangled state with full control over the phase. Initially, ion-photon entanglement is generated. A second photon is subsequently generated, mapping the ion's state onto the second photon. By adjusting the drive field the phase of the entangled state can be fully controlled. We implement this scheme in the most resource efficient way by utilizing a single $^{40}$Ca$^+$ ion coupled to an optical cavity and demonstrate the generation of a two-photon entangled stated with full phase control with a fidelity of up to 82\%.

</details>


### [32] [Quantum Position Verification with Remote Untrusted Devices](https://arxiv.org/abs/2601.16892)
*Gautam A. Kavuri,Yanbao Zhang,Abigail R. Gookin,Soumyadip Patra,Joshua C. Bienfang,Honghao Fu,Yusuf Alnawakhtha,Dileep V. Reddy,Michael D. Mazurek,Carlos Abellán,Waldimar Amaya,Morgan W. Mitchell,Sae Woo Nam,Carl A. Miller,Richard P. Mirin,Martin J. Stevens,Scott Glancy,Emanuel Knill,Lynden K. Shalm*

Main category: quant-ph

TL;DR: Experimental demonstration of device-independent quantum position verification using loophole-free Bell tests across a quantum network, achieving superior localization compared to classical protocols.


<details>
  <summary>Details</summary>
Motivation: Secure localization of remote parties is fundamentally impossible in classical physics due to adversaries having complete knowledge of devices. Quantum technologies can overcome this limitation, but existing proposals require trusting vulnerable hardware.

Method: Developed and experimentally demonstrated a protocol for device-independent quantum position verification that guarantees security using only observed correlations from a loophole-free Bell test across a quantum network. The protocol certifies position against adversaries who are weakly entangled before each test instance but otherwise have unlimited quantum computation and communication capabilities.

Result: Achieved one-dimensional localization that is 2.47(2) times smaller than the best necessarily non-remote classical localization protocol. Compared to a classical protocol with identical latencies, the localization is 4.53(5) times smaller.

Conclusion: This work anchors digital security in the physical world by providing a practical device-independent quantum position verification protocol that overcomes fundamental limitations of classical approaches.

Abstract: Many applications require or benefit from being able to securely localize remote parties. In classical physics, adversaries can in principle have complete knowledge of such a party's devices, and secure localization is fundamentally impossible. This limitation can be overcome with quantum technologies, but proposals to date require trusting vulnerable hardware. Here we develop and experimentally demonstrate a protocol for device-independent quantum position verification that guarantees security with only observed correlations from a loophole-free Bell test across a quantum network. The protocol certifies the position of a remote party against adversaries who, before each instance of the test, are weakly entangled, but otherwise have unlimited quantum computation and communication capabilities. Our demonstration achieves a one-dimensional localization that is 2.47(2) times smaller than the best, necessarily non-remote, classical localization protocol. Compared to such a classical protocol having identical latencies, the localization is 4.53(5) times smaller. This work anchors digital security in the physical world.

</details>


### [33] [Upper bounds on the purity of Wigner positive quantum states that verify the Wigner entropy conjecture](https://arxiv.org/abs/2601.16898)
*Qipeng Qian,Christos Gagatsos*

Main category: quant-ph

TL;DR: The paper proves analytical results supporting the Wigner entropy conjecture, establishing purity-based sufficient conditions for Wigner non-negative states to satisfy the conjecture, with explicit lower bounds and systematic relaxations.


<details>
  <summary>Details</summary>
Motivation: To provide rigorous analytical support for the Wigner entropy conjecture, which states that among all physical Wigner non-negative states, pure Gaussian states minimize the Wigner entropy, attaining the value 1+lnπ.

Method: Construct an explicit hierarchy of lower bounds B_n on the Wigner entropy S[W] by combining a truncated series lower bound for -ln x with moment identities of the Wigner function, working under minimal constraints (non-negativity, normalization, and pointwise bound πW ≤ 1).

Result: Proved that all Wigner non-negative states with purity μ ≤ 4-2√3 satisfy the Wigner entropy conjecture; obtained systematic purity-only relaxation yielding simple sufficient condition μ ≤ 2/e; clarified why additional physicality constraints are needed for purity-based approaches approaching extremal case μ ≤ 1.

Conclusion: The analysis provides closed-form purity-based sufficient conditions ensuring S[W] ≥ 1+lnπ, establishes explicit lower bounds on Wigner entropy, and clarifies the role of physicality constraints in purity-based approaches to the Wigner entropy conjecture.

Abstract: We present analytical results toward the Wigner entropy conjecture, which posits that among all physical Wigner non-negative states the Wigner entropy is minimized by pure Gaussian states for which it attains the value $1+\lnπ$.Working under a minimal set of constraints on the Wigner function, namely, non-negativity, normalization, and the pointwise bound $πW\le 1$, we construct an explicit hierarchy of lower bounds $B_n$ on $S[W]$ by combining a truncated series lower bound for $-\ln x$ with moment identities of the Wigner function.This yields closed-form purity-based sufficient conditions ensuring $S[W]\ge 1+\lnπ$.In particular, we first prove that all Wigner non-negative states with $μ\le 4-2\sqrt3$ satisfy the Wigner entropy conjecture. We further obtain a systematic purity-only relaxation of the hierarchy, yielding the simple sufficient condition $μ\le 2/e$. On top of aforesaid results, our analysis clarifies why additional physicality constraints are necessary for purity-based approaches that aim to approach the extremal case $μ\leq1$.

</details>


### [34] [Quantum Fisher information analysis for absorption measurements with undetected photons](https://arxiv.org/abs/2601.16941)
*Martin Houde,Franz Roeder,Christine Silberhorn,Benjamin Brecht,Nicolás Quesada*

Main category: quant-ph

TL;DR: Theoretical comparison of quantum Fisher information (QFI) for three absorption spectroscopy configurations using undetected idler photons, identifying optimal regimes for each architecture based on loss levels and parametric gain.


<details>
  <summary>Details</summary>
Motivation: To determine which quantum optical configuration provides the best metrological performance for absorption spectroscopy with undetected idler photons under different loss conditions and parametric gain settings.

Method: Theoretical comparison of QFI for three configurations: SU(1,1) interferometer with inter-source idler loss, induced-coherence (IC) setup with partial idler seeding and vacuum ancilla, and distributed-loss (DL) scheme with in-medium attenuation. QFI calculations performed as function of parametric gain for both full and signal-only detection access.

Result: For losses below 99% and low to moderate gain, SU(1,1) configuration provides largest QFI. At high gain and intermediate loss, IC scheme performs best. Under extreme attenuation (transmission < 1%), DL model becomes optimal. Results delineate measurement regimes where each architecture is information-theoretically optimal.

Conclusion: Different quantum optical configurations for absorption spectroscopy with undetected idler photons are optimal in different regimes: SU(1,1) for low-moderate gain with losses <99%, IC for high gain with intermediate loss, and DL for extreme attenuation (<1% transmission). This provides guidance for selecting optimal experimental architectures based on expected loss conditions.

Abstract: We theoretically compare the quantum Fisher information (QFI) for three configurations of absorption spectroscopy with undetected idler photons: an SU(1,1) interferometer with inter-source idler loss, an induced-coherence (IC) setup in which the idler partially seeds a second squeezer together with a vacuum ancilla, and a distributed-loss (DL) scheme with in-medium attenuation. We calculate the QFI as a function of parametric gain for both full and signal-only detection access. For losses below 99% and low to moderate gain, the SU(1,1) configuration provides the largest QFI. At high gain and intermediate loss, the IC scheme performs best, while under extreme attenuation (transmission $<$ 1%) the DL model becomes optimal. These results delineate the measurement regimes in which each architecture is optimal in terms of information theory.

</details>


### [35] [Experimental investigation of nonclassicality in the simplest scenario via the degrees of freedom of light](https://arxiv.org/abs/2601.16952)
*João M. M. Gama,Guilherme T. C. Cruz,Massy Khoshbin,Lorenzo Catani,José A. O. Huguenin,Wagner F. Balthazar*

Main category: quant-ph

TL;DR: Experimental implementation using classical light emulates nonclassical statistics in simplest prepare-and-measure scenario, violating noise-robust inequalities that indicate inconsistencies with preparation noncontextuality and bounded ontological distinctness.


<details>
  <summary>Details</summary>
Motivation: To experimentally investigate classical-light emulation of different notions of nonclassicality in the simplest prepare-and-measure scenario, and to demonstrate that classical systems can reproduce statistics that violate fundamental classical principles like preparation noncontextuality and bounded ontological distinctness.

Method: Implemented prepare-and-measure scenario with four preparations and two binary-outcome measurements using two experimental setups exploiting different degrees of freedom: polarization and first-order Hermite-Gaussian transverse modes. Modeled experimental noise through all-optical setup reproducing operational effect of depolarizing channel.

Result: Experimental results consistent with Khoshbin et al. findings: under tomographic completeness assumption, observed statistics violate noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations. Classical light implementation reproduces statistics predicted for simplest scenario.

Conclusion: Classical light can emulate nonclassical statistics that violate fundamental classical principles, making implementation directly relevant for applications like two-bit quantum random access codes and semi-device-independent certification of nonclassicality.

Abstract: In this work, we experimentally investigate the classical-light emulation of different notions of nonclassicality in the simplest scenario. We implement this prepare-and-measure scenario involving four preparations and two binary-outcome measurements using two distinct experimental setups that exploit different degrees of freedom of light: polarization and first-order Hermite-Gaussian transverse modes. We additionally model experimental noise through an all-optical setup that reproduces the operational effect of a depolarizing channel. Our experimental results are consistent with the findings of Khoshbin et al. [Phys. Rev. A 109, 032212 (2024)]: under the assumption that the two measurements performed form a tomographically complete set, the observed statistics violate their noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations. Although our implementation uses classical light, it reproduces the statistics predicted for the simplest scenario. Since the states and measurements of this scenario underpin computational advantages in tasks such as two-bit quantum random access codes -- among the simplest communication primitives enabling semi-device-independent certification of nonclassicality -- our implementation is directly relevant for such applications.

</details>


### [36] [Engineering discrete local dynamics in globally driven dual-species atom arrays](https://arxiv.org/abs/2601.16961)
*Francesco Cesa,Andrea Di Fini,David Aram Korbany,Roberto Tricarico,Hannes Bernien,Hannes Pichler,Lorenzo Piroli*

Main category: quant-ph

TL;DR: A method for engineering discrete local dynamics in dual-species neutral atom experiments using uniform analog controls to study emergent digital models, with applications to quantum cellular automata and chaotic dynamics.


<details>
  <summary>Details</summary>
Motivation: To leverage the new capabilities of dual-species neutral atom systems (species-alternated driving, different inter- and intra-species interactions) to engineer discrete dynamical models that are typically difficult to implement directly, enabling the study of quantum cellular automata and chaotic many-body dynamics.

Method: Uses simple Floquet protocols on static atom arrangements in dual-species systems, exploiting species-alternated driving and generalized blockade regimes (different interaction strengths between and within species). Focuses on implementing discrete dynamical models as special examples of Quantum Cellular Automata.

Result: The method enables explicit implementation of several relevant models including the kicked-Ising model, Floquet Kitaev honeycomb model, and digitization of generic translation-invariant nearest-neighbor Hamiltonians (e.g., for Trotterized evolution). Demonstrates application to studying chaotic features of discretized many-body dynamics using only demonstrated capabilities of globally-driven experiments.

Conclusion: The approach provides a practical way to study emergent digital models in analog quantum simulators, particularly leveraging the unique advantages of dual-species neutral atom systems, with demonstrated ability to discriminate chaotic evolution in many-body quantum dynamics.

Abstract: We introduce a method for engineering discrete local dynamics in globally-driven dual-species neutral atom experiments, allowing us to study emergent digital models through uniform analog controls. Leveraging the new opportunities offered by dual-species systems, such as species-alternated driving, our construction exploits simple Floquet protocols on static atom arrangements, and benefits of generalized blockade regimes (different inter- and intra-species interactions). We focus on discrete dynamical models that are special examples of Quantum Cellular Automata (QCA), and explicitly consider a number of relevant examples, including the kicked-Ising model, the Floquet Kitaev honeycomb model, and the digitization of generic translation-invariant nearest-neighbor Hamiltonians (e.g., for Trotterized evolution). As an application, we study chaotic features of discretized many-body dynamics that can be detected by leveraging only demonstrated capabilities of globally-driven experiments, and benchmark their ability to discriminate chaotic evolution.

</details>


### [37] [Autonomous Optical Alignment of Satellite-Based Entanglement Sources using Reinforcement Learning](https://arxiv.org/abs/2601.16968)
*Andrzej Gajewski,Robert Okuła,Marcin Pawłowski,Akshata Shenoy H*

Main category: quant-ph

TL;DR: Two automated recalibration methods (heuristic algorithm and reinforcement learning) for satellite-based quantum entanglement sources demonstrate RL's superior performance in maintaining alignment under orbital dynamics.


<details>
  <summary>Details</summary>
Motivation: Satellite-based quantum entanglement distribution is essential for global quantum communication, but onboard sources suffer from misalignment due to orbital dynamics, requiring automated recalibration solutions.

Method: Two recalibration techniques: 1) Heuristic algorithm (HA) mimicking manual laboratory alignment, and 2) Reinforcement learning (RL) approach. Both target PPLN-based SPDC sources for entanglement generation with minimal intervention.

Result: RL outperforms HA with AUC=0.9119 vs 0.7042 in modified ROC analysis (60 min threshold). RL achieves perfect alignment in 10 minutes compared to HA's 30 minutes. Both methods operate within satellite constraints.

Conclusion: Reinforcement learning provides superior automated recalibration for satellite quantum entanglement sources, offering scalable automation for complex quantum communication scenarios with minimal intervention.

Abstract: Quantum entanglement distributed via satellites enable global-scale quantum communication. However, onboard sources are susceptible to misalignment due to dynamical orbital conditions. Here, we present two recalibration techniques for efficient generation of high quality entanglement using a periodically poled lithium niobate (PPLN)-based spontaneous parametric down-conversion (SPDC) source with minimum intervention. The first is a heuristic algorithm (HA) which mimics the manual alignment process in a laboratory. The second is based on reinforcement learning (RL). Our simulation demonstrates superior performance of RL with AUC=0.9119 compared to HA's 0.7042 in the modified ROC analysis (60 min threshold). RL achieves perfect alignment in 10 min as opposed to HA's 30 min. Both the methods operate within feasible satellite constraints, offering scalable automation for complex quantum communication scenarios.

</details>


### [38] [Formalising an operational continuum limit of quantum combs](https://arxiv.org/abs/2601.16974)
*Clara Wassner,Jonáš Fuksa,Jens Eisert,Gregory A. L. White*

Main category: quant-ph

TL;DR: The paper introduces a fully continuous process tensor framework by translating discrete quantum combs into field-theoretic states in bosonic Fock space, enabling rigorous continuum treatment of multi-time quantum processes.


<details>
  <summary>Details</summary>
Motivation: Quantum combs lack meaningful physical connection to time despite their causal nature, and process tensors have an uncomfortable conceptual gap regarding continuous mathematical representation. The paper aims to remedy this by developing a fully continuous framework.

Method: Translate discrete multi-partite Choi states into field-theoretic states in bosonic Fock space, creating intrinsically continuum-defined objects. Use continuous matrix product state representatives to analyze multi-time correlations information-theoretically.

Result: Established a rigorous continuum process tensor framework where quantum combs become field-theoretic states in bosonic Fock space, enabling proper treatment of multi-time correlations in continuous quantum stochastic processes.

Conclusion: The work closes a gap in quantum information literature by providing a fully continuous process tensor framework, opening opportunities to apply many-body physics insights to understanding quantum stochastic processes in the continuum.

Abstract: Quantum combs are powerful conceptual tools for capturing multi-time processes in quantum information theory, constituting the most general quantum mechanical process. But, despite their causal nature, they lack a meaningful physical connection to time -- and are, by and large, arguably incompatible with it without extra structure. The subclass of quantum combs which assumes an underlying process is described by the so-called process tensor framework, which has been successfully used to study and characterise non-Markovian open quantum systems. But, although process tensors are motivated by an underlying dynamics, it is not a priori clear how to connect to a continuous process tensor object mathematically -- leaving an uncomfortable conceptual gap. In this work, we take a decisive step toward remedying this situation. We introduce a fully continuous process tensor framework by showing how the discrete multi-partite Choi state becomes a field-theoretic state in bosonic Fock space, which is intrinsically and rigorously defined in the continuum. With this equipped, we lay out the core structural elements of this framework and its properties. This translation allows for an information-theoretic treatment of multi-time correlations in the continuum via the analysis of their continuous matrix product state representatives. Our work closes a gap in the quantum information literature, and opens up the opportunity for the application of many-body physics insights to our understanding of quantum stochastic processes in the continuum.

</details>
