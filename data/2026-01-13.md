<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 27]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Investigation of Hardware Architecture Effects on Quantum Algorithm Performance: A Comparative Hardware Study](https://arxiv.org/abs/2601.05286)
*Askar Oralkhan,Temirlan Zhaxalykov*

Main category: quant-ph

TL;DR: Systematic benchmarking of five quantum algorithms across different quantum hardware platforms reveals significant performance variations due to architectural differences, highlighting the need for hardware-aware algorithm selection in the NISQ era.


<details>
  <summary>Details</summary>
Motivation: Quantum circuits exhibit substantially different behavior across devices due to architectural variations in qubit connectivity, gate fidelity, and coherence times, necessitating systematic benchmarking to understand hardware-algorithm compatibility.

Method: Benchmark five representative quantum algorithms (Bell state preparation, GHZ state generation, QFT, Grover's Search, QAOA) across trapped-ion, superconducting, and simulator backends using Amazon Braket, evaluating performance metrics including fidelity, CHSH violation, success probability, circuit depth, and gate counts.

Result: Strong dependence of algorithmic performance on hardware topology and noise characteristics; 10-qubit GHZ states achieved fidelities above 0.8 on trapped-ion hardware but dropped below 0.15 on superconducting platforms due to routing overhead and accumulated two-qubit gate errors.

Conclusion: Hardware-aware algorithm selection is crucial for quantum computing in the NISQ era, and systematic benchmarking provides practical guidance for algorithm deployment across heterogeneous quantum platforms.

Abstract: Cloud-accessible quantum processors enable direct execution of quantum algorithms on heterogeneous hardware platforms. Unlike classical systems, however, identical quantum circuits may exhibit substantially different behavior across devices due to architectural variations in qubit connectivity, gate fidelity, and coherence times.
  In this work, we systematically benchmark five representative quantum algorithms - Bell state preparation, GHZ state generation, Quantum Fourier Transform (QFT), Grover's Search, and the Quantum Approximate Optimization Algorithm (QAOA) - across trapped-ion, superconducting, and simulator backends using Amazon Braket. Performance metrics including fidelity, CHSH violation, success probability, circuit depth, and gate counts are evaluated.
  Our results demonstrate a strong dependence of algorithmic performance on hardware topology and noise characteristics. For example, 10-qubit GHZ states achieved fidelities above 0.8 on trapped-ion hardware, while superconducting platforms dropped below 0.15 due to routing overhead and accumulated two-qubit gate errors. These findings highlight the importance of hardware-aware algorithm selection and provide practical guidance for benchmarking in the NISQ era.

</details>


### [2] [Temporal Kirkwood-Dirac Quasiprobability Distribution and Unification of Temporal State Formalisms through Temporal Bloch Tomography](https://arxiv.org/abs/2601.05294)
*Zhian Jia,Kavan Modi,Dagomir Kaszlikowski*

Main category: quant-ph

TL;DR: Extends Kirkwood-Dirac quasiprobability distributions to multi-time quantum processes and spatiotemporal settings, providing unified operational foundation for temporal state formalisms.


<details>
  <summary>Details</summary>
Motivation: Temporal quantum states generalize density operators to time domain but lack clear operational relationships and conceptual distinctions between different formalisms.

Method: Extends Kirkwood-Dirac quasiprobability distribution to arbitrary multi-time quantum processes and spatiotemporal settings, defining left, right, and doubled temporal KD quasiprobabilities with their real components (temporal Margenau-Hill quasiprobabilities).

Result: All quantities are experimentally accessible through interferometric measurement schemes; nonclassical features characterize the framework; provides unified operational foundation for temporal state approaches; can be implemented via temporal or spatiotemporal Bloch tomography.

Conclusion: Generalized KD framework resolves operational relationships between temporal state formalisms and offers experimentally implementable foundation for studying timelike and spacelike quantum correlations.

Abstract: Temporal quantum states generalize the multipartite density operator formalism to the time domain, enabling a unified treatment of quantum systems with both timelike and spacelike correlations. Despite a growing body of temporal state formalisms, their precise operational relationships and conceptual distinctions remain unclear. In this work, we resolve this issue by extending the Kirkwood-Dirac (KD) quasiprobability distribution to arbitrary multi-time quantum processes and, more broadly, to general spatiotemporal settings. We define left, right, and doubled temporal KD quasiprobabilities, together with their real components, which we identify as temporal Margenau-Hill (MH) quasiprobabilities. All of these quantities are experimentally accessible through interferometric measurement schemes. By characterizing their nonclassical features, we show that the generalized KD framework provides a unified operational foundation for a wide class of temporal state approaches and can be directly implemented via temporal or spatiotemporal Bloch tomography.

</details>


### [3] [Fundamental Limitations on the Reliabilities of Power and Work in Quantum Batteries](https://arxiv.org/abs/2601.05315)
*Brij Mohan,Tanmoy Pandit,Maciej Lewenstein,Manabendra Nath Bera*

Main category: quant-ph

TL;DR: Quantum batteries face fundamental reliability limits: work and power fluctuations are bounded by charging speed, and an uncertainty relation prevents simultaneous suppression of both fluctuations, creating a trade-off between power and reliability.


<details>
  <summary>Details</summary>
Motivation: Quantum batteries promise high power for quantum technologies, but their practical usefulness depends on reliability quantified by noise-to-signal ratios (NSRs). Understanding fundamental limits to this reliability is crucial for designing practical quantum batteries.

Method: Established fundamental limits to reliability by deriving universal lower bounds for work and power NSRs as functions of charging speed. Analyzed an uncertainty relation that forbids simultaneous suppression of work and power fluctuations. Examined these limits across parallel (local), collective (fully non-local), and hybrid (semi-local) charging schemes for many-body quantum batteries, including transverse Ising-like interactions.

Result: Found that increasing power through stronger entanglement comes at the cost of diminished power reliability. Both parallel and collective charging schemes have limitations: parallel charging has poor power scaling, while collective charging sacrifices reliability. Hybrid charging with intermediate-range interactions offers the best balance for achieving both high power and reliability.

Conclusion: Achieving both high power and reliability in quantum batteries requires neither purely parallel nor fully collective charging, but rather hybrid charging schemes with intermediate-range interactions. This analysis provides practical guidance for designing efficient and reliable quantum batteries.

Abstract: Quantum batteries, microscopic devices designed to address energy demands in quantum technologies, promise high power during charging and discharging processes. Yet their practical usefulness and performance depend critically on reliability, quantified by the noise-to-signal ratios (NSRs), i.e., normalized fluctuations of work and power, where reliability decreases inversely with increasing NSR. We establish fundamental limits to this reliability: both work and power NSRs are universally bounded from below by a function of charging speed, imposing a reliability limit inherent to any quantum battery. More strikingly, we find that a quantum mechanical uncertainty relation forbids the simultaneous suppression of work and power fluctuations, revealing a fundamental trade-off that also limits the reliability of quantum batteries. We analyze the trade-off and limits, as well as their scaling behavior, across parallel (local), collective {(fully non-local)}, and hybrid (semi-local) charging schemes for many-body quantum batteries, finding that increasing power by exploiting stronger entanglement comes at the cost of diminished reliability of power. Similar trends are also observed in the charging of quantum batteries utilizing transverse Ising-like interactions. These suggest that achieving both high power and reliability require neither parallel nor collective charging, but a hybrid charging scheme with an intermediate range of interactions. Therefore, our analysis shapes the practical and efficient design of reliable and high-performance quantum batteries.

</details>


### [4] [From compatibility of measurements to exploring Quantum Darwinism on NISQ](https://arxiv.org/abs/2601.05350)
*Emery Doucet,Sebastian Deffner*

Main category: quant-ph

TL;DR: Study of Quantum Darwinism breaking in a specific model and its translation to non-classical measurement statistics, providing tools for benchmarking quantum characteristics of NISQ hardware.


<details>
  <summary>Details</summary>
Motivation: To understand how the breaking of Quantum Darwinism manifests as non-classical measurement statistics and to develop effective benchmarking tools for NISQ hardware quantum characteristics.

Method: Study a specific model where Quantum Darwinism breaks down, analyze resulting non-classical measurement statistics, and apply this framework to benchmark IonQ's trapped-ion and IBM's superconducting quantum computing platforms.

Result: Demonstrated that breaking of Quantum Darwinism translates to observable non-classical measurement statistics, providing effective benchmarking tools for assessing genuine quantum characteristics of NISQ hardware.

Conclusion: The breakdown of Quantum Darwinism offers practical tools for benchmarking quantum hardware, bridging theoretical quantum foundations with experimental quantum computing applications.

Abstract: Quantum Darwinism explains how tenets of classical reality, such as objectivity and repeatability, emerge within a quantum universe. As a mathematical framework, Quantum Darwinism also provides guiding principles that determine what physical models support emergent classical behavior, what specific observables obey classical laws, and much more. For instance, in a recent work we elucidated that the limit under which Kirkwood-Dirac quasiprobability distributions become effectively classical coincides with the regime where the underlying physical model obeys the rules of Quantum Darwinism. In the present work, we study the breaking of Quantum Darwinism in a specific model and how that translates to non-classical measurement statistics. Interestingly, this provides effective tools for benchmarking the genuine quantum characteristics of NISQ hardware, which we demonstrate with IonQ's trapped-ion and IBM's superconducting quantum computing platforms.

</details>


### [5] [Dynamical entanglement percolation with spatially correlated disorder](https://arxiv.org/abs/2601.05925)
*Lorenzo Cirigliano,Valentina Brosco,Claudio Castellano,Simone Felicetti,Laura Pilozzi,Bernard van Heck*

Main category: quant-ph

TL;DR: The paper studies entanglement spreading in quantum networks using percolation theory, revealing non-standard percolation with hysteresis due to interplay between unitary evolution and correlated disorder.


<details>
  <summary>Details</summary>
Motivation: To understand how entanglement dynamically spreads across quantum networks, which is fundamental for quantum information applications, by investigating networks where edges correspond to independent two-qubit interactions.

Method: Apply percolation theory tools to study entanglement dynamics in qubit networks; develop a two-colour correlated bond percolation model analyzed via numerical simulations and mean-field theory.

Result: The interplay between unitary evolution and spatially correlated disorder leads to non-standard percolation phenomenology richer than uniform bond percolation, featuring hysteresis. The two-colour correlated bond percolation model fully elucidates this physics.

Conclusion: Entanglement spreading in quantum networks exhibits complex percolation behavior with hysteresis, fundamentally different from classical percolation, as captured by the developed two-colour correlated bond percolation model.

Abstract: The distribution of entanglement between the nodes of a quantum network plays a fundamental role in quantum information applications. In this work, we investigate the dynamics of a network of qubits where each edge corresponds to an independent two-qubit interaction. By applying tools from percolation theory, we study how entanglement dynamically spreads across the network. We show that the interplay between unitary evolution and spatially correlated disorder leads to a non-standard percolation phenomenology, significantly richer than uniform bond percolation and featuring hysteresis. A two-colour correlated bond percolation model, whose phase diagram is determined via numerical simulations and a mean-field theory, fully elucidates the physics behind this phenomenon.

</details>


### [6] [Analytical Solutions to Asymmetric Two-Photon Rabi Model](https://arxiv.org/abs/2601.05421)
*M. Baradaran,L. M. Nieto,S. Zarrinkamar*

Main category: quant-ph

TL;DR: Generalized Rabi model with two-photon and asymmetric terms solved via Segal-Bargmann representation and Bethe ansatz, yielding nearly exact analytical solutions for fourth-order problem.


<details>
  <summary>Details</summary>
Motivation: To solve the generalized Rabi model that includes both two-photon and asymmetric terms, which extends beyond the standard Rabi model and presents analytical challenges due to its complexity.

Method: Utilizes Segal-Bargmann representation to transform the problem, then applies Bethe ansatz approach to obtain nearly exact solutions by analyzing the meromorphic structure of the resulting differential equation.

Result: Obtains exact analytical form solutions for the fourth-order problem, both for arbitrary states and for parameter restrictions, demonstrating the effectiveness of the Bethe ansatz approach in this context.

Conclusion: The Bethe ansatz approach combined with Segal-Bargmann representation provides a powerful method for solving generalized Rabi models with two-photon and asymmetric terms, yielding nearly exact analytical solutions for complex quantum systems.

Abstract: Within the Segal-Bargmann representation, a generalized Rabi model is considered that includes both two-photon and asymmetric terms. It is shown that, through a suitable transformation, nearly exact solutions can be obtained using the Bethe ansatz approach. Applying this approach to the meromorphic structure of the resulting differential equation, solutions in exact analytical form of the fourth-order problem are presented for both an arbitrary state and for the restriction between the parameters.

</details>


### [7] [Achieving the Heisenberg limit using fault-tolerant quantum error correction](https://arxiv.org/abs/2601.05457)
*Himanshu Sahu,Qian Xu,Sisi Zhou*

Main category: quant-ph

TL;DR: The paper proposes a fault-tolerant quantum metrology protocol using repetition codes that achieves the Heisenberg limit even when all quantum operations (including state preparation and measurement) are noisy, not just the signal accumulation step.


<details>
  <summary>Details</summary>
Motivation: Previous quantum metrology protocols using quantum error correction assume noise only affects signal accumulation while QEC operations (state preparation, measurement) are noiseless. This is unrealistic for practical implementations where all operations are subject to noise.

Method: Developed a fault-tolerant metrological protocol for estimating Pauli-Z signals under bit-flip noise. Uses repetition codes prepared via repeated syndrome measurements followed by fault-tolerant logical measurement. All qubit operations (including state prep and measurement) are subject to noise.

Result: Demonstrated existence of an error threshold below which errors are effectively suppressed and the Heisenberg limit is attained, even with noisy QEC operations.

Conclusion: The proposed fault-tolerant protocol overcomes the limitation of assuming noiseless QEC operations and enables practical quantum metrology that achieves the ultimate Heisenberg limit in realistic noisy environments.

Abstract: Quantum effect enables enhanced estimation precision in metrology, with the Heisenberg limit (HL) representing the ultimate limit allowed by quantum mechanics. Although the HL is generally unattainable in the presence of noise, quantum error correction (QEC) can recover the HL in various scenarios. A notable example is estimating a Pauli-$Z$ signal under bit-flip noise using the repetition code, which is both optimal for metrology and robust against noise. However, previous protocols often assume noise affects only the signal accumulation step, while the QEC operations -- including state preparation and measurement -- are noiseless. To overcome this limitation, we study fault-tolerant quantum metrology where all qubit operations are subject to noise. We focus on estimating a Pauli-$Z$ signal under bit-flip noise, together with state preparation and measurement errors in all QEC operations. We propose a fault-tolerant metrological protocol where a repetition code is prepared via repeated syndrome measurements, followed by a fault-tolerant logical measurement. We demonstrate the existence of an error threshold, below which errors are effectively suppressed and the HL is attained.

</details>


### [8] [A three-dimensional multimode lumped-element resonator for collective spin manipulation and dispersive readout](https://arxiv.org/abs/2601.05476)
*Zhuo Chen,Wenhua Qin,Hanyu Ren,Ziyi Liu,Kae Nemoto,William John Munro,Yingqiu Mao,Johannes Majer*

Main category: quant-ph

TL;DR: 3D multimode microwave resonator enables homogeneous collective manipulation and dispersive readout of macroscopic spin ensembles using geometric symmetry to create two antisymmetric modes with minimal cross-talk.


<details>
  <summary>Details</summary>
Motivation: To develop a versatile resonator for hybrid spin-photon systems that enables both collective manipulation and non-destructive readout of macroscopic spin ensembles with high field homogeneity and tunable coupling.

Method: Engineered a 3D lumped-element multimode microwave resonator using geometric symmetry to create two antisymmetric modes with strongly suppressed cross-talk that spatially overlap and couple to the same spin ensemble at distinct frequencies. Demonstrated using negatively charged nitrogen-vacancy centers in diamond at 28 mK.

Result: Achieved collective strong coupling with coupling strength of 5.0 MHz and demonstrated non-destructive dispersive readout via a detuned mode. The resonator shows compact design, tunable coupling, and high field homogeneity.

Conclusion: The developed resonator provides a versatile platform for hybrid spin-photon systems and multimode solid-state quantum technologies, enabling both manipulation and readout capabilities with minimal interference between modes.

Abstract: We report a three-dimensional lumped-element multimode microwave resonator that enables homogeneous collective manipulation and dispersive readout of a macroscopic spin ensemble. By exploiting geometric symmetry, two antisymmetric modes with strongly suppressed cross-talk are engineered to spatially overlap and couple to the same ensemble at distinct frequencies. Using negatively charged nitrogen-vacancy centers in diamond at 28 mK, we observe collective strong coupling with a coupling strength of 5.0 MHz and demonstrate non-destructive dispersive readout via a detuned mode. The compact design, tunable coupling, and high field homogeneity make this resonator a versatile device for hybrid spin-photon systems and multimode solid-state quantum technologies.

</details>


### [9] [Emergence of the 2nd Law in an Exactly Solvable Model of a Quantum Wire](https://arxiv.org/abs/2601.05514)
*Marco A. Jimenez-Valencia,Charles A. Stafford*

Main category: quant-ph

TL;DR: The paper shows that entropy production from Joule heating in quantum wires requires decoherence from local measurements or inelastic scattering, rather than arising automatically from unitary quantum evolution.


<details>
  <summary>Details</summary>
Motivation: To investigate how the Second Law of Thermodynamics manifests in microscopic quantum systems, specifically examining why entropy production from Joule heating doesn't automatically emerge in exact quantum descriptions despite being readily proved statistically.

Method: Analyzed an exactly solvable model of a quantum wire under electrical bias, using an exact formula for entropy current of independent quantum particles. Introduced a series of floating thermoelectric probes along the wire that perform continuous local measurements, creating decoherence through inelastic processes.

Result: Entropy production due to Joule heating doesn't arise automatically in exact microscopic quantum dynamics. Expected entropy production only emerges in the limit of many local measurements by thermoelectric probes, which inject entropy into the system through information obtained from continuous measurements.

Conclusion: Decoherence resulting from inelastic processes introduced by local measurements is essential for entropy production in Joule heating. This decoherence would naturally arise from inelastic scattering in real systems of interacting particles, explaining how the Second Law manifests at microscopic scales.

Abstract: As remarked by Boltzmann, the Second Law of Thermodynamics is notable for the fact that it is readily proved using elementary statistical arguments, but becomes harder and harder to verify the more precise the microscopic description of a system. In this article, we investigate one particular realization of the 2nd Law, namely Joule heating in a wire under electrical bias. We analyze the production of entropy in an exactly solvable model of a quantum wire wherein the conserved flow of entropy under unitary quantum evolution is taken into account using an exact formula for the entropy current of a system of independent quantum particles. In this exact microscopic description of the quantum dynamics, the entropy production due to Joule heating does not arise automatically. Instead, we show that the expected entropy production is realized in the limit of a large number of local measurements by a series of floating thermoelectric probes along the length of the wire, which inject entropy into the system as a result of the information obtained via their continuous measurements of the system. The decoherence resulting from inelastic processes introduced by the local measurements is essential to the phenomenon of entropy production due to Joule heating, and would be expected to arise due to inelastic scattering in real systems of interacting particles.

</details>


### [10] [Narrowband four-photon states from spontaneous four-wave mixing](https://arxiv.org/abs/2601.05558)
*Yifan Li,Justin Yu Xiang Peh,Chang Hoong Chow,Boon Long Ng,Vindhiya Prakash,Christian Kurtsiefer*

Main category: quant-ph

TL;DR: Observation of time-correlated four-photon states generated via spontaneous four-wave mixing in a cold Rb-87 atomic cloud using continuous-wave pumping at nominal powers.


<details>
  <summary>Details</summary>
Motivation: To generate correlated four-photon states compatible with atomic quantum networking applications, avoiding the need for high-power pulsed pumping typically required in chi^(2) nonlinear processes in crystals.

Method: Used spontaneous four-wave mixing via a double-Lambda scheme in a cold cloud of Rb-87 atoms with direct continuous-wave pumping at nominal powers, and verified correlations through higher-order intensity cross-correlation measurements and accidental subtraction.

Result: Observed time-correlated four photons within 20ns correlation window with generation rate of 2.5(4)×10^6 counts/s near saturation; photons are near-resonant with atomic transitions and have MHz bandwidth.

Conclusion: Demonstrated generation of genuinely correlated four-photon states compatible with atomic quantum networking applications using continuous-wave pumping in atomic systems, offering advantages over crystal-based approaches.

Abstract: We observe time-correlated four photons within a correlation window of 20ns from spontaneous four-wave mixing via a double-Lambda scheme in a cold cloud of Rb-87 atoms. In contrast to high-power pulsed pumping of chi^(2) nonlinear processes in crystals, our scheme generates correlated four-photon states by direct continuous-wave pumping at nominal powers. We verify the presence of genuinely correlated four-photon states over accidentals by higher-order intensity cross-correlation measurements and accidental subtraction. We infer a time-correlated four-photon generation rate of 2.5(4)x10^6 counts per second close to saturation. The photons produced are near-resonant with atomic transitions, and have a bandwidth in the order of MHz, making them readily compatible with quantum networking applications involving atoms.

</details>


### [11] [Bath-free squeezed phonon lasing via intrinsic ion-phonon coupling](https://arxiv.org/abs/2601.05575)
*Chen-Yu Lee,Guin-Dar Lin*

Main category: quant-ph

TL;DR: Squeezed lasing achieved in trapped-ion system using intrinsic ion-phonon interactions without engineered baths, enabling phonon squeezing through red/blue-sideband transitions.


<details>
  <summary>Details</summary>
Motivation: To develop a simpler method for achieving squeezed lasing that doesn't require complex bath engineering or tailored dissipative reservoirs, leveraging natural ion-phonon interactions in trapped-ion systems.

Method: Two trapped ions interact with a shared vibrational mode, driven on both red- and blue-sideband transitions to create squeezed motion states through dynamic coupling between internal states and phonon mode.

Result: Demonstrates squeezed lasing can be achieved through direct manipulation of ion-phonon interactions without external reservoirs, with analysis of steady-state behavior, lasing onset, gain-loss balance, and squeezing parameter effects.

Conclusion: Provides a simple yet effective method for achieving squeezed lasing in quantum systems using intrinsic interactions, offering new insights for phonon-based squeezed states with applications in quantum metrology and information processing.

Abstract: We present a theoretical model for realizing squeezed lasing in a trapped-ion system without relying on engineered baths or tailored dissipative reservoirs. Our approach leverages the intrinsic ion-phonon interactions, where two trapped ions, each interacting with a shared vibrational mode, are driven on both red- and blue-sideband transitions. This enables the creation of a squeezed state of motion through the dynamic coupling between the ions' internal states and the phonon mode. Unlike traditional methods that require bath engineering, our model demonstrates that squeezed lasing can be achieved through a direct manipulation of ion-phonon interactions, with no external reservoirs required. We explore the steady-state behavior of the system, analyzing the onset of lasing, gain-loss balance, and the role of the squeezing parameter in shaping the phonon field's statistical properties. Furthermore, we show how external coherent drives can stabilize phase coherence and achieve controlled quadrature squeezing, offering a simple yet effective method for achieving squeezed lasing in quantum mechanical systems. Our findings provide new insights into the realization of squeezed states in phonon-based systems, with potential applications in quantum metrology and information processing.

</details>


### [12] [Squeezing-Enhanced Two-Phase Estimation with N-Particle W-type States](https://arxiv.org/abs/2601.05595)
*Huan Zhang,Ying Xia,Xiuxing Zhang,Shoukang Chang,Wei Ye*

Main category: quant-ph

TL;DR: OPA in three-mode interferometer enhances multiparameter phase estimation precision via amplified intra-mode photon-number correlations, with robustness against moderate photon loss.


<details>
  <summary>Details</summary>
Motivation: To investigate how optical parametric amplification (OPA) can enhance simultaneous estimation of multiple optical phases in interferometric setups, and to understand the physical mechanisms behind this enhancement in both ideal and lossy scenarios.

Method: Employed normally ordered characteristic-function formalism to analytically obtain all photon-number moments of output quantum state, enabling explicit evaluation of quantum Fisher information matrix for multiparameter phase estimation. Used second-order correlation functions to analyze correlation mechanisms. Extended analysis to lossy interferometers using purification-based variational approach.

Result: Uniformly applied OPA significantly enhances attainable precision beyond unamplified interferometer in lossless scenario. Enhancement originates from amplification of intra-mode photon-number correlations rather than inter-mode correlations. For moderate photon loss, OPA-assisted scheme retains clear advantage despite precision degradation, showing robustness against dissipation.

Conclusion: OPA enhances multiparameter quantum metrology by amplifying intra-mode photon-number correlations, providing guidelines for optimizing phase estimation protocols in realistic noisy environments with demonstrated robustness against moderate dissipation.

Abstract: We investigate the simultaneous estimation of two optical phases in a three-mode interferometer assisted by optical parametric amplification (OPA). By employing the normally ordered characteristic-function formalism, we analytically obtain all photon-number moments of the output quantum state, enabling an explicit evaluation of the quantum Fisher information matrix for multiparameter phase estimation. In the lossless scenario, we show that uniformly applied OPA significantly enhances the attainable precision beyond that of an unamplified interferometer. By analyzing the second-order correlation functions, we demonstrate that this enhancement originates from the amplification of intra-mode photon-number correlations, rather than from inter-mode correlations. We further extend our analysis to realistic interferometers with photon loss using a purification-based variational approach. Although loss degrades the achievable precision, the OPA-assisted scheme retains a clear advantage for moderate loss, indicating a degree of robustness against dissipation. Our results clarify the physical mechanism underlying OPA-enhanced multiparameter quantum metrology and provide guidelines for optimizing phase estimation protocols in realistic noisy environments.

</details>


### [13] [Chaos, thermalization and breakdown of quantum-classical correspondence in a collective many-body system](https://arxiv.org/abs/2601.05627)
*Ángel L. Corps,Sebastián Gómez,Pavel Stránský,Armando Relaño,Pavel Cejnar*

Main category: quant-ph

TL;DR: Quantum-classical correspondence in 4-site Bose-Hubbard model shows three dynamical regimes with unexpectedly slow convergence to classical limit due to robust finite-size effects.


<details>
  <summary>Details</summary>
Motivation: To investigate thermalization and quantum-classical correspondence in the fully-connected Bose-Hubbard model, specifically examining how quantum dynamics relates to classical phase-space structure and excited-state quantum phase transitions.

Method: Analysis of classical phase-space structure and excited-state quantum phase transitions in the four-site fully-connected Bose-Hubbard model, comparing quantum and classical equilibrium states across different energy regimes.

Result: Three dynamical regimes identified: (1) symmetry-breaking low-energy states, (2) intermediate region with marked disagreement between quantum and classical equilibrium states, and (3) high-energy regime with restored correspondence. Classical intermittency above first excited-state quantum phase transition contrasts with quantum dynamics that remains trapped in symmetry-breaking sectors despite classically connected phase space.

Conclusion: The mismatch originates from population of imbalance-carrying eigenstates and persists even for relatively large particle numbers, revealing unexpectedly slow convergence to the classical limit and signaling robust finite-size effects in collective many-body dynamics.

Abstract: We investigate thermalization and the quantum-classical correspondence in the fully-connected Bose-Hubbard model, focusing on the four-site case. Our analysis of the classical phase-space structure and its excited-state quantum phase transitions leads us to three dynamical regimes: symmetry-breaking low-energy states, an intermediate region where quantum and classical equilibrium states markedly disagree, and a high-energy regime with restored correspondence. The observed classical intermittency above the first excited-state quantum phase transition contrasts with quantum dynamics, which remains trapped in symmetry-breaking sectors despite the existence of a classically connected phase space. This mismatch originates from the population of imbalance-carrying eigenstates and persists even for relatively large number of particles. Our results reveal unexpectedly slow convergence to the classical limit, signaling robust finite-size effects in collective many-body dynamics.

</details>


### [14] [Improving quantum interference visibility between independent sources by enhancing the purity of correlated photon pairs](https://arxiv.org/abs/2601.05671)
*Hsin-Pin Lo,Kai Asaoka,Hiroki Takesue*

Main category: quant-ph

TL;DR: Two methods for enhancing spectral purity of photon pairs from type-0 PPLN waveguides are compared: varying pump bandwidth and interference-filter bandwidth, both achieving ~80% HOM visibility, with the former providing higher three-fold coincidence rates for multi-photon GHZ state generation.


<details>
  <summary>Details</summary>
Motivation: High-visibility quantum interference between independent photons is essential for multi-photon quantum information processing, and it is closely linked to the spectral purity of correlated photon pairs. The study aims to compare approaches to enhance purity for improved quantum state generation.

Method: Systematically vary both pump bandwidth and interference-filter bandwidth for photon pairs generated from a type-0 PPLN waveguide. Compare performance under identical experimental conditions. Evaluate spectral purity from measured joint spectral intensities using Schmidt decomposition.

Result: Both methods significantly improve Hong-Ou-Mandel interference visibility to approximately 80%. The pump bandwidth variation approach yields higher three-fold coincidence rate compared to the interference-filter bandwidth method.

Conclusion: The pump bandwidth variation approach is advantageous for increasing state fidelity and generation rate of multi-photon time-bin Greenberger-Horne-Zeilinger (GHZ) states due to its higher three-fold coincidence rate while achieving similar HOM visibility.

Abstract: High-visibility quantum interference between independent photons is essential for demonstrating multi-photon quantum information processing, and it is closely linked to the spectral purity of correlated photon pairs. In this study, we investigate two approaches to enhance the purity of photon pairs generated from a type-0 PPLN waveguide by systematically varying both the pump bandwidth and the interference-filter bandwidth, and we directly compare their performance under identical experimental conditions. The spectral purity is evaluated from measured joint spectral intensities using Schmidt decomposition. Both methods significantly improve the Hong-Ou-Mandel interference visibility to approximately 80%. However, the former approach also yields a higher three-fold coincidence rate, which is advantageous for our ongoing efforts to increase the state fidelity and generation rate of multi-photon time-bin Greenberger-Horne-Zeilinger (GHZ) states.

</details>


### [15] [Block Encoding Linear Combinations of Pauli Strings Using the Stabilizer Formalism](https://arxiv.org/abs/2601.05740)
*Niclas Schillo,Andreas Sturm,Rüdiger Quay*

Main category: quant-ph

TL;DR: Novel method for constructing quantum circuits that block encode linear combinations of Pauli strings using anti-commuting transformations and stabilizer-based corrections, achieving logarithmic ancilla scaling and competitive circuit complexity compared to LCU.


<details>
  <summary>Details</summary>
Motivation: QSVT's practical quantum advantage depends on efficient block encodings, whose gate complexity largely determines overall algorithm cost. Current methods for block encoding linear combinations of Pauli strings need improvement to enable practical quantum speedups.

Method: Two-step approach: (1) Transform Pauli strings into pairwise anti-commuting ones, making the linear combination unitary and directly implementable as a quantum circuit; (2) Apply correction transformation using stabilizer formalism with ancilla register to restore original Pauli strings. Supports logarithmic ancilla scaling with system qubits and extensible to larger ancilla registers for circuit complexity reduction.

Result: Method achieves ancilla register size scaling logarithmically with number of system qubits. Numerical simulations comparing circuit complexity with LCU approach show comparable or better performance, with particular advantages when exploiting target operator structure. Four concrete examples demonstrate practical implementation.

Conclusion: The proposed approach enables more efficient block encodings for linear combinations of Pauli strings, potentially benefiting a range of QSVT-based algorithms beyond the analyzed examples and contributing to practical quantum advantage.

Abstract: The Quantum Singular Value Transformation (QSVT) provides a powerful framework with the potential for quantum speedups across a wide range of applications. Its core input model is the block encoding framework, in which non-unitary matrices are embedded into larger unitary matrices. Because the gate complexity of the block-encoding subroutine largely determines the overall cost of QSVT-based algorithms, developing new and more efficient block encodings is crucial for achieving practical quantum advantage. In this paper, we introduce a novel method for constructing quantum circuits that block encode linear combinations of Pauli strings. Our approach relies on two key components. First, we apply a transformation that converts the Pauli strings into pairwise anti-commuting ones, making the transformed linear combination unitary and thus directly implementable as a quantum circuit. Second, we employ a correction transformation based on the stabilizer formalism which uses an ancilla register to restore the original Pauli strings. Our method can be implemented with an ancilla register whose size scales logarithmically with the number of system qubits. It can also be extended to larger ancilla registers, which can substantially reduce the overall quantum circuit complexity. We present four concrete examples and use numerical simulations to compare our method's circuit complexity with that of the Linear Combination of Unitaries (LCU) approach. We find that our method achieves circuit complexities comparable to or better than LCU, with possible advantages when the structure of the target operators can be exploited. These results suggest that our approach could enable more efficient block encodings for a range of relevant problems extending beyond the examples analyzed in this work.

</details>


### [16] [Quantum Interference-Induced Bhattacharyya Distance](https://arxiv.org/abs/2601.05749)
*Mostafizur Rahaman Laskar*

Main category: quant-ph

TL;DR: Quantum Interference-Induced Bhattacharyya Distance (QIBD) is a quantum distance measure between probability distributions encoded in quantum states, based on interference fragility under entangling evolution.


<details>
  <summary>Details</summary>
Motivation: To develop a quantum distance measure that captures correlation structure beyond fidelity-based measures, leveraging quantum interference fragility under entangling interactions.

Method: Single-ancilla interferometric circuit with interaction Hamiltonian generating correlation-dependent phases that modulate interference visibility; reduces to classical Bhattacharyya distance when interaction vanishes.

Result: QIBD cannot be expressed as a function of fidelity alone for entangling interactions; responds to correlation structure in ways that overlap-based measures do not.

Conclusion: QIBD has potential utility in contexts where interaction-aligned correlations are physically relevant, offering a quantum distance measure sensitive to correlation structure.

Abstract: We propose a quantum distance measure between probability distributions encoded in quantum states based on the fragility of quantum interference under entangling evolution. The Quantum Interference-Induced Bhattacharyya Distance (QIBD) is defined through a single-ancilla interferometric circuit in which an interaction Hamiltonian generates correlation-dependent phases that modulate interference visibility. When the interaction vanishes, QIBD reduces to the classical Bhattacharyya distance; however, for entangling interactions, it cannot be expressed as a function of fidelity alone. Numerical simulations demonstrate that QIBD responds to correlation structure in ways that overlap-based measures do not, suggesting potential utility in contexts where interaction-aligned correlations are physically relevant.

</details>


### [17] [Hidden time-nonlocal Floquet symmetries](https://arxiv.org/abs/2601.05783)
*Sigmund Kohler,Jesús Casado-Pascual*

Main category: quant-ph

TL;DR: The paper reveals exact quasienergy crossings in detuned driven two-level systems when detuning equals integer multiples of driving frequency, explained by a hidden time-nonlocal parity symmetry.


<details>
  <summary>Details</summary>
Motivation: To understand the spectral properties of periodically driven quantum systems, specifically the occurrence of exact quasienergy crossings in detuned driven two-level systems, which has implications for quantum control and topological properties.

Method: Analytical investigation of Floquet spectrum using hidden time-nonlocal parity symmetry classification, constructive proof via scalar recurrence relation, and numerical computation scheme applicable to broader models.

Result: Exact quasienergy crossings occur when detuning is integer multiple of driving frequency; Floquet modes can be classified as even/odd under hidden parity symmetry, leading to generic crossings between different parity states.

Conclusion: The hidden time-nonlocal parity symmetry provides fundamental explanation for exact quasienergy crossings in driven systems, with implications for quantum control and topological phenomena in Floquet systems.

Abstract: We investigate the Floquet spectrum of a detuned, driven two-level system and show that it exhibits exact quasienergy crossings when the detuning is an integer multiple of the energy quantum of the driving field. This behavior can be explained by a hidden time-nonlocal parity, which allows the Floquet modes to be classified as even or odd. Then a generic feature is the emergence of exact crossings between quasienergies of different parity. A constructive proof of the existence of the symmetry is based on a scalar recurrence relation. Moreover, we present a general scheme for its numerical computation, which can be applied to models beyond the two-level system. Analytical results are illustrated with numerical data.

</details>


### [18] [On the robustness of Quantum Phase Estimation to compute ground properties of many-electron systems](https://arxiv.org/abs/2601.05788)
*Wassil Sennane,Jérémie Messud*

Main category: quant-ph

TL;DR: Analysis of Quantum Phase Estimation parameters for electronic systems with a constructive method to set free parameters and conditions for chemical accuracy in ground energy estimation.


<details>
  <summary>Details</summary>
Motivation: To enable more automation of QPE for predictive computational chemistry and material science by developing a holistic parameter selection method, as various aspects of QPE parameter optimization remain unexplored.

Method: Proposes a constructive method to set QPE free parameters including time step, number of phase qubits, initial state preparation, measurement shots, and unitary implementation parameters. Derives explicit conditions for achieving chemical accuracy in ground energy estimation.

Result: Demonstrates that using the proposed conditions, the complexity of Trotterized QPE tends to depend only on physical system properties rather than the number of phase qubits. Numerical simulations on H2 molecule provide initial validation.

Conclusion: The paper provides a systematic approach to parameter selection for QPE in electronic systems, establishing conditions for chemical accuracy and showing that proper parameterization can make algorithm complexity dependent on physical properties rather than quantum resources.

Abstract: We propose an analysis of the Quantum Phase Estimation (QPE) algorithm applied to electronic systems by investigating its free parameters such as the time step, number of phase qubits, initial state preparation, number of measurement shots, and parameters related to the unitary operators implementation. A deep understanding of these parameters is crucial to pave the way towards more automation of QPE applied to predictive computational chemistry and material science. To our knowledge, various aspects remain unexplored and a holistic parameter selection method remains to be developed. After reviewing key QPE features, we propose a constructive method to set the QPE free parameters. We derive, among other things, explicit conditions for achieving chemical accuracy in ground energy estimation. We also demonstrate that, using our conditions, the complexity of the Trotterized version of QPE tends to depend only on physical system properties and not on the number of phase qubits. Numerical simulations on the H2 molecule provide a first validation of our approach.

</details>


### [19] [Optimally driving multi-photon transitions in the perturbative single-mode regime](https://arxiv.org/abs/2601.05854)
*Frieder Lindel,Stefan Yoshi Buhmann,Andreas Buchleitner,Edoardo G. Carnio*

Main category: quant-ph

TL;DR: Optimal classical light states (coherent state mixtures) maximize m-photon transition rates in short-lived multilevel atoms, without requiring quantum light properties.


<details>
  <summary>Details</summary>
Motivation: Multi-photon transition rates depend on light field's mth-order coherence, suggesting coherence shaping could enhance these transitions. The paper aims to find optimal light states for driving m-photon transitions in specific atomic systems.

Method: Theoretical analysis determining optimal states of weak fixed-intensity, narrow-band light fields with restricted maximal photon number for driving m-photon transitions in short-lived atomic multilevel systems.

Result: Classical mixtures of coherent states are optimal for maximizing m-photon transition rates in this scenario, demonstrating that quantum light properties are not necessary for optimal performance.

Conclusion: For weak, narrow-band light driving m-photon transitions in short-lived multilevel atoms, classical light (coherent state mixtures) is optimal, providing practical advantages over quantum light sources.

Abstract: The rate of $m$-photon transitions in matter, induced by an incident light field, depends on the field's $m$th order coherence function. Consequently, the coherence properties of the light field may be shaped to increase the rate of multi-photon transitions. Here, we determine the optimal state of a weak fixed-intensity, narrow-band incident light field, with a restricted maximal photon number, that optimally drives $m$-photon transitions in the case of a short-lived atomic multilevel system. We show that, in this case, no quantum properties of the light field need to be exploited, but that classical mixtures of coherent states are optimal.

</details>


### [20] [Breaking the Exponential: Decoherence-Driven Power-Law Spontaneous Emission in Waveguide Quantum Electrodynamics](https://arxiv.org/abs/2601.05884)
*Stefano Longhi*

Main category: quant-ph

TL;DR: Dynamical dephasing in waveguide QED induces robust power-law decay in spontaneous emission, contrasting with conventional exponential decay followed by weak power-law tails in dephasing-free systems.


<details>
  <summary>Details</summary>
Motivation: To understand how dynamical dephasing in photonic waveguides affects spontaneous emission dynamics, particularly whether dephasing can induce non-exponential decay mechanisms distinct from conventional spectral edge effects.

Method: Theoretical investigation of a two-level system coupled to a photonic waveguide, analyzing spontaneous emission dynamics with and without dynamical dephasing in photon modes. Focuses on photon diffusion in dynamically disordered environments rather than spectral edge effects.

Result: Without dephasing: conventional exponential decay followed by extremely weak power-law tail at very low survival probabilities. With dephasing: robust power-law decay emerges at short times, driven by photon diffusion in the dynamically disordered environment rather than spectral edge effects.

Conclusion: Dynamical dephasing introduces a novel, decoherence-induced mechanism for non-exponential spontaneous emission in waveguide QED platforms, fundamentally altering decay dynamics through photon diffusion rather than spectral properties.

Abstract: We investigate the spontaneous emission of a two-level system coupled to a photonic waveguide, showing that dynamical dephasing in the photon modes profoundly alters the decay law. In the absence of dephasing, the emitter displays conventional exponential decay followed by a long-time power-law tail -- observable only at extremely low survival probabilities. Strikingly, when dephasing is introduced, a robust power-law decay emerges already at short times, driven by photon diffusion in the dynamically disordered environment rather than spectral edge effects. These results reveal a novel, decoherence-induced mechanism for non-exponential spontaneous emission in waveguide QED platforms.

</details>


### [21] [Sub-Planck structure quantification in non-Gaussian probability densities](https://arxiv.org/abs/2601.05898)
*Darren W. Moore,Vojtěch Švarc,Kratveer Singh,Artem Kovalenko,Minh Tuan Pham,Ondřej Číp,Lukáš Slodička,Radim Filip*

Main category: quant-ph

TL;DR: A universal method to identify, quantify, and compare sub-Planck structures in bosonic quantum systems using measurable probability densities, demonstrated on experimental Fock states.


<details>
  <summary>Details</summary>
Motivation: Sub-Planck structures are pervasive in bosonic quantum systems with nonlinear dynamics or measurements, but their identification and comparison have remained qualitative so far.

Method: Developed a universally applicable, experimentally friendly method to identify, quantify, and compare sub-Planck structures from directly measurable or estimated probability densities of single phase space variables.

Result: Demonstrated the method's efficacy on experimental high-order Fock states of a single-atom mechanical oscillator, showing provably finer sub-Planck structures as Fock occupation increases despite increasing uncertainties in phonon, position, and momentum bases.

Conclusion: Provides a practical framework for quantitative analysis of sub-Planck structures in quantum systems, enabling systematic comparison and characterization of these fundamental quantum features.

Abstract: Sub-Planck structures in non-Gaussian probability densities of phase space variables are pervasive in bosonic quantum systems. They are almost universally present if the bosonic system evolves via nonlinear dynamics or nonlinear measurements. So far, identification and comparison of such structures remains qualitative. Here we provide a universally applicable and experimentally friendly method to identify, quantify and compare sub-Planck structures from directly measurable or estimated probability densities of single phase space variables. We demonstrate the efficacy of this method on experimental high order Fock states of a single-atom mechanical oscillator, showing provably finer sub-Planck structures as the Fock occupation increases despite the accompanying uncertainty increase in the phonon, position, and momentum bases.

</details>


### [22] [Generation of squeezed optical states via stored classical pulses in a Bose gas](https://arxiv.org/abs/2601.05908)
*Sevilay Sevinçli,Dennis Rätzel,Markus Krutzik,Mehmet Özgür Oktel,Mustafa Gündoğan*

Main category: quant-ph

TL;DR: Squeezed light generation via storing classical probe pulses in BEC, using atom-atom collisions during storage to create spin squeezing via one-axis-twisting, then transferring squeezing to retrieved light.


<details>
  <summary>Details</summary>
Motivation: To generate squeezed light by leveraging the nonlinear evolution from atom-atom collisions in a BEC during optical storage, overcoming limitations of conventional squeezing generation methods.

Method: Use Λ-type optical memory interface to map probe pulse onto collective spin wave in BEC, prepare coherent spin state, exploit collisional interactions during storage for one-axis-twisting dynamics to generate spin squeezing, then transfer squeezing to retrieved light via beam-splitter mapping.

Result: Under realistic conditions with loss and finite memory efficiency, several dB of squeezing can be transferred to retrieved light by optimizing storage times.

Conclusion: BEC-based optical memory with collisional interactions provides a viable platform for generating squeezed light, with practical squeezing levels achievable despite realistic experimental imperfections.

Abstract: We propose and analyze a scheme to generate squeezed light by storing a classical probe pulse in a Bose--Einstein condensate (BEC) and exploiting the nonlinear evolution caused by atom--atom collisions during the storage time. A $Λ$-type optical memory interface maps a chosen temporal probe mode onto a single phase-matched collective spin wave; for a coherent input this prepares a tunable coherent spin state of a two-component BEC, with its initial spin orientation set by the stored mean excitation number and the phase relation between the probe and control fields. Collisional interactions during storage then implement one-axis-twisting dynamics and generate spin squeezing in the atomic ensemble. We account for realistic loss and finite memory and retrieval efficiencies, and model readout as a single-mode beam-splitter mapping that transfers the atomic quadrature squeezing onto a propagating optical mode. We identify optimal storage times and predict that, under realistic conditions, several dB of squeezing can be transferred to the retrieved light.

</details>


### [23] [Universal Dilation of Linear Itô SDEs: Quantum Trajectories and Lindblad Simulation of Second Moments](https://arxiv.org/abs/2601.05928)
*Hsuan-Cheng Wu,Xiantao Li*

Main category: quant-ph

TL;DR: A quantum computing framework for simulating N-dimensional linear Itô SDEs using unitary dilation to map SDEs to Stochastic Schrödinger Equations, enabling both trajectory-based and ensemble-based quantum algorithms.


<details>
  <summary>Details</summary>
Motivation: To develop a universal quantum framework for simulating linear stochastic differential equations, addressing the computational challenges of classical SDE simulation and leveraging quantum advantages for stochastic processes.

Method: Uses unitary dilation technique to establish exact pathwise correspondence between linear Itô SDEs and Stochastic Schrödinger Equations on dilated Hilbert space. Implements two algorithmic strategies: trajectory-based approach using sequential weak measurements for stochastic integrators, and ensemble-based approach mapping moment evolution to deterministic Lindblad master equations.

Result: Demonstrates that the SSE is naturally implementable on digital quantum processors with Wiener increments corresponding to measurement outcomes of ancillary qubits. Provides error bounds via stochastic light-cone analysis and validates framework with numerical simulations.

Conclusion: Presents a universal quantum framework for linear SDE simulation that offers both trajectory-based and ensemble-based approaches, enabling efficient quantum algorithms for stochastic processes with rigorous theoretical foundations.

Abstract: We present a universal framework for simulating $N$-dimensional linear Itô stochastic differential equations (SDEs) on quantum computers with additive or multiplicative noises. Building on a unitary dilation technique, we establish a rigorous correspondence between the general linear SDE \[ dX_t = A(t) X_t\,dt + \sum_{j=1}^J B_j(t)X_t\,dW_t^j \] and a Stochastic Schrödinger Equation (SSE) on a dilated Hilbert space. Crucially, this embedding is pathwise exact: the classical solution is recovered as a projection of the dilated quantum state for each fixed noise realization. We demonstrate that the resulting SSE is {naturally implementable} on digital quantum processors, where the stochastic Wiener increments correspond directly to measurement outcomes of ancillary qubits. Exploiting this physical mapping, we develop two algorithmic strategies: (1) a trajectory-based approach that uses sequential weak measurements to realize efficient stochastic integrators, including a second-order scheme, and (2) an ensemble-based approach that maps moment evolution to a deterministic Lindblad quantum master equation, enabling simulation without Monte Carlo sampling. We provide error bounds based on a stochastic light-cone analysis and validate the framework with numerical simulations.

</details>


### [24] [Below-threshold error reduction in single photons through photon distillation](https://arxiv.org/abs/2601.05947)
*F. H. B. Somhorst,J. Saied,N. Kannan,B. Kassenberg,J. Marshall,M. de Goede,H. J. Snijders,P. Stremoukhov,A. Lukianenko,P. Venderbosch,T. B. Demille,A. Roos,N. Walk,J. Eisert,E. G. Rieffel,D. H. Smith,J. J. Renema*

Main category: quant-ph

TL;DR: Photon distillation is a resource-efficient bosonic error-mitigation technique that uses quantum interference to purify photon indistinguishability, outperforming quantum error correction in efficiency and error threshold for photonic quantum computing.


<details>
  <summary>Details</summary>
Motivation: Photonic quantum computers rely on quantum interference of indistinguishable photons, but which-way information degrades interference and introduces errors. Quantum error correction is resource-intensive with low error thresholds, requiring many high-quality optical components.

Method: Scalable, optimal photon distillation - an intrinsically bosonic, coherent error-mitigation technique that exploits quantum interference to project single photons into purified internal states, reducing indistinguishability errors more efficiently than quantum error correction.

Result: Experimental demonstration of unconditional error reduction (below-threshold behavior) consistent with theoretical predictions, achieving actual net-gain error mitigation even when accounting for noise from the distillation gate, under conditions relevant for fault-tolerant quantum computing.

Conclusion: Photon distillation is a substantially more resource-efficient strategy than quantum error correction for reducing indistinguishability errors in photonic quantum computers, compatible with fault-tolerant operation and expected to inspire additional bosonic error-reduction strategies.

Abstract: Photonic quantum computers use the bosonic statistics of photons to construct, through quantum interference, the large entangled states required for measurement-based quantum computation. Therefore, any which-way information present in the photons will degrade quantum interference and introduce errors. While quantum error correction can address such errors in principle, it is highly resource-intensive and operates with a low error threshold, requiring numerous high-quality optical components. We experimentally demonstrate scalable, optimal photon distillation as a substantially more resource-efficient strategy to reduce indistinguishability errors in a way that is compatible with fault-tolerant operation. Photon distillation is an intrinsically bosonic, coherent error-mitigation technique which exploits quantum interference to project single photons into purified internal states, thereby reducing indistinguishability errors at both a higher efficiency and higher threshold than quantum error correction. We observe unconditional error reduction (i.e., below-threshold behaviour) consistent with theoretical predictions, even when accounting for noise introduced by the distillation gate, thereby achieving actual net-gain error mitigation under conditions relevant for fault-tolerant quantum computing. We anticipate photon distillation will find uses in large-scale quantum computers. We also expect this work to inspire the search for additional intrinsically bosonic error-reduction strategies, even for fault-tolerant architectures.

</details>


### [25] [Continuous-time noise mitigation in analogue quantum simulation](https://arxiv.org/abs/2601.05952)
*Gabriele Bressanini,Yue Ma,Hyukjoon Kwon,M. S. Kim*

Main category: quant-ph

TL;DR: First fully analogue protocol for exact noise cancellation in quantum simulators using ancillary qubits and continuous-time operations.


<details>
  <summary>Details</summary>
Motivation: Analogue quantum simulators are promising for exploring quantum many-body dynamics beyond classical computation, but their accuracy is limited by vulnerability to noise, necessitating effective noise mitigation strategies.

Method: Time-continuous framework using small number of ancillary qubits whose interaction with the system, combined with classical post-processing of joint measurement data, is tailored to cancel noise effects; Hamiltonian-independent and preserves continuous-time nature.

Result: First fully analogue protocol achieving exact noise cancellation, robust to realistic ancilla noise, avoiding discretization while preserving continuous-time dynamics of the system.

Conclusion: Establishes new direction for high-fidelity analogue quantum simulation in noisy environments through continuous-time noise mitigation framework.

Abstract: Analogue quantum simulators offer a promising route to explore quantum many-body dynamics beyond classical reach in the near term. However, their vulnerability to noise limits the accuracy of simulations. Here, we establish a new framework for mitigating noise in analogue quantum simulation, operating in a time-continuous manner. To our knowledge, this is the first protocol that is fully analogue and that achieves exact noise cancellation. Our method requires a small number of ancillary qubits, whose interaction with the system$-$combined with classical post-processing of joint measurement data$-$is tailored to cancel the effect of noise. Furthermore, the protocol is Hamiltonian-independent, robust to realistic ancilla noise, and avoids any discretization, preserving the continuous-time nature of the system's dynamics. This work opens a new direction for achieving high-fidelity analogue quantum simulation in the presence of noise.

</details>


### [26] [Counterdiabatic ADAPT-VQE for molecular simulation](https://arxiv.org/abs/2601.05973)
*Diego Tancara,Herbert Díaz-Moraga,Dardo Goyeneche*

Main category: quant-ph

TL;DR: Hybrid method combining ADAPT-VQE with counterdiabatic driving for molecular simulations shows improved performance and reduced circuit depth compared to using either approach separately.


<details>
  <summary>Details</summary>
Motivation: ADAPT-VQE is robust against barren plateaus for molecular ground states, while counterdiabatic algorithms offer advantages in performance and circuit depth over standard adiabatic approaches. The authors aim to combine these strengths.

Method: Map molecular Hamiltonian to qubit representation, construct adiabatic Hamiltonian, compute approximate adiabatic gauge potential using nested commutators, use resulting operator terms to define operator pool, then apply ADAPT-VQE to iteratively select most relevant elements for ansatz.

Result: Demonstrates improvements in performance and reductions in circuit depth compared to using either counterdiabatic algorithms alone or ADAPT-VQE with fermionic excitation operators.

Conclusion: Combining ADAPT-VQE framework with counterdiabatic driving within adiabatic evolution scheme is effective for molecular simulations, supporting the hybrid paradigm approach.

Abstract: Among variational quantum algorithms designed for NISQ devices, ADAPT-VQE stands out for its robustness against barren plateaus, particularly in estimating molecular ground states. On the other hand, counterdiabatic algorithms have shown advantages in both performance and circuit depth when compared to standard adiabatic approaches. In this work, we propose a hybrid method that integrates the ADAPT-VQE framework with counterdiabatic driving within an adiabatic evolution scheme. Specifically, we map the molecular Hamiltonian to a qubit representation and construct an adiabatic Hamiltonian, from which an approximate adiabatic gauge potential is computed using nested commutators. The resulting operator terms define the operator pool, and the ADAPT-VQE algorithm is applied to iteratively select the most relevant elements for the ansatz. Our results demonstrate improvements in performance and reductions in circuit depth compared to using either counterdiabatic algorithms or ADAPT-VQE with fermionic excitation operators, thus supporting the effectiveness of combining both paradigms in molecular simulations.

</details>


### [27] [From Superradiance to Superabsorption: An Exact Treatment of Non-Markovian Cooperative Radiation](https://arxiv.org/abs/2601.05989)
*Ignacio González,Ángel Rivas*

Main category: quant-ph

TL;DR: The paper studies cooperative radiation in atom-cavity systems beyond Markovian and mean-field approximations, revealing three dynamical regimes and showing how cooperativity enhances non-Markovian memory effects.


<details>
  <summary>Details</summary>
Motivation: To understand collective radiation phenomena in ensembles of two-level atoms coupled to lossy resonant cavities beyond the limitations of Markovian and mean-field approximations, particularly exploring the interplay between cooperativity and environmental memory effects.

Method: Derived complete analytical solution for two-emitter case and employed numerically exact methods for larger ensembles (up to 10^3 emitters) to characterize the transition from Markovian to non-Markovian collective dynamics.

Result: Identified three distinct regimes: Markovian phase with standard superradiant burst, non-Markovian phase with spontaneous superabsorption, and critical regime with pulsed collective emission. Found that critical spectral width separating behaviors increases with emitter number, and superradiant scaling degrades with system size approaching subquadratic law for perfect cavities.

Conclusion: Environmental memory effects can be enhanced by cooperativity, and spontaneous superabsorption emerges as a distinct manifestation of non-Markovian cooperativity in the limit of perfect cavities, with implications for quantum optics and cavity QED systems.

Abstract: We investigate the emergence of cooperative radiation phenomena in ensembles of two-level atoms coupled to a lossy resonant cavity beyond the Markovian and mean-field approximations. By deriving a complete analytical solution for the two-emitter case and employing a numerically exact method for larger ensembles, we characterize the full transition from Markovian to non-Markovian collective dynamics for systems of up to $10^3$ emitters. Our results reveal three distinct regimes: a Markovian phase exhibiting the standard superradiant burst, a non-Markovian phase featuring spontaneous superabsorption of the emitted field, and a critical regime marked by pulsed collective emission. We show that the critical spectral width separating these behaviors increases monotonically with the number of emitters, demonstrating that environmental memory effects can be enhanced by cooperativity. Finally, we find that the superradiant scaling of the peak intensity progressively degrades with increasing system size, approaching a subquadratic law in the limit of a perfect cavity. In this regime, spontaneous superabsorption emerges as a distinct manifestation of non-Markovian cooperativity.

</details>
