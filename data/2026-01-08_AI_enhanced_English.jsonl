{"id": "2601.03310", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03310", "abs": "https://arxiv.org/abs/2601.03310", "authors": ["Vincenzo Chilla"], "title": "Duality and measurement: the Copenhagen reconciliation", "comment": "25 pages", "summary": "Duality, not monism, constitutes the hermeneutic lens that characterizes the original Copenhagen interpretation of Quantum Mechanics. Therefore, evoking the principles of correspondence and complementarity, in this work we re assert a dual-aspect reading of quantum theory, structured through a multi-perspective schema encompassing its ontological, analytical, epistemological, causal, and information dimensions. We then show how this schema dissolves the so-called measurement problem, along with the associated knowledge-information and macro-micro dichotomies, issues historically raised within later monistic or universalist philosophical settings that ultimately depart from the traditional Copenhagen spirit.", "AI": {"tldr": "The paper argues that the original Copenhagen interpretation of quantum mechanics is fundamentally dualistic rather than monistic, and proposes a dual-aspect framework that resolves key quantum paradoxes.", "motivation": "To correct what the authors see as a misinterpretation of the Copenhagen interpretation as monistic, and to address persistent problems in quantum theory like the measurement problem by returning to the original dualistic spirit of Copenhagen.", "method": "The authors develop a dual-aspect reading of quantum theory using a multi-perspective schema that encompasses ontological, analytical, epistemological, causal, and information dimensions, based on the principles of correspondence and complementarity.", "result": "The proposed dual-aspect framework dissolves the measurement problem and resolves the knowledge-information and macro-micro dichotomies that have historically troubled quantum interpretations.", "conclusion": "The original Copenhagen interpretation is fundamentally dualistic, and embracing this duality through a comprehensive multi-dimensional schema provides a coherent resolution to longstanding quantum paradoxes, contrasting with later monistic interpretations that depart from Copenhagen's original spirit."}}
{"id": "2601.03365", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03365", "abs": "https://arxiv.org/abs/2601.03365", "authors": ["Boubakeur Khantoul", "Ahmed Tedjani"], "title": "Time-Dependent Dunkl-Pauli Oscillator in the Presence of the Aharonov-Bohm Effect", "comment": null, "summary": "We present an exact, time-dependent solution for a two-dimensional Pauli oscillator deformed by Dunkl operators in the presence of an Aharonov--Bohm (AB) flux. By replacing conventional momenta with Dunkl momenta and allowing arbitrary time dependence in both, mass and frequency, we derive a deformed Pauli Hamiltonian that encodes reflection symmetries and topological gauge phases. Employing the Lewis-Riesenfeld invariant method, we derive exact expressions for the eigenvalues and spinor eigenfunctions of the system. Crucially, the AB flux imposes symmetry constraints on the Dunkl parameters of the form $\u03bd_1 = \\mp \u03bd_2 $, linking the reflection symmetry ($\u03b5= \\pm 1 $) to the quantization of angular momentum. These constraints modify the energy spectrum and wavefunctions of the angular operator and the invariant operator. Our framework reveals novel spectral characteristics arising from the interplay between topology and Dunkl symmetry, with potential implications for quantum simulation in engineered systems such as cold atoms and quantum dots.", "AI": {"tldr": "Exact solution for 2D Pauli oscillator deformed by Dunkl operators with time-dependent parameters and Aharonov-Bohm flux, revealing topological-Dunkl symmetry interplay.", "motivation": "To study quantum systems combining Dunkl deformation (reflection symmetry) with topological effects from AB flux, exploring novel spectral characteristics from their interplay for potential quantum simulation applications.", "method": "Replace conventional momenta with Dunkl momenta in Pauli Hamiltonian with arbitrary time-dependent mass and frequency; use Lewis-Riesenfeld invariant method to derive exact eigenvalues and spinor eigenfunctions; impose symmetry constraints from AB flux on Dunkl parameters.", "result": "AB flux imposes symmetry constraints \u03bd\u2081 = \u2213\u03bd\u2082 linking reflection symmetry (\u03b5 = \u00b11) to angular momentum quantization; these constraints modify energy spectrum and wavefunctions of angular and invariant operators; reveals novel spectral characteristics from topology-Dunkl symmetry interplay.", "conclusion": "Framework provides exact solution showing how AB flux constrains Dunkl parameters, linking reflection symmetry to angular momentum quantization, with potential applications in quantum simulation using engineered systems like cold atoms and quantum dots."}}
{"id": "2601.03383", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03383", "abs": "https://arxiv.org/abs/2601.03383", "authors": ["Mei Yu", "Walter T. Strunz", "Stefan Nimmrichter"], "title": "Non-Markovian dynamics of the giant atom beyond the rotating-wave approximation", "comment": "12 pages, 5 figure", "summary": "Superconducting qubits coupled to meandering transmission lines or surface acoustic waves may realize giant artificial atoms, whose spatially separated coupling points give rise to long-lived non-Markovian dynamics. Previous studies were limited to the zero-temperature, weak-coupling regime, where the rotating-wave approximation applies and only single-phonon processes contribute. Here we go beyond these limits using the hierarchical equations of motion (HEOM). We show that HEOM accurately captures the exact dynamics at zero temperature and weak coupling, whereas perturbative Redfield theory fails due to long bath memory times. The non-Markovian effects persist at finite temperatures. In the strong-coupling regime, they are further enhanced, and we observe bound-state formation at zero temperature with only two coupling points. These results establish giant atoms as a powerful platform for exploring non-Markovian open quantum dynamics and their applications in quantum information and thermodynamics.", "AI": {"tldr": "HEOM method reveals enhanced non-Markovian effects in giant artificial atoms beyond weak-coupling, zero-temperature limits, showing bound-state formation and persistent non-Markovian dynamics at finite temperatures.", "motivation": "Previous studies of giant artificial atoms were limited to zero-temperature, weak-coupling regimes with rotating-wave approximation. The paper aims to go beyond these limits to explore non-Markovian dynamics in more realistic conditions.", "method": "Uses hierarchical equations of motion (HEOM) to capture exact dynamics, comparing with perturbative Redfield theory. Studies superconducting qubits coupled to meandering transmission lines or surface acoustic waves as giant artificial atoms with spatially separated coupling points.", "result": "HEOM accurately captures exact dynamics at zero temperature and weak coupling, while Redfield theory fails due to long bath memory times. Non-Markovian effects persist at finite temperatures and are enhanced in strong-coupling regime. Bound-state formation observed at zero temperature with only two coupling points.", "conclusion": "Giant artificial atoms establish a powerful platform for exploring non-Markovian open quantum dynamics with applications in quantum information and thermodynamics, going beyond previous limitations."}}
{"id": "2601.03399", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.03399", "abs": "https://arxiv.org/abs/2601.03399", "authors": ["V. V. Ryazanov"], "title": "Multifractality, percolation threshold and critical point of a nuclear reactor", "comment": "24 pages, 8 figures", "summary": "A multifractal model is used to analyze neutron evolution within a reactor. For chain reactions, various characteristics of multifractal neutron behavior have been determined. These include the dimension of the multifractal carrier, information and correlation dimensions, the entropy of the fractal set, maximum and minimum dimension values, and the multifractal spectrum function. The geometric features of a multifractal allow for the description of a stochastic system consisting of hierarchically subordinate statistical ensembles, which are characterized by Cayley trees. A stationary distribution over hierarchical levels is established, which follows the Tsallis power law. The text also points out some potential applications of fractal patterns in nuclear reactor theory. The chance of percolation, which is when we see a state in the Bethe lattice where there's at least one continuous path through neighboring conducting nodes all the way across, is similar to the likelihood of a self-sustaining fission chain reaction happening. When this probability hits a critical point, we get a (conditionally) infinite cluster of neutrons forming. The percolation probability, influenced by how long the reactor has been running and its size, is linked to the reactor's criticality. We take a look at how the neutron multiplication factor behaves over time. We especially focus on the early stages of a self-sustaining nuclear fission chain reaction. We also highlight the ways to identify the boundaries of the critical region.", "AI": {"tldr": "A multifractal model analyzes neutron evolution in reactors, revealing hierarchical statistical ensembles described by Cayley trees with Tsallis power law distributions, connecting percolation theory to criticality and chain reaction dynamics.", "motivation": "To develop a multifractal framework for understanding neutron behavior in nuclear reactors, particularly for analyzing chain reactions, criticality, and the geometric organization of neutron populations using fractal mathematics and percolation theory.", "method": "Multifractal analysis of neutron evolution using Cayley trees to model hierarchical statistical ensembles, establishing stationary distributions following Tsallis power law, and applying percolation theory from Bethe lattices to analyze criticality and chain reaction dynamics.", "result": "Determined multifractal characteristics including carrier dimension, information/correlation dimensions, entropy, dimension extremes, and spectrum function; established connection between percolation probability and reactor criticality; analyzed neutron multiplication factor temporal behavior and critical region boundaries.", "conclusion": "Multifractal modeling provides powerful geometric framework for analyzing neutron chain reactions, connecting hierarchical statistical ensembles with percolation theory to understand criticality and early-stage fission dynamics, with potential applications in reactor theory."}}
{"id": "2601.03395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03395", "abs": "https://arxiv.org/abs/2601.03395", "authors": ["Paul M. Alsing", "Richard J. Birrittella", "Peter L. Kaulfuss"], "title": "Multiphoton Interference with a symmetric SU(N) beam splitter and the generalization of the extended Hong-Ou-Mandel effect", "comment": "31 pages including 2 source code, and10 figures", "summary": "We examine multiphoton interference with a symmetric $SU(N)$ beam splitter $S_N$, an extension of features of the $SU(2)$ 50/50 beam splitter extended Hong-Ou-Mandel (eHOM) effect, whereby one obtains a zero amplitude (probability) for the output coincidence state (defined by equal number of photons $n/N$ in each output port), when a total number $n$ of photons impinges on the $N$-port device. These are transitions of the form $|n_1,n_2,\\ldots,n_N\\rangle\\overset{S_N}{\\to}|n/N\\rangle^{\\otimes N}$, where $n=\\sum_{i=1}^N n_i$, which generalize the Hong-Ou-Mandel (HOM) effect $|1,1\\rangle \\overset{S_2}{\\to}|1,1\\rangle $, the eHOM effect $|n_1,n_2\\rangle \\overset{S_2}{\\to}|\\tfrac{n_1+n_2}{2},\\tfrac{n_1+n_2}{2}\\rangle $, and the generalized HOM effect (gHOM) $|1\\rangle^{\\otimes N}\\overset{S_N}{\\to}|1\\rangle^{\\otimes N}$, which have previously been studied in the literature. The emphasis of this work is on illuminating how the overall destructive interference occurs in separate groups of destructive interferences of sub-amplitudes of the total zero amplitude. We develop symmetry properties for the generalized eHOM effect (geHOM) $|n_1,n_2,\\ldots,n_N\\rangle\\overset{S_N}{\\to}|n/N\\rangle^{\\otimes N}$ involving a zero amplitude governed by Perm($\u039b$)=0, for an appropriately constructed matrix $\u039b(S_N)$ built from the matrix elements of $S_N$. We develop an analytical constraint equation for Perm$(\u039b)$ for arbitrary $N$ that allows us to determine when it is zero. We generalize the SU(2) beam splitter feature of central nodal line (CNL), which has a zero diagonal along the output probability distribution when one of the input states is of odd parity (containing only odd number of photons), to the general case of $N = 2 * N'$ where $N'\\in odd$.", "AI": {"tldr": "The paper analyzes multiphoton interference in symmetric SU(N) beam splitters, generalizing the Hong-Ou-Mandel effect to N-port devices, with focus on destructive interference patterns and symmetry properties.", "motivation": "To extend the understanding of multiphoton interference effects from SU(2) beam splitters to symmetric SU(N) beam splitters, particularly focusing on destructive interference patterns and zero-amplitude conditions in generalized Hong-Ou-Mandel effects.", "method": "Develop symmetry properties for generalized extended Hong-Ou-Mandel (geHOM) effects using permutation matrix analysis, construct matrix \u039b(S_N) from beam splitter elements, derive analytical constraint equations for Perm(\u039b)=0 conditions, and generalize central nodal line concepts from SU(2) to SU(N) systems.", "result": "Established conditions for zero amplitude in geHOM effects |n\u2081,n\u2082,...,n_N\u27e9\u2192|n/N\u27e9^\u2297N, derived analytical constraint equations for Perm(\u039b)=0 for arbitrary N, and generalized central nodal line features from SU(2) to SU(N) systems with N=2\u00d7N' where N' is odd.", "conclusion": "The work provides a comprehensive framework for understanding destructive interference patterns in symmetric SU(N) beam splitters, generalizing known SU(2) phenomena to arbitrary N-port systems through symmetry analysis and matrix permutation methods."}}
{"id": "2601.04155", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.04155", "abs": "https://arxiv.org/abs/2601.04155", "authors": ["Dafne Prado Bandeira", "Marco Tarzia"], "title": "Anderson Localization on Husimi Trees and its implications for Many-Body localization", "comment": null, "summary": "Motivated by the analogy between many-body localization (MBL) and single-particle Anderson localization on hierarchical graphs, we study localization on the Husimi tree, a generalization of the Bethe lattice with a finite density of local loops of arbitrary but finite length. The exact solution of the model provides a transparent and quantitative framework to systematically inspect the effect of loops on localization. Our analysis indicates that local loops enhance resonant processes, thereby reducing the critical disorder with increasing their number and size. At the same time, loops promote local hybridization, leading to an increase in the spatial extent of localized eigenstates. These effects reconcile key discrepancies between MBL phenomenology and its single-particle Anderson analog. These results show that local loops are a crucial structural ingredient for realistic single-particle analogies to many-body Hilbert spaces.", "AI": {"tldr": "Local loops in hierarchical graphs enhance resonant processes and reduce critical disorder for localization, reconciling discrepancies between many-body localization and single-particle Anderson localization.", "motivation": "To understand the analogy between many-body localization (MBL) and single-particle Anderson localization on hierarchical graphs, specifically investigating how local loops affect localization properties.", "method": "Study localization on the Husimi tree (a generalization of the Bethe lattice with finite density of local loops of arbitrary finite length) using exact solution of the model to systematically inspect loop effects.", "result": "Local loops enhance resonant processes, reducing critical disorder with increasing loop number and size. Loops also promote local hybridization, increasing spatial extent of localized eigenstates.", "conclusion": "Local loops are crucial structural ingredients for realistic single-particle analogies to many-body Hilbert spaces, reconciling key discrepancies between MBL phenomenology and its single-particle Anderson analog."}}
{"id": "2601.03407", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03407", "abs": "https://arxiv.org/abs/2601.03407", "authors": ["Roman Ovsiannikov", "Kurt Jacobs", "Andrii G. Sotnikov", "Matthew E. Trusheim", "Denys I. Bondar"], "title": "Hybrid non-degenerate parametric amplifier for a microwave cavity mode and an NV ensemble", "comment": "12 pages, 5 figures", "summary": "We introduce an implementation of a non-degenerate parametric amplifier in which the signal and idler modes, respectively, a microwave mode and an ensemble of spins (e.g., nitrogen-vacancy centers in diamond), are operated in their linear regime. This paramp, which amplifies signals in both parts at room and cryogenic temperatures, can be used to generate both the two-mode and single-mode squeezing of either system. It requires merely modulating the frequency of the spin ensemble at the sum of the cavity and spin frequencies (providing the classical pump) with the two systems sufficiently detuned. This effect is remarkable given that modulating a spin ensemble by itself produces neither amplification nor squeezing, unlike modulating an oscillator, and that an off-resonant perturbative analysis would suggest that modulating the spin ensemble merely parametrically drives the cavity mode. With typical cavity parameters including a cavity quality factor~$Q=10^4$, and a 1 GHz modulation amplitude, the microwave signal can be amplified by approximately $18~\\mbox{dB}$ in $1.7~\\mbox{$\u03bc$s}$, with a resonant bandwidth of about $0.5~\\mbox{MHz}$. At $10~\\mbox{mK}$ with the same modulation amplitude and a cavity and spin $Q=5\\times 10^4$ it generates approximately $5~\\mbox{dB}$ of squeezing. We also examine the experimental requirements for implementation.", "AI": {"tldr": "Implementation of a non-degenerate parametric amplifier using a microwave cavity and spin ensemble that generates amplification and squeezing at room/cryogenic temperatures via spin frequency modulation.", "motivation": "To create a parametric amplifier that can amplify signals and generate squeezing in both microwave and spin systems using a novel approach where modulation of spin ensemble frequency serves as the classical pump, overcoming limitations of conventional parametric amplifiers.", "method": "Modulating the frequency of a spin ensemble (e.g., nitrogen-vacancy centers) at the sum of cavity and spin frequencies while keeping the two systems sufficiently detuned. This creates parametric amplification without requiring direct modulation of the cavity.", "result": "Achieves ~18 dB microwave signal amplification in 1.7 \u03bcs with 0.5 MHz bandwidth at room temperature (Q=10\u2074). Generates ~5 dB squeezing at 10 mK with Q=5\u00d710\u2074. The system amplifies both microwave and spin signals and can produce two-mode and single-mode squeezing.", "conclusion": "Demonstrates a novel parametric amplifier architecture using spin ensemble modulation that enables amplification and squeezing in hybrid microwave-spin systems, with practical experimental implementation requirements examined."}}
{"id": "2601.03426", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03426", "abs": "https://arxiv.org/abs/2601.03426", "authors": ["Ryohei Weil", "Dmytro Bondarenko", "Arnab Adhikary", "Robert Raussendorf"], "title": "Testing measurement-based computational phases of quantum matter on a quantum processor", "comment": "22 pages, 12 figures", "summary": "Many symmetry protected or symmetry enriched phases of quantum matter have the property that every ground state in a given such phase endows measurement based quantum computation with the same computational power. Such phases are called computational phases of quantum matter. Here, we experimentally verify four theoretical predictions for them on an IBM superconducting quantum device. We comprehensively investigate how symmetric imperfections of the resource states translate into logical decoherence, and how this decoherence is mitigated. In particular, the central experiment probes the scaling law from which the uniformity of computational power follows. We also analyze the correlated regime, where local measurements give rise to logical operations collectively. We test the prediction that densest packing of a measurement-based algorithms remains the most efficient, in spite of the correlations. Our experiments corroborate the operational stability of measurement based quantum computation in quantum phases of matter with symmetry.", "AI": {"tldr": "Experimental verification of computational phases of quantum matter on IBM superconducting quantum device, testing theoretical predictions about measurement-based quantum computation stability and efficiency in symmetric phases.", "motivation": "To experimentally validate theoretical predictions about computational phases of quantum matter - phases where every ground state provides the same computational power for measurement-based quantum computation - using real quantum hardware.", "method": "Experimental implementation on IBM superconducting quantum device, investigating symmetric imperfections in resource states and their translation to logical decoherence, testing scaling laws, analyzing correlated regime, and examining algorithm packing efficiency.", "result": "Experimental corroboration of four theoretical predictions: (1) how symmetric imperfections cause logical decoherence and mitigation strategies, (2) scaling law supporting uniformity of computational power, (3) collective logical operations in correlated regime, (4) densest packing remains most efficient despite correlations.", "conclusion": "The experiments demonstrate operational stability of measurement-based quantum computation in quantum phases of matter with symmetry, validating theoretical predictions about computational phases on real quantum hardware."}}
{"id": "2601.03616", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03616", "abs": "https://arxiv.org/abs/2601.03616", "authors": ["Shi Jin", "Chuwen Ma", "Enrique Zuazua"], "title": "Transmutation based Quantum Simulation for Non-unitary Dynamics", "comment": null, "summary": "We present a quantum algorithm for simulating dissipative diffusion dynamics generated by positive semidefinite operators of the form $A=L^\\dagger L$, a structure that arises naturally in standard discretizations of elliptic operators. Our main tool is the Kannai transform, which represents the diffusion semigroup $e^{-TA}$ as a Gaussian-weighted superposition of unitary wave propagators. This representation leads to a linear-combination-of-unitaries implementation with a Gaussian tail and yields query complexity $\\tilde{\\mathcal{O}}(\\sqrt{\\|A\\| T \\log(1/\\varepsilon)})$, up to standard dependence on state-preparation and output norms, improving the scaling in $\\|A\\|, T$ and $\\varepsilon$ compared with generic Hamiltonian-simulation-based methods. We instantiate the method for the heat equation and biharmonic diffusion under non-periodic physical boundary conditions, and we further use it as a subroutine for constant-coefficient linear parabolic surrogates arising in entropy-penalization schemes for viscous Hamilton--Jacobi equations. In the long-time regime, the same framework yields a structured quantum linear solver for $A\\mathbf{x}=\\mathbf{b}$ with $A=L^\\dagger L$, achieving $\\tilde{\\mathcal{O}}(\u03ba^{3/2}\\log^2(1/\\varepsilon))$ queries and improving the condition-number dependence over standard quantum linear-system algorithms in this factorized setting.", "AI": {"tldr": "Quantum algorithm for simulating dissipative diffusion dynamics using Kannai transform to represent diffusion semigroup as Gaussian-weighted superposition of unitaries, achieving improved query complexity scaling.", "motivation": "Current quantum simulation methods for dissipative diffusion dynamics have suboptimal scaling in parameters like operator norm, time, and precision. There's a need for more efficient quantum algorithms specifically tailored for positive semidefinite operators of the form A=L\u2020L that arise naturally in discretizations of elliptic operators.", "method": "Uses the Kannai transform to represent the diffusion semigroup e^{-TA} as a Gaussian-weighted superposition of unitary wave propagators. This leads to a linear-combination-of-unitaries implementation with Gaussian tail. The method is instantiated for heat equation and biharmonic diffusion under non-periodic boundary conditions, and used as subroutine for linear parabolic surrogates in entropy-penalization schemes.", "result": "Achieves query complexity $\\tilde{\\mathcal{O}}(\\sqrt{\\|A\\| T \\log(1/\\varepsilon)})$, improving scaling in $\\|A\\|$, T, and $\\varepsilon$ compared to generic Hamiltonian-simulation methods. In long-time regime, yields structured quantum linear solver for A\\mathbf{x}=\\mathbf{b} with $\\tilde{\\mathcal{O}}(\u03ba^{3/2}\\log^2(1/\\varepsilon))$ queries, improving condition-number dependence over standard quantum linear-system algorithms in factorized setting.", "conclusion": "The Kannai transform provides an efficient quantum algorithm for simulating dissipative diffusion dynamics with improved parameter scaling, applicable to various PDE problems and enabling better quantum linear solvers for factorized positive semidefinite operators."}}
{"id": "2601.03623", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03623", "abs": "https://arxiv.org/abs/2601.03623", "authors": ["Mohammad Rowshan"], "title": "Strip-Symmetric Quantum Codes for Biased Noise: Z-Decoupling in Stabilizer and Floquet Codes", "comment": null, "summary": "Bias-tailored codes such as the XZZX surface code and the domain wall color code achieve high dephasing-biased thresholds because, in the infinite-bias limit, their $Z$ syndromes decouple into one-dimensional repetition-like chains; the $X^3Z^3$ Floquet code shows an analogous strip-wise structure for detector events in spacetime. We capture this common mechanism by defining strip-symmetric biased codes, a class of static stabilizer and dynamical (Floquet) codes for which, under pure dephasing and perfect measurements, each elementary $Z$ fault is confined to a strip and the Z-detector--fault incidence matrix is block diagonal. For such codes the Z-detector hypergraph decomposes into independent strip components and maximum-likelihood $Z$ decoding factorizes across strips, yielding complexity savings for matching-based decoders. We characterize strip symmetry via per-strip stabilizer products, viewed as a $\\mathbb{Z}_2$ 1-form symmetry, place XZZX, the domain wall color code, and $X^3Z^3$ in this framework, and introduce synthetic strip-symmetric detector models and domain-wise Clifford constructions that serve as design tools for new bias-tailored Floquet codes.", "AI": {"tldr": "The paper introduces \"strip-symmetric biased codes\" as a unified framework for analyzing bias-tailored quantum error correcting codes like XZZX surface code and domain wall color code, showing how their structure enables efficient decoding under pure dephasing noise.", "motivation": "Existing bias-tailored codes like XZZX surface code and domain wall color code achieve high thresholds under dephasing-biased noise, but their common structural mechanism wasn't formally captured. The paper aims to develop a unified framework to understand and design such codes.", "method": "Defines \"strip-symmetric biased codes\" as a class of static stabilizer and dynamical Floquet codes where Z faults are confined to strips under pure dephasing. Characterizes strip symmetry via per-strip stabilizer products viewed as a \u2124\u2082 1-form symmetry. Analyzes existing codes (XZZX, domain wall color code, X\u00b3Z\u00b3 Floquet code) within this framework and introduces synthetic detector models and domain-wise Clifford constructions as design tools.", "result": "Shows that for strip-symmetric codes, the Z-detector hypergraph decomposes into independent strip components, enabling maximum-likelihood Z decoding to factorize across strips. This yields complexity savings for matching-based decoders. Provides a unified understanding of bias-tailored codes' performance advantages.", "conclusion": "The strip-symmetric framework captures the common mechanism behind bias-tailored codes' high dephasing-biased thresholds, provides tools for analyzing existing codes, and enables systematic design of new bias-tailored Floquet codes through synthetic models and domain-wise Clifford constructions."}}
{"id": "2601.03651", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.03651", "abs": "https://arxiv.org/abs/2601.03651", "authors": ["Zhouhao Guo", "Jiaju Zhang"], "title": "Double interval entanglement in quasiparticle excited states", "comment": "14 pages, 6 figures", "summary": "We investigate double-interval entanglement measures, specifically reflected entropy, mutual information, and logarithmic negativity, in quasiparticle excited states for classical, bosonic, and fermionic systems. We develop an algorithm that efficiently calculates these measures from density matrices expressed in a non-orthonormal basis, enabling straightforward numerical implementation. We find a universal additivity property that emerges at large momentum differences, where the entanglement measures for states with distinct quasiparticle sets equal the sum of their individual contributions. The classical limit arises as a special case of this additivity, with both bosonic and fermionic results converging to classical behavior when all momentum differences are large.", "AI": {"tldr": "The paper develops an algorithm for calculating double-interval entanglement measures (reflected entropy, mutual information, logarithmic negativity) in quasiparticle excited states across classical, bosonic, and fermionic systems, revealing universal additivity at large momentum differences.", "motivation": "To investigate entanglement measures in quasiparticle excited states across different physical systems and develop computational methods for analyzing these measures in non-orthonormal basis representations.", "method": "Developed an algorithm that efficiently calculates double-interval entanglement measures (reflected entropy, mutual information, logarithmic negativity) from density matrices expressed in a non-orthonormal basis, enabling straightforward numerical implementation.", "result": "Found a universal additivity property: at large momentum differences, entanglement measures for states with distinct quasiparticle sets equal the sum of their individual contributions. The classical limit emerges as a special case where both bosonic and fermionic results converge to classical behavior when all momentum differences are large.", "conclusion": "The study provides computational tools for entanglement analysis in quasiparticle systems and reveals fundamental universal properties of entanglement measures, particularly the emergence of additivity and classical behavior in the large momentum difference regime."}}
{"id": "2601.03734", "categories": ["quant-ph", "cs.CC", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.03734", "abs": "https://arxiv.org/abs/2601.03734", "authors": ["Yupan Liu"], "title": "Computational hardness of estimating quantum entropies via binary entropy bounds", "comment": "39 pages, 3 tables. To appear in STACS 2026", "summary": "We investigate the computational hardness of estimating the quantum $\u03b1$-R\u00e9nyi entropy ${\\rm S}^{\\tt R}_\u03b1(\u03c1) = \\frac{\\ln {\\rm Tr}(\u03c1^\u03b1)}{1-\u03b1}$ and the quantum $q$-Tsallis entropy ${\\rm S}^{\\tt T}_q(\u03c1) = \\frac{1-{\\rm Tr}(\u03c1^q)}{q-1}$, both converging to the von Neumann entropy as the order approaches $1$. The promise problems Quantum $\u03b1$-R\u00e9nyi Entropy Approximation (R\u00e9nyiQEA$_\u03b1$) and Quantum $q$-Tsallis Entropy Approximation (TsallisQEA$_q$) ask whether $ {\\rm S}^ {\\tt R}_\u03b1(\u03c1)$ or ${\\rm S}^{\\tt T}_q(\u03c1)$, respectively, is at least $\u03c4_{\\tt Y}$ or at most $\u03c4_{\\tt N}$, where $\u03c4_{\\tt Y} - \u03c4_{\\tt N}$ is typically a positive constant. Previous hardness results cover only the von Neumann entropy (order $1$) and some cases of the quantum $q$-Tsallis entropy, while existing approaches do not readily extend to other orders.\n  We establish that for all positive real orders, the rank-$2$ variants Rank2R\u00e9nyiQEA$_\u03b1$ and Rank2TsallisQEA$_q$ are ${\\sf BQP}$-hard. Combined with prior (rank-dependent) quantum query algorithms in Wang, Guan, Liu, Zhang, and Ying (TIT 2024), Wang, Zhang, and Li (TIT 2024), and Liu and Wang (SODA 2025), our results imply:\n  - For all real orders $\u03b1> 0$ and $0 < q \\leq 1$, LowRankR\u00e9nyiQEA$_\u03b1$ and LowRankTsallisQEA$_q$ are ${\\sf BQP}$-complete, where both are restricted versions of R\u00e9nyiQEA$_\u03b1$ and TsallisQEA$_q$ with $\u03c1$ of polynomial rank.\n  - For all real order $q>1$, TsallisQEA$_q$ is ${\\sf BQP}$-complete.\n  Our hardness results stem from reductions based on new inequalities relating the $\u03b1$-R\u00e9nyi or $q$-Tsallis binary entropies of different orders, where the reductions differ substantially from previous approaches, and the inequalities are also of independent interest.", "AI": {"tldr": "The paper establishes BQP-completeness for quantum R\u00e9nyi and Tsallis entropy approximation problems across various parameter regimes through hardness reductions and matching quantum algorithms.", "motivation": "Previous hardness results for quantum entropy estimation were limited to von Neumann entropy (order 1) and some Tsallis entropy cases, leaving gaps for other orders. The authors aim to characterize computational complexity of \u03b1-R\u00e9nyi and q-Tsallis entropy approximation across all positive real orders.", "method": "Develop reductions based on new inequalities relating \u03b1-R\u00e9nyi or q-Tsallis binary entropies of different orders. These reductions differ substantially from previous approaches and enable establishing BQP-hardness for rank-2 variants of the problems.", "result": "For all positive real orders: rank-2 variants are BQP-hard. Combined with prior quantum query algorithms: (1) LowRank variants are BQP-complete for \u03b1>0 and 0<q\u22641; (2) TsallisQEA_q is BQP-complete for all q>1.", "conclusion": "The paper provides comprehensive complexity characterization for quantum R\u00e9nyi and Tsallis entropy approximation, establishing BQP-completeness across various parameter regimes through novel hardness reductions and inequalities that are also of independent mathematical interest."}}
{"id": "2601.03817", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03817", "abs": "https://arxiv.org/abs/2601.03817", "authors": ["Nandana T Raveendranath", "Travis J. Baker", "Emanuele Polino", "Marwan Haddara", "Lynden K. Shalm", "Varun B. Verma", "Geoff J. Pryde", "Sergei Slussarenko", "Howard M. Wiseman", "Nora Tischler"], "title": "Detection-loophole-free nonlocality in the simplest scenario", "comment": null, "summary": "Loophole-free quantum nonlocality often demands experiments with high complexity (defined by all parties' settings and outcomes) and multiple efficient detectors. Here, we identify the fundamental efficiency and complexity thresholds for quantum steering using two-qubit entangled states. Remarkably, it requires only one photon detector on the untrusted side, with efficiency $\u03b5> 1/X$, where $X \\geq 2$ is the number of settings on that side. This threshold applies to all pure entangled states, in contrast to analogous Bell-nonlocality tests, which require almost unentangled states to be loss-tolerant. We confirm these predictions in a minimal-complexity ($X = 2$ for the untrusted party and a single three-outcome measurement for the trusted party), detection-loophole-free photonic experiment with $\u03b5= (51.6 \\pm 0.4)\\% $.", "AI": {"tldr": "Quantum steering can be demonstrated loophole-free with minimal complexity: only one inefficient photon detector (\u03b5 > 1/X) on the untrusted side, applicable to all pure entangled states, unlike Bell tests.", "motivation": "Loophole-free quantum nonlocality experiments typically require high complexity (multiple settings/outcomes) and multiple efficient detectors. The authors aim to identify fundamental efficiency and complexity thresholds for quantum steering that are significantly lower than those for Bell nonlocality tests.", "method": "Theoretical identification of efficiency thresholds for quantum steering using two-qubit entangled states, requiring only one photon detector on the untrusted side with efficiency \u03b5 > 1/X (where X \u2265 2 is the number of settings on that side). Experimental confirmation with minimal complexity: X = 2 for untrusted party and single three-outcome measurement for trusted party, using detection-loophole-free photonic setup with \u03b5 = (51.6 \u00b1 0.4)%.", "result": "Demonstrated loophole-free quantum steering with minimal complexity requirements: only one inefficient photon detector needed on untrusted side, applicable to all pure entangled states. Experimental confirmation achieved with 51.6% detector efficiency, well above the theoretical threshold of 50% for X = 2 settings.", "conclusion": "Quantum steering can be demonstrated loophole-free with dramatically reduced experimental complexity compared to Bell nonlocality tests, requiring only one inefficient detector on the untrusted side. This makes steering more practical for experimental verification and applicable to all pure entangled states, unlike Bell tests which require almost unentangled states for loss tolerance."}}
{"id": "2601.03821", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.03821", "abs": "https://arxiv.org/abs/2601.03821", "authors": ["Xiaowei Tong", "Xingze Qiu", "Xiang Zhan", "Quan Lin", "Kunkun Wang", "Franco Nori", "Peng Xue"], "title": "Topological Sensing in the Dynamics of Quantum Walks with Defects", "comment": "13 pages, 9 figures", "summary": "Topological quantum sensing leverages unique topological features to suppress noise and improve the precision of parameter estimation, emerging as a promising tool in both fundamental research and practical application. In this Letter, we propose a sensing protocol that exploits the dynamics of topological quantum walks incorporating localized defects. Unlike conventional schemes that rely on topological protection to suppress disorder and defects, our protocol harnesses the evolution time as a resource to enable precise estimation of the defect parameter. By utilizing topologically nontrivial properties of the quantum walks, the sensing precision can approach the Heisenberg limit. We further demonstrate the performance and robustness of the protocol through Bayesian estimation. Our results show that this approach maintains high precision over a broad range of parameters and exhibits strong robustness against disorder, offering a practical pathway for topologically enhanced quantum metrology.", "AI": {"tldr": "Topological quantum sensing protocol using quantum walks with defects achieves Heisenberg-limited precision by exploiting evolution time as a resource.", "motivation": "To develop a practical topological quantum sensing approach that leverages defects as sensing targets rather than suppressing them, enabling precise parameter estimation with noise suppression capabilities.", "method": "Protocol uses topological quantum walks with localized defects, where evolution time serves as a resource for parameter estimation. Bayesian estimation is employed to demonstrate performance and robustness.", "result": "The protocol achieves sensing precision approaching the Heisenberg limit, maintains high precision across broad parameter ranges, and exhibits strong robustness against disorder.", "conclusion": "This approach offers a practical pathway for topologically enhanced quantum metrology by harnessing defects as sensing resources rather than treating them as noise sources."}}
{"id": "2601.03829", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03829", "abs": "https://arxiv.org/abs/2601.03829", "authors": ["Gabriele Staffieri", "Giovanni Scala", "Cosmo Lupo"], "title": "Finite-size security of QKD: comparison of three proof techniques", "comment": "8 pages, 4 figures", "summary": "We compare three proof techniques for composable finite-size security of quantum key distribution under collective attacks, with emphasis on how the resulting secret-key rates behave at practically relevant block lengths. As a benchmark, we consider the BB84 protocol and evaluate finite-size key-rate estimates obtained from entropic uncertainty relations (EUR), from the asymptotic equipartition property (AEP), and from a direct finite-block analysis based on the conditional min-entropy, which we refer to as the finite-size min-entropy (FME) approach. For BB84 we show that the EUR-based bound provides the most favorable performance across the considered parameter range, while the AEP bound is asymptotically tight but can become overly pessimistic at moderate and small block sizes, where it may fail to certify a positive key. The FME approach remains effective in this small-block regime, yielding nonzero rates in situations where the AEP estimate vanishes, although it is not asymptotically optimal for BB84. These results motivate the use of FME-type analyses for continuous-variable protocols in settings where tight EUR-based bounds are unavailable, notably for coherent-state schemes where current finite-size analyses typically rely on AEP-style corrections.", "AI": {"tldr": "Comparison of three proof techniques for composable finite-size security of QKD under collective attacks, showing EUR-based bounds perform best for BB84, AEP is asymptotically tight but pessimistic at small blocks, and FME approach works well in small-block regimes where AEP fails.", "motivation": "To compare different proof techniques for composable finite-size security of QKD under collective attacks, focusing on how their resulting secret-key rates behave at practically relevant block lengths, particularly for BB84 protocol.", "method": "Compare three approaches: 1) Entropic uncertainty relations (EUR), 2) Asymptotic equipartition property (AEP), and 3) Direct finite-block analysis based on conditional min-entropy (FME approach). Evaluate finite-size key-rate estimates for BB84 protocol under collective attacks.", "result": "For BB84: EUR-based bound provides most favorable performance across considered parameter range; AEP bound is asymptotically tight but becomes overly pessimistic at moderate/small block sizes (may fail to certify positive key); FME approach remains effective in small-block regime, yielding nonzero rates where AEP estimate vanishes, though not asymptotically optimal for BB84.", "conclusion": "Results motivate use of FME-type analyses for continuous-variable protocols where tight EUR-based bounds are unavailable, particularly for coherent-state schemes where current finite-size analyses typically rely on AEP-style corrections."}}
{"id": "2601.03832", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03832", "abs": "https://arxiv.org/abs/2601.03832", "authors": ["Mei Ian Sam", "Tzu-Ling Kuo", "Tai-Yue Li"], "title": "Iterative Matrix Product State Simulation for Scalable Grover's Algorithm", "comment": null, "summary": "Grover's algorithm is a cornerstone of quantum search algorithm, offering quadratic speedup for unstructured problems. However, limited qubit counts and noise in today's noisy intermediate-scale quantum (NISQ) devices hinder large-scale hardware validation, making efficient classical simulation essential for algorithm development and hardware assessment. We present an iterative Grover simulation framework based on matrix product states (MPS) to efficiently simulate large-scale Grover's algorithm. Within the NVIDIA CUDA-Q environment, we compare iterative and common (non-iterative) Grover's circuits across statevector and MPS backends. On the MPS backend at 29 qubits, the iterative Grover's circuit runs about 15x faster than the common (non-iterative) Grover's circuit, and about 3-4x faster than the statevector backend. In sampling experiments, Grover's circuits demonstrate strong low-shot stability: as the qubit number increases beyond 13, a single-shot measurement still closely mirrors the results from 4,096 shots, indicating reliable estimates with minimal sampling and significant potential to cut measurement costs. Overall, an iterative MPS design delivers speed and scalability for Grover's circuit simulation, enabling practical large-scale implementations.", "AI": {"tldr": "Iterative MPS-based simulation framework for Grover's algorithm achieves 15x speedup over non-iterative MPS and 3-4x over statevector backends at 29 qubits, with strong low-shot stability enabling reliable single-shot measurements.", "motivation": "Limited qubit counts and noise in NISQ devices hinder large-scale hardware validation of Grover's algorithm, making efficient classical simulation essential for algorithm development and hardware assessment.", "method": "Developed an iterative Grover simulation framework based on matrix product states (MPS) within NVIDIA CUDA-Q environment, comparing iterative and non-iterative Grover circuits across statevector and MPS backends.", "result": "At 29 qubits, iterative Grover circuit runs 15x faster than non-iterative MPS and 3-4x faster than statevector backend. Grover circuits show strong low-shot stability: beyond 13 qubits, single-shot measurements closely match 4096-shot results.", "conclusion": "Iterative MPS design delivers speed and scalability for Grover circuit simulation, enabling practical large-scale implementations with significant potential to reduce measurement costs through reliable low-shot sampling."}}
{"id": "2601.03855", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.03855", "abs": "https://arxiv.org/abs/2601.03855", "authors": ["Chong-Wei Wang", "Mei Ian Sam", "Tzu-Ling Kuo", "Nan-Yow Chen", "Tai-Yue Li"], "title": "MPM-QIR: Measurement-Probability Matching for Quantum Image Representation and Compression via Variational Quantum Circuit", "comment": null, "summary": "We present MPM-QIR, a variational-quantum-circuit (VQC) framework for classical image compression and representation whose core objective is to achieve equal or better reconstruction quality at a lower Parameter Compression Ratio (PCR). The method aligns a generative VQC's measurement-probability distribution with normalized pixel intensities and learns positional information implicitly via an ordered mapping to the flattened pixel array, thus eliminating explicit coordinate qubits and tying compression efficiency directly to circuit (ansatz) complexity. A bidirectional convolutional architecture induces long-range entanglement at shallow depth, capturing global image correlations with fewer parameters. Under a unified protocol, the approach attains PSNR $\\geq$ 30 dB with lower PCR across benchmarks: MNIST 31.80 dB / SSIM 0.81 at PCR 0.69, Fashion-MNIST 31.30 dB / 0.91 at PCR 0.83, and CIFAR-10 31.56 dB / 0.97 at PCR 0.84. Overall, this compression-first design improves parameter efficiency, validates VQCs as direct and effective generative models for classical image compression, and is amenable to two-stage pipelines with classical codecs and to extensions beyond 2D imagery.", "AI": {"tldr": "MPM-QIR is a variational quantum circuit framework for classical image compression that achieves better reconstruction quality with lower parameter compression ratio by aligning quantum measurement probabilities with pixel intensities and using implicit positional encoding.", "motivation": "To develop a quantum-inspired compression framework that achieves equal or better reconstruction quality than classical methods while using fewer parameters, demonstrating the potential of variational quantum circuits as direct generative models for image compression.", "method": "Aligns generative VQC's measurement-probability distribution with normalized pixel intensities; learns positional information implicitly via ordered mapping to flattened pixel array (eliminating explicit coordinate qubits); uses bidirectional convolutional architecture to induce long-range entanglement at shallow depth for capturing global correlations; ties compression efficiency directly to circuit (ansatz) complexity.", "result": "Achieves PSNR \u2265 30 dB with lower Parameter Compression Ratio across benchmarks: MNIST (31.80 dB, SSIM 0.81, PCR 0.69), Fashion-MNIST (31.30 dB, SSIM 0.91, PCR 0.83), and CIFAR-10 (31.56 dB, SSIM 0.97, PCR 0.84).", "conclusion": "The compression-first design improves parameter efficiency, validates VQCs as direct and effective generative models for classical image compression, and is amenable to two-stage pipelines with classical codecs and extensions beyond 2D imagery."}}
{"id": "2601.03922", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.supr-con", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.03922", "abs": "https://arxiv.org/abs/2601.03922", "authors": ["Shiro Kawabata"], "title": "Integration and Resource Estimation of Cryoelectronics for Superconducting Fault-Tolerant Quantum Computers", "comment": "8 pages, 3 figures", "summary": "Scaling superconducting quantum computers to the fault-tolerant regime calls for a commensurate scaling of the classical control and readout stack. Today's systems largely rely on room-temperature, rack-based instrumentation connected to dilution-refrigerator cryostats through many coaxial cables. Looking ahead, superconducting fault-tolerant quantum computers (FTQCs) will likely adopt a heterogeneous quantum-classical architecture that places selected electronics at cryogenic stages -- for example, cryo-CMOS at 4~K and superconducting digital logic at 4~K and/or mK stages -- to curb wiring and thermal-load overheads. This review distills key requirements, surveys representative room-temperature and cryogenic approaches, and provides a transparent first-order accounting framework for cryoelectronics. Using an RSA-2048-scale benchmark as a concrete reference point, we illustrate how scaling targets motivate constraints on multiplexing and stage-wise cryogenic power, and discuss implications for functional partitioning across room-temperature electronics, cryo-CMOS, and superconducting logic.", "AI": {"tldr": "Review of cryogenic electronics for fault-tolerant quantum computers, analyzing control/readout scaling challenges and proposing heterogeneous quantum-classical architectures with cryo-CMOS and superconducting logic.", "motivation": "Current room-temperature control systems with coaxial cables won't scale to fault-tolerant quantum computers due to wiring and thermal-load overheads; need cryogenic electronics integration.", "method": "Review paper surveying existing approaches, providing accounting framework for cryoelectronics, using RSA-2048-scale benchmark to analyze multiplexing and power constraints.", "result": "Identifies key scaling requirements, demonstrates how benchmark motivates constraints on multiplexing and cryogenic power, discusses functional partitioning across temperature stages.", "conclusion": "Fault-tolerant quantum computers require heterogeneous architectures with cryo-CMOS (4K) and superconducting logic (4K/mK) to address scaling challenges; provides framework for evaluating cryoelectronics solutions."}}
{"id": "2601.04082", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.04082", "abs": "https://arxiv.org/abs/2601.04082", "authors": ["Simon J. K. Lang", "Ignaz Eisele", "Alwin Maiwald", "Emir Music", "Luis Schwarzenbach", "Carla Mor\u00e1n-Guiz\u00e1n", "Johannes Weber", "Daniela Zahn", "Thomas Mayer", "Rui N. Pereira", "Christoph Kutter"], "title": "Surface Optimization of Aluminum Resonators for Robust Quantum Device Fabrication", "comment": "7 pages, 9 figures", "summary": "Aluminum remains the central material for superconducting qubits, and considerable effort has been devoted to optimizing its deposition and patterning for quantum devices. However, while post-processing of Nb- and Ta-based resonators has been widely explored, primarily focusing on oxide removal using buffered oxide etch (BOE), post-treatment strategies for Al resonators remain underdeveloped. This challenge becomes particularly relevant for industry-scale fabrication with multichip bonding, where delays between sample preparation and cooldown require surface treatments that preserve low dielectric loss during extended exposure to ambient conditions. In this work, we investigate surface modification approaches for Al resonators subjected to a 24-hour delay prior to cryogenic measurement. Passivation using self-limiting oxygen and fluorine chemistries was evaluated utilizing different plasma processes. Remote oxygen plasma treatment reduced dielectric losses, in contrast to direct plasma, likely due to additional ashing of residual resist despite the formation of a thicker oxide layer on both Si and Al surfaces. A fluorine-based plasma process was developed that passivated the Al surface with fluorine for subsequent BOE treatment. However, increasing fluorine incorporation in the aluminum oxide correlated with higher loss, identifying fluorine as an unsuitable passivation material for Al resonators. Finally, selective oxide removal using HF vapor and phosphoric acid was assessed for surface preparation. HF vapor selectively etched SiO2 while preserving Al2O3, whereas phosphoric acid exhibited the opposite selectivity. Sequential application of both etches yielded dielectric losses as low as $\u03b4_\\mathrm{LP} = 5.2 \\times 10^{-7}$ ($Q\\mathrm{i} \\approx 1.9\\,\\mathrm{M}$) in the single photon regime, demonstrating a promising pathway for robust Al-based resonator fabrication.", "AI": {"tldr": "Surface treatment strategies for aluminum resonators to maintain low dielectric loss after 24-hour ambient exposure, with sequential HF vapor and phosphoric acid etching achieving best results.", "motivation": "Aluminum is crucial for superconducting qubits but lacks developed post-treatment strategies, especially for industry-scale fabrication where delays between preparation and measurement require surface treatments that preserve low dielectric loss during ambient exposure.", "method": "Investigated surface modification approaches including: 1) passivation using self-limiting oxygen and fluorine chemistries via different plasma processes, 2) remote vs. direct oxygen plasma treatment, 3) fluorine-based plasma passivation for subsequent BOE treatment, and 4) selective oxide removal using HF vapor and phosphoric acid.", "result": "Remote oxygen plasma reduced dielectric losses despite thicker oxide formation; fluorine incorporation correlated with higher loss; HF vapor selectively etched SiO2 while preserving Al2O3; phosphoric acid showed opposite selectivity; sequential application of both etches achieved dielectric loss \u03b4_LP = 5.2 \u00d7 10\u207b\u2077 (Qi \u2248 1.9M) in single photon regime.", "conclusion": "Sequential HF vapor and phosphoric acid etching provides a promising pathway for robust Al-based resonator fabrication with low dielectric loss after ambient exposure, while fluorine-based passivation is unsuitable for Al resonators."}}
{"id": "2601.04092", "categories": ["quant-ph", "hep-lat", "hep-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2601.04092", "abs": "https://arxiv.org/abs/2601.04092", "authors": ["Peng Guo", "Paul LeVan", "Frank X. Lee", "Yong Zhao"], "title": "Extracting scattering phase shift in quantum mechanics on quantum computers", "comment": "17 pages, 30 figures", "summary": "We investigate the feasibility of extracting infinite volume scattering phase shift on quantum computers in a simple one-dimensional quantum mechanical model, using the formalism established in Ref.~\\cite{Guo:2023ecc} that relates the integrated correlation functions (ICF) for a trapped system to the infinite volume scattering phase shifts through a weighted integral. The system is first discretized in a finite box with periodic boundary conditions, and the formalism in real time is verified by employing a contact interaction potential with exact solutions. Quantum circuits are then designed and constructed to implement the formalism on current quantum computing architectures. To overcome the fast oscillatory behavior of the integrated correlation functions in real-time simulation, different methods of post-data analysis are proposed and discussed. Test results on IBM hardware show that good agreement can be achieved with two qubits, but complete failure ensues with three qubits due to two-qubit gate operation errors and thermal relaxation errors.", "AI": {"tldr": "Quantum computing approach for extracting infinite volume scattering phase shifts from trapped quantum systems using integrated correlation functions, tested on IBM hardware with 2-qubit success but 3-qubit failure due to gate errors.", "motivation": "To investigate the feasibility of extracting infinite volume scattering phase shifts on quantum computers using a formalism that relates integrated correlation functions for trapped systems to scattering phase shifts through weighted integrals.", "method": "1) Discretize system in finite box with periodic boundary conditions; 2) Verify formalism using contact interaction potential with exact solutions; 3) Design quantum circuits for implementation on current quantum architectures; 4) Propose post-data analysis methods to overcome fast oscillatory behavior of integrated correlation functions in real-time simulation.", "result": "Test results on IBM hardware show good agreement with exact solutions using two qubits, but complete failure with three qubits due to two-qubit gate operation errors and thermal relaxation errors.", "conclusion": "The approach demonstrates feasibility for simple quantum mechanical models with limited qubits, but highlights significant challenges with current quantum hardware limitations, particularly gate errors and decoherence effects that prevent scaling to larger systems."}}
{"id": "2601.04139", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.04139", "abs": "https://arxiv.org/abs/2601.04139", "authors": ["Cristofero Oglialoro", "Gerard J. Machado", "Felix Farsch", "Daniel F. Urrego", "Alejandra A. Padilla", "Raj B. Patel", "Ian A. Walmsley", "Markus Gr\u00e4fe", "Juan P. Torres", "Enno Giese"], "title": "Below-shot-noise capacity in phase estimation using nonlinear interferometers", "comment": "14 pages, 5 figures", "summary": "Over the past decade, several schemes for imaging and sensing based on nonlinear interferometers have been proposed and demonstrated experimentally. These interferometers exhibit two main advantages. First, they enable probing a sample at a chosen wavelength while detecting light at a different wavelength with high efficiency (bicolor quantum imaging and sensing with undetected light). Second, they can show quantum-enhanced sensitivities below the shot-noise limit, potentially reaching Heisenberg-limited precision in parameter estimation. Here, we compare three quantum-imaging configurations using only easily accessible intensity-based measurements for phase estimation: a Yurke-type SU(1,1) interferometer, a Mandel-type induced-coherence interferometer, and a hybrid scheme that continuously interpolates between them. While an ideal Yurke interferometer can exhibit Heisenberg scaling, this advantage is known to be fragile under realistic detection constraints and in the presence of loss. We demonstrate that differential intensity detection in the Mandel interferometer provides the highest and most robust phase sensitivity among the considered schemes, reaching but not surpassing the shot-noise limit, even in the presence of loss. Intensity measurements in a Yurke-type configuration can achieve genuine sub-shot-noise sensitivity under balanced losses and moderate gain; however, their performance degrades in realistic high-gain regimes. Consequently, in this regime, the Mandel configuration with differential detection outperforms the Yurke-type setup and constitutes the most robust approach for phase estimation.", "AI": {"tldr": "Comparison of three quantum imaging configurations shows Mandel interferometer with differential intensity detection provides highest robustness and reaches shot-noise limit, while Yurke interferometer can achieve sub-shot-noise sensitivity but is fragile to realistic conditions.", "motivation": "To compare the performance and robustness of three quantum-imaging configurations (Yurke-type SU(1,1), Mandel-type induced-coherence, and hybrid scheme) for phase estimation using only easily accessible intensity-based measurements, particularly under realistic conditions including loss and detection constraints.", "method": "Comparative analysis of three quantum-imaging configurations: 1) Yurke-type SU(1,1) interferometer, 2) Mandel-type induced-coherence interferometer, and 3) a hybrid scheme that continuously interpolates between them. The study focuses on intensity-based measurements for phase estimation and evaluates performance under realistic conditions including loss, detection constraints, and varying gain regimes.", "result": "Differential intensity detection in the Mandel interferometer provides the highest and most robust phase sensitivity among the considered schemes, reaching but not surpassing the shot-noise limit even with loss. The Yurke-type configuration can achieve genuine sub-shot-noise sensitivity under balanced losses and moderate gain, but performance degrades in realistic high-gain regimes. In high-gain regimes, the Mandel configuration with differential detection outperforms the Yurke-type setup.", "conclusion": "The Mandel interferometer with differential intensity detection constitutes the most robust approach for phase estimation in quantum imaging, particularly under realistic conditions. While ideal Yurke interferometers can theoretically achieve Heisenberg scaling, this advantage is fragile to practical constraints, making the Mandel configuration preferable for practical applications requiring robust performance."}}
{"id": "2601.04180", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04180", "abs": "https://arxiv.org/abs/2601.04180", "authors": ["Aadil Oufkir", "Filippo Girardi"], "title": "Improved Lower Bounds for Learning Quantum Channels in Diamond Distance", "comment": "21 pages, 2 figures", "summary": "We prove that learning an unknown quantum channel with input dimension $d_A$, output dimension $d_B$, and Choi rank $r$ to diamond distance $\\varepsilon$ requires $ \u03a9\\!\\left( \\frac{d_A d_B r}{\\varepsilon \\log(d_B r / \\varepsilon)} \\right)$ queries. This improves the best previous $\u03a9(d_A d_B r)$ bound by introducing explicit $\\varepsilon$-dependence, with a scaling in $\\varepsilon$ that is near-optimal when $d_A=rd_B$ but not tight in general. The proof constructs an ensemble of channels that are well-separated in diamond norm yet admit Stinespring isometries that are close in operator norm.", "AI": {"tldr": "The paper establishes a lower bound on the query complexity of learning quantum channels, improving previous results by introducing explicit \u03b5-dependence.", "motivation": "To understand the fundamental limits of learning quantum channels, specifically determining the minimum number of queries needed to learn an unknown quantum channel to within diamond distance \u03b5, given its input dimension, output dimension, and Choi rank.", "method": "Constructs an ensemble of quantum channels that are well-separated in diamond norm but have Stinespring isometries that are close in operator norm, enabling the derivation of information-theoretic lower bounds.", "result": "Proves a lower bound of \u03a9(d_A d_B r / (\u03b5 log(d_B r / \u03b5))) queries for learning quantum channels, improving the previous \u03a9(d_A d_B r) bound by introducing explicit \u03b5-dependence.", "conclusion": "The result provides a near-optimal scaling in \u03b5 when d_A = r d_B, though not tight in general, advancing understanding of quantum channel learning complexity."}}
