<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 40]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Precision limit under weak-coupling with ancillary qubit](https://arxiv.org/abs/2601.15354)
*Peng Chen,Jun Jing*

Main category: quant-ph

TL;DR: Measurement-based quantum metrology protocol using spin ensemble coupled to qubit via XXZ interaction achieves Heisenberg-limited phase sensitivity without requiring GHZ states or squeezing Hamiltonians.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of standard quantum metrology that requires complex resources like GHZ states or squeezing Hamiltonians to surpass the standard quantum limit, by developing a simpler protocol using unconditional measurements on ancillary qubits.

Method: Composite model with spin ensemble probe coupled to ancillary qubit via Heisenberg XXZ interaction. Optimized weak probe-ancilla coupling with proper joint evolution duration creates two-component states with large eigenspace separation. Uses parity detection on qubit or probe system for phase estimation.

Result: Achieves exact or asymptotic quadratic scaling of quantum Fisher information with spin number N (Heisenberg scaling). Phase sensitivity approaches Heisenberg limit. Quadratic scaling is robust to imperfections in encoding operator and coupling strength.

Conclusion: Unconditional measurement on qubit can efficiently replace GHZ-like states and squeezing Hamiltonians for surpassing standard quantum limit in metrology, providing a simpler resource for Heisenberg-limited quantum metrology.

Abstract: We propose a measurement-based quantum metrology protocol in a composite model, where the probe system (a spin ensemble) is coupled to an ancillary two-level system (qubit) with a general Heisenberg XXZ interaction. With an optimized and weak probe-ancilla coupling strength and a proper duration of joint evolution, the two parallel evolution paths of the probe system induced by the unconditional measurement on qubit can transform an eigenstate of the collective angular momentum operator of spin ensemble to be a two-component state with a large distance in eigenspace. The quantum Fisher information about the phase encoded in the probe system of polarized states or their superposition, that could be relaxed to mixed states, can therefore manifest an exact or asymptotic quadratic scaling with respect to the probe size (spin number) $N$. The quadratic scaling behavior is found to be insensitive to the imperfect encoding operator and coupling strength. By virtue of the parity detection on the ancillary qubit or the probe system, the phase sensitivity can approach the Heisenberg limit. We suggest that the unconditional measurement on qubit could become an efficient resource to replace Greenberger-Horne-Zeilinger-like states and squeezing Hamiltonian for exceeding the standard quantum limit in metrology precision.

</details>


### [2] [Studying energy-resolved transport with wavepacket dynamics on quantum computers](https://arxiv.org/abs/2601.16180)
*Melody Lee,Roland C. Farrell*

Main category: quant-ph

TL;DR: Wavepackets enable energy-resolved transport studies on quantum computers, revealing a finite-size mobility edge in Anderson model and demonstrating error mitigation that outperforms post-selection.


<details>
  <summary>Details</summary>
Motivation: Existing approaches using computational basis states for quench dynamics have poor energy resolution, limiting the study of energy-dependent transport phenomena in quantum simulators.

Method: Use wavepackets with tunable energy and small variance to probe transport; implement on Quantinuum H2-2 quantum computer with maximum-likelihood error mitigation; extend to many-particle regime with quantum algorithm for quasiparticle wavepacket preparation.

Result: Observed energy-dependent localization transition in 8x7 Anderson lattice: low-energy wavepackets remain localized, high-energy ones delocalize, indicating finite-size mobility edge; error mitigation reduced statistical uncertainty by factor of 5 compared to post-selection.

Conclusion: Wavepacket-based transport studies with improved energy resolution are feasible on near-term quantum computers, enabling investigation of energy-dependent phenomena like mobility edges in disordered and interacting systems.

Abstract: Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers.

</details>


### [3] [USDs: A universal stabilizer decoder framework using symmetry](https://arxiv.org/abs/2601.15361)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: quant-ph

TL;DR: Generalizes decoder re-optimization technique from toric code to arbitrary stabilizer codes to address label degeneracy in deep learning-based quantum error correction decoding.


<details>
  <summary>Details</summary>
Motivation: Addresses the challenge of label degeneracy in deep learning for quantum error correction decoding, where syndrome measurements don't uniquely map to error patterns, building on prior work for toric code.

Method: Generalizes symmetry-based decoder re-optimization to arbitrary stabilizer codes, uses multilayer perceptrons to approximate continuous functions complementing syndrome measurements, applies to Color code and Golay code.

Result: Achieved 0.8% decoding accuracy improvement for Color code at 5% physical error rate, 0.1% improvement for Golay code; showed generalized continuous functions better learn geometric code structure.

Conclusion: Decoder re-optimization technique effective for toric code can be generalized to address label degeneracy in deep learning decoding of stabilizer codes, with faithful code structure approximations significantly impacting reoptimization effectiveness.

Abstract: Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes.

</details>


### [4] [The computational two-way quantum capacity](https://arxiv.org/abs/2601.15393)
*Johannes Jakob Meyer,Jacopo Rizzo,Asad Raza,Lorenzo Leone,Sofiene Jerbi,Jens Eisert*

Main category: quant-ph

TL;DR: Computational quantum capacities impose efficiency constraints on quantum communication, revealing stark separations from unbounded capacities under cryptographic assumptions.


<details>
  <summary>Details</summary>
Motivation: Traditional quantum channel capacities don't limit computational resources of sender/receiver, creating a gap between theoretical limits and practical implementations where computational efficiency is essential.

Method: Initiate study of computational quantum capacities focusing on computational two-way quantum capacity, relate it to computational distillable entanglement of channel's Choi state, use cryptographic assumptions to construct polynomial-complexity channels.

Result: Show stark computational capacity separation: under standard cryptographic assumptions, exists polynomial-complexity channel with zero computational two-way capacity but nearly maximal unbounded capacity. Sharp transition occurs when channel complexity leaves polynomial realm.

Conclusion: Computational efficiency requirements radically alter quantum communication limits, demonstrating fundamental differences between theoretical unbounded capacities and practically achievable computational capacities.

Abstract: Quantum channel capacities are fundamental to quantum information theory. Their definition, however, does not limit the computational resources of sender and receiver. In this work, we initiate the study of computational quantum capacities. These quantify how much information can be reliably transmitted when imposing the natural requirement that en- and decoding have to be computationally efficient. We focus on the computational two-way quantum capacity and showcase that it is closely related to the computational distillable entanglement of the Choi state of the channel. This connection allows us to show a stark computational capacity separation. Under standard cryptographic assumptions, there exists a quantum channel of polynomial complexity whose computational two-way quantum capacity vanishes while its unbounded counterpart is nearly maximal. More so, we show that there exists a sharp transition in computational quantum capacity from nearly maximal to zero when the channel complexity leaves the polynomial realm. Our results demonstrate that the natural requirement of computational efficiency can radically alter the limits of quantum communication.

</details>


### [5] [Quadratic tensors as a unification of Clifford, Gaussian, and free-fermion physics](https://arxiv.org/abs/2601.15396)
*Andreas Bauer,Seth Lloyd*

Main category: quant-ph

TL;DR: The paper presents a unified algebraic framework using quadratic functions over abelian groups/Hopf algebras to describe and efficiently solve various quantum models including Clifford circuits, stabilizer codes, free bosons/fermions, rotor codes, and GKP codes.


<details>
  <summary>Details</summary>
Motivation: To unify disparate families of classically simulable quantum models under a single algebraic structure, enabling efficient description and manipulation of these systems while accommodating mixed degrees of freedom.

Method: Represent quantum objects (states, operators, etc.) as quadratic tensors based on quadratic functions over abelian groups or (super) Hopf algebras. Different quantum degrees of freedom correspond to different elementary algebraic structures. Develop efficient tensor contraction algorithms using operations similar to Schur complement.

Result: Shows that quadratic tensors with n degrees of freedom require only O(n²) coefficients and can be contracted efficiently. The framework naturally handles mixed degrees of freedom and enables definition of generalized stabilizer codes and Clifford gates for arbitrary abelian groups.

Conclusion: Quadratic functions over abelian groups/Hopf algebras provide a unifying algebraic framework for classically simulable quantum models, enabling efficient representation and manipulation while generalizing to higher-order tensors (though without guaranteed efficient contraction).

Abstract: Certain families of quantum mechanical models can be described and solved efficiently on a classical computer, including qubit or qudit Clifford circuits and stabilizer codes, free-boson or free-fermion models, and certain rotor and GKP codes. We show that all of these families can be described as instances of the same algebraic structure, namely quadratic functions over abelian groups, or more generally over (super) Hopf algebras. Different kinds of degrees of freedom correspond to different "elementary" abelian groups or Hopf algebras: $\mathbb{Z}_2$ for qubits, $\mathbb{Z}_d$ for qudits, $\mathbb{R}$ for continuous variables, both $\mathbb{Z}$ and $\mathbb{R}/\mathbb{Z}$ for rotors, and a super Hopf algebra $\mathcal F$ for fermionic modes. Objects such as states, operators, superoperators, or projection-operator valued measures, etc, are tensors. For the solvable models above, these tensors are quadratic tensors based on quadratic functions. Quadratic tensors with $n$ degrees of freedom are fully specified by only $O(n^2)$ coefficients. Tensor networks of quadratic tensors can be contracted efficiently on the level of these coefficients, using an operation reminiscent of the Schur complement. Our formalism naturally includes models with mixed degrees of freedom, such as qudits of different dimensions. We also use quadratic functions to define generalized stabilizer codes and Clifford gates for arbitrary abelian groups. Finally, we give a generalization from quadratic (or 2nd order) to $i$th order tensors, which are specified by $O(n^i)$ coefficients but cannot be contracted efficiently in general.

</details>


### [6] [Dissipative Quantum Dynamics in Static Network with Different Topologies](https://arxiv.org/abs/2601.15439)
*Wei-Yang Liu,Hsuan-Wei Lee*

Main category: quant-ph

TL;DR: The paper investigates how quantum dissipative dynamics of population and coherence depend on network topology using a quantum spin model coupled to a thermal reservoir, with applications to complex systems.


<details>
  <summary>Details</summary>
Motivation: To understand how network topology influences quantum dissipative dynamics and coherence in quantum networks, with potential applications to complex systems like social models, epidemiology, and biological systems.

Method: Two-part approach: 1) Analysis of small Ising spin networks coupled to a dissipative bath using Lindblad master equation, 2) Development of a mean-field approach for larger-scale networks to capture dissipative dynamics.

Result: Network topology significantly shapes quantum dissipative dynamics, revealing how tailored network structures can control quantum coherence and showing sensitivity of quantum coherence to network structure.

Conclusion: Dissipative quantum dynamics strongly depend on network topology, providing insights into coherent dynamics of entangled states in networks, with potential extensions to various complex systems.

Abstract: We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems.

</details>


### [7] [Check-weight-constrained quantum codes: Bounds and examples](https://arxiv.org/abs/2601.15446)
*Lily Wang,Andy Zeyi Liu,Ray Li,Aleksander Kubica,Shouzhen Gu*

Main category: quant-ph

TL;DR: The paper establishes fundamental limits on quantum LDPC code parameters when check weights are constrained, proving that stabilizer codes with weight-3 checks cannot have nontrivial distance, and deriving tight rate-distance tradeoffs for CSS codes with weight-4 checks and subsystem codes with weight-2 checks.


<details>
  <summary>Details</summary>
Motivation: To understand how constraints on check weight limit achievable parameters of qLDPC codes, which are crucial for building noise-resilient quantum computers since low-weight checks make them compatible with noisy quantum hardware.

Method: Combines analytical arguments with numerical optimization, using linear programming techniques for finite-size bounds and identifying explicit code constructions that approach these limits.

Result: Proves stabilizer codes with weight-3 checks cannot have nontrivial distance; establishes tight rate-distance tradeoffs for CSS codes with weight-4 checks and subsystem codes with weight-2 checks; derives numerical upper bounds for finite-size codes; identifies constructions approaching these limits.

Conclusion: The work provides fundamental bounds on qLDPC code parameters under check-weight constraints, delineating the landscape of practically relevant codes for quantum computing applications with tens to hundreds of physical qubits.

Abstract: Quantum low-density parity-check (qLDPC) codes can be implemented by measuring only low-weight checks, making them compatible with noisy quantum hardware and central to the quest to build noise-resilient quantum computers. A fundamental open question is how constraints on check weight limit the achievable parameters of qLDPC codes. Here, we study stabilizer and subsystem codes with constrained check weight, combining analytical arguments with numerical optimization to establish strong upper bounds on their parameters. We show that stabilizer codes with checks of weight at most three cannot have nontrivial distance. We also prove tight tradeoffs between rate and distance for broad families of CSS stabilizer and subsystem codes with checks of weight at most four and two, respectively. Notably, our bounds are applicable to general qLDPC codes, as they rely only on check-weight constraints without assuming geometric locality or special graph connectivity. In the finite-size regime, we derive numerical upper bounds using linear programming techniques and identify explicit code constructions that approach these limits, delineating the landscape of practically relevant qLDPC codes with tens or hundreds of physical qubits.

</details>


### [8] [A Sublinear-Time Quantum Algorithm for High-Dimensional Reaction Rates](https://arxiv.org/abs/2601.15523)
*Tyler Kharazi,Ahmad M. Alkadri,Kranthi K. Mandadapu,K. Birgitta Whaley*

Main category: quant-ph

TL;DR: Quantum algorithm for Fokker-Planck equation achieves exponential speedup in particle number over classical worst-case bounds for computing reaction rates.


<details>
  <summary>Details</summary>
Motivation: The Fokker-Planck equation models rare events in high-dimensional systems, but classical computers struggle with dimensionality, and existing quantum algorithms suffer from exponential decay in success probability.

Method: Developed Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) using sum-of-squares representation to represent non-unitary propagator, paired with novel technique to directly estimate matrix elements without exponential decay.

Result: Achieves $\widetilde{O}\left((η^{5/2}\sqrt{tβ}α_V + η^{3/2}\sqrt{t/β}N)/ε\right)$ gate complexity, showing exponential separation in particle number η, quartic speedup in ε, and quadratic speedup in t compared to classical worst-case bounds.

Conclusion: Demonstrates rigorous route toward quantum advantage for high-dimensional dissipative dynamics, overcoming limitations of previous quantum algorithms for non-unitary dynamics.

Abstract: The Fokker-Planck equation models rare events across sciences, but its high-dimensional nature challenges classical computers. Quantum algorithms for such non-unitary dynamics often suffer from exponential {decay in} success probability. We introduce a quantum algorithm that overcomes this for computing reaction rates. Using a sum-of-squares representation, we develop a Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) to represent the non-unitary propagator with $O\left(\sqrt{t\|H\|\log(1/ε)}\right)$ queries to its block encoding. Crucially, we pair this with {a} novel technique to directly estimate matrix elements without exponential decay. For $η$ pairwise interacting particles discretized with $N$ plane waves per degree of freedom, we estimate reactive flux to error $ε$ using $\widetilde{O}\left((η^{5/2}\sqrt{tβ}α_V + η^{3/2}\sqrt{t/β}N)/ε\right)$ quantum gates, where $α_V = \max_{r}|V'(r)/r|$. For non-convex potentials, the {sharpest classical} worst-case analytical bounds to simulate the related overdamped Langevin {equation} scale as $O(te^{Ω(η)}/ε^4)$. This {implies} an exponential separation in particle number $η$, a quartic speedup in $ε$, and quadratic speedup in $t$. While specialized classical heuristics may outperform these bounds in practice, this demonstrates a rigorous route toward quantum advantage for high-dimensional dissipative dynamics.

</details>


### [9] [Bidirectional teleportation using scrambling dynamics: a practical protocol](https://arxiv.org/abs/2601.15536)
*Amit Vikram,Edwin Chaparro,Muhammad Miskeen Khan,Andrew Lucas,Chris Akers,Ana Maria Rey*

Main category: quant-ph

TL;DR: Quantum scrambling enables SWAP gates between collective degrees of freedom without local control by combining Hayden-Preskill recovery with teleportation in opposite directions.


<details>
  <summary>Details</summary>
Motivation: To enable quantum state exchange between collective degrees of freedom in systems lacking universal local control, leveraging quantum information scrambling to overcome control limitations.

Method: Combines Hayden-Preskill recovery scheme (from black hole information paradox) with quantum teleportation, running them in parallel and opposite directions to enable bidirectional state exchange through global interactions alone.

Result: Protocol enables generic SWAP gates between collective degrees of freedom using only global interactions, distinguishing roles of information spreading, entanglement, and chaos for coherent state transfer and recovery.

Conclusion: Quantum scrambling enables practical quantum gates without local control, with proposed experimental realization using Dicke model in cavity-QED and trapped-ion platforms, demonstrating holography's utility in quantum gate design.

Abstract: We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates.

</details>


### [10] [Spectator-transition crosstalk in a spin-3/2 silicon vacancy qudit in silicon carbide revealed by broadband Ramsey interferometry](https://arxiv.org/abs/2601.15559)
*Jun-Jae Choi,Seung-Jae Hwang,Seoyoung Paik,Juhwan Kim,Jawad UI-Hassan,Nguyen Tien Son,Hiroshi Abe,Takeshi Oshima,Jaekwon Suk,Hyeon-Ho Jeong,Dong-Hee Kim,Sang-Yun Lee*

Main category: quant-ph

TL;DR: Broadband Ramsey interferometry reveals and quantifies spectator-transition crosstalk in silicon vacancy qudits in 4H-SiC, providing a framework for multilevel control.


<details>
  <summary>Details</summary>
Motivation: Silicon vacancy centers in 4H-SiC offer wafer-scale materials with long spin coherence and chip-level photonics, making them promising for scalable quantum technologies. The S=3/2 ground state provides a native qudit enabling compact encodings but introduces spectator transitions that cause crosstalk when using short, detuned pulses.

Method: Used broadband Ramsey interferometry to reveal and quantify spectator-transition crosstalk. Developed analytic mapping of Ramsey Fourier spectra lines to pairwise energy differences between qudit levels in the rotating-frame Hamiltonian, assigning weights via compact amplitudes. Performed numerical time-domain propagation with experimental sampling to reproduce detuning maps.

Result: Ramsey Fourier spectra displayed multiple lines beyond addressed single-quantum transitions. Measured peak positions coincided with analytic branch lines without frequency fitting, revealing a deterministic six-branch structure. The approach successfully quantified spectator-transition crosstalk and provided practical framework for multilevel control.

Conclusion: Provides a practical, spectator-aware framework for multilevel control in silicon vacancy qudits. Offers guidance to suppress crosstalk or exploit spectator lines for applications like in situ pulse calibration and phase-sensitive quantum state/process estimation.

Abstract: Color center spins in 4H-SiC offer a rare combination of wafer-scale materials maturity with long spin coherence and chip-level photonics, making them promising building blocks for scalable quantum technologies. In particular, the silicon vacancy hosts an S=3/2 ground state, a native qudit that enables compact encodings and subspace-selective control, but also introduces spectator transitions: short, detuned pulses can coherently drive non-addressed level pairs and create crosstalk. Here we use broadband Ramsey interferometry to reveal and quantify such spectator-transition crosstalk. Experimentally, the Ramsey Fourier spectra display multiple lines beyond the addressed single-quantum transition. Analytically, we map each line to a pairwise energy difference between qudit levels of the rotating-frame Hamiltonian and assign its weight via compact amplitudes set by the prepared state and the microwave pulse parameters, predicting a deterministic six-branch structure. Numerical time-domain propagation with the experimental sampling reproduces the detuning map, and the measured peak positions coincide with the analytic branch lines without frequency fitting. Together these results provide a practical, spectator-aware framework for multilevel control in the silicon vacancy qudit. The approach offers clear guidance to suppress crosstalk or, conversely, to exploit spectator lines, for example as additional constraints for in situ pulse calibration and for phase-sensitive quantum state and process estimation.

</details>


### [11] [Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy](https://arxiv.org/abs/2601.15565)
*Alex Terrasson,Lars Madsen,Joel Grim,Warwick Bowen*

Main category: quant-ph

TL;DR: Efficient generation of high-level bright picosecond pulsed squeezed light using χ² optical parametric amplification in a waveguide for quantum-enhanced nonlinear microscopy.


<details>
  <summary>Details</summary>
Motivation: Squeezed states of light enable enhanced measurement precision below the standard quantum limit, but generating and detecting bright pulsed squeezing at high levels remains challenging for nonlinear microscopy applications where photodamage and quantum-limited noise limit performance.

Method: Used a χ² optical parametric amplification process in a waveguide to efficiently generate bright picosecond pulsed squeezed light, measuring both bright squeezing and vacuum squeezing levels.

Result: Achieved -3.2 dB of bright squeezing with optical power compatible with nonlinear microscopy and -3.6 dB of vacuum squeezing. Corrected for losses, these correspond to -15.4^{+2.7}_{-8.7} dB of squeezing generated in the waveguide, representing the highest reported level of bright amplitude pulsed squeezing to date.

Conclusion: The demonstrated efficient generation of high-level bright pulsed squeezing will contribute to broader adoption of quantum-enhanced nonlinear microscopy in biological studies by overcoming current limitations in photodamage and quantum noise.

Abstract: Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies.

</details>


### [12] [Optimized Slice-Phase Control of Mirror Pulse in Cold-Atom Interferometry with Finite Response Time](https://arxiv.org/abs/2601.15586)
*Xueting Fang,Doudou Wang,Kun Yuan,Jie Deng,Qin Luo,Xiaochun Duan,Minkang Zhou,Lushuai Cao,Zhongkun Hu*

Main category: quant-ph

TL;DR: Quantum optimal control with adaptive sliced structure enhances atom interferometer mirror pulse robustness to experimental inhomogeneities while maintaining high efficiency.


<details>
  <summary>Details</summary>
Motivation: Atom interferometers require high efficiency and robust performance in mirror pulses under experimental inhomogeneities like detuning variations, Rabi frequency fluctuations, and response-time delays.

Method: Used gradient ascent pulse engineering (GRAPE) to design optimized mirror pulses by discretizing control into non-uniform phase slices (adaptive sliced structure) for a Mach-Zehnder light-pulse atom interferometer.

Result: Optimized pulse broadened tolerance to detuning variations [-Ω₀,Ω₀] and Rabi frequency variations [0.1×Ω₀,1.9×Ω₀] (Ω₀=2π×25 kHz), maintained high transfer efficiency with response-time delays up to 1.6 μs, and showed robustness to coupling inhomogeneity and velocity spread.

Conclusion: The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative quantum optimal control scheme for high-precision atom interferometry.

Abstract: Atom interferometers require both high efficiency and robust performance in their mirror pulses under experimental inhomogeneities. In this work, we demonstrated that quantum optimal control designed mirror pulse significantly enhance interferometer performance by using novel adaptive sliced structure. Using gradient ascent pulse engineering (GRAPE), optimized mirror pulse for a Mach-Zehnder light-pulse atom interferometer was designed by discretizing the control into non-uniform phase slices. This design broadened the tolerence to experimentally relevant variations in detuning $[-Ω_0,Ω_0]$ and Rabi frequency $[0.1\timesΩ_0,1.9\timesΩ_0]$ ($Ω_0=2π\times25$ kHz), while maintaining high transfer efficiency even when the response-time delays up to 1.6 $\rm{μs}$. The optimized pulse was found to be robust to coupling inhomogeneity and velocity spread, offering a significant improvement in robustness over conventional pulse. The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative scheme for quantum optimal control in high precision atom interferometry.

</details>


### [13] [Tensor-based phase difference estimation on time series analysis](https://arxiv.org/abs/2601.15616)
*Shu Kanno,Kenji Sugisaki,Rei Sakuma,Jumpei Kato,Hajime Nakamura,Naoki Yamamoto*

Main category: quant-ph

TL;DR: Tensor-network circuit compression enables scalable quantum phase estimation with improved accuracy using algorithmic error mitigation and iterative optimization techniques.


<details>
  <summary>Details</summary>
Motivation: To develop a scalable and accurate quantum phase estimation algorithm that can handle larger quantum systems by leveraging tensor networks and error mitigation techniques for near-term quantum devices.

Method: Proposes a phase-difference estimation algorithm using tensor-network circuit compression, constructing circuits with nearest-neighbor gates and extracting time-evolution data via four-type circuit measurements. Includes algorithmic error mitigation for time-evolution circuits and iterative circuit optimization combined with matrix product state merging for state preparation.

Result: Achieves 0.4-4.7% error from true energy gap for 8-qubit Hubbard model on noiseless simulator. Algorithmic error mitigation improves accuracy, and iterative optimization enhances overlap with matrix product states. Successfully demonstrated on IBM Heron devices with Q-CTRL error suppression for 8-, 36-, and 52-qubit models using over 5,000 2-qubit gates.

Conclusion: The proposed algorithm represents significant progress toward practical near-term quantum computing applications and preparation for error-corrected quantum devices, demonstrating largest-scale QPE-type algorithm implementations to date.

Abstract: We propose a phase-difference estimation algorithm based on the tensor-network circuit compression, leveraging time-evolution data to pursue scalability and higher accuracy on a quantum phase estimation (QPE)-type algorithm. Using tensor networks, we construct circuits composed solely of nearest-neighbor gates and extract time-evolution data by four-type circuit measurements. In addition, to enhance the accuracy of time-evolution and state-preparation circuits, we propose techniques based on algorithmic error mitigation and on iterative circuit optimization combined with merging into matrix product states, respectively. Verifications using a noiseless simulator for the 8-qubit one-dimensional Hubbard model using an ancilla qubit show that the proposed algorithm achieves accuracies with 0.4--4.7\% error from a true energy gap on an appropriate time-step size, and that accuracy improvements due to the algorithmic error mitigation are observed. We also confirm the enhancement of the overlap with matrix product states through iterative optimization. Finally, the proposed algorithm is demonstrated on IBM Heron devices with Q-CTRL error suppression for 8-, 36-, and 52-qubit models using more than 5,000 2-qubit gates. These largest-scale demonstrations for the QPE-type algorithm represent significant progress not only toward practical applications of near-term quantum computing but also toward preparation for the era of error-corrected quantum devices.

</details>


### [14] [Machine Failure Detection Based on Projected Quantum Models](https://arxiv.org/abs/2601.15641)
*Larry Bowden,Qi Chu,Bernard Cena,Kentaro Ohno,Bob Parney,Deepak Sharma,Mitsuharu Takeori*

Main category: quant-ph

TL;DR: Quantum-based failure detection algorithm using projected quantum feature maps and statistical change-point detection for industrial machine monitoring, validated on benchmark and real-world IoT datasets using IBM's 133-qubit Heron processor.


<details>
  <summary>Details</summary>
Motivation: Prompt detection of machine failures is critical for industrial efficiency and minimizing downtime. Current methods may lack precision in noisy environments, creating a need for more accurate anomaly detection approaches that can handle complex time series data.

Method: Combines quantum computing with statistical change-point detection using projected quantum feature maps. The algorithm enhances anomaly detection precision by leveraging quantum computational advantages for feature extraction and pattern recognition in time series data.

Result: Empirically validated on benchmark multi-dimensional time series datasets and real-world IoT sensor readings. Demonstrated feasibility on IBM's 133-qubit Heron quantum processor, showing effective anomaly detection in noisy time series data with practical industrial relevance.

Conclusion: The quantum-based failure detection system effectively identifies anomalies in industrial machine monitoring, highlighting quantum computing's potential in industrial diagnostics and paving the way for more sophisticated quantum algorithms in predictive maintenance.

Abstract: Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance.

</details>


### [15] [Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations](https://arxiv.org/abs/2601.15654)
*Arman,Prasanta K. Panigrahi*

Main category: quant-ph

TL;DR: Photon-added cat and kitten states show metrological advantage over original states due to phase-space broadening from increased amplitude, though with higher energy cost. Squeezed and superposed states constructed from weak squeezing and displacement are analyzed via QFI and fidelity, revealing regimes for practical preparation via Gaussian operations and photon addition.


<details>
  <summary>Details</summary>
Motivation: To investigate whether photon addition to cat and kitten states can enhance their metrological performance for phase estimation, despite the increased energy cost, and to identify practical regimes where these enhanced states can be prepared using accessible non-classical resources (weak squeezing and displacement).

Method: Construct squeezed states and two superposed states (squeezed cat state and symmetrically squeezed state) using weak squeezing and displacement. Create photon-added variants of these states and compare them with parity-matched cat and kitten states using quantum Fisher information (QFI) and fidelity analysis. Analyze QFI isocontours to identify regimes of high fidelity and large amplitude.

Result: Photon-added cat and kitten states demonstrate metrological advantage over original states due to phase-space broadening from increased amplitude. QFI isocontours reveal specific regimes where kitten states exhibit both high fidelity and large amplitude, enabling practical preparation via Gaussian operations and photon addition. Similar regimes exist for cat states enhanced by squeezing and photon addition, showing improved metrological performance. Increased amplitude reduces interferometric fringe size, enhancing quantum error correction effectiveness in cat codes.

Conclusion: Photon addition to cat and kitten states provides a metrological advantage for phase estimation through phase-space broadening, despite higher energy costs. Practical preparation regimes exist using accessible non-classical resources (weak squeezing, displacement, and photon addition), offering improved performance for quantum metrology and enhanced quantum error correction in cat codes.

Abstract: We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes.

</details>


### [16] [Quantum-HPC hybrid computation of biomolecular excited-state energies](https://arxiv.org/abs/2601.15677)
*Kentaro Yamamoto,Riku Masui,Takahito Nakajima,Miwako Tsuji,Mitsuhisa Sato,Peter Schow,Lukas Heidemann,Matthew Burke,Philipp Seitz,Oliver J. Backhouse,Juan W. Pedersen,John Children,Craig Holliman,Nathan Lysne,Daichi Okuno,Seyon Sivarajah,David Muñoz Ramo,Alex Chernoguzov,Ross Duncan*

Main category: quant-ph

TL;DR: Hybrid quantum-classical workflow combining Fugaku supercomputer and Quantinuum quantum computer for scalable biomolecular reaction simulations


<details>
  <summary>Details</summary>
Motivation: To enable accurate simulation of complex biomolecular reactions by extending layered approaches to treat both active sites and large molecular environments

Method: Developed workflow within ONIOM framework combining Fugaku supercomputer (classical) and Quantinuum Reimei trapped-ion quantum computer (quantum) for hybrid computing

Result: Demonstrated successful implementation on hybrid platform, marking significant milestone for scalable biomolecular reaction simulations

Conclusion: Hybrid quantum-classical approach enables accurate treatment of biomolecular chemical reactions by combining quantum computing for active sites with classical computing for molecular environments

Abstract: We develop a workflow within the ONIOM framework and demonstrate it on the hybrid computing system consisting of the supercomputer Fugaku and the Quantinuum Reimei trapped-ion quantum computer. This hybrid platform extends the layered approach for biomolecular chemical reactions to accurately treat the active site, such as a protein, and the large and often weakly correlated molecular environment. Our result marks a significant milestone in enabling scalable and accurate simulation of complex biomolecular reactions

</details>


### [17] [Fractional squeezing: spectra and dynamics from generalized squeezing Hamiltonian with fractional orders](https://arxiv.org/abs/2601.15693)
*Sahel Ashhab*

Main category: quant-ph

TL;DR: Generalization of squeezing problem to fractional squeezing orders n enables identification of critical points where qualitative behavior changes occur, including continuous-to-discrete spectrum transitions and amplitude changes.


<details>
  <summary>Details</summary>
Motivation: To extend the generalized-squeezing problem to fractional squeezing orders n, allowing identification of critical points where qualitative behavior changes occur that are challenging for conventional computational methods.

Method: Generalize the generalized-squeezing problem to include fractional values of squeezing order n, perform numerical calculations to identify critical points, and investigate behavior in the large n regime.

Result: Identification with high confidence of critical points: where spectrum turns from continuous to discrete, and where oscillations transition from asymptotically infinite to finite amplitudes. Numerical investigation of large n regime behavior with intuitive explanation matching numerical results.

Conclusion: Fractional generalization of squeezing order n enables accurate prediction of critical behavior points and provides insights into large n regime behavior that conventional methods struggle to capture.

Abstract: We generalize the generalized-squeezing problem to include fractional values of the squeezing order $n$. This approach allows us to determine the locations of critical points at which qualitative changes in behaviour occur and accurately predict the behaviour at these critical points, which are challenging for conventional computational methods. Based on our numerical calculations, we identify with a high degree of confidence the point at which the spectrum turns from continuous to discrete and the point at which oscillations turn from having asymptotically infinite amplitudes to finite amplitudes. Furthermore, we numerically investigate the behaviour in the large $n$ regime and provide an intuitive explanation that coincides with the numerical results.

</details>


### [18] [Unsplit Spreading: An Overlooked Signature of Long-Range Interaction](https://arxiv.org/abs/2601.15752)
*Jian-Feng Wu,Yi Huang,Yu-Xiang Zhang*

Main category: quant-ph

TL;DR: Long-range interactions create singular features in dispersion relations that enable unsplit spreading of excitations, unlike conventional smooth dispersions that cause splitting into counter-propagating wave packets.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the unrecognized phenomenon of unsplit spreading in quantum systems, which contradicts conventional understanding that localized excitations always split into counter-propagating wave packets due to smooth dispersion relations.

Method: The authors prove mathematically that smooth dispersion relations necessarily cause splitting, and demonstrate that unsplit spreading requires singular features in ω(k) that can be induced by long-range interactions. They analyze realistic open quantum systems including 1D and 2D subwavelength atomic arrays where subradiant states host effective dispersion with the required singularities.

Result: The work shows that unsplit spreading emerges in realistic quantum systems and was actually visible in published quantum simulation experiments as early as 2014, though unrecognized as a distinct physical effect. They establish unsplit spreading as an experimentally accessible signature of singular band structure induced by long-range physics.

Conclusion: Unsplit spreading serves as a smoking-gun signature of singular dispersion relations enabled by long-range interactions, providing a new diagnostic tool for identifying long-range physics in quantum systems that was previously overlooked despite being observable in existing experimental data.

Abstract: In conventional lattice models, the dispersion relation $ω(k)$ is assumed to be a smooth function. We prove that this smoothness implies the splitting of an initially localized excitation into counter-propagating wave packets. Consequently, unsplit spreading can occur only when $ω(k)$ develops singular features, precisely what long-range interactions enable. Remarkably, this phenomenon was clearly visible in published quantum simulation experiments as early as 2014, yet it has remained unrecognized or discussed as a distinct physical effect. We show that unsplit spreading emerges in realistic open quantum systems, such as 1D and 2D subwavelength atomic arrays, where the long-lived subradiant states host effective dispersion with the required singularities. Our work establishes unsplit spreading as an experimentally accessible, smoking-gun signature of singular band structure induced by long-range physics.

</details>


### [19] [Improving the efficiency of QAOA using efficient parameter transfer initialization and targeted-single-layer regularized optimization with minimal performance degradation](https://arxiv.org/abs/2601.15760)
*Shubham Patel,Utkarsh Mishra*

Main category: quant-ph

TL;DR: Parameter transfer initialization with targeted single-layer QAOA achieves near-optimal performance (98.88%) with 8x speedup for unweighted graphs, but performs poorly on weighted graphs; ridge regularization reduces optimization inconsistencies.


<details>
  <summary>Details</summary>
Motivation: To improve QAOA efficiency for combinatorial optimization problems by developing parameter initialization strategies that reduce computational cost while maintaining solution quality, addressing the challenge of complex parameter landscapes that trap optimization in local minima.

Method: Applied QAOA with parameter transfer initialization followed by targeted single-layer optimization on three graph families (3-regular, Erdős-Rényi, Barabási-Albert). Used ridge (L2) regularization to smooth solution landscapes and reduce optimization inconsistencies.

Result: For unweighted graphs: achieved mean approximation ratio of 0.9443 vs 0.9551 for full optimization (98.88% optimal performance) with 8.06x computational speedup. For weighted graphs: performance degraded (<90% for higher nodes). Ridge regularization reduced inconsistent test cases from 8.92% to 3.81%.

Conclusion: Parameter transfer with targeted single-layer optimization significantly improves QAOA efficiency with minimal performance degradation for unweighted graphs, but is less effective for weighted graphs. Ridge regularization helps mitigate optimization inconsistencies caused by complex parameter landscapes.

Abstract: Quantum approximate optimization algorithm (QAOA) have promising applications in combinatorial optimization problems (COPs). We investigated the MaxCut problem in three different families of graphs using QAOA ansats with parameter transfer initialization followed by targeted single layer optimization. For 3 regular (3R), Erdos Renyi (ER), and Barabasi Albert (BA) graphs, the parameter transfer approach achieved mean approximation ratios of 0.9443 for targeted-single layer optimization as compared to 0.9551 of full optimization. It represents 98.88 percent optimal performance, with 8.06 times computational speedup in unweighted graphs. But, in weighted graph families, optimal performance is relatively low (less than 90 percent) for higher nodes graph, suggesting parameter transfer followed by targeted-single-layer optimization is not ideal for weighted graph families, however, we find that for some weighted families (weighted 3-regular) this approach works perfectly. In 8.92 percent test cases, targeted single layer optimization outperformed the full optimization, indicating that complex parameter landscape can trap full optimization in sub-optimal local minima. To mitigate this inconsistency, ridge (L2) regularization is used to smoothen the solution landscape, which helps the optimizer to find better optimum parameters during full optimization and reduces these inconsistent test cases from 8.92 percent to 3.81 percent. This work demonstrates that efficient parameter initialization and targeted-single-layer optimization can improve the efficiency of QAOA with minimal performance degradation.

</details>


### [20] [Classical Simulation of Noiseless Quantum Dynamics without Randomness](https://arxiv.org/abs/2601.15770)
*Jue Xu,Chu Zhao,Xiangran Zhang,Shuchen Zhu,Qi Zhao*

Main category: quant-ph

TL;DR: LPD algorithm efficiently approximates local observables for short-time quantum dynamics without noise, using entanglement to reduce classical simulation error.


<details>
  <summary>Details</summary>
Motivation: Classical simulation of noiseless quantum dynamics faces limitations: tensor-network methods fail with high entanglement, while Pauli-truncation methods typically require noise or randomness. There's a need for efficient classical simulation methods that work without noise assumptions.

Method: Proposes Low-weight Pauli Dynamics (LPD) algorithm that approximates local observables for short-time dynamics without noise. Uses entanglement to bound truncation errors without randomness assumptions. Shows entangled states can be generated by tensor-network classical simulation or near-term quantum devices.

Result: Proves average-case bound for truncation error without randomness assumptions when states are sufficiently entangled. Demonstrates counterintuitive result that entanglement reduces classical simulation error. Shows synergy between classical simulation methods and quantum devices for reducing circuit depth in long-time dynamics.

Conclusion: LPD algorithm establishes rigorous synergy between classical simulation methods and provides complementary route to quantum simulation, extending accessible regime of quantum dynamics by reducing circuit depth requirements for long-time dynamics.

Abstract: Simulating noiseless quantum dynamics classically faces a fundamental dilemma: tensor-network methods become inefficient as entanglement saturates, while Pauli-truncation approaches typically rely on noise or randomness. To close the gap, we propose the Low-weight Pauli Dynamics (LPD) algorithm that efficiently approximates local observables for short-time dynamics in the absence of noise. We prove that the truncation error admits an average-case bound without assuming randomness, provided that the state is sufficiently entangled. Counterintuitively, entanglement--usually an obstacle for classical simulation--alleviates classical simulation error. We further show that such entangled states can be generated either by tensor-network classical simulation or near-term quantum devices. Our results establish a rigorous synergy between existing classical simulation methods and provide a complementary route to quantum simulation that reduces circuit depth for long-time dynamics, thereby extending the accessible regime of quantum dynamics.

</details>


### [21] [Fermion Doubling in Dirac Quantum Walks](https://arxiv.org/abs/2601.15885)
*Chaitanya Gupta,Anthony J. Short*

Main category: quant-ph

TL;DR: A family of quantum walks is proposed that eliminates fermion doublers and pseudo-doublers while still simulating the Dirac equation, achieved by allowing non-zero probability for the walker to stay at the same point.


<details>
  <summary>Details</summary>
Motivation: Fermion doubling in quantum walks creates spurious low-energy solutions that behave like Dirac particles, which persist in second-quantized versions (quantum cellular automata) and cause problems when introducing interactions. Pseudo-doublers also create vacuum stability issues.

Method: Propose a family of quantum walks that eliminates doublers and pseudo-doublers by modifying the conventional Dirac walk to allow non-zero probability for the walker to stay at the same point, while maintaining the Dirac equation in the continuum limit.

Result: The proposed quantum walk family successfully eliminates fermion doublers and pseudo-doublers, though a small number of additional low-energy solutions remain that don't directly correspond to Dirac particles. The walks still simulate the Dirac equation in the continuum limit.

Conclusion: By allowing non-zero probability for staying at the same point, a family of quantum walks can be constructed that avoids the problems of fermion doubling and pseudo-doublers while preserving the Dirac equation simulation capability, though some non-Dirac low-energy solutions persist.

Abstract: We consider discrete spacetime models known as quantum walks, which can be used to simulate Dirac particles. In particular we look at fermion doubling in these models, in which high momentum states yield additional low energy solutions which behave like Dirac particles. The presence of doublers carries over to the `second quantised' version of the walks represented by quantum cellular automata, which may lead to spurious solutions when introducing interactions. Moreover, we also consider pseudo-doublers, which have high energy but behave like low energy Dirac particles, and cause potential problems regarding the stability of the vacuum. To address these issues, we propose a family of quantum walks, that are free of these doublers and pseudo-doublers, but still simulate the Dirac equation in the continuum limit. However, there remain a small number of additional low energy solutions which do not directly correspond to Dirac particles. While the conventional Dirac walk always has a zero probability for the walker staying at the same point, we obtain the family of walks by allowing this probability to be non-zero.

</details>


### [22] [Improved cryptographic security in teleportation with q-deformed non-maximal entangled states](https://arxiv.org/abs/2601.15902)
*Prabal Dasgupta,Debashis Gangopadhyay*

Main category: quant-ph

TL;DR: The paper proposes using q-deformed algebras to enhance cryptographic security in quantum teleportation by introducing additional parameters through deformed Bell-like states that must be shared for decryption.


<details>
  <summary>Details</summary>
Motivation: To improve cryptographic security in quantum teleportation protocols by leveraging the mathematical framework of q-deformed algebras, which introduces additional degrees of freedom that must be shared between parties for successful decryption.

Method: 1. Construct q-deformed Bell-like states using q-deformed harmonic oscillator states that reduce to standard Bell states when q→1. 2. Develop orthonormal basis for q-deformed entangled bipartite states with constraints on arbitrary q-functions. 3. Generalize standard teleportation protocol to non-maximally entangled states. 4. Create two new teleportation protocols using q-deformed non-maximally entangled states with additional parameters.

Result: Successfully developed q-deformed Bell-like states that form orthonormal basis under specific constraints. Created two new teleportation protocols with enhanced cryptographic security due to additional parameters that must be shared for decryption.

Conclusion: The q-deformed algebra framework provides a powerful method to enhance cryptographic security in quantum teleportation by introducing extra parameters that must be securely shared between communicating parties, offering improved protection against eavesdropping.

Abstract: In this work the machinery of q-deformed algebras are used to enhance cryptographic security during teleportation. We use q-deformed harmonic oscillator states to develop a novel method of teleportation. The deformed states can be expressed in terms of standard oscillator states and the expressions contain certain arbitrary functions of $q$. It is the presence of these arbitrary functions that allows an enhancement of cryptographic security. The specifics are :
  (a) q-deformed Bell-like states are constructed which reduce to the usual Bell states when the deformation parameter $q\rightarrow 1$. These deformed states form an orthonormal basis for q-deformed entangled bipartite states when certain arbitrary functions of $q$ satisfy a constraint.
  (b) We discuss the generalisation of the usual teleportation protocol with non-maximally entangled states. This generalisation is then employed to construct two new protocols using q-deformed non-maximally entangled states. These states have additional parameters and these have to be shared for decryption after teleportation. Consequently, the cryptographic security is improved.

</details>


### [23] [Automated quantum circuit optimization with randomized replacements](https://arxiv.org/abs/2601.15934)
*Marcin Szyniszewski,Aleks Kissinger,Noah Linden,Paul Skrzypczyk*

Main category: quant-ph

TL;DR: Automated quantum circuit optimization using ZX-calculus with greedy stochastic approximations that replace small-angle operations with mixtures of identity and over-rotations to reduce gate count while maintaining error budget.


<details>
  <summary>Details</summary>
Motivation: Current quantum circuit optimization focuses on exact unitary transformations, but substantial resource reduction opportunities exist by allowing approximate local transformations and employing mixed quantum channels to approximate pure circuits, converting experimental noise into deliberately engineered random noise.

Method: Refined ZX-calculus-based automated optimization with greedy strategy that selectively replaces ZX-diagrams with small phase angles using stochastic mixtures of identity and carefully chosen over-rotations, designed to reduce overall gate count in expectation while staying within strict error budget.

Result: Modest two-qubit gate count reduction in random quantum circuits, substantial reduction in structured circuits like quantum Fourier transform, outperforms many other approximation methods on average by converting experimental noise into deliberately engineered random noise.

Conclusion: Mixed-channel approximations have potential to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels.

Abstract: Quantum circuit optimization - the process of transforming a quantum circuit into an equivalent one with reduced time and space requirements - is crucial for maximizing the utility of current and near-future quantum devices. While most automated optimization techniques focus on transforming circuits into equivalent ones that implement the same unitary, we show that substantial new opportunities for resource reduction can be achieved by (1) allowing approximate local transformations and (2) employing mixed quantum channels to approximate pure circuits. Our novel automated protocol for approximate circuit rewriting is a refined evolution of automated optimization techniques based on the ZX-calculus, where we add a greedy strategy that selectively replaces ZX-diagrams with small phase angles with stochastic mixtures of the identity and carefully chosen over-rotations, which are designed to reduce the overall gate count in expectation while staying within a strict error budget. This approach yields modest two-qubit gate count reduction in random quantum circuits, and achieves a substantial reduction in structured circuits such as the quantum Fourier transform. Fundamentally, our protocol converts experimental noise due to gate applications into deliberately engineered random noise, outperforming many other approximation methods on average. These results highlight the potential of mixed-channel approximations to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels.

</details>


### [24] [Frictional work and entropy production in integrable and non-integrable spin chains](https://arxiv.org/abs/2601.15941)
*Vishnu Muraleedharan Sajitha,Matthew J. Davis,L. A. Williamson*

Main category: quant-ph

TL;DR: Frictional work in quantum systems is linked to diagonal entropy production from quantum coherence buildup, with relationships characterized by effective temperatures that differ between integrable and non-integrable spin chains.


<details>
  <summary>Details</summary>
Motivation: To understand how frictional work (work difference between adiabatic and non-adiabatic driving) relates to quantum coherence buildup and how integrability affects work extraction in quantum spin chains.

Method: Analyze frictional work in non-integrable spin chains using diagonal entropy production associated with quantum coherence buildup, characterized by effective temperature of final adiabatic state. Compare with integrable spin chains where adiabatic state has multiple effective temperatures for independent subspaces.

Result: For slow/moderate driving, frictional work is described by diagonal entropy production with effective temperature; for fast driving, by quantum relative entropy between final non-adiabatic and adiabatic states. Integrability breaking enhances work extraction in adiabatic limit but degrades it in sufficiently non-adiabatic regimes.

Conclusion: Frictional work in quantum systems is fundamentally connected to coherence-induced entropy production, with integrability playing a crucial role in determining the effective temperature structure and work extraction efficiency across different driving regimes.

Abstract: The maximum work extractable from a quantum system is achieved when the system is driven adiabatically. Frictional work then quantifies the difference in work output between adiabatic and non-adiabatic driving. Here we show that frictional work in a non-integrable spin chain is well-described by the diagonal entropy production associated with the build up of quantum coherence. The relationship is characterized by an effective temperature of the final adiabatic state and holds for slow to moderate driving protocols. For fast protocols, the frictional work is instead described by the quantum relative entropy between the final non-adiabatic and adiabatic states. We compare our results to those obtained from an integrable spin chain, in which case the adiabatic state is no longer described by a single temperature. In this case, the frictional work is described by a sum of terms for each independent subspace of the spin chain, which are at different effective temperatures. We show how integrability breaking can enhance work extraction in the adiabatic limit, but degrade work extraction in sufficiently non-adiabatic regimes.

</details>


### [25] [Renormalization Treatment of IR and UV Cutoffs in Waveguide QED and Implications to Numerical Model Simulation](https://arxiv.org/abs/2601.15945)
*Romain Piron,Akihito Soeda*

Main category: quant-ph

TL;DR: Non-perturbative derivation of renormalization relations for waveguide-QED models with explicit treatment of numerical cutoffs, enabling efficient multi-photon simulations.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of infrared and ultraviolet cutoffs introduced in numerical simulations of waveguide-QED models, which require proper renormalization to connect bare model parameters to physically observable quantities.

Method: Formulate atomic dynamics in the time domain to derive explicit renormalization relations linking bare parameters to observable atomic frequency and decay rate, verify consistency with scattering theory, and connect to Feynman diagrams for physical interpretation.

Result: Obtained explicit renormalization relations that enable parameterization of simulations with minimal frequency bandwidth while preserving physical accuracy, reducing computational cost for multi-photon simulations.

Conclusion: The approach provides a transparent, general framework for efficient and reliable multi-photon light-matter simulations in waveguide-QED by properly handling numerical cutoffs through first-principles renormalization.

Abstract: We present a non-perturbative, first-principles derivation of renormalization relations for waveguide-QED models, explicitly accounting for the infrared (IR) and ultraviolet (UV) cutoffs that are necessarily introduced in numerical simulations. By formulating the atomic dynamics in the time domain, we obtain explicit expressions linking the bare model parameters to the physically observable atomic frequency and decay rate, and verify their consistency with scattering theory. We further connect these results to standard Feynman diagrams, providing a transparent physical interpretation and ensuring the generality of the approach. Finally, we show how these renormalization relations can be used to parameterize simulations with a minimal frequency bandwidth, simultaneously preserving physical accuracy and reducing computational cost, thereby paving the way for efficient and reliable multi-photon light-matter simulations.

</details>


### [26] [Universal Digitized Counterdiabatic Driving](https://arxiv.org/abs/2601.15972)
*Takuya Hatomura*

Main category: quant-ph

TL;DR: Proposes a universal digitized counterdiabatic driving method that constructs adiabatic gauge potential digitally without introducing many-body/nonlocal interactions, incorporates infinite nested commutators, and provides explicit rotation angles for digital implementation.


<details>
  <summary>Details</summary>
Motivation: To develop a universal method for digitized counterdiabatic driving that overcomes limitations of existing approaches, particularly avoiding introduction of many-body/nonlocal interactions while enabling incorporation of infinite nested commutators and providing explicit digital implementation parameters.

Method: Universal digitized counterdiabatic driving that constructs adiabatic gauge potential in a digital way using universal counterdiabatic driving principles. The method digitally implements the counterdiabatic protocol without modifying the original Hamiltonian structure.

Result: The method shows consistency with exact theory analytically and demonstrates effectiveness through numerical simulations. It successfully achieves parameter displacement of energy eigenstates while avoiding introduction of many-body/nonlocal interactions.

Conclusion: The proposed universal digitized counterdiabatic driving method provides a practical approach for quantum control that overcomes key limitations of existing methods, offering advantages in implementation feasibility and theoretical completeness.

Abstract: Counterdiabatic driving realizes parameter displacement of an energy eigenstate of a given parametrized Hamiltonian using the adiabatic gauge potential. In this paper, we propose a universal method of digitized counterdiabatic driving, constructing the adiabatic gauge potential in a digital way with the idea of universal counterdiabatic driving. This method has three advantages over existing universal counterdiabatic driving and/or digitized counterdiabatic driving: it does not introduce any many-body and/or nonlocal interactions to an original target Hamiltonian; it can incorporate infinite nested commutators, which constitute the adiabatic gauge potential; and it gives explicit expression of rotation angles for digital implementation. We show the consistency of our method to the exact theory in an analytical way and the effectiveness of our method with the aid of numerical simulations.

</details>


### [27] [Semiclassical entanglement entropy for spin-field interaction](https://arxiv.org/abs/2601.15986)
*Matheus V. Scherer,Lea F. Santos,Alexandre D. Ribeiro*

Main category: quant-ph

TL;DR: Semiclassical framework for entanglement dynamics in spin-boson systems using complex classical trajectories


<details>
  <summary>Details</summary>
Motivation: Develop a semiclassical description of entanglement dynamics between spin and bosonic subsystems beyond the Ehrenfest time limit

Method: Use semiclassical approximations to derive entanglement entropy from classical trajectories, extend phase space to complex domain to include complex trajectories

Result: Complex trajectories significantly improve accuracy of semiclassical entanglement description, enabling precise capture of dynamics beyond Ehrenfest time

Conclusion: Analytic continuation to complex phase space provides powerful semiclassical framework for entanglement dynamics in bipartite quantum systems

Abstract: We study a general bipartite quantum system consisting of a spin interacting with a bosonic field, with the initial state prepared as the product of a spin coherent state and a canonical coherent state. Our goal is to develop a semiclassical framework to describe the entanglement dynamics between these two subsystems. Using appropriate approximations, we derive a semiclassical expression for the entanglement entropy that depends exclusively on the trajectories of the underlying classical description. By analytically extending the classical phase space into the complex domain, we identify additional complex trajectories that significantly improve the accuracy of the semiclassical description. The inclusion of these complex trajectories allows us to capture the entanglement dynamics with remarkable precision, even well beyond the Ehrenfest time. The approach is illustrated with a representative example, where the role of real and complex trajectories in reproducing the quantum entanglement entropy is explicitly demonstrated.

</details>


### [28] [Engineering quantum Mpemba effect by Liouvillian skin effect](https://arxiv.org/abs/2601.16002)
*Xiang Zhang Chen Sun,Fuxiang Li*

Main category: quant-ph

TL;DR: The paper proposes using the Liouvillian skin effect in open quantum systems to engineer the quantum Mpemba effect, revealing a new type of QME with two distance reversals and providing intuitive physical understanding.


<details>
  <summary>Details</summary>
Motivation: To develop a new approach for engineering the quantum Mpemba effect (where distant initial states relax faster than closer ones) using the Liouvillian skin effect as an ideal platform, and to provide more intuitive physical understanding of this phenomenon.

Method: Focus on quadratic Lindbladians in open quantum systems, use the Liouvillian skin effect as a platform, design initial states based on the spatial profile of LSE, and analyze two concrete cases to realize different types of QME.

Result: Successfully engineered QME using LSE, discovered a new type of QME (QME-III) characterized by two reversals in Hilbert-Schmidt distance at different times, and demonstrated that LSE provides physically intuitive understanding of the QME phenomenon.

Conclusion: The Liouvillian skin effect serves as an ideal platform for realizing and understanding the quantum Mpemba effect, enabling accessible experimental preparation and revealing novel QME types with distinctive temporal signatures.

Abstract: We propose a new approach to engineer the quantum Mpemba effect (QME) -- wherein an initial state farther from system relaxes faster than a close one -- by the Liouvillian skin effect (LSE) in open quantum systems. Moreover, the LSE serves as an ideal platform for realizing the QME and the spatial profile of the LSE provides a straightforward pathway for the initial state preparation, thereby enabling readily accessible experimental preparation. Focusing on the quadratic Lindbladians, we consider two concrete cases to design the initial states, thereby realizing the QME. Interestingly, we uncover a new kind of QME (QME-III) that is distinct from the two typical scenarios, manifested as two reversals in the Hilbert-Schmidt distance at two different times. In particular, the LSE provides a physically more intuitive understanding of the QME.

</details>


### [29] [Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware](https://arxiv.org/abs/2601.16004)
*Christopher Altman*

Main category: quant-ph

TL;DR: Experimental implementation of Violaris' circuit family on IBM quantum hardware to estimate operational inter-branch communication witnesses using Wigner's-friend-style circuits, demonstrating visibility and coherence metrics under realistic noise.


<details>
  <summary>Details</summary>
Motivation: To experimentally benchmark quantum circuits designed to estimate operational inter-branch communication witnesses (correlations in classical measurement records) on real quantum hardware, evaluating their behavior under realistic device noise and compilation constraints.

Method: Implemented a five-qubit instance of Violaris' protocol as an inter-register message-transfer pattern within a single circuit. The circuit encodes branch-conditioned evolution of an observer subsystem dependent on a control qubit, followed by controlled transfer operations to probe correlations between conditional measurement contexts. Executed on IBM's ibm_fez backend with 20000 shots.

Result: Observed population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and phase-sensitive magnitude of approximately 1.17. The visibility metric was insensitive to some dephasing classes, while coherence witnesses provided complementary sensitivity to off-diagonal noise.

Conclusion: The work establishes a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise, without testing quantum interpretations. Demonstrates practical benchmarking of communication witness circuits on noisy intermediate-scale quantum hardware.

Abstract: We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.
  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.
  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise.

</details>


### [30] [Echoed Random Quantum Metrology](https://arxiv.org/abs/2601.16026)
*Dong-Sheng Liu,Zi-Jie Chen,Ziyue Hua,Yilong Zhou,Qing-Xuan Jie,Weizhou Cai,Ming Li,Luyan Sun,Chang-Ling Zou,Xi-Feng Ren,Guang-Can Guo*

Main category: quant-ph

TL;DR: Random pulse-driven Kerr nonlinearity achieves Heisenberg-limited quantum metrology without requiring complex quantum control or exotic probe states.


<details>
  <summary>Details</summary>
Motivation: Traditional quantum metrology requires carefully prepared entangled/squeezed states and optimized quantum controls, which limits scalability and robustness. The authors aim to circumvent these limitations.

Method: Introduces an echoed random process using random pulses to drive a Kerr nonlinear mode, creating sub-Planck phase-space structures that enable high sensitivity without complex quantum control.

Result: Achieves sensitivity approaching the Heisenberg limit while remaining blind to random probe states. The protocol is statistically robust across broad parameter ranges and resilient to control fluctuations and photon loss.

Conclusion: Provides a practical, hardware-efficient, scalable, and optimization-free route to quantum-enhanced metrology applicable to both bosonic and qubit platforms in high-dimensional Hilbert spaces.

Abstract: Quantum metrology typically demands the preparation of exotic quantum probe states, such as entangled or squeezed states, to surpass classical limits. However, the need for carefully calibrated system parameters and finely optimized quantum controls imposes limitations on scalability and robustness. Here, we circumvent these limitations by introducing an echoed random process that achieves sensitivity approaching the Heisenberg limit while remaining blind to the random probe state. We demonstrate that by simply driving a Kerr nonlinear mode with random pulses, the emergence of sub-Planck phase-space structures grants high sensitivity, eliminating the need for complex quantum control. The protocol is statistically robust, yielding high performance across broad driving parameter ranges while exhibiting resilience to control fluctuations and photon loss. Broadly applicable to both bosonic and qubit platforms, our work reveals a practical, hardware-efficient, scalable, and optimization-free route to quantum-enhanced metrology in high-dimensional Hilbert spaces.

</details>


### [31] [Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals](https://arxiv.org/abs/2601.16081)
*Aishwarya Majumdar,Yuan Liu*

Main category: quant-ph

TL;DR: GQSPI framework for binary/multi-threshold detection of displacement parameter β using quantum signal processing interferometry with O(1/d log d) error probability.


<details>
  <summary>Details</summary>
Motivation: Address binary decision problem for determining if a displacement parameter β lies within asymmetric thresholds [β_{-th}, β_{+th}] in quantum sensing, extending to multi-threshold cases.

Method: Generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems, recasting active binary hypothesis testing as polynomial approximation problem.

Result: Achieves small decision error probability p_err ~ O(1/d log d) with circuit depth d; robust under dephasing noise; works for both deterministic β and random β with known prior; extends to multi-threshold cases.

Conclusion: Framework enables decision-making over arbitrary thresholds for general displacement signals in single/few shots, providing efficient quantum sensing protocol with theoretical guarantees.

Abstract: A relevant signal in the quantum domain may manifest as a displacement or a phase shift operator in the bosonic phase space. For a real parameter $β$ embedded in such a displacement operator, the task of determining if $β\in [β_{-th}, β_{+th}]$ for real asymmetric thresholds $(β_{-th} \ne -β_{+th})$ is a binary decision problem. We propose a framework based on generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems that addresses this parameter detection problem by recasting the practical task of active binary hypothesis testing on quantum systems to that of a polynomial approximation. We achieve a small decision error probability $p_{err}$ on the order of $O(\frac{1}{d}\log{(d)})$, with $d$ as the circuit depth. We analyze the protocol when (i) $β$ is a deterministic parameter, and (ii) when $β$ is drawn randomly from a known prior distribution. The performance of the sensing protocol under dephasing noise is also shown to be robust. We further extend our protocol from two thresholds to more general multi-threshold cases as well. Overall, the proposed framework enables decision-making over arbitrary thresholds for any general displacement signal in a single or a few shots.

</details>


### [32] [Quantum Metrology under Coarse-Grained Measurement](https://arxiv.org/abs/2601.16106)
*Byeong-Yoon Go,Geunhee Gwak,Young-Do Yoon,Sungho Lee,Nicolas Treps,Jiyong Park,Young-Sik Ra*

Main category: quant-ph

TL;DR: Quantum metrology with coarse-grained measurements: Even extremely coarse (2-bin) homodyne detection enables phase estimation beyond classical limits with Heisenberg scaling, demonstrated experimentally with 1.2-3.8 dB quantum enhancement.


<details>
  <summary>Details</summary>
Motivation: Quantum metrology offers precision beyond classical limits but is sensitive to experimental imperfections. While most prior work focused on imperfections in states and operations, this paper investigates the effect of coarse graining in quantum measurement - a practical limitation often overlooked in theoretical studies.

Method: Theoretical analysis and experimental demonstration using an interferometer with squeezed vacuum and laser input. Analyzed how coarse graining in homodyne detection affects phase estimation precision. Evaluated Fisher information under various coarse-graining conditions and determined optimal estimation strategies saturating the Cramér-Rao bound. Experimentally employed method of moments with calibration procedures for general experimental settings.

Result: Remarkably, even extremely coarse-grained measurement with only two bins enables phase estimation beyond the standard quantum limit and achieves Heisenberg scaling. Experimental demonstration showed quantum enhancement of 1.2 dB compared to classical method using ideal measurement with 2 bins, improving to 3.8 dB as bin number increases.

Conclusion: Coarse-grained measurements, even with severe limitations (just 2 bins), can still achieve quantum-enhanced metrology. This provides a practical pathway to realizing quantum advantages under realistic experimental imperfections, making quantum metrology more robust and applicable to real-world settings with limited measurement resolution.

Abstract: While quantum metrology enables measurement precision beyond classical limits, its performance is often susceptible to experimental imperfections. Most prior studies have focused on imperfections in quantum states and operations. Here, we investigate the effect of coarse graining in quantum measurement through both theoretical analysis and experimental demonstration. Using an interferometer with a squeezed vacuum and a laser input, we analyze how coarse graining in homodyne detection affects the precision of phase estimation. We evaluate the Fisher information under various coarse-graining conditions and determine, in each case, an optimal estimation strategy that saturates the Cramér-Rao bound. Remarkably, even extremely coarse-grained measurement -- with only two bins -- enables phase estimation beyond the standard quantum limit and even achieves a precision that follows the Heisenberg scaling. We experimentally demonstrate quantum-enhanced phase estimation under coarse-grained homodyne detection. To determine an optimal estimation strategy, we employ the method of moments and present calibration procedures that enable its application to general experimental settings. Using only two bins, we observe a quantum enhancement of 1.2 dB compared to the classical method using the ideal measurement, improving towards 3.8 dB as the bin number increases. These results highlight a practical pathway to achieving quantum enhancement under the presence of severe experimental imperfections.

</details>


### [33] [Experimental prime factorization via a feedback quantum control](https://arxiv.org/abs/2601.16116)
*Hari Krishnan KB,Vishal Varma,T. S. Mahesh*

Main category: quant-ph

TL;DR: Measurement-based feedback approach for quantum prime factorization that eliminates classical parameter computation, demonstrated experimentally on NMR quantum processor.


<details>
  <summary>Details</summary>
Motivation: Existing quantum factorization methods either require high-fidelity gates (Shor's algorithm) or substantial classical post-processing (Hamiltonian optimization methods). There's a need for an all-quantum approach that minimizes classical computation overhead.

Method: All-quantum, measurement-based feedback approach that iteratively steers a quantum system toward target ground state. Problem Hamiltonian encodes prime factors as degenerate ground states. Method eliminates need for classical computation of drive parameters once Hamiltonian is realized. Uses measurement feedback to guide evolution.

Result: Experimentally factored biprime 551 using three-qubit NMR quantum register. Numerically demonstrated robustness against control field errors. Scaled method to factor larger biprimes: 9,167 (5 qubits) and 2,106,287 (9 qubits) using FALQON factorization approach.

Conclusion: Proposed measurement-based feedback approach provides a practical alternative to existing quantum factorization methods, eliminating classical parameter computation while demonstrating experimental feasibility and scalability to larger problems.

Abstract: Prime factorization on quantum processors is typically implemented either via circuit-based approaches such as Shor's algorithm or through Hamiltonian optimization methods based on adiabatic, annealing, or variational techniques. While Shor's algorithm demands high-fidelity quantum gates, Hamiltonian optimization schemes, with prime factors encoded as degenerate ground states of a problem Hamiltonian, generally require substantial classical post-processing to determine control parameters. We propose an all-quantum, measurement-based feedback approach that iteratively steers a quantum system toward the target ground state, eliminating the need for classical computation of drive parameters once the problem Hamiltonian is determined and realized. As a proof of principle, we experimentally factor the biprime 551 using a three-qubit NMR quantum register and numerically analyze the robustness of the method against control field-errors. We further demonstrate scalability by numerically implementing the FALQON factorization of larger biprimes, 9,167 and 2,106,287, using 5 and 9 qubits, respectively.

</details>


### [34] [Exceptional points in Gaussian channels: diffusion gauging and drift-governed spectrum](https://arxiv.org/abs/2601.16121)
*Frank Ernesto Quintela Rodríguez*

Main category: quant-ph

TL;DR: The paper establishes a noise-independence principle for Gaussian quantum systems, showing that Liouvillian spectra and non-diagonalizability are determined solely by drift, while diffusion affects only steady states and eigenoperator structure.


<details>
  <summary>Details</summary>
Motivation: To extend and formalize the noise-independence principle discovered by McDonald and Clerk for linear open quantum systems, specifically for Gaussian Markov semigroups and channels, demonstrating that spectral properties are independent of noise strength.

Method: Develops Gaussian similarity transformations that gauge away diffusion: continuous-time approach for multimode bosonic Gaussian Markov semigroups using Lyapunov equations, and discrete-time approach for general stable multimode bosonic Gaussian channels via explicit channel parametrization transformations.

Result: Shows that eigenvalues and non-diagonalizability are controlled entirely by drift, while diffusion determines steady states and eigenoperator structure; provides explicit constructions for gauging transformations; demonstrates with single-mode squeezed-reservoir Lindbladian and non-Markovian Gaussian channels.

Conclusion: Establishes a fundamental separation principle for Gaussian quantum dynamics where drift governs spectral properties and non-diagonalizability, while diffusion affects only stationary properties and eigenoperator structure, unifying continuous and discrete-time formulations.

Abstract: McDonald and Clerk [Phys.\ Rev.\ Research 5, 033107 (2023)] showed that for linear open quantum systems the Liouvillian spectrum is independent of the noise strength. We first make this noise-independence principle precise in continuous time for multimode bosonic Gaussian Markov semigroups: for Hurwitz drift, a time-independent Gaussian similarity fixed by the Lyapunov equation gauges away diffusion for all times, so eigenvalues and non-diagonalizability are controlled entirely by the drift, while diffusion determines steady states and the structure of eigenoperators. We then extend the same separation to discrete time for general stable multimode bosonic Gaussian channels: for any stable Gaussian channel, we construct an explicit Gaussian similarity transformation that gauges away diffusion at the level of the channel parametrization. We illustrate the method with a single-mode squeezed-reservoir Lindbladian and with a non-Markovian family of single-mode Gaussian channels, where the exceptional-point manifolds and the associated gauging covariances can be obtained analytically.

</details>


### [35] [Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments](https://arxiv.org/abs/2601.16123)
*Samuel Stein,Shuwen Kan,Chenxu Liu,Adrian Harkness,Sean Garner,Zefan Du,Yufei Ding,Ying Mao,Ang Li*

Main category: quant-ph

TL;DR: Hardware-conditioned neural decoder for quantum error correction achieves adaptive performance with negligible latency by exploiting timescale separation between slow calibration drifts and fast decoding needs.


<details>
  <summary>Details</summary>
Motivation: Real-time quantum error correction decoding requires high accuracy, low latency, and robustness to hardware noise variations. Current decoders struggle with adapting to calibration drifts in superconducting processors where calibration changes occur over hours while decoding must respond in microseconds.

Method: Introduces a hardware-conditioned neural decoder framework with graph-based encoder for calibration data and lightweight convolutional backbone conditioned via feature-wise linear modulation (FiLM). This decouples heavy device statistics processing from low-latency syndrome decoding, exploiting the natural timescale separation in superconducting quantum processors.

Result: Evaluated on IBM quantum processors (Fez, Kingston, Pittsburgh) using 1D repetition code with over 2.7 million experimental shots up to distance d=11. Single trained model generalizes to unseen qubit chains and new calibration data days later without retraining, achieving up to 11.1x reduction in logical error rate compared to modified minimum-weight perfect matching.

Conclusion: Hardware-conditioned neural decoding demonstrates promising adaptive performance with negligible latency overhead by exploiting the asynchronous nature of system calibration and decoding, enabling practical real-time quantum error correction for fault-tolerant quantum computation.

Abstract: Real-time decoding of quantum error correction (QEC) is essential for enabling fault-tolerant quantum computation. A practical decoder must operate with high accuracy at low latency, while remaining robust to spatial and temporal variations in hardware noise. We introduce a hardware-conditioned neural decoder framework designed to exploit the natural separation of timescales in superconducting processors, where calibration drifts occur over hours while error correction requires microsecond-scale responses. By processing calibration data through a graph-based encoder and conditioning a lightweight convolutional backbone via feature-wise linear modulation (FiLM), we decouple the heavy processing of device statistics from the low-latency syndrome decoding.
  We evaluate this approach using the 1D repetition code as a testbed on IBM Fez, Kingston, and Pittsburgh processors, collecting over 2.7 million experimental shots spanning distances up to d = 11. We demonstrate that a single trained model generalizes to unseen qubit chains and new calibration data acquired days later without retraining. On these unseen experiments, the FiLM-conditioned decoder achieves up to an 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching. We observe that by employing a network architecture that exploits the highly asynchronous nature of system calibration and decoding, hardware-conditioned neural decoding demonstrates promising, adaptive performance with negligible latency overhead relative to unconditioned baselines.

</details>


### [36] [Quantum Dimension Reduction of Hidden Markov Models](https://arxiv.org/abs/2601.16126)
*Rishi Sundar,Thomas Elliott*

Main category: quant-ph

TL;DR: Quantum HMM compression pipeline enables dimension reduction for any finite ergodic HMM, outperforming classical methods in memory-accuracy trade-offs.


<details>
  <summary>Details</summary>
Motivation: Classical HMMs are widely used but often large and high-dimensional. Quantum HMMs (QHMMs) are more expressive but existing compression methods based on tensor networks only work for deterministic transition HMMs, limiting applicability.

Method: Developed a pipeline that can compress any finite, ergodic HMM using quantum dimension reduction techniques, extending beyond the deterministic transition restriction of previous tensor network approaches.

Result: Demonstrated favorable memory-accuracy trade-offs compared to classical compression approaches on both a toy model and a speech-derived HMM trained from real data.

Conclusion: The proposed pipeline enables effective quantum dimension reduction for general HMMs, overcoming previous limitations and providing practical advantages over classical compression methods.

Abstract: Hidden Markov models (HMMs) are ubiquitous in time-series modelling, with applications ranging from chemical reaction modelling to speech recognition. These HMMs are often large, with high-dimensional memories. A recently-proposed application of quantum technologies is to execute quantum analogues of HMMs. Such quantum HMMs (QHMMs) are strictly more expressive than their classical counterparts, enabling the construction of more parsimonious models of stochastic processes. However, state-of-the-art techniques for QHMM compression, based on tensor networks, are only applicable for a restricted subset of HMMs, where the transitions are deterministic. In this work we introduce a pipeline by which \emph{any} finite, ergodic HMM can be compressed in this manner, providing a route for effective quantum dimension reduction of general HMMs. We demonstrate the method on both a simple toy model, and on a speech-derived HMM trained from data, obtaining favourable memory--accuracy trade-offs compared to classical compression approaches.

</details>


### [37] [Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory](https://arxiv.org/abs/2601.16144)
*Tetsuro Abe,Shu Tanaka*

Main category: quant-ph

TL;DR: SBO-QAOA addresses bias in degenerate ground state sampling by using temperature-dependent Hamiltonian encoding Gibbs distribution, achieving fair sampling and temperature-targeting with minimal parameters.


<details>
  <summary>Details</summary>
Motivation: Standard QAOA with transverse-field mixer introduces biases among degenerate ground states as circuit depth increases, compromising fair sampling essential for combinatorial optimization problems with degenerate solutions.

Method: SBO-QAOA employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state, based on quantum-classical correspondence theory. Uses only four variational parameters under a linear schedule.

Result: Numerical simulations show SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states, unlike standard QAOA. Fairness and temperature-targeting properties preserved with minimal parameters.

Conclusion: SBO-QAOA provides an effective solution for fair sampling in degenerate combinatorial optimization problems, maintaining temperature-targeting capabilities with parameter-efficient implementation.

Abstract: In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule.

</details>


### [38] [Polynomial-time thermalization and Gibbs sampling from system-bath couplings](https://arxiv.org/abs/2601.16154)
*Samuel Slezak,Matteo Scandi,Álvaro M. Alhambra,Daniel Stilck França,Cambyse Rouzé*

Main category: quant-ph

TL;DR: The paper proves polynomial-time convergence for two families of Lindblad processes modeling quantum Gibbs sampling and open many-body thermalization in non-commuting systems.


<details>
  <summary>Details</summary>
Motivation: Understanding convergence speed of Lindbladians is crucial for bounding algorithmic runtimes and thermalization timescales in quantum systems weakly coupled to baths.

Method: The authors study two families of Lindblad processes: repeated-interaction Gibbs sampling algorithm and open many-body quantum thermalization models. They develop a novel technical approach that extrapolates spectral gap lower bounds from quasi-local Lindbladians to non-local generators.

Result: Proved polynomial-time convergence for both processes in several non-commuting systems including high-temperature local lattices, weakly interacting fermions, and 1D spin chains.

Conclusion: Simple dissipative quantum algorithms can prepare complex Gibbs states efficiently, and Lindblad dynamics accurately capture thermal relaxation in these systems.

Abstract: Many physical phenomena, including thermalization in open quantum systems and quantum Gibbs sampling, are modeled by Lindbladians approximating a system weakly coupled to a bath. Understanding the convergence speed of these Lindbladians to their steady states is crucial for bounding algorithmic runtimes and thermalization timescales. We study two such families of processes: one characterizing a repeated-interaction Gibbs sampling algorithm, and another modeling open many-body quantum thermalization. We prove that both converge in polynomial time for several non-commuting systems, including high-temperature local lattices, weakly interacting fermions, and 1D spin chains. These results demonstrate that simple dissipative quantum algorithms can prepare complex Gibbs states and that Lindblad dynamics accurately capture thermal relaxation. Our proofs rely on a novel technical result that extrapolates spectral gap lower bounds from quasi-local Lindbladians to the non-local generators governing these dynamics.

</details>


### [39] [Stabilizer Thermal Eigenstates at Infinite Temperature](https://arxiv.org/abs/2601.16177)
*Akihiro Hokkyo*

Main category: quant-ph

TL;DR: Stabilizer-based approach for constructing analytically tractable energy eigenstates of nonintegrable Hamiltonians, with a no-go theorem showing stabilizer eigenstates of two-body Hamiltonians cannot satisfy k-body microscopic thermal equilibrium for k≥4, and tightness demonstrated through explicit constructions.


<details>
  <summary>Details</summary>
Motivation: Understanding how to analyze highly entangled thermal eigenstates is a central challenge in quantum many-body systems, requiring new approaches to construct analytically tractable eigenstates of nonintegrable Hamiltonians.

Method: Introduces a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians, focusing on zero-energy eigenstates at infinite temperature, proving a sharp no-go theorem about limitations of stabilizer eigenstates.

Result: Proves a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy k-body microscopic thermal equilibrium for any k≥4. Shows this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables.

Conclusion: Reveals a fundamental constraint imposed by the few-body nature of interactions on stabilizer states appearing as zero-energy eigenstates of Hamiltonians, identifying the structural origin of limitations in achieving microscopic thermal equilibrium beyond three-body observables.

Abstract: Understanding how to analyze highly entangled thermal eigenstates is a central challenge in the study of quantum many-body systems. In this Letter, we introduce a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians. Focusing on zero-energy eigenstates at infinite temperature, we prove a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy $k$-body microscopic thermal equilibrium for any $k\ge4$. We further show that this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables. Finally, we identify the structural origin of this limitation by characterizing the conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian, thereby revealing a fundamental constraint imposed by the few-body nature of interactions.

</details>


### [40] [Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States](https://arxiv.org/abs/2601.16189)
*Xiaotian Yang,Santiago Zamora,Rafael Chaves,Ulrik L. Andersen,Jonatan Bohr Brask,A. de Oliveira Junior*

Main category: quant-ph

TL;DR: GKP encoding enables homodyne-based Bell tests in CV systems: bipartite CHSH violation impossible for Bell pairs, but multipartite nonlocality achievable with finitely squeezed GKP-encoded GHZ/W states.


<details>
  <summary>Details</summary>
Motivation: Homodyne detection in continuous-variable systems faces strong constraints for Bell tests. The paper investigates whether Gottesman-Kitaev-Preskill (GKP) encoding can transform homodyne detection into a practical tool for revealing Bell nonlocality in CV systems.

Method: The authors consider a physically motivated model where each party performs homodyne detection and digitizes continuous outcomes via fixed periodic binning (corresponding to logical Pauli measurements). They analyze bipartite and multipartite scenarios, deriving no-go theorems and quantifying squeezing thresholds.

Result: 1. Bipartite no-go: CHSH inequality cannot be violated for Bell-pair states with homodyne-only readout. 2. Multipartite success: Finitely squeezed GKP-encoded GHZ and W states exhibit strong multipartite nonlocality, violating multipartite Bell inequalities. 3. Quantified squeezing thresholds and robustness to loss are provided.

Conclusion: GKP encoding enables homodyne-based Bell tests in continuous-variable systems, particularly for multipartite scenarios where finitely squeezed GKP-encoded states can demonstrate nonlocality, providing a practical route for Bell tests in CV quantum information processing.

Abstract: Bell tests based on homodyne detection are strongly constrained in continuous-variable systems. Can Gottesman-Kitaev-Preskill (GKP) encoding turn homodyne detection into a practical tool for revealing Bell nonlocality? We consider a physically motivated model in which each party performs homodyne detection and digitizes the continuous outcome via a fixed periodic binning, corresponding to logical Pauli measurements. Within this framework, we derive a bipartite no-go: CHSH cannot be violated for Bell-pair states. Moving beyond two parties, we show that finitely squeezed GKP-encoded GHZ and W states nevertheless exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. We quantify the required squeezing thresholds and robustness to loss, providing a route toward homodyne-based Bell tests in continuous-variable systems.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [41] [Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks](https://arxiv.org/abs/2601.15340)
*Fabiana Taglietti,Andrea Pulici,Maxwell Roxburgh,Gabriele Seguini,Ian Vidamour,Stephan Menzel,Edoardo Franco,Michele Laus,Eleni Vasilaki,Michele Perego,Thomas J. Hayward,Marco Fanciulli,Jack C. Gartside*

Main category: cond-mat.dis-nn

TL;DR: Physical KANs (Kolmogorov-Arnold Networks) trained on nonlinear synaptic elements outperform linear weight-based networks with far fewer parameters/devices, demonstrated experimentally in silicon devices.


<details>
  <summary>Details</summary>
Motivation: Physical neural networks typically train only linear synaptic weights while treating device nonlinearities as fixed. The authors propose to instead train the synaptic nonlinearity itself to exploit reconfigurable nonlinear physical dynamics for more efficient computation.

Method: Implemented physical KANs using silicon-on-insulator devices called 'Synaptic Nonlinear Elements' (SYNEs) that operate at room temperature with 0.1-1 μA currents and 2 MHz speeds. Demonstrated nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from real-world sensor data.

Result: Physical KANs outperformed equivalently-parameterized software multilayer perceptron networks across all tasks, with up to 100× fewer parameters and 100× fewer devices than linear weight-based physical networks. Devices showed no degradation over 10^13 measurements and months-long operation.

Conclusion: Learned physical nonlinearity serves as a hardware-native computational primitive for compact and efficient learning systems, with SYNE devices providing effective substrates for heterogeneous nonlinear computing.

Abstract: Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.
  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.
  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing.

</details>


### [42] [Non-zero Momentum Implies Long-Range Entanglement When Translation Symmetry is Broken in 1D](https://arxiv.org/abs/2601.15345)
*Amanda Gatto Lamas,Taylor L. Hughes*

Main category: cond-mat.dis-nn

TL;DR: The paper extends Gioia and Wang's result linking momentum to long-range entanglement from translation-symmetric to non-translation-symmetric 1D systems, showing that the expectation value of the translation operator |⟨T⟩| approaches 1 for delocalized states, serving as a momentum-space analog to Resta's formula for localization length.


<details>
  <summary>Details</summary>
Motivation: To determine whether momentum can encode entanglement nature for non-translation-symmetric states, as it does for translation-symmetric states per Gioia and Wang's result. The practical challenge is that finding finite-depth quantum circuits connecting states to translation-symmetric ones is often impractical for translation-symmetry-broken states.

Method: Focus on many-body momentum distribution and expectation value of translation operator ⟨T⟩ in broken-translation-symmetry systems. Show that in continuum limit, |⟨T⟩| → 1 for delocalized states (proxy for LRE in 1D). Introduce two lattice models: deterministic random dimer model (illustrates thermodynamic/continuum limits) and simplified Aubry-André model (commensurate hopping in momentum/position space). Use random dimer model to test |⟨T⟩| as localization/entanglement probe for 1D periodic lattice models without well-defined continuum limit.

Result: Affirmative answer for 1D systems: momentum can encode entanglement nature for non-translation-symmetric states. |⟨T⟩| → 1 for delocalized states in continuum limit, serving as momentum-space version of Resta's localization length formula. Higher-dimensional extensions and topologically ordered systems require further investigation. Models demonstrate accuracy of |⟨T⟩| as localization/entanglement probe.

Conclusion: Momentum expectation value |⟨T⟩| provides practical probe for entanglement nature in 1D non-translation-symmetric systems, extending Gioia and Wang's result. The approach offers momentum-space analog to Resta's formula and works for lattice models with/without continuum limits, though higher-dimensional and topological generalizations need further work.

Abstract: A result by Gioia and Wang [Phys Rev X 12, 031007 (2022)] showed that translationally symmetric states having nonzero momentum are necessarily long range entangled (LRE). Here, we consider the question: can a notion of momentum for non-translation symmetric states directly encode the nature of their entanglement, as it does for translation symmetric states? We show the answer is affirmative for 1D systems, while higher dimensional extensions and topologically ordered systems require further work. While Gioia and Wang's result applies to states connected via finite depth quantum circuits to a translation symmetric state, it is often impractical to find such a circuit to determine the nature of the entanglement of states that break translation symmetry. Here, instead of translation eigenstates, we focus on the many-body momentum distribution and the expectation value of the translation operator in many-body states of systems having broken translation symmetry. We show that in the continuum limit the magnitude of the expectation value of the translation operator $|<T>|$ necessarily goes to $1$ for delocalized states, a proxy for LRE states in 1D systems. This result can be seen as a momentum-space version of Resta's formula for the localization length. We investigate how accurate our results are in different lattice models with and without well-defined continuum limits. To that end, we introduce two models: a deterministic version of the random dimer model, illustrating the role of the thermodynamic and continuum limits for our result at a lattice level, and a simplified version of the Aubry-Andre model, with commensurate hopping for both momentum and position space. Finally, we use the random dimer model as a test case for the accuracy of $|<T>|$ as a localization (and thus entanglement) probe for 1D periodic lattice models without a well-defined continuum limit.

</details>


### [43] [Structural constraints on mobility edges in one-dimensional quasiperiodic systems](https://arxiv.org/abs/2601.15799)
*Sanghoon Lee,Tilen Cadez,Kyoung-Min Kim*

Main category: cond-mat.dis-nn

TL;DR: Mobility edge positions in quasiperiodic systems are structurally constrained across isospectral dual Hamiltonians, leading to reduced possible energies for mobility edges and linear critical scaling near self-dual points.


<details>
  <summary>Details</summary>
Motivation: To understand why mobility edge positions are not independent spectral features but are structurally constrained across quasiperiodic Hamiltonians related by isospectral duality, moving beyond individual Hamiltonian analysis.

Method: Use bichromatic Aubry-André model as minimal setting; derive exact identity for Lyapunov exponents from Thouless formula; analyze structural constraints on mobility edge positions; examine critical scaling near self-dual point.

Result: Mobility edge positions are restricted to reduced set of energies; in self-dual limit they coincide at single localization-delocalization transition; structural constraint enforces linear critical scaling of physical Lyapunov spectrum near self-dual point; numerical results confirm critical exponent ν=1 with novel non-universal energy-dependent prefactor.

Conclusion: Mobility edges in quasiperiodic systems are structurally constrained by isospectral duality, leading to universal critical behavior with standard exponent but energy-dependent prefactors, revealing deeper connections between duality and localization physics.

Abstract: Mobility edges commonly arise in one-dimensional quasiperiodic systems once exact self-duality is broken, yet their origin is typically understood only at the level of individual Hamiltonians. Here we show that mobility edge positions are not independent spectral features of individual Hamiltonians, but are structurally constrained across quasiperiodic Hamiltonians related by an isospectral duality. Using a bichromatic Aubry--André model as a minimal setting, we demonstrate that this constraint is encoded in an exact identity for Lyapunov exponents derived from the Thouless formula. As a consequence, the mobility edge positions are restricted to a reduced set of energies. In the self-dual limit, these mobility edge positions coincide at a single localization--delocalization transition. This structural constraint enforces a linear critical scaling of the physical Lyapunov spectrum near the self-dual point. Numerical results confirm a critical exponent consistent with the standard Aubry--André value of $ν= 1$, while simultaneously revealing a novel, non-universal energy-dependent prefactor.

</details>
