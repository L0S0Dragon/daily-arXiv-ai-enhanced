<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 27]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [Dynamical entanglement percolation with spatially correlated disorder](https://arxiv.org/abs/2601.05925)
*Lorenzo Cirigliano,Valentina Brosco,Claudio Castellano,Simone Felicetti,Laura Pilozzi,Bernard van Heck*

Main category: quant-ph

TL;DR: The paper studies entanglement dynamics in quantum networks with independent two-qubit interactions, revealing non-standard percolation phenomena with hysteresis due to unitary evolution and spatially correlated disorder.


<details>
  <summary>Details</summary>
Motivation: Understanding how entanglement spreads dynamically across quantum networks is fundamental for quantum information applications, particularly when networks involve independent two-qubit interactions between nodes.

Method: The authors apply percolation theory tools to analyze entanglement dynamics in qubit networks with independent two-qubit interactions. They develop a two-colour correlated bond percolation model, using numerical simulations and mean-field theory to determine the phase diagram.

Result: The interplay between unitary evolution and spatially correlated disorder leads to non-standard percolation phenomenology that is significantly richer than uniform bond percolation and features hysteresis. The two-colour correlated bond percolation model successfully elucidates the underlying physics.

Conclusion: Entanglement spreading in quantum networks with independent two-qubit interactions exhibits complex percolation behavior with hysteresis, which can be understood through a correlated bond percolation framework combining numerical and analytical approaches.

Abstract: The distribution of entanglement between the nodes of a quantum network plays a fundamental role in quantum information applications. In this work, we investigate the dynamics of a network of qubits where each edge corresponds to an independent two-qubit interaction. By applying tools from percolation theory, we study how entanglement dynamically spreads across the network. We show that the interplay between unitary evolution and spatially correlated disorder leads to a non-standard percolation phenomenology, significantly richer than uniform bond percolation and featuring hysteresis. A two-colour correlated bond percolation model, whose phase diagram is determined via numerical simulations and a mean-field theory, fully elucidates the physics behind this phenomenon.

</details>


### [2] [Investigation of Hardware Architecture Effects on Quantum Algorithm Performance: A Comparative Hardware Study](https://arxiv.org/abs/2601.05286)
*Askar Oralkhan,Temirlan Zhaxalykov*

Main category: quant-ph

TL;DR: Systematic benchmarking of five quantum algorithms across different quantum hardware platforms reveals significant performance variations due to architectural differences, highlighting the need for hardware-aware algorithm selection in the NISQ era.


<details>
  <summary>Details</summary>
Motivation: Quantum circuits exhibit substantially different behavior across devices due to architectural variations in qubit connectivity, gate fidelity, and coherence times, necessitating systematic benchmarking to understand hardware-algorithm interactions.

Method: Benchmarked five representative quantum algorithms (Bell state preparation, GHZ state generation, Quantum Fourier Transform, Grover's Search, QAOA) across trapped-ion, superconducting, and simulator backends using Amazon Braket, evaluating performance metrics including fidelity, CHSH violation, success probability, circuit depth, and gate counts.

Result: Strong dependence of algorithmic performance on hardware topology and noise characteristics; 10-qubit GHZ states achieved fidelities above 0.8 on trapped-ion hardware but dropped below 0.15 on superconducting platforms due to routing overhead and accumulated two-qubit gate errors.

Conclusion: Hardware-aware algorithm selection is crucial for quantum computing in the NISQ era, and systematic benchmarking provides practical guidance for algorithm deployment across heterogeneous quantum platforms.

Abstract: Cloud-accessible quantum processors enable direct execution of quantum algorithms on heterogeneous hardware platforms. Unlike classical systems, however, identical quantum circuits may exhibit substantially different behavior across devices due to architectural variations in qubit connectivity, gate fidelity, and coherence times.
  In this work, we systematically benchmark five representative quantum algorithms - Bell state preparation, GHZ state generation, Quantum Fourier Transform (QFT), Grover's Search, and the Quantum Approximate Optimization Algorithm (QAOA) - across trapped-ion, superconducting, and simulator backends using Amazon Braket. Performance metrics including fidelity, CHSH violation, success probability, circuit depth, and gate counts are evaluated.
  Our results demonstrate a strong dependence of algorithmic performance on hardware topology and noise characteristics. For example, 10-qubit GHZ states achieved fidelities above 0.8 on trapped-ion hardware, while superconducting platforms dropped below 0.15 due to routing overhead and accumulated two-qubit gate errors. These findings highlight the importance of hardware-aware algorithm selection and provide practical guidance for benchmarking in the NISQ era.

</details>


### [3] [Temporal Kirkwood-Dirac Quasiprobability Distribution and Unification of Temporal State Formalisms through Temporal Bloch Tomography](https://arxiv.org/abs/2601.05294)
*Zhian Jia,Kavan Modi,Dagomir Kaszlikowski*

Main category: quant-ph

TL;DR: The paper extends Kirkwood-Dirac quasiprobability distributions to multi-time quantum processes and spatiotemporal settings, providing a unified operational foundation for temporal state formalisms.


<details>
  <summary>Details</summary>
Motivation: To clarify the operational relationships and conceptual distinctions between various temporal state formalisms, which remain unclear despite growing theoretical developments.

Method: Extends Kirkwood-Dirac quasiprobability distributions to arbitrary multi-time quantum processes and general spatiotemporal settings, defining left, right, and doubled temporal KD quasiprobabilities along with their real components (temporal Margenau-Hill quasiprobabilities).

Result: Shows that these generalized KD quasiprobabilities are experimentally accessible through interferometric measurement schemes and can characterize nonclassical features, providing a unified operational foundation for temporal state approaches.

Conclusion: The generalized KD framework unifies various temporal state formalisms and can be directly implemented via temporal or spatiotemporal Bloch tomography.

Abstract: Temporal quantum states generalize the multipartite density operator formalism to the time domain, enabling a unified treatment of quantum systems with both timelike and spacelike correlations. Despite a growing body of temporal state formalisms, their precise operational relationships and conceptual distinctions remain unclear. In this work, we resolve this issue by extending the Kirkwood-Dirac (KD) quasiprobability distribution to arbitrary multi-time quantum processes and, more broadly, to general spatiotemporal settings. We define left, right, and doubled temporal KD quasiprobabilities, together with their real components, which we identify as temporal Margenau-Hill (MH) quasiprobabilities. All of these quantities are experimentally accessible through interferometric measurement schemes. By characterizing their nonclassical features, we show that the generalized KD framework provides a unified operational foundation for a wide class of temporal state approaches and can be directly implemented via temporal or spatiotemporal Bloch tomography.

</details>


### [4] [Fundamental Limitations on the Reliabilities of Power and Work in Quantum Batteries](https://arxiv.org/abs/2601.05315)
*Brij Mohan,Tanmoy Pandit,Maciej Lewenstein,Manabendra Nath Bera*

Main category: quant-ph

TL;DR: Quantum batteries face fundamental reliability limits: work and power fluctuations cannot be simultaneously suppressed due to quantum uncertainty, creating a trade-off between power and reliability that favors hybrid charging schemes.


<details>
  <summary>Details</summary>
Motivation: Quantum batteries promise high power for quantum technologies, but their practical usefulness depends on reliability quantified by noise-to-signal ratios (NSRs). Understanding fundamental limits to reliability is crucial for designing practical quantum batteries.

Method: Established universal lower bounds for work and power NSRs as functions of charging speed. Analyzed quantum mechanical uncertainty relation that forbids simultaneous suppression of work and power fluctuations. Examined scaling behavior across parallel (local), collective (fully non-local), and hybrid (semi-local) charging schemes for many-body quantum batteries, including transverse Ising-like interactions.

Result: Found fundamental trade-off: increasing power through stronger entanglement comes at the cost of diminished power reliability. Hybrid charging schemes with intermediate-range interactions offer the best balance between high power and reliability, outperforming both purely parallel and collective charging approaches.

Conclusion: Achieving both high power and reliability in quantum batteries requires neither purely parallel nor collective charging, but hybrid charging schemes with intermediate interaction ranges. This analysis provides practical guidelines for designing efficient and reliable quantum batteries.

Abstract: Quantum batteries, microscopic devices designed to address energy demands in quantum technologies, promise high power during charging and discharging processes. Yet their practical usefulness and performance depend critically on reliability, quantified by the noise-to-signal ratios (NSRs), i.e., normalized fluctuations of work and power, where reliability decreases inversely with increasing NSR. We establish fundamental limits to this reliability: both work and power NSRs are universally bounded from below by a function of charging speed, imposing a reliability limit inherent to any quantum battery. More strikingly, we find that a quantum mechanical uncertainty relation forbids the simultaneous suppression of work and power fluctuations, revealing a fundamental trade-off that also limits the reliability of quantum batteries. We analyze the trade-off and limits, as well as their scaling behavior, across parallel (local), collective {(fully non-local)}, and hybrid (semi-local) charging schemes for many-body quantum batteries, finding that increasing power by exploiting stronger entanglement comes at the cost of diminished reliability of power. Similar trends are also observed in the charging of quantum batteries utilizing transverse Ising-like interactions. These suggest that achieving both high power and reliability require neither parallel nor collective charging, but a hybrid charging scheme with an intermediate range of interactions. Therefore, our analysis shapes the practical and efficient design of reliable and high-performance quantum batteries.

</details>


### [5] [From compatibility of measurements to exploring Quantum Darwinism on NISQ](https://arxiv.org/abs/2601.05350)
*Emery Doucet,Sebastian Deffner*

Main category: quant-ph

TL;DR: Quantum Darwinism framework explains emergence of classical reality from quantum systems; breaking of this framework leads to non-classical statistics that can benchmark quantum characteristics of NISQ hardware.


<details>
  <summary>Details</summary>
Motivation: To understand how breaking of Quantum Darwinism translates to non-classical measurement statistics and to develop effective benchmarking tools for assessing genuine quantum characteristics of NISQ (Noisy Intermediate-Scale Quantum) hardware.

Method: Study the breaking of Quantum Darwinism in a specific model, analyze how this translates to non-classical measurement statistics, and apply these insights to benchmark quantum characteristics using IonQ's trapped-ion and IBM's superconducting quantum computing platforms.

Result: The breaking of Quantum Darwinism provides effective tools for benchmarking genuine quantum characteristics of NISQ hardware, demonstrated through experimental implementation on IonQ's trapped-ion and IBM's superconducting quantum computing platforms.

Conclusion: The framework connecting Quantum Darwinism breaking to non-classical statistics offers practical benchmarking methods for assessing quantum hardware performance, bridging theoretical quantum foundations with experimental quantum computing applications.

Abstract: Quantum Darwinism explains how tenets of classical reality, such as objectivity and repeatability, emerge within a quantum universe. As a mathematical framework, Quantum Darwinism also provides guiding principles that determine what physical models support emergent classical behavior, what specific observables obey classical laws, and much more. For instance, in a recent work we elucidated that the limit under which Kirkwood-Dirac quasiprobability distributions become effectively classical coincides with the regime where the underlying physical model obeys the rules of Quantum Darwinism. In the present work, we study the breaking of Quantum Darwinism in a specific model and how that translates to non-classical measurement statistics. Interestingly, this provides effective tools for benchmarking the genuine quantum characteristics of NISQ hardware, which we demonstrate with IonQ's trapped-ion and IBM's superconducting quantum computing platforms.

</details>


### [6] [Analytical Solutions to Asymmetric Two-Photon Rabi Model](https://arxiv.org/abs/2601.05421)
*M. Baradaran,L. M. Nieto,S. Zarrinkamar*

Main category: quant-ph

TL;DR: Generalized Rabi model with two-photon and asymmetric terms solved via Segal-Bargmann representation and Bethe ansatz, yielding nearly exact analytical solutions for fourth-order problem.


<details>
  <summary>Details</summary>
Motivation: To solve the generalized Rabi model that includes both two-photon and asymmetric terms, which extends beyond the standard Rabi model and presents analytical challenges.

Method: Use Segal-Bargmann representation to transform the problem, then apply Bethe ansatz approach to analyze the meromorphic structure of the resulting differential equation.

Result: Obtained nearly exact solutions in exact analytical form for the fourth-order problem, both for arbitrary states and for parameter restrictions.

Conclusion: The Bethe ansatz approach combined with Segal-Bargmann representation provides an effective method for obtaining analytical solutions to the generalized Rabi model with two-photon and asymmetric interactions.

Abstract: Within the Segal-Bargmann representation, a generalized Rabi model is considered that includes both two-photon and asymmetric terms. It is shown that, through a suitable transformation, nearly exact solutions can be obtained using the Bethe ansatz approach. Applying this approach to the meromorphic structure of the resulting differential equation, solutions in exact analytical form of the fourth-order problem are presented for both an arbitrary state and for the restriction between the parameters.

</details>


### [7] [Achieving the Heisenberg limit using fault-tolerant quantum error correction](https://arxiv.org/abs/2601.05457)
*Himanshu Sahu,Qian Xu,Sisi Zhou*

Main category: quant-ph

TL;DR: Fault-tolerant quantum metrology protocol using repetition codes achieves Heisenberg limit under realistic noise affecting all operations, including state preparation and measurement.


<details>
  <summary>Details</summary>
Motivation: Previous quantum metrology protocols with QEC assume noise only affects signal accumulation, while QEC operations (state prep, measurement) are noiseless. This is unrealistic for practical implementations.

Method: Propose fault-tolerant metrological protocol using repetition code prepared via repeated syndrome measurements, followed by fault-tolerant logical measurement. Study Pauli-Z signal estimation under bit-flip noise with state preparation and measurement errors in all QEC operations.

Result: Demonstrate existence of error threshold below which errors are effectively suppressed and the Heisenberg limit is attained, even with noise affecting all operations.

Conclusion: Fault-tolerant quantum metrology can achieve the ultimate Heisenberg limit under realistic noise conditions affecting all qubit operations, overcoming limitations of previous idealized protocols.

Abstract: Quantum effect enables enhanced estimation precision in metrology, with the Heisenberg limit (HL) representing the ultimate limit allowed by quantum mechanics. Although the HL is generally unattainable in the presence of noise, quantum error correction (QEC) can recover the HL in various scenarios. A notable example is estimating a Pauli-$Z$ signal under bit-flip noise using the repetition code, which is both optimal for metrology and robust against noise. However, previous protocols often assume noise affects only the signal accumulation step, while the QEC operations -- including state preparation and measurement -- are noiseless. To overcome this limitation, we study fault-tolerant quantum metrology where all qubit operations are subject to noise. We focus on estimating a Pauli-$Z$ signal under bit-flip noise, together with state preparation and measurement errors in all QEC operations. We propose a fault-tolerant metrological protocol where a repetition code is prepared via repeated syndrome measurements, followed by a fault-tolerant logical measurement. We demonstrate the existence of an error threshold, below which errors are effectively suppressed and the HL is attained.

</details>


### [8] [A three-dimensional multimode lumped-element resonator for collective spin manipulation and dispersive readout](https://arxiv.org/abs/2601.05476)
*Zhuo Chen,Wenhua Qin,Hanyu Ren,Ziyi Liu,Kae Nemoto,William John Munro,Yingqiu Mao,Johannes Majer*

Main category: quant-ph

TL;DR: 3D lumped-element multimode microwave resonator enables homogeneous collective manipulation and dispersive readout of macroscopic spin ensembles using geometric symmetry to create two antisymmetric modes with suppressed cross-talk.


<details>
  <summary>Details</summary>
Motivation: To develop a versatile resonator for hybrid spin-photon systems that enables homogeneous collective manipulation and non-destructive dispersive readout of macroscopic spin ensembles, addressing challenges in multimode solid-state quantum technologies.

Method: Engineered a three-dimensional lumped-element multimode microwave resonator exploiting geometric symmetry to create two antisymmetric modes with strongly suppressed cross-talk that spatially overlap and couple to the same spin ensemble at distinct frequencies. Used negatively charged nitrogen-vacancy centers in diamond at 28 mK temperature.

Result: Achieved collective strong coupling with a coupling strength of 5.0 MHz and demonstrated non-destructive dispersive readout via a detuned mode. The resonator shows compact design, tunable coupling, and high field homogeneity.

Conclusion: The developed resonator represents a versatile device for hybrid spin-photon systems and multimode solid-state quantum technologies, offering homogeneous collective manipulation and dispersive readout capabilities for macroscopic spin ensembles.

Abstract: We report a three-dimensional lumped-element multimode microwave resonator that enables homogeneous collective manipulation and dispersive readout of a macroscopic spin ensemble. By exploiting geometric symmetry, two antisymmetric modes with strongly suppressed cross-talk are engineered to spatially overlap and couple to the same ensemble at distinct frequencies. Using negatively charged nitrogen-vacancy centers in diamond at 28 mK, we observe collective strong coupling with a coupling strength of 5.0 MHz and demonstrate non-destructive dispersive readout via a detuned mode. The compact design, tunable coupling, and high field homogeneity make this resonator a versatile device for hybrid spin-photon systems and multimode solid-state quantum technologies.

</details>


### [9] [Emergence of the 2nd Law in an Exactly Solvable Model of a Quantum Wire](https://arxiv.org/abs/2601.05514)
*Marco A. Jimenez-Valencia,Charles A. Stafford*

Main category: quant-ph

TL;DR: The paper investigates entropy production in quantum wires under electrical bias, showing that Joule heating entropy production requires decoherence from local measurements or inelastic scattering, rather than arising automatically from unitary quantum evolution.


<details>
  <summary>Details</summary>
Motivation: To understand how the Second Law of Thermodynamics manifests in microscopic quantum systems, specifically examining why entropy production due to Joule heating doesn't automatically emerge in exact microscopic quantum descriptions despite being readily proved statistically.

Method: Analysis of an exactly solvable model of a quantum wire using an exact formula for entropy current of independent quantum particles, examining entropy production under unitary evolution and with local measurements by floating thermoelectric probes.

Result: Entropy production due to Joule heating doesn't arise automatically in exact microscopic quantum description; it only emerges in the limit of many local measurements by thermoelectric probes, which inject entropy via information obtained from continuous measurements.

Conclusion: Decoherence from inelastic processes (introduced by local measurements or expected from inelastic scattering in interacting systems) is essential for entropy production due to Joule heating in quantum systems, reconciling microscopic quantum dynamics with macroscopic thermodynamics.

Abstract: As remarked by Boltzmann, the Second Law of Thermodynamics is notable for the fact that it is readily proved using elementary statistical arguments, but becomes harder and harder to verify the more precise the microscopic description of a system. In this article, we investigate one particular realization of the 2nd Law, namely Joule heating in a wire under electrical bias. We analyze the production of entropy in an exactly solvable model of a quantum wire wherein the conserved flow of entropy under unitary quantum evolution is taken into account using an exact formula for the entropy current of a system of independent quantum particles. In this exact microscopic description of the quantum dynamics, the entropy production due to Joule heating does not arise automatically. Instead, we show that the expected entropy production is realized in the limit of a large number of local measurements by a series of floating thermoelectric probes along the length of the wire, which inject entropy into the system as a result of the information obtained via their continuous measurements of the system. The decoherence resulting from inelastic processes introduced by the local measurements is essential to the phenomenon of entropy production due to Joule heating, and would be expected to arise due to inelastic scattering in real systems of interacting particles.

</details>


### [10] [Narrowband four-photon states from spontaneous four-wave mixing](https://arxiv.org/abs/2601.05558)
*Yifan Li,Justin Yu Xiang Peh,Chang Hoong Chow,Boon Long Ng,Vindhiya Prakash,Christian Kurtsiefer*

Main category: quant-ph

TL;DR: Continuous-wave pumping of cold Rb-87 atoms via double-Lambda scheme generates time-correlated four-photon states at MHz bandwidth, compatible with atomic quantum networks.


<details>
  <summary>Details</summary>
Motivation: To generate correlated four-photon states using continuous-wave pumping rather than high-power pulsed methods, producing photons compatible with atomic quantum networking applications.

Method: Spontaneous four-wave mixing via double-Lambda scheme in cold cloud of Rb-87 atoms with continuous-wave pumping at nominal powers, verified by higher-order intensity cross-correlation measurements and accidental subtraction.

Result: Time-correlated four-photon generation rate of 2.5(4)×10⁶ counts per second near saturation, with 20ns correlation window, MHz bandwidth photons resonant with atomic transitions.

Conclusion: Demonstrated efficient generation of correlated four-photon states using continuous-wave pumping, producing atomic-compatible photons suitable for quantum networking applications.

Abstract: We observe time-correlated four photons within a correlation window of 20ns from spontaneous four-wave mixing via a double-Lambda scheme in a cold cloud of Rb-87 atoms. In contrast to high-power pulsed pumping of chi^(2) nonlinear processes in crystals, our scheme generates correlated four-photon states by direct continuous-wave pumping at nominal powers. We verify the presence of genuinely correlated four-photon states over accidentals by higher-order intensity cross-correlation measurements and accidental subtraction. We infer a time-correlated four-photon generation rate of 2.5(4)x10^6 counts per second close to saturation. The photons produced are near-resonant with atomic transitions, and have a bandwidth in the order of MHz, making them readily compatible with quantum networking applications involving atoms.

</details>


### [11] [Bath-free squeezed phonon lasing via intrinsic ion-phonon coupling](https://arxiv.org/abs/2601.05575)
*Chen-Yu Lee,Guin-Dar Lin*

Main category: quant-ph

TL;DR: Squeezed lasing achieved in trapped-ion system using intrinsic ion-phonon interactions without engineered baths, enabling controlled quadrature squeezing for quantum applications.


<details>
  <summary>Details</summary>
Motivation: To develop a simpler method for achieving squeezed lasing in quantum systems without requiring complex bath engineering or tailored dissipative reservoirs, leveraging natural ion-phonon interactions instead.

Method: Two trapped ions interact with a shared vibrational mode, driven on both red- and blue-sideband transitions to create squeezed motion states through dynamic coupling between internal states and phonon modes, with external coherent drives for phase stabilization.

Result: Demonstrated that squeezed lasing can be achieved through direct manipulation of ion-phonon interactions without external reservoirs, with analysis of steady-state behavior, lasing onset, gain-loss balance, and squeezing parameter effects on phonon field statistics.

Conclusion: The approach provides a simple yet effective method for achieving squeezed lasing in quantum mechanical systems, offering new insights for realizing squeezed states in phonon-based systems with applications in quantum metrology and information processing.

Abstract: We present a theoretical model for realizing squeezed lasing in a trapped-ion system without relying on engineered baths or tailored dissipative reservoirs. Our approach leverages the intrinsic ion-phonon interactions, where two trapped ions, each interacting with a shared vibrational mode, are driven on both red- and blue-sideband transitions. This enables the creation of a squeezed state of motion through the dynamic coupling between the ions' internal states and the phonon mode. Unlike traditional methods that require bath engineering, our model demonstrates that squeezed lasing can be achieved through a direct manipulation of ion-phonon interactions, with no external reservoirs required. We explore the steady-state behavior of the system, analyzing the onset of lasing, gain-loss balance, and the role of the squeezing parameter in shaping the phonon field's statistical properties. Furthermore, we show how external coherent drives can stabilize phase coherence and achieve controlled quadrature squeezing, offering a simple yet effective method for achieving squeezed lasing in quantum mechanical systems. Our findings provide new insights into the realization of squeezed states in phonon-based systems, with potential applications in quantum metrology and information processing.

</details>


### [12] [Squeezing-Enhanced Two-Phase Estimation with N-Particle W-type States](https://arxiv.org/abs/2601.05595)
*Huan Zhang,Ying Xia,Xiuxing Zhang,Shoukang Chang,Wei Ye*

Main category: quant-ph

TL;DR: OPA-enhanced three-mode interferometer for multiparameter phase estimation shows precision improvement via intra-mode photon-number correlations, robust to moderate loss.


<details>
  <summary>Details</summary>
Motivation: To investigate how optical parametric amplification (OPA) can enhance simultaneous estimation of two optical phases in a three-mode interferometer, and to understand the physical mechanisms behind this enhancement in both ideal and lossy scenarios.

Method: Used normally ordered characteristic-function formalism to analytically obtain all photon-number moments of output quantum state, enabling explicit evaluation of quantum Fisher information matrix. Extended analysis to lossy interferometers using purification-based variational approach.

Result: Uniformly applied OPA significantly enhances attainable precision beyond unamplified interferometer in lossless scenario. Enhancement originates from amplification of intra-mode photon-number correlations rather than inter-mode correlations. OPA-assisted scheme retains advantage for moderate photon loss, showing robustness against dissipation.

Conclusion: OPA enhances multiparameter quantum metrology by amplifying intra-mode photon-number correlations, providing guidelines for optimizing phase estimation protocols in realistic noisy environments with demonstrated robustness to moderate loss.

Abstract: We investigate the simultaneous estimation of two optical phases in a three-mode interferometer assisted by optical parametric amplification (OPA). By employing the normally ordered characteristic-function formalism, we analytically obtain all photon-number moments of the output quantum state, enabling an explicit evaluation of the quantum Fisher information matrix for multiparameter phase estimation. In the lossless scenario, we show that uniformly applied OPA significantly enhances the attainable precision beyond that of an unamplified interferometer. By analyzing the second-order correlation functions, we demonstrate that this enhancement originates from the amplification of intra-mode photon-number correlations, rather than from inter-mode correlations. We further extend our analysis to realistic interferometers with photon loss using a purification-based variational approach. Although loss degrades the achievable precision, the OPA-assisted scheme retains a clear advantage for moderate loss, indicating a degree of robustness against dissipation. Our results clarify the physical mechanism underlying OPA-enhanced multiparameter quantum metrology and provide guidelines for optimizing phase estimation protocols in realistic noisy environments.

</details>


### [13] [Chaos, thermalization and breakdown of quantum-classical correspondence in a collective many-body system](https://arxiv.org/abs/2601.05627)
*Ángel L. Corps,Sebastián Gómez,Pavel Stránský,Armando Relaño,Pavel Cejnar*

Main category: quant-ph

TL;DR: Quantum-classical correspondence in 4-site Bose-Hubbard model shows three regimes: symmetry-breaking low-energy, intermediate mismatch, and high-energy restored correspondence, with unexpectedly slow convergence to classical limit.


<details>
  <summary>Details</summary>
Motivation: To investigate thermalization and quantum-classical correspondence in the fully-connected Bose-Hubbard model, specifically examining how classical phase-space structure and excited-state quantum phase transitions relate to dynamical regimes and the convergence to classical behavior.

Method: Analysis of the four-site fully-connected Bose-Hubbard model, examining classical phase-space structure, excited-state quantum phase transitions, and comparing quantum and classical equilibrium states across different energy regimes.

Result: Three distinct dynamical regimes identified: 1) symmetry-breaking low-energy states, 2) intermediate region with marked disagreement between quantum and classical equilibrium states, and 3) high-energy regime with restored correspondence. Classical intermittency above first excited-state quantum phase transition contrasts with quantum dynamics trapped in symmetry-breaking sectors. Mismatch persists even for relatively large particle numbers, revealing unexpectedly slow convergence to classical limit.

Conclusion: The study reveals robust finite-size effects in collective many-body dynamics, with quantum-classical correspondence showing unexpectedly slow convergence. The persistence of quantum trapping in symmetry-breaking sectors despite classically connected phase space highlights fundamental differences between quantum and classical dynamics in many-body systems.

Abstract: We investigate thermalization and the quantum-classical correspondence in the fully-connected Bose-Hubbard model, focusing on the four-site case. Our analysis of the classical phase-space structure and its excited-state quantum phase transitions leads us to three dynamical regimes: symmetry-breaking low-energy states, an intermediate region where quantum and classical equilibrium states markedly disagree, and a high-energy regime with restored correspondence. The observed classical intermittency above the first excited-state quantum phase transition contrasts with quantum dynamics, which remains trapped in symmetry-breaking sectors despite the existence of a classically connected phase space. This mismatch originates from the population of imbalance-carrying eigenstates and persists even for relatively large number of particles. Our results reveal unexpectedly slow convergence to the classical limit, signaling robust finite-size effects in collective many-body dynamics.

</details>


### [14] [Improving quantum interference visibility between independent sources by enhancing the purity of correlated photon pairs](https://arxiv.org/abs/2601.05671)
*Hsin-Pin Lo,Kai Asaoka,Hiroki Takesue*

Main category: quant-ph

TL;DR: Two methods for enhancing spectral purity of photon pairs from type-0 PPLN waveguides are compared, both achieving ~80% HOM visibility, with one method providing higher three-fold coincidence rates for multi-photon GHZ state generation.


<details>
  <summary>Details</summary>
Motivation: High-visibility quantum interference between independent photons is essential for multi-photon quantum information processing, and spectral purity of correlated photon pairs is crucial for achieving this interference.

Method: Systematically vary both pump bandwidth and interference-filter bandwidth to enhance purity of photon pairs from type-0 PPLN waveguide; compare two approaches under identical experimental conditions; evaluate spectral purity from measured joint spectral intensities using Schmidt decomposition.

Result: Both methods significantly improve Hong-Ou-Mandel interference visibility to approximately 80%; one approach yields higher three-fold coincidence rate, advantageous for increasing state fidelity and generation rate of multi-photon time-bin GHZ states.

Conclusion: Both approaches effectively enhance photon pair purity for quantum interference, with the method providing higher coincidence rates being particularly advantageous for scaling up multi-photon quantum information processing with time-bin GHZ states.

Abstract: High-visibility quantum interference between independent photons is essential for demonstrating multi-photon quantum information processing, and it is closely linked to the spectral purity of correlated photon pairs. In this study, we investigate two approaches to enhance the purity of photon pairs generated from a type-0 PPLN waveguide by systematically varying both the pump bandwidth and the interference-filter bandwidth, and we directly compare their performance under identical experimental conditions. The spectral purity is evaluated from measured joint spectral intensities using Schmidt decomposition. Both methods significantly improve the Hong-Ou-Mandel interference visibility to approximately 80%. However, the former approach also yields a higher three-fold coincidence rate, which is advantageous for our ongoing efforts to increase the state fidelity and generation rate of multi-photon time-bin Greenberger-Horne-Zeilinger (GHZ) states.

</details>


### [15] [Block Encoding Linear Combinations of Pauli Strings Using the Stabilizer Formalism](https://arxiv.org/abs/2601.05740)
*Niclas Schillo,Andreas Sturm,Rüdiger Quay*

Main category: quant-ph

TL;DR: A novel method for constructing quantum circuits that block encode linear combinations of Pauli strings, using Pauli transformation and stabilizer-based correction, achieving logarithmic ancilla scaling and competitive circuit complexity compared to LCU.


<details>
  <summary>Details</summary>
Motivation: The Quantum Singular Value Transformation (QSVT) framework requires efficient block encodings for practical quantum advantage, as gate complexity of block-encoding largely determines overall QSVT algorithm cost. Current methods like Linear Combination of Unitaries (LCU) may not be optimal for Pauli string combinations.

Method: Two-step approach: 1) Transform Pauli strings into pairwise anti-commuting ones, making the linear combination unitary and directly implementable as a quantum circuit; 2) Apply correction transformation based on stabilizer formalism using ancilla registers to restore original Pauli strings. Method supports logarithmic ancilla scaling with system qubits and can be extended to larger ancilla registers for circuit complexity reduction.

Result: Method achieves ancilla register size scaling logarithmically with number of system qubits. Numerical simulations comparing with LCU approach show comparable or better circuit complexities, with particular advantages when target operator structure can be exploited. Four concrete examples demonstrate the approach's effectiveness.

Conclusion: The proposed method enables more efficient block encodings for linear combinations of Pauli strings, potentially benefiting a range of QSVT-based algorithms beyond the analyzed examples, contributing to practical quantum advantage through reduced circuit complexity.

Abstract: The Quantum Singular Value Transformation (QSVT) provides a powerful framework with the potential for quantum speedups across a wide range of applications. Its core input model is the block encoding framework, in which non-unitary matrices are embedded into larger unitary matrices. Because the gate complexity of the block-encoding subroutine largely determines the overall cost of QSVT-based algorithms, developing new and more efficient block encodings is crucial for achieving practical quantum advantage. In this paper, we introduce a novel method for constructing quantum circuits that block encode linear combinations of Pauli strings. Our approach relies on two key components. First, we apply a transformation that converts the Pauli strings into pairwise anti-commuting ones, making the transformed linear combination unitary and thus directly implementable as a quantum circuit. Second, we employ a correction transformation based on the stabilizer formalism which uses an ancilla register to restore the original Pauli strings. Our method can be implemented with an ancilla register whose size scales logarithmically with the number of system qubits. It can also be extended to larger ancilla registers, which can substantially reduce the overall quantum circuit complexity. We present four concrete examples and use numerical simulations to compare our method's circuit complexity with that of the Linear Combination of Unitaries (LCU) approach. We find that our method achieves circuit complexities comparable to or better than LCU, with possible advantages when the structure of the target operators can be exploited. These results suggest that our approach could enable more efficient block encodings for a range of relevant problems extending beyond the examples analyzed in this work.

</details>


### [16] [Quantum Interference-Induced Bhattacharyya Distance](https://arxiv.org/abs/2601.05749)
*Mostafizur Rahaman Laskar*

Main category: quant-ph

TL;DR: A quantum distance measure called QIBD is proposed that quantifies distance between probability distributions encoded in quantum states based on interference fragility under entangling evolution, reducing to classical Bhattacharyya distance for vanishing interactions but capturing correlation structure beyond fidelity for entangling cases.


<details>
  <summary>Details</summary>
Motivation: Current quantum distance measures often rely on fidelity-based approaches that may not adequately capture correlation structure relevant in physically meaningful contexts where interactions play a role. There is a need for distance measures that respond to correlation structure in ways that overlap-based measures do not, particularly when interaction-aligned correlations are physically relevant.

Method: The Quantum Interference-Induced Bhattacharyya Distance (QIBD) is defined through a single-ancilla interferometric circuit where an interaction Hamiltonian generates correlation-dependent phases that modulate interference visibility. The measure is based on the fragility of quantum interference under entangling evolution, with the circuit designed so that when the interaction vanishes, QIBD reduces to the classical Bhattacharyya distance.

Result: Numerical simulations demonstrate that QIBD responds to correlation structure in ways that overlap-based measures do not. For entangling interactions, QIBD cannot be expressed as a function of fidelity alone, indicating it captures different aspects of quantum state relationships than traditional fidelity-based measures.

Conclusion: QIBD represents a novel quantum distance measure that leverages interference fragility to capture correlation structure beyond what fidelity-based measures can detect, suggesting potential utility in contexts where interaction-aligned correlations are physically relevant, such as quantum information processing, quantum metrology, and quantum machine learning applications.

Abstract: We propose a quantum distance measure between probability distributions encoded in quantum states based on the fragility of quantum interference under entangling evolution. The Quantum Interference-Induced Bhattacharyya Distance (QIBD) is defined through a single-ancilla interferometric circuit in which an interaction Hamiltonian generates correlation-dependent phases that modulate interference visibility. When the interaction vanishes, QIBD reduces to the classical Bhattacharyya distance; however, for entangling interactions, it cannot be expressed as a function of fidelity alone. Numerical simulations demonstrate that QIBD responds to correlation structure in ways that overlap-based measures do not, suggesting potential utility in contexts where interaction-aligned correlations are physically relevant.

</details>


### [17] [Hidden time-nonlocal Floquet symmetries](https://arxiv.org/abs/2601.05783)
*Sigmund Kohler,Jesús Casado-Pascual*

Main category: quant-ph

TL;DR: Floquet spectrum of detuned driven two-level system shows exact quasienergy crossings when detuning equals integer multiples of driving frequency, explained by hidden time-nonlocal parity symmetry.


<details>
  <summary>Details</summary>
Motivation: To understand the spectral properties of periodically driven quantum systems, specifically the occurrence of exact quasienergy crossings in detuned driven two-level systems, and to reveal the underlying symmetry principles governing these crossings.

Method: Analysis of Floquet spectrum using hidden time-nonlocal parity symmetry classification, constructive proof via scalar recurrence relation, and development of numerical computation scheme applicable to models beyond two-level systems.

Result: Exact quasienergy crossings occur when detuning is integer multiple of driving frequency; Floquet modes can be classified as even/odd under hidden parity symmetry; crossings emerge between quasienergies of different parity.

Conclusion: The study reveals a fundamental symmetry principle in periodically driven quantum systems, providing analytical understanding and computational tools for quasienergy crossings with implications for quantum control and Floquet engineering.

Abstract: We investigate the Floquet spectrum of a detuned, driven two-level system and show that it exhibits exact quasienergy crossings when the detuning is an integer multiple of the energy quantum of the driving field. This behavior can be explained by a hidden time-nonlocal parity, which allows the Floquet modes to be classified as even or odd. Then a generic feature is the emergence of exact crossings between quasienergies of different parity. A constructive proof of the existence of the symmetry is based on a scalar recurrence relation. Moreover, we present a general scheme for its numerical computation, which can be applied to models beyond the two-level system. Analytical results are illustrated with numerical data.

</details>


### [18] [On the robustness of Quantum Phase Estimation to compute ground properties of many-electron systems](https://arxiv.org/abs/2601.05788)
*Wassil Sennane,Jérémie Messud*

Main category: quant-ph

TL;DR: Analysis of Quantum Phase Estimation (QPE) parameters for electronic systems with a constructive method to set free parameters and conditions for achieving chemical accuracy in ground energy estimation.


<details>
  <summary>Details</summary>
Motivation: To enable more automation of QPE for predictive computational chemistry and material science by developing a holistic parameter selection method, as various aspects of QPE parameters remain unexplored.

Method: Proposes a constructive method to set QPE free parameters (time step, number of phase qubits, initial state preparation, measurement shots, unitary implementation parameters) and derives explicit conditions for chemical accuracy in ground energy estimation.

Result: Demonstrates that using the proposed conditions, the complexity of Trotterized QPE tends to depend only on physical system properties rather than the number of phase qubits, with numerical simulations on H2 molecule providing initial validation.

Conclusion: The analysis provides a systematic approach to parameter selection for QPE in electronic systems, paving the way for more automated applications in computational chemistry and material science.

Abstract: We propose an analysis of the Quantum Phase Estimation (QPE) algorithm applied to electronic systems by investigating its free parameters such as the time step, number of phase qubits, initial state preparation, number of measurement shots, and parameters related to the unitary operators implementation. A deep understanding of these parameters is crucial to pave the way towards more automation of QPE applied to predictive computational chemistry and material science. To our knowledge, various aspects remain unexplored and a holistic parameter selection method remains to be developed. After reviewing key QPE features, we propose a constructive method to set the QPE free parameters. We derive, among other things, explicit conditions for achieving chemical accuracy in ground energy estimation. We also demonstrate that, using our conditions, the complexity of the Trotterized version of QPE tends to depend only on physical system properties and not on the number of phase qubits. Numerical simulations on the H2 molecule provide a first validation of our approach.

</details>


### [19] [Optimally driving multi-photon transitions in the perturbative single-mode regime](https://arxiv.org/abs/2601.05854)
*Frieder Lindel,Stefan Yoshi Buhmann,Andreas Buchleitner,Edoardo G. Carnio*

Main category: quant-ph

TL;DR: Optimal classical light states (coherent state mixtures) maximize m-photon transition rates in short-lived multilevel atoms under fixed intensity and photon number constraints.


<details>
  <summary>Details</summary>
Motivation: Multi-photon transition rates depend on light field's mth-order coherence, suggesting coherence shaping could enhance these transitions. The paper aims to find optimal light states for driving m-photon transitions in specific atomic systems.

Method: Theoretical analysis determining optimal states of weak fixed-intensity, narrow-band light fields with restricted maximal photon number for driving m-photon transitions in short-lived atomic multilevel systems. Shows classical mixtures of coherent states are optimal.

Result: For short-lived multilevel atomic systems, no quantum properties of light need to be exploited - classical mixtures of coherent states are optimal for maximizing m-photon transition rates under given constraints.

Conclusion: Quantum light advantages are unnecessary for optimizing m-photon transitions in short-lived multilevel atoms; classical coherent state mixtures provide optimal performance within specified intensity and photon number constraints.

Abstract: The rate of $m$-photon transitions in matter, induced by an incident light field, depends on the field's $m$th order coherence function. Consequently, the coherence properties of the light field may be shaped to increase the rate of multi-photon transitions. Here, we determine the optimal state of a weak fixed-intensity, narrow-band incident light field, with a restricted maximal photon number, that optimally drives $m$-photon transitions in the case of a short-lived atomic multilevel system. We show that, in this case, no quantum properties of the light field need to be exploited, but that classical mixtures of coherent states are optimal.

</details>


### [20] [Breaking the Exponential: Decoherence-Driven Power-Law Spontaneous Emission in Waveguide Quantum Electrodynamics](https://arxiv.org/abs/2601.05884)
*Stefano Longhi*

Main category: quant-ph

TL;DR: Dynamical dephasing in waveguide QED transforms spontaneous emission from exponential decay with rare power-law tails to robust early-time power-law decay via photon diffusion.


<details>
  <summary>Details</summary>
Motivation: To understand how dynamical dephasing in photonic waveguides affects the spontaneous emission decay law of two-level quantum emitters, moving beyond conventional exponential decay models.

Method: Investigation of a two-level system coupled to a photonic waveguide with dynamical dephasing in photon modes, analyzing decay dynamics through photon diffusion in disordered environments rather than spectral edge effects.

Result: Without dephasing: conventional exponential decay with extremely rare long-time power-law tails. With dephasing: robust power-law decay emerges at short times, driven by photon diffusion in dynamically disordered environment.

Conclusion: Dynamical dephasing introduces a novel decoherence-induced mechanism for non-exponential spontaneous emission in waveguide QED platforms, fundamentally altering decay dynamics.

Abstract: We investigate the spontaneous emission of a two-level system coupled to a photonic waveguide, showing that dynamical dephasing in the photon modes profoundly alters the decay law. In the absence of dephasing, the emitter displays conventional exponential decay followed by a long-time power-law tail -- observable only at extremely low survival probabilities. Strikingly, when dephasing is introduced, a robust power-law decay emerges already at short times, driven by photon diffusion in the dynamically disordered environment rather than spectral edge effects. These results reveal a novel, decoherence-induced mechanism for non-exponential spontaneous emission in waveguide QED platforms.

</details>


### [21] [Sub-Planck structure quantification in non-Gaussian probability densities](https://arxiv.org/abs/2601.05898)
*Darren W. Moore,Vojtěch Švarc,Kratveer Singh,Artem Kovalenko,Minh Tuan Pham,Ondřej Číp,Lukáš Slodička,Radim Filip*

Main category: quant-ph

TL;DR: A universal method to identify, quantify, and compare sub-Planck structures in bosonic quantum systems using measurable probability densities, demonstrated experimentally with high-order Fock states.


<details>
  <summary>Details</summary>
Motivation: Sub-Planck structures in phase space probability densities are pervasive in bosonic quantum systems with nonlinear dynamics or measurements, but existing identification and comparison methods remain qualitative.

Method: Developed a universally applicable, experimentally friendly method to identify, quantify, and compare sub-Planck structures from directly measurable or estimated probability densities of single phase space variables.

Result: Demonstrated the method's efficacy on experimental high-order Fock states of a single-atom mechanical oscillator, showing provably finer sub-Planck structures as Fock occupation increases despite increased uncertainty in phonon, position, and momentum bases.

Conclusion: The method provides a quantitative framework for analyzing sub-Planck structures in bosonic quantum systems, enabling systematic comparison and characterization of these fine-scale quantum features.

Abstract: Sub-Planck structures in non-Gaussian probability densities of phase space variables are pervasive in bosonic quantum systems. They are almost universally present if the bosonic system evolves via nonlinear dynamics or nonlinear measurements. So far, identification and comparison of such structures remains qualitative. Here we provide a universally applicable and experimentally friendly method to identify, quantify and compare sub-Planck structures from directly measurable or estimated probability densities of single phase space variables. We demonstrate the efficacy of this method on experimental high order Fock states of a single-atom mechanical oscillator, showing provably finer sub-Planck structures as the Fock occupation increases despite the accompanying uncertainty increase in the phonon, position, and momentum bases.

</details>


### [22] [Generation of squeezed optical states via stored classical pulses in a Bose gas](https://arxiv.org/abs/2601.05908)
*Sevilay Sevinçli,Dennis Rätzel,Markus Krutzik,Mehmet Özgür Oktel,Mustafa Gündoğan*

Main category: quant-ph

TL;DR: Squeezed light generation via storage of classical probe pulse in BEC, using atom-atom collisions during storage to create spin squeezing via one-axis-twisting, then transferring atomic squeezing to retrieved optical mode.


<details>
  <summary>Details</summary>
Motivation: To generate squeezed light by exploiting nonlinear evolution from atom-atom collisions during storage in a BEC-based optical memory, overcoming limitations of conventional squeezing generation methods.

Method: Λ-type optical memory interface maps temporal probe mode onto collective spin wave in BEC; collisional interactions during storage implement one-axis-twisting dynamics to generate spin squeezing; readout via single-mode beam-splitter mapping transfers atomic quadrature squeezing to propagating optical mode.

Result: Under realistic conditions with loss and finite memory/retrieval efficiencies, optimal storage times identified; several dB of squeezing predicted to be transferable to retrieved light.

Conclusion: BEC-based optical memory with collisional interactions provides viable scheme for generating squeezed light, with potential for significant squeezing transfer despite realistic experimental imperfections.

Abstract: We propose and analyze a scheme to generate squeezed light by storing a classical probe pulse in a Bose--Einstein condensate (BEC) and exploiting the nonlinear evolution caused by atom--atom collisions during the storage time. A $Λ$-type optical memory interface maps a chosen temporal probe mode onto a single phase-matched collective spin wave; for a coherent input this prepares a tunable coherent spin state of a two-component BEC, with its initial spin orientation set by the stored mean excitation number and the phase relation between the probe and control fields. Collisional interactions during storage then implement one-axis-twisting dynamics and generate spin squeezing in the atomic ensemble. We account for realistic loss and finite memory and retrieval efficiencies, and model readout as a single-mode beam-splitter mapping that transfers the atomic quadrature squeezing onto a propagating optical mode. We identify optimal storage times and predict that, under realistic conditions, several dB of squeezing can be transferred to the retrieved light.

</details>


### [23] [Universal Dilation of Linear Itô SDEs: Quantum Trajectories and Lindblad Simulation of Second Moments](https://arxiv.org/abs/2601.05928)
*Hsuan-Cheng Wu,Xiantao Li*

Main category: quant-ph

TL;DR: A quantum framework for simulating N-dimensional linear Itô SDEs using unitary dilation to map them to Stochastic Schrödinger Equations, enabling both trajectory-based and ensemble-based quantum algorithms.


<details>
  <summary>Details</summary>
Motivation: To develop a universal quantum framework for simulating linear stochastic differential equations, overcoming classical computational limitations by leveraging quantum computers for both trajectory-based and ensemble-based approaches.

Method: Uses unitary dilation technique to establish exact correspondence between linear Itô SDEs and Stochastic Schrödinger Equations on dilated Hilbert space. Two algorithmic strategies: (1) trajectory-based approach using sequential weak measurements for stochastic integrators, (2) ensemble-based approach mapping moment evolution to deterministic Lindblad master equations.

Result: Pathwise exact embedding where classical SDE solutions are recovered as projections of dilated quantum states. The SSE is naturally implementable on digital quantum processors with stochastic Wiener increments corresponding to measurement outcomes. Provides error bounds via stochastic light-cone analysis and validates with numerical simulations.

Conclusion: The framework enables quantum simulation of linear SDEs with both additive and multiplicative noise, offering two complementary algorithmic approaches that leverage quantum processors for efficient stochastic simulation beyond classical Monte Carlo methods.

Abstract: We present a universal framework for simulating $N$-dimensional linear Itô stochastic differential equations (SDEs) on quantum computers with additive or multiplicative noises. Building on a unitary dilation technique, we establish a rigorous correspondence between the general linear SDE \[ dX_t = A(t) X_t\,dt + \sum_{j=1}^J B_j(t)X_t\,dW_t^j \] and a Stochastic Schrödinger Equation (SSE) on a dilated Hilbert space. Crucially, this embedding is pathwise exact: the classical solution is recovered as a projection of the dilated quantum state for each fixed noise realization. We demonstrate that the resulting SSE is {naturally implementable} on digital quantum processors, where the stochastic Wiener increments correspond directly to measurement outcomes of ancillary qubits. Exploiting this physical mapping, we develop two algorithmic strategies: (1) a trajectory-based approach that uses sequential weak measurements to realize efficient stochastic integrators, including a second-order scheme, and (2) an ensemble-based approach that maps moment evolution to a deterministic Lindblad quantum master equation, enabling simulation without Monte Carlo sampling. We provide error bounds based on a stochastic light-cone analysis and validate the framework with numerical simulations.

</details>


### [24] [Below-threshold error reduction in single photons through photon distillation](https://arxiv.org/abs/2601.05947)
*F. H. B. Somhorst,J. Saied,N. Kannan,B. Kassenberg,J. Marshall,M. de Goede,H. J. Snijders,P. Stremoukhov,A. Lukianenko,P. Venderbosch,T. B. Demille,A. Roos,N. Walk,J. Eisert,E. G. Rieffel,D. H. Smith,J. J. Renema*

Main category: quant-ph

TL;DR: Photon distillation reduces indistinguishability errors in photonic quantum computers more efficiently than quantum error correction, enabling scalable error mitigation compatible with fault-tolerant operation.


<details>
  <summary>Details</summary>
Motivation: Photonic quantum computers rely on quantum interference of indistinguishable photons for measurement-based quantum computation. Any which-way information degrades interference and introduces errors. While quantum error correction can address these errors, it is highly resource-intensive with low error thresholds, requiring numerous high-quality optical components.

Method: Scalable, optimal photon distillation - an intrinsically bosonic, coherent error-mitigation technique that exploits quantum interference to project single photons into purified internal states. This reduces indistinguishability errors at higher efficiency and threshold than quantum error correction.

Result: Experimental demonstration of unconditional error reduction (below-threshold behavior) consistent with theoretical predictions, even when accounting for noise introduced by the distillation gate. Achieved actual net-gain error mitigation under conditions relevant for fault-tolerant quantum computing.

Conclusion: Photon distillation is a substantially more resource-efficient strategy than quantum error correction for reducing indistinguishability errors in photonic quantum computers, compatible with fault-tolerant operation. Expected to find uses in large-scale quantum computers and inspire search for additional intrinsically bosonic error-reduction strategies.

Abstract: Photonic quantum computers use the bosonic statistics of photons to construct, through quantum interference, the large entangled states required for measurement-based quantum computation. Therefore, any which-way information present in the photons will degrade quantum interference and introduce errors. While quantum error correction can address such errors in principle, it is highly resource-intensive and operates with a low error threshold, requiring numerous high-quality optical components. We experimentally demonstrate scalable, optimal photon distillation as a substantially more resource-efficient strategy to reduce indistinguishability errors in a way that is compatible with fault-tolerant operation. Photon distillation is an intrinsically bosonic, coherent error-mitigation technique which exploits quantum interference to project single photons into purified internal states, thereby reducing indistinguishability errors at both a higher efficiency and higher threshold than quantum error correction. We observe unconditional error reduction (i.e., below-threshold behaviour) consistent with theoretical predictions, even when accounting for noise introduced by the distillation gate, thereby achieving actual net-gain error mitigation under conditions relevant for fault-tolerant quantum computing. We anticipate photon distillation will find uses in large-scale quantum computers. We also expect this work to inspire the search for additional intrinsically bosonic error-reduction strategies, even for fault-tolerant architectures.

</details>


### [25] [Continuous-time noise mitigation in analogue quantum simulation](https://arxiv.org/abs/2601.05952)
*Gabriele Bressanini,Yue Ma,Hyukjoon Kwon,M. S. Kim*

Main category: quant-ph

TL;DR: First fully analogue protocol for exact noise cancellation in quantum simulators using ancillary qubits and continuous-time operation.


<details>
  <summary>Details</summary>
Motivation: Analogue quantum simulators are promising for exploring quantum many-body dynamics beyond classical capabilities, but their accuracy is limited by vulnerability to noise, requiring effective noise mitigation strategies.

Method: Time-continuous framework using a small number of ancillary qubits whose interaction with the system, combined with classical post-processing of joint measurement data, is tailored to cancel noise effects. The protocol is Hamiltonian-independent, robust to ancilla noise, and preserves continuous-time dynamics.

Result: Achieves exact noise cancellation in analogue quantum simulation, operating in a fully analogue manner without discretization, while maintaining the continuous-time nature of system dynamics.

Conclusion: Establishes a new direction for high-fidelity analogue quantum simulation in noisy environments, offering the first protocol that is both fully analogue and achieves exact noise cancellation.

Abstract: Analogue quantum simulators offer a promising route to explore quantum many-body dynamics beyond classical reach in the near term. However, their vulnerability to noise limits the accuracy of simulations. Here, we establish a new framework for mitigating noise in analogue quantum simulation, operating in a time-continuous manner. To our knowledge, this is the first protocol that is fully analogue and that achieves exact noise cancellation. Our method requires a small number of ancillary qubits, whose interaction with the system$-$combined with classical post-processing of joint measurement data$-$is tailored to cancel the effect of noise. Furthermore, the protocol is Hamiltonian-independent, robust to realistic ancilla noise, and avoids any discretization, preserving the continuous-time nature of the system's dynamics. This work opens a new direction for achieving high-fidelity analogue quantum simulation in the presence of noise.

</details>


### [26] [Counterdiabatic ADAPT-VQE for molecular simulation](https://arxiv.org/abs/2601.05973)
*Diego Tancara,Herbert Díaz-Moraga,Dardo Goyeneche*

Main category: quant-ph

TL;DR: Hybrid method combining ADAPT-VQE framework with counterdiabatic driving for molecular simulations shows improved performance and reduced circuit depth compared to individual approaches.


<details>
  <summary>Details</summary>
Motivation: ADAPT-VQE offers robustness against barren plateaus for molecular ground states, while counterdiabatic algorithms provide performance advantages and reduced circuit depth compared to standard adiabatic approaches. The authors seek to combine these strengths.

Method: Map molecular Hamiltonian to qubit representation, construct adiabatic Hamiltonian, compute approximate adiabatic gauge potential using nested commutators to define operator pool, then apply ADAPT-VQE to iteratively select most relevant ansatz elements.

Result: Demonstrates improvements in performance and reductions in circuit depth compared to using either counterdiabatic algorithms alone or ADAPT-VQE with fermionic excitation operators.

Conclusion: The hybrid approach combining ADAPT-VQE with counterdiabatic driving is effective for molecular simulations, leveraging strengths of both paradigms.

Abstract: Among variational quantum algorithms designed for NISQ devices, ADAPT-VQE stands out for its robustness against barren plateaus, particularly in estimating molecular ground states. On the other hand, counterdiabatic algorithms have shown advantages in both performance and circuit depth when compared to standard adiabatic approaches. In this work, we propose a hybrid method that integrates the ADAPT-VQE framework with counterdiabatic driving within an adiabatic evolution scheme. Specifically, we map the molecular Hamiltonian to a qubit representation and construct an adiabatic Hamiltonian, from which an approximate adiabatic gauge potential is computed using nested commutators. The resulting operator terms define the operator pool, and the ADAPT-VQE algorithm is applied to iteratively select the most relevant elements for the ansatz. Our results demonstrate improvements in performance and reductions in circuit depth compared to using either counterdiabatic algorithms or ADAPT-VQE with fermionic excitation operators, thus supporting the effectiveness of combining both paradigms in molecular simulations.

</details>


### [27] [From Superradiance to Superabsorption: An Exact Treatment of Non-Markovian Cooperative Radiation](https://arxiv.org/abs/2601.05989)
*Ignacio González,Ángel Rivas*

Main category: quant-ph

TL;DR: Study of cooperative radiation in atomic ensembles coupled to lossy cavities beyond Markovian and mean-field approximations, revealing three dynamical regimes and showing how cooperativity enhances environmental memory effects.


<details>
  <summary>Details</summary>
Motivation: To understand cooperative radiation phenomena in atomic ensembles coupled to lossy resonant cavities beyond the limitations of Markovian and mean-field approximations, particularly investigating the interplay between cooperativity and environmental memory effects.

Method: Derived complete analytical solution for two-emitter case and employed numerically exact method for larger ensembles (up to 10^3 emitters) to characterize the transition from Markovian to non-Markovian collective dynamics.

Result: Revealed three distinct regimes: Markovian phase with standard superradiant burst, non-Markovian phase with spontaneous superabsorption, and critical regime with pulsed collective emission. Found that critical spectral width separating these behaviors increases with number of emitters, demonstrating cooperativity enhances environmental memory effects. Superradiant scaling of peak intensity degrades with system size, approaching subquadratic law for perfect cavities.

Conclusion: Cooperativity can enhance environmental memory effects in quantum optical systems, with spontaneous superabsorption emerging as a distinct manifestation of non-Markovian cooperativity in the strong coupling regime.

Abstract: We investigate the emergence of cooperative radiation phenomena in ensembles of two-level atoms coupled to a lossy resonant cavity beyond the Markovian and mean-field approximations. By deriving a complete analytical solution for the two-emitter case and employing a numerically exact method for larger ensembles, we characterize the full transition from Markovian to non-Markovian collective dynamics for systems of up to $10^3$ emitters. Our results reveal three distinct regimes: a Markovian phase exhibiting the standard superradiant burst, a non-Markovian phase featuring spontaneous superabsorption of the emitted field, and a critical regime marked by pulsed collective emission. We show that the critical spectral width separating these behaviors increases monotonically with the number of emitters, demonstrating that environmental memory effects can be enhanced by cooperativity. Finally, we find that the superradiant scaling of the peak intensity progressively degrades with increasing system size, approaching a subquadratic law in the limit of a perfect cavity. In this regime, spontaneous superabsorption emerges as a distinct manifestation of non-Markovian cooperativity.

</details>
