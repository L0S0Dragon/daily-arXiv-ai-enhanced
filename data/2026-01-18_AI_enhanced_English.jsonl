{"id": "2601.09793", "categories": ["cond-mat.dis-nn", "cond-mat.other", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09793", "abs": "https://arxiv.org/abs/2601.09793", "authors": ["Soumadip Pakrashi", "Atanu Rajak", "Sambuddha Sanyal"], "title": "Emergent Nonperturbative Universal Floquet Localization", "comment": "4.5+2+6 pages, 2+5 figures", "summary": "We show that a robust, nonperturbative localization plateau emerges in periodically driven quasiperiodic lattices, independent of the static localization properties and drive protocol. Using exact Floquet dynamics, Floquet perturbation theory, and optimal-order van Vleck analysis, we identify a fine-tuned amplitude-to-frequency ratio where all Floquet states become localized despite dense resonances. The van Vleck expansion achieves superasymptotic accuracy up to an optimal orde; it ultimately breaks down due to resonant hybridization at a weak quasiperiodic potential, revealing that the observed localization is nonperturbative.", "AI": {"tldr": "A nonperturbative localization plateau emerges in driven quasiperiodic lattices at a fine-tuned amplitude-to-frequency ratio, where all Floquet states become localized despite dense resonances.", "motivation": "To understand localization phenomena in periodically driven quasiperiodic systems, particularly how robust localization can emerge independent of static localization properties and drive protocols.", "method": "Used exact Floquet dynamics, Floquet perturbation theory, and optimal-order van Vleck analysis to study the system.", "result": "Identified a fine-tuned amplitude-to-frequency ratio where all Floquet states become localized despite dense resonances. The van Vleck expansion achieves superasymptotic accuracy up to an optimal order but ultimately breaks down due to resonant hybridization at weak quasiperiodic potential.", "conclusion": "The observed localization is nonperturbative, emerging robustly in periodically driven quasiperiodic lattices independent of static localization properties and drive protocol."}}
{"id": "2601.10226", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.10226", "abs": "https://arxiv.org/abs/2601.10226", "authors": ["Chenxin Qin", "Chenyan Wang", "Mouyang Cheng", "Ji Chen"], "title": "Integral Variable Range Hopping for Modeling Electrical Transport in Disordered Systems", "comment": "7 pages, 4 figures", "summary": "The variable range hopping (VRH) model has been widely applied to describe electrical transport in disordered systems, providing theoretical formulas to fit temperature-dependent electric conductivity. These models rely on oversimplified assumptions that restrict their applicability and result in problematic fitting behaviors, yet their overusing situation is becoming increasingly serious. In this work we formulate an integral variable range hopping (IVRH) model, which replaces the empirical temperature power-law dependence in standard VRH theories with a physics-inspired integral formulation. The model builds upon the standard hopping probability $\u03c9(R)$ w.r.t. hopping distance $R$ and incorporates the density of accessible electronic states through an effective volume function $V(R)$, which reflects the influence of system geometry. The IVRH formulation inherently reproduces both the Mott behavior at low temperatures and the Arrhenius behavior at high temperatures, respectively, and enables a smooth transition between the two regimes. We apply the IVRH model to two-dimensional, three-dimensional, and multi-layered systems. Monte Carlo simulations validate the model's predictions and yield consistent values for the fitting parameters, with substantially reduced variances compared to fitting using the standard VRH model. Furthermore, the improved robustness of IVRH also extends to the transport measurements in monolayer MoS$_2$ system and monolayer WS$_2$ system, enabling more physically meaningful interpretation.IVRH model offers a more stable and physically sound framework for interpreting hopping transport in low-dimensional amorphous materials, providing deeper insights into the universal geometric scaling factors that govern charge transport in disordered systems.", "AI": {"tldr": "The paper introduces an Integral Variable Range Hopping (IVRH) model that replaces empirical temperature power-law dependencies in standard VRH theories with a physics-inspired integral formulation, providing more stable and physically meaningful fitting for disordered systems.", "motivation": "Standard VRH models rely on oversimplified assumptions that restrict applicability and cause problematic fitting behaviors, yet they are overused in describing electrical transport in disordered systems.", "method": "Develops an integral formulation that replaces empirical temperature power-law dependence with a physics-inspired integral approach. The model builds on standard hopping probability \u03c9(R) with respect to hopping distance R and incorporates density of accessible electronic states through an effective volume function V(R) that reflects system geometry influence.", "result": "IVRH inherently reproduces both Mott behavior at low temperatures and Arrhenius behavior at high temperatures with smooth transition between regimes. Monte Carlo simulations validate predictions and yield consistent fitting parameters with substantially reduced variances compared to standard VRH. Improved robustness extends to transport measurements in monolayer MoS\u2082 and WS\u2082 systems.", "conclusion": "IVRH offers a more stable and physically sound framework for interpreting hopping transport in low-dimensional amorphous materials, providing deeper insights into universal geometric scaling factors governing charge transport in disordered systems."}}
{"id": "2601.10333", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.10333", "abs": "https://arxiv.org/abs/2601.10333", "authors": ["Florin Hemmann", "Vincent Glauser", "Ullrich Steiner", "Matthias Saba"], "title": "Computer Generation of Disordered Networks with Targeted Structural Properties", "comment": null, "summary": "Disordered spatial networks are model systems that describe structures and interactions across multiple length scales. Scattering and interference of waves in these networks can give rise to structural phase transitions, localization, diffusion, and band gaps. The study of these complex phenomena requires efficient numerical methods to computer-generate disordered networks with targeted structural properties. In the established Wooten-Weaire-Winer algorithm, a series of bond switch moves introduces disorder into an initial network. Conventional strain energies that govern this evolution are limited to 3D networks with coordination numbers of no more than four. We extend the algorithm to arbitrary coordination number statistics by introducing bond repulsion in the Keating strain energy. We tune the degree and type of disorder introduced into initially crystalline networks by varying the bond-bending force constant in the strain energy and the temperature profile. The effects of these variables are analyzed using a list of order metrics that capture both direct and reciprocal space. A feedforward neural network is trained to predict the structural characteristics from the algorithm inputs, enabling targeted network generation. As a case study, we statistically reproduce four disordered biophotonic networks exhibiting structural color. This work presents a versatile method for generating disordered networks with tailored structural properties. It will enable new insights into structure-property relations, such as photonic band gaps in disordered networks.", "AI": {"tldr": "Extended Wooten-Weaire-Winer algorithm for generating disordered spatial networks with arbitrary coordination numbers using bond repulsion in Keating strain energy, enabling targeted disorder and structural property control via neural network prediction.", "motivation": "Existing methods for generating disordered spatial networks are limited to specific coordination numbers (\u22644) and lack control over structural properties needed for studying complex wave phenomena like localization, diffusion, and band gaps in disordered systems.", "method": "Extended the Wooten-Weaire-Winer algorithm by introducing bond repulsion in the Keating strain energy to handle arbitrary coordination numbers. Controlled disorder through bond-bending force constant and temperature profile variations. Used order metrics in direct/reciprocal space to analyze structural properties. Trained a feedforward neural network to predict structural characteristics from algorithm inputs for targeted network generation.", "result": "Successfully generated disordered networks with tailored structural properties, demonstrated by statistically reproducing four disordered biophotonic networks exhibiting structural color. The neural network accurately predicts structural characteristics from algorithm parameters.", "conclusion": "Developed a versatile method for generating disordered networks with controlled structural properties, enabling new insights into structure-property relations such as photonic band gaps in disordered networks."}}
{"id": "2601.10427", "categories": ["cond-mat.dis-nn", "math-ph", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10427", "abs": "https://arxiv.org/abs/2601.10427", "authors": ["Pierre Bousseyroux", "Marc Potters"], "title": "The eigenvalues and eigenvectors of finite-rank normal perturbations of large rotationally invariant non-Hermitian matrices", "comment": null, "summary": "We study finite-rank normal deformations of rotationally invariant non-Hermitian random matrices. Extending the classical Baik-Ben Arous-P\u00e9ch\u00e9 (BBP) framework, we characterize the emergence and fluctuations of outlier eigenvalues in models of the form $\\mathbf{A} + \\mathbf{T}$, where $\\mathbf{A}$ is a large rotationally invariant non-Hermitian random matrix and $\\mathbf{T}$ is a finite-rank normal perturbation. We also describe the corresponding eigenvector behavior. Our results provide a unified framework encompassing both Hermitian and non-Hermitian settings, thereby generalizing several known cases.", "AI": {"tldr": "Finite-rank normal deformations of rotationally invariant non-Hermitian random matrices: characterization of outlier eigenvalues and eigenvector behavior, generalizing BBP framework.", "motivation": "Extend the classical Baik-Ben Arous-P\u00e9ch\u00e9 (BBP) framework from Hermitian to non-Hermitian random matrices, providing a unified theory for outlier eigenvalue emergence and fluctuations in deformed random matrix models.", "method": "Study models of the form A + T, where A is a large rotationally invariant non-Hermitian random matrix and T is a finite-rank normal perturbation. Analyze the spectral properties through mathematical analysis of the deformed matrix structure.", "result": "Characterize the emergence and fluctuations of outlier eigenvalues, describe corresponding eigenvector behavior, and provide a unified framework that encompasses both Hermitian and non-Hermitian settings, generalizing several known cases.", "conclusion": "The work establishes a comprehensive theory for finite-rank normal deformations of rotationally invariant non-Hermitian random matrices, extending classical results and providing a unified framework for understanding outlier phenomena in both Hermitian and non-Hermitian contexts."}}
{"id": "2601.09754", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09754", "abs": "https://arxiv.org/abs/2601.09754", "authors": ["Seungbeom Choi"], "title": "Limits of Rank Recovery in Bilinear Observation Problems", "comment": "10 pages, 5 figures", "summary": "Bilinear observation problems arise in many physical and information-theoretic settings, where observables and states enter multiplicatively. Rank-based diagnostics are commonly used in such problems to assess the effective dimensionality accessible to observation, often under the implicit assumption that rank deficiency can be resolved through numerical refinement. Here we examine this assumption by analyzing the rank and nullity of a bilinear observation operator under systematic tolerance variation. Rather than focusing on a specific reconstruction algorithm, we study the operator directly and identify extended rank plateaus that persist across broad tolerance ranges. These plateaus indicate stable dimensional deficits that are not removed by refinement procedures applied within a fixed problem definition. To investigate the origin of this behavior, we resolve the nullspace into algebraic sectors defined by the block structure of the variables. The nullspace exhibits a pronounced but nonexclusive concentration in specific sectors, revealing an organized internal structure rather than uniform dimensional loss. Comparing refinement with explicit modification of the problem formulation further shows that rank recovery in the reported setting requires a change in the structure of the observation problem itself. Here, \"problem modification\" refers to changes that alter the bilinear observation structure (e.g., admissible operator/state families or coupling constraints), in contrast to refinements that preserve the original formulation such as tolerance adjustment and numerical reparameterizations. Together, these results delineate limits of rank recovery in bilinear observation problems and clarify the distinction between numerical refinement and problem modification in accessing effective dimensional structure.", "AI": {"tldr": "Bilinear observation problems exhibit stable rank plateaus that persist across tolerance variations, indicating dimensional deficits not resolved by numerical refinement but requiring structural problem modification.", "motivation": "To examine the assumption that rank deficiency in bilinear observation problems can be resolved through numerical refinement, and to understand the limits of rank recovery in such problems.", "method": "Analyzed rank and nullity of bilinear observation operators under systematic tolerance variation, studied the operator directly rather than specific reconstruction algorithms, resolved nullspace into algebraic sectors defined by variable block structure, and compared refinement with explicit problem modification.", "result": "Identified extended rank plateaus persisting across broad tolerance ranges, revealing stable dimensional deficits. Nullspace exhibits pronounced but nonexclusive concentration in specific algebraic sectors, showing organized internal structure. Rank recovery requires changing the bilinear observation structure itself, not just numerical refinements.", "conclusion": "Bilinear observation problems have inherent dimensional limitations that cannot be overcome by numerical refinement alone; structural problem modification is necessary for rank recovery, clarifying the distinction between refinement and modification in accessing effective dimensional structure."}}
{"id": "2601.09763", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09763", "abs": "https://arxiv.org/abs/2601.09763", "authors": ["Ashish Kumar Patra", "Saikumar Krithivasan"], "title": "Fractional Revival Dynamics in Kerr-Type Systems: Angular Momentum Moments and Classical Analogs", "comment": "42 pages, 24 figures", "summary": "Wave packet revivals and fractional revivals are hallmark quantum interference phenomena that arise in systems with nonlinear energy spectra, and their signatures in expectation values of observables have been studied extensively in earlier work. In this article, we build on these studies and extend the analysis in two important directions. First, we investigate fractional revival dynamics in angular momentum observables, deriving explicit expressions for the time evolution of their moments and demonstrating that higher-order angular momentum moments provide clear and selective signatures of fractional revivals. Second, we examine classical analogs of quantum revival phenomena and elucidate structural similarities between quantum fractional revivals and recurrence behavior in representative classical systems. Using the Kerr-type nonlinear Hamiltonian as a paradigmatic model, we analyze the autocorrelation function, moment dynamics, and phase-space structures, supported by visualizations such as quantum carpets. Our results broaden the range of experimentally accessible diagnostics of fractional revivals and provide a unified perspective on revival phenomena across quantum and classical dynamical systems.", "AI": {"tldr": "Analysis of fractional revival dynamics in angular momentum observables and classical analogs of quantum revival phenomena using Kerr-type nonlinear Hamiltonian model.", "motivation": "To extend previous studies on quantum revival phenomena by investigating fractional revivals in angular momentum observables and exploring classical analogs of quantum revival phenomena, providing a unified perspective across quantum and classical systems.", "method": "Using Kerr-type nonlinear Hamiltonian as paradigmatic model, analyzing autocorrelation function, moment dynamics, and phase-space structures with visualizations like quantum carpets. Deriving explicit expressions for time evolution of angular momentum moments.", "result": "Higher-order angular momentum moments provide clear and selective signatures of fractional revivals. Structural similarities identified between quantum fractional revivals and recurrence behavior in classical systems.", "conclusion": "Results broaden experimentally accessible diagnostics of fractional revivals and provide unified perspective on revival phenomena across quantum and classical dynamical systems."}}
{"id": "2601.09769", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09769", "abs": "https://arxiv.org/abs/2601.09769", "authors": ["S. Radenkovic", "M. Dugic", "I. Radojevic"], "title": "Three questions on the future of quantum science and technology", "comment": "The Editorial Board of the Kragujevac Journal of Science decided to ask the prominent researchers and scholars to take part in the poll on the status and the future of Quantum Science and Technology", "summary": "The answers on the current status and future development of Quantum Science and Technology are presented.", "AI": {"tldr": "Analysis of current status and future development of Quantum Science and Technology", "motivation": "To provide comprehensive insights into the present state and future trajectory of Quantum Science and Technology, addressing both current achievements and upcoming challenges in this rapidly evolving field.", "method": "Systematic review and analysis of existing quantum technologies, theoretical frameworks, experimental implementations, and development roadmaps across various quantum domains including computing, communication, sensing, and simulation.", "result": "Current quantum technologies have achieved significant milestones in quantum computing (qubit coherence, gate fidelities), quantum communication (entanglement distribution, QKD networks), and quantum sensing (precision measurements). However, challenges remain in scalability, error correction, and practical implementation.", "conclusion": "Quantum Science and Technology is transitioning from fundamental research to practical applications, with future development requiring advances in materials, control systems, and integration technologies to realize full-scale quantum advantage across multiple domains."}}
{"id": "2601.09779", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09779", "abs": "https://arxiv.org/abs/2601.09779", "authors": ["Jan Carlo Schumann", "Igor Lesanovsky", "Parvinder Solanki"], "title": "Hierarchical time crystals", "comment": null, "summary": "Spontaneous symmetry breaking is one of the central organizing principles in physics. Time crystals have emerged as an exotic phase of matter, spontaneously breaking the time translational symmetry, and are mainly categorized as discrete or continuous. While these distinct types of time crystals have been extensively explored as standalone systems, intriguing effects can arise from their mutual interaction. Here, we demonstrate that a time-independent coupled system of discrete and continuous time crystals induces a simultaneous two-fold temporal symmetry breaking, resulting in a hierarchical time crystal phase. Interestingly, one of the subsystems breaks an emergent discrete temporal symmetry that does not exist in the dynamical generator but rather emerges dynamically, leading to a convoluted non-equilibrium phase. We demonstrate that hierarchical time crystals are robust, emerging for fundamentally different coupling schemes and persisting across wide ranges of system parameters.", "AI": {"tldr": "A hierarchical time crystal phase emerges from coupling discrete and continuous time crystals, resulting in simultaneous two-fold temporal symmetry breaking with emergent discrete symmetry.", "motivation": "While discrete and continuous time crystals have been studied separately, their mutual interaction could reveal novel non-equilibrium phases and emergent phenomena beyond standalone systems.", "method": "Time-independent coupled system of discrete and continuous time crystals, studied across different coupling schemes and wide parameter ranges.", "result": "Demonstrates robust hierarchical time crystal phase with simultaneous two-fold temporal symmetry breaking, where one subsystem breaks an emergent discrete temporal symmetry that arises dynamically rather than from the generator.", "conclusion": "Hierarchical time crystals represent a convoluted non-equilibrium phase that emerges robustly from coupling distinct types of time crystals, revealing novel symmetry breaking phenomena."}}
{"id": "2601.09786", "categories": ["quant-ph", "cs.IT", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09786", "abs": "https://arxiv.org/abs/2601.09786", "authors": ["Marco Dalai", "Filippo Girardi", "Ludovico Lami"], "title": "Zero-Error List Decoding for Classical-Quantum Channels", "comment": "5+1 pages, 1 figure", "summary": "The aim of this work is to study the zero-error capacity of pure-state classical-quantum channels in the setting of list decoding. We provide an achievability bound for list-size two and a converse bound holding for every fixed list size. The two bounds coincide for channels whose pairwise absolute state overlaps form a positive semi-definite matrix. Finally, we discuss a remarkable peculiarity of the classical-quantum case: differently from the fully classical setting, the rate at which the sphere-packing bound diverges might not be achievable by zero-error list codes, even when we take the limit of fixed but arbitrarily large list size.", "AI": {"tldr": "Study of zero-error capacity for pure-state classical-quantum channels with list decoding, providing achievability bound for list-size 2 and general converse bound, identifying conditions where bounds match, and revealing quantum peculiarity where sphere-packing bound divergence rate may not be achievable even with arbitrarily large list size.", "motivation": "To investigate zero-error capacity in the context of pure-state classical-quantum channels with list decoding, addressing fundamental limits of reliable communication when exact message recovery is required but with allowance for a small list of candidate messages.", "method": "Develop achievability bound for list-size two and general converse bound applicable to any fixed list size. Analyze channels where pairwise absolute state overlaps form positive semi-definite matrices. Compare with classical case and examine divergence behavior of sphere-packing bound.", "result": "Achievability and converse bounds are established, coinciding for channels with positive semi-definite pairwise overlap matrices. A key finding: unlike classical setting, the rate at which sphere-packing bound diverges might not be achievable by zero-error list codes even with arbitrarily large list size, revealing fundamental quantum limitation.", "conclusion": "The work provides fundamental bounds on zero-error capacity with list decoding for pure-state classical-quantum channels, identifies specific channel classes where bounds are tight, and uncovers a distinctive quantum phenomenon where classical intuition about achievable rates with large list sizes fails."}}
{"id": "2601.09792", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09792", "abs": "https://arxiv.org/abs/2601.09792", "authors": ["Ricard Puig", "Nathan Constantinides", "Bharath Hebbe Madhusudhana", "Daniel Bowring", "C. Huerta Alderete", "Andrew T. Sornborger"], "title": "Background cancellation for frequency-selective quantum sensing", "comment": "5 + 11 pages, 3 figures", "summary": "A key challenge in quantum sensing is the detection of weak time dependent signals, particularly those that arise as specific frequency perturbations over a background field. Conventional methods usually demand complex dynamical control of the quantum sensor and heavy classical post-processing. We propose a quantum sensor that leverages time independent interactions and entanglement to function as a passive, tunable, thresholded frequency filter. By encoding the frequency selectivity and thresholding behavior directly into the dynamics, the sensor is responsive only to a target frequency of choice whose amplitude is above a threshold. This approach circumvents the need for complex control schemes and reduces the post-processing overhead.", "AI": {"tldr": "A quantum sensor using time-independent interactions and entanglement as a passive, tunable frequency filter that responds only to target frequencies above a threshold, eliminating complex control and heavy post-processing.", "motivation": "Current quantum sensing methods for detecting weak time-dependent signals require complex dynamical control and heavy classical post-processing, creating implementation challenges.", "method": "Leverages time-independent interactions and entanglement to create a passive, tunable, thresholded frequency filter that encodes frequency selectivity and thresholding directly into the sensor dynamics.", "result": "The sensor becomes responsive only to a target frequency of choice whose amplitude is above a threshold, functioning as an autonomous frequency-selective detector.", "conclusion": "This approach circumvents the need for complex control schemes and reduces post-processing overhead in quantum sensing applications."}}
{"id": "2601.09817", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09817", "abs": "https://arxiv.org/abs/2601.09817", "authors": ["L. L. Salcedo"], "title": "Localization of quantum states within subspaces", "comment": "15 pages, 4 figures, 1 table", "summary": "A precise definition is proposed for the localization probability of a quantum state within a given subspace of the full Hilbert space of a quantum system. The corresponding localized component of the state is explicitly identified, and several mathematical properties are established. Applications and interpretations in the context of quantum information are also discussed.", "AI": {"tldr": "The paper proposes a formal definition for localization probability of quantum states within subspaces, identifies localized components, establishes mathematical properties, and discusses quantum information applications.", "motivation": "To provide a rigorous mathematical framework for quantifying how quantum states are localized within specific subspaces of a system's Hilbert space, addressing a fundamental aspect of quantum state characterization that has applications in quantum information processing.", "method": "Proposes a precise mathematical definition for localization probability, explicitly identifies the localized component of quantum states, and establishes formal mathematical properties of this localization measure.", "result": "Develops a formal definition of localization probability, identifies the localized state component, establishes mathematical properties of the localization measure, and provides quantum information interpretations.", "conclusion": "The paper establishes a rigorous mathematical framework for quantifying quantum state localization within subspaces, with demonstrated relevance to quantum information theory and potential applications in quantum computation and information processing."}}
{"id": "2601.09850", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09850", "abs": "https://arxiv.org/abs/2601.09850", "authors": ["Meng-Yuan Li", "Yue Wu"], "title": "Fragmented Topological Excitations in Generalized Hypergraph Product Codes", "comment": "12 pages, 10 figures", "summary": "Product code construction is a powerful tool for constructing quantum stabilizer codes, which serve as a promising paradigm for realizing fault-tolerant quantum computation. Furthermore, the natural mapping between stabilizer codes and the ground states of exactly solvable spin models also motivates the exploration of many-body orders in the stabilizer codes. In this work, we investigate the fracton topological orders in a family of codes obtained by a recently proposed general construction. More specifically, this code family can be regarded as a class of generalized hypergraph product (HGP) codes. We term the corresponding exactly solvable spin models \\textit{orthoplex models}, based on the geometry of the stabilizers. In the 3D orthoplex model, we identify a series of intriguing properties within this model family, including non-monotonic ground state degeneracy (GSD) as a function of system size and non-Abelian lattice defects. Most remarkably, in 4D we discover \\textit{fragmented topological excitations}: while such excitations manifest as discrete, isolated points in real space, their projections onto lower-dimensional subsystems form connected objects such as loops, revealing the intrinsic topological nature of these excitations. Therefore, fragmented excitations constitute an intriguing intermediate class between point-like and spatially extended topological excitations. In addition, these rich features establish the generalized HGP codes as a versatile and analytically tractable platform for studying the physics of fracton orders.", "AI": {"tldr": "Generalized hypergraph product codes reveal fracton topological orders with non-monotonic ground state degeneracy, non-Abelian defects, and novel fragmented excitations in 4D.", "motivation": "To investigate fracton topological orders in a family of codes obtained via a general construction, specifically generalized hypergraph product codes, and explore their connection to exactly solvable spin models called orthoplex models.", "method": "Analysis of generalized hypergraph product codes as a class of quantum stabilizer codes, mapping them to exactly solvable orthoplex spin models based on stabilizer geometry, with investigation of properties in 3D and 4D.", "result": "In 3D orthoplex models: non-monotonic ground state degeneracy as function of system size and non-Abelian lattice defects. In 4D: discovery of fragmented topological excitations - point-like in real space but projecting to connected objects (loops) in lower dimensions, representing intermediate class between point-like and extended excitations.", "conclusion": "Generalized HGP codes provide versatile, analytically tractable platform for studying fracton orders, revealing rich features including fragmented excitations that bridge point-like and spatially extended topological excitations."}}
{"id": "2601.09854", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09854", "abs": "https://arxiv.org/abs/2601.09854", "authors": ["Ben Lang"], "title": "Multi-level quantum emitter in an optical waveguide: paradoxes and resolutions", "comment": "15 pages, 4 figures", "summary": "We theoretically investigate the optical dipole interaction between a multi-level quantum system and a single-mode optical waveguide of any local polarisation. We investigate several paradoxical seeming situations, for example we find a situation in which there exist two non-orthogonal quantum states, each of which results in a photon flux in the opposite direction to the other. We show how, despite appearances, this does not break the unitary requirements of quantum mechanics. We also find that an isotropic quantum emitter can be either reflective or transmissive to light depending on the waveguide polarisation at the emitter location, indeed in the zero loss limit such a system changes from 100% transmission to 100% reflection due to an infinitesimal polarisation rotation. An example case for a four level system is also considered, which is found to operate as a non-destructive parity measurement of the photon number.", "AI": {"tldr": "Theoretical investigation of optical dipole interactions between multi-level quantum systems and single-mode waveguides with arbitrary local polarization, revealing paradoxical directional photon flux effects and polarization-dependent transmission/reflection behavior.", "motivation": "To explore fundamental quantum optical phenomena in waveguide-QED systems, particularly paradoxical situations where non-orthogonal quantum states produce opposite photon flux directions, and to understand polarization-dependent behavior of isotropic emitters.", "method": "Theoretical analysis of optical dipole interactions between multi-level quantum systems and single-mode optical waveguides with arbitrary local polarization. Mathematical modeling of paradoxical directional photon flux scenarios and polarization-dependent transmission/reflection properties. Consideration of a specific four-level system example.", "result": "Discovery of paradoxical situations where non-orthogonal quantum states produce photon fluxes in opposite directions without violating quantum unitarity. Demonstration that isotropic quantum emitters can switch between 100% transmission and 100% reflection with infinitesimal polarization rotations in the zero-loss limit. Identification of a four-level system that functions as a non-destructive parity measurement of photon number.", "conclusion": "The study reveals counterintuitive quantum optical phenomena in waveguide systems, showing that apparent paradoxes can be resolved within unitary quantum mechanics framework, and demonstrates practical applications like non-destructive parity measurements through careful polarization engineering."}}
{"id": "2601.09911", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09911", "abs": "https://arxiv.org/abs/2601.09911", "authors": ["Younghun Kim", "Spiro Gicev", "Martin Sevior", "Muhammad Usman"], "title": "Time-Dynamic Circuits for Fault-Tolerant Shift Automorphisms in Quantum LDPC Codes", "comment": "16 pages, 8 figures", "summary": "Quantum low-density parity-check (qLDPC) codes have emerged as a promising approach for realizing low-overhead logical quantum memories. Recent theoretical developments have established shift automorphisms as a fundamental building block for completing the universal set of logical gates for qLDPC codes. However, practical challenges remain because the existing SWAP-based shift automorphism yields logical error rates that are orders of magnitude higher than those for fault-tolerant idle operations. In this work, we address this issue by dynamically varying the syndrome measurement circuits to implement the shift automorphisms without reducing the circuit distance. We benchmark our approach on both twisted and untwisted weight-6 generalized toric codes, including the gross code family. Our time-dynamic circuits for shift automorphisms achieve performance comparable to the idle operations under the circuit-level noise model (SI1000). Specifically, the dynamic circuits achieve more than an order of magnitude reduction in logical error rates relative to the SWAP-based scheme for the gross code at a physical error rate of $10^{-3}$, employing the BP-OSD decoder. Our findings improve both the error resilience and the time overhead of the shift automorphisms in qLDPC codes. Furthermore, our work can lead to alternative syndrome extraction circuit designs, such as leakage removal protocols, providing a practical pathway to utilizing dynamic circuits that extend beyond surface codes towards qLDPC codes.", "AI": {"tldr": "Dynamic syndrome measurement circuits enable shift automorphisms in qLDPC codes without SWAP operations, achieving logical error rates comparable to idle operations and significantly outperforming SWAP-based approaches.", "motivation": "Shift automorphisms are essential for completing universal gate sets in qLDPC codes, but existing SWAP-based implementations suffer from orders-of-magnitude higher logical error rates compared to fault-tolerant idle operations, creating a practical bottleneck.", "method": "Dynamically varying syndrome measurement circuits to implement shift automorphisms without reducing circuit distance, avoiding SWAP operations. Benchmarking on twisted and untwisted weight-6 generalized toric codes (including gross code family) using time-dynamic circuits under circuit-level noise model (SI1000) with BP-OSD decoder.", "result": "Dynamic circuits achieve logical error rates comparable to idle operations, with more than an order of magnitude reduction relative to SWAP-based scheme for gross code at physical error rate of 10^-3. Performance improvements demonstrated across both twisted and untwisted weight-6 generalized toric codes.", "conclusion": "Dynamic circuits significantly improve both error resilience and time overhead of shift automorphisms in qLDPC codes, providing a practical pathway beyond surface codes. The approach enables alternative syndrome extraction circuit designs and can facilitate leakage removal protocols."}}
{"id": "2601.09921", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09921", "abs": "https://arxiv.org/abs/2601.09921", "authors": ["Kai Zhang", "Zhengzhong Yi", "Shaojun Guo", "Linghang Kong", "Situ Wang", "Xiaoyu Zhan", "Tan He", "Weiping Lin", "Tao Jiang", "Dongxin Gao", "Yiming Zhang", "Fangming Liu", "Fang Zhang", "Zhengfeng Ji", "Fusheng Chen", "Jianxin Chen"], "title": "Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction", "comment": "The main text consists of 25 pages and 9 figures, extending our prior work (arXiv:2509.03815) with new results on surface code decoding in superconducting qubit systems and real-time performance benchmarks on TPU v6e", "summary": "Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation (FTQC). Neural network decoders like AlphaQubit have demonstrated potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders lack the parallelism required to decode the syndrome stream generated by a superconducting logical qubit in real time. Moreover, integrating AlphaQubit with sliding window-based parallel decoding schemes presents non-trivial challenges: AlphaQubit is trained solely to output a single bit corresponding to the global logical correction for an entire memory experiment, rather than local physical corrections that can be easily integrated. We address this issue by training a recurrent, transformer-based neural network specifically tailored for parallel window decoding. While it still outputs a single bit, we derive training labels from a consistent set of local corrections and train on various types of decoding windows simultaneously. This approach enables the network to self-coordinate across neighboring windows, facilitating high-accuracy parallel decoding of arbitrarily long memory experiments.\n  As a result, we overcome the throughput bottleneck that previously precluded the use of AlphaQubit-type decoders in FTQC. Our work presents the first scalable, neural-network-based parallel decoding framework that simultaneously achieves SOTA accuracy and the stringent throughput required for real-time quantum error correction. Using an end-to-end experimental workflow, we benchmark our decoder on the Zuchongzhi 3.2 superconducting quantum processor on surface codes with distances up to 7, demonstrating its superior accuracy. Moreover, we demonstrate that, using our approach, a single TPU v6e is capable of decoding surface codes with distances up to 25 within 1us per decoding round.", "AI": {"tldr": "A neural network decoder for quantum error correction that enables real-time parallel decoding of surface codes, overcoming throughput bottlenecks while maintaining state-of-the-art accuracy.", "motivation": "Existing neural network decoders like AlphaQubit lack the parallelism needed for real-time decoding of superconducting logical qubits, and integrating them with parallel window decoding schemes is challenging due to their training for global logical corrections rather than local physical corrections.", "method": "Train a recurrent, transformer-based neural network specifically for parallel window decoding. Derive training labels from consistent local corrections and train on various decoding window types simultaneously, enabling self-coordination across neighboring windows for high-accuracy parallel decoding of long memory experiments.", "result": "Overcomes throughput bottleneck preventing AlphaQubit-type decoders in FTQC; achieves SOTA accuracy with required throughput for real-time QEC; benchmarks on Zuchongzhi 3.2 processor with surface codes up to distance 7 show superior accuracy; single TPU v6e can decode surface codes up to distance 25 within 1\u03bcs per round.", "conclusion": "Presents the first scalable neural-network-based parallel decoding framework that simultaneously achieves state-of-the-art accuracy and the stringent throughput required for real-time quantum error correction, enabling practical fault-tolerant quantum computation."}}
{"id": "2601.09938", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09938", "abs": "https://arxiv.org/abs/2601.09938", "authors": ["Akitada Sakurai", "Aoi Hayashi", "Tadayoshi Matumori", "Daisuke Kaji", "Tadashi Kadowaki", "Kae Nemoto"], "title": "Beyond Optimization: Harnessing Quantum Annealer Dynamics for Machine Learning", "comment": "6pages, 3 figures", "summary": "Quantum annealing is typically regarded as a tool for combinatorial optimization, but its coherent dynamics also offer potential for machine learning. We present a model that encodes classical data into an Ising Hamiltonian, evolves it on a quantum annealer, and uses the resulting probability distributions as feature maps for classification. Experiments on the quantum annealer machine with the Digits dataset, together with simulations on MNIST, demonstrate that short annealing times yield higher classification accuracy, while longer times reduce accuracy but lower sampling costs. We introduce the participation ratio as a measure of the effective model size and show its strong correlation with generalization.", "AI": {"tldr": "Quantum annealing used for machine learning by encoding classical data into Ising Hamiltonians, evolving on quantum annealer, and using resulting probability distributions as feature maps for classification.", "motivation": "Quantum annealing is typically viewed only for combinatorial optimization, but its coherent dynamics offer potential for machine learning applications beyond traditional optimization tasks.", "method": "Encode classical data into Ising Hamiltonian, evolve on quantum annealer, use resulting probability distributions as feature maps for classification; introduce participation ratio as measure of effective model size.", "result": "Experiments on quantum annealer with Digits dataset and simulations on MNIST show short annealing times yield higher classification accuracy, longer times reduce accuracy but lower sampling costs; participation ratio strongly correlates with generalization.", "conclusion": "Quantum annealing can be effectively used for machine learning beyond combinatorial optimization, with annealing time trade-offs between accuracy and sampling cost, and participation ratio serving as useful generalization metric."}}
{"id": "2601.09943", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09943", "abs": "https://arxiv.org/abs/2601.09943", "authors": ["Darrell Teegarden", "Allison Casey", "F. Gino Serpa", "Patrick Becker", "Asmita Brahme", "Saanvi Kataria", "Paul Lopata"], "title": "Three Months in the Life of Cloud Quantum Computing", "comment": null, "summary": "Quantum Computing (QC) has evolved from a few custom quantum computers, which were only accessible to their creators, to an array of commercial quantum computers that can be accessed on the cloud by anyone. Accessing these cloud quantum computers requires a complex chain of tools that facilitate connecting, programming, simulating algorithms, estimating resources, submitting quantum computing jobs, retrieving results, and more. Some steps in the chain are hardware dependent and subject to change as both hardware and software tools, such as available gate sets and optimizing compilers, evolve. Understanding the trade-offs inherent in this process is essential for evaluating the power and utility of quantum computers. ARLIS has been systematically investigating these environments to understand these complexities. The work presented here is a detailed summary of three months of using such quantum programming environments. We show metadata obtained from these environments, including the connection metrics to the different services, the execution of algorithms, the testing of the effects of varying the number of qubits, comparisons to simulations, execution times, and cost. Our objective is to provide concrete data and insights for those who are exploring the potential of quantum computing. It is not our objective to present any new algorithms or optimize performance on any particular machine or cloud platform; rather, this work is focused on providing a consistent view of a single algorithm executed using out-of-the-box settings and tools across machines, cloud platforms, and time. We present insights only available from these carefully curated data.", "AI": {"tldr": "Systematic analysis of cloud quantum computing environments over three months, documenting connection metrics, algorithm execution, qubit scaling effects, simulation comparisons, execution times, and costs across multiple platforms using out-of-the-box settings.", "motivation": "Cloud quantum computing has become accessible but requires complex toolchains that are hardware-dependent and evolving. Understanding the trade-offs in this process is essential for evaluating quantum computer utility, yet systematic empirical data on real-world cloud quantum environments is lacking.", "method": "Three-month systematic investigation using out-of-the-box settings and tools across multiple quantum machines and cloud platforms. Executed a single algorithm consistently across environments, collecting metadata on connection metrics, algorithm execution, qubit scaling effects, simulation comparisons, execution times, and costs.", "result": "Collected concrete data including connection metrics to different services, algorithm execution results, effects of varying qubit counts, comparisons to simulations, execution times, and cost metrics across platforms. Provides insights only available from carefully curated empirical data on real quantum computing environments.", "conclusion": "This work provides essential empirical data and insights for evaluating quantum computing's practical utility, focusing on consistent cross-platform comparisons rather than algorithm optimization. The curated data offers unique insights into the current state of cloud quantum computing accessible to researchers and practitioners."}}
{"id": "2601.09951", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09951", "abs": "https://arxiv.org/abs/2601.09951", "authors": ["Rylan Malarchick", "Ashton Steed"], "title": "Parallelizing the Variational Quantum Eigensolver: From JIT Compilation to Multi-GPU Scaling", "comment": null, "summary": "The Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm for computing ground state energies of molecular systems. We implement VQE to calculate the potential energy surface of the hydrogen molecule (H$_2$) across 100 bond lengths using the PennyLane quantum computing framework on an HPC cluster featuring 4$\\times$ NVIDIA H100 GPUs (80GB each). We present a comprehensive parallelization study with four phases: (1) Optimizer + JIT compilation achieving 4.13$\\times$ speedup, (2) GPU device acceleration achieving 3.60$\\times$ speedup at 4 qubits scaling to 80.5$\\times$ at 26 qubits, (3) MPI parallelization achieving 28.5$\\times$ speedup, and (4) Multi-GPU scaling achieving 3.98$\\times$ speedup with 99.4% parallel efficiency across 4 H100 GPUs. The combined effect yields 117$\\times$ total speedup for the H$_2$ potential energy surface (593.95s $\\rightarrow$ 5.04s). We conduct a CPU vs GPU scaling study from 4--26 qubits, finding GPU advantage at all scales with speedups ranging from 10.5$\\times$ to 80.5$\\times$. Multi-GPU benchmarks demonstrate near-perfect scaling with 99.4% efficiency and establish that a single H100 can simulate up to 29 qubits before hitting memory limits. The optimized implementation reduces runtime from nearly 10 minutes to 5 seconds, enabling interactive quantum chemistry exploration.", "AI": {"tldr": "VQE implementation for H2 potential energy surface achieves 117\u00d7 speedup through multi-level parallelization on HPC cluster with 4\u00d7 NVIDIA H100 GPUs, reducing runtime from ~10 minutes to 5 seconds.", "motivation": "To accelerate variational quantum eigensolver calculations for quantum chemistry applications by leveraging HPC resources and parallelization techniques to enable interactive exploration of molecular systems.", "method": "Implemented VQE for H2 molecule across 100 bond lengths using PennyLane framework on HPC cluster with 4\u00d7 NVIDIA H100 GPUs, employing four-phase parallelization: optimizer + JIT compilation, GPU acceleration, MPI parallelization, and multi-GPU scaling.", "result": "Achieved 117\u00d7 total speedup (593.95s \u2192 5.04s) for H2 potential energy surface. Individual speedups: 4.13\u00d7 from optimizer+JIT, 3.60-80.5\u00d7 from GPU acceleration (4-26 qubits), 28.5\u00d7 from MPI, and 3.98\u00d7 from multi-GPU with 99.4% parallel efficiency. Single H100 can simulate up to 29 qubits before memory limits.", "conclusion": "Comprehensive parallelization strategy enables dramatic VQE acceleration, reducing runtime from nearly 10 minutes to 5 seconds, making interactive quantum chemistry exploration feasible and demonstrating effective HPC resource utilization for quantum simulations."}}
{"id": "2601.09977", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09977", "abs": "https://arxiv.org/abs/2601.09977", "authors": ["Rikizo Ikuta"], "title": "Statistical-noise-enhanced multi-photon interference", "comment": "11 pages, 6 figures", "summary": "Photon statistics plays a governing role in multi-photon interference. While interference visibility in the standard two-photon case, known as Hong-Ou-Mandel interference, monotonically degrades with higher intensity correlation functions, we show that this monotonicity does not hold for three-photon interference in symmetric circuits. We reveal that, in the discrete Fourier transform circuit, engineered super-Poissonian photon-number fluctuations, realized using a modulated laser, maximize the visibility, surpassing the magnitude of the single-photon signature. In addition, by tuning the symmetric circuit parameters, we demonstrate that the visibility hierarchy inverts relative to the benchmark of Poissonian statistics. This trade-off implies that quantum and classical advantages are mutually exclusive resources for interference, indicating a form of statistical complementarity.", "AI": {"tldr": "Non-monotonic relationship between photon statistics and interference visibility in multi-photon systems, with engineered super-Poissonian statistics maximizing three-photon interference in symmetric circuits.", "motivation": "To investigate how photon statistics governs multi-photon interference beyond the standard two-photon case, where Hong-Ou-Mandel interference shows monotonic degradation with higher intensity correlation functions.", "method": "Analysis of three-photon interference in symmetric circuits, specifically using discrete Fourier transform circuits with engineered super-Poissonian photon-number fluctuations created via modulated laser sources.", "result": "Engineered super-Poissonian statistics maximize interference visibility in three-photon systems, surpassing single-photon signature magnitudes. Visibility hierarchy inverts relative to Poissonian benchmark by tuning symmetric circuit parameters.", "conclusion": "Quantum and classical advantages are mutually exclusive resources for interference, indicating a form of statistical complementarity where non-monotonic relationships exist between photon statistics and interference visibility in multi-photon systems."}}
{"id": "2601.09995", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09995", "abs": "https://arxiv.org/abs/2601.09995", "authors": ["Masahito Hayashi", "Jinpei Zhao"], "title": "Double Markovity for quantum systems", "comment": null, "summary": "The subadditivity-doubling-rotation (SDR) technique is a powerful route to Gaussian optimality in classical information theory and relies on strict subadditivity and its equality-case analysis, where double Markovity is a standard tool. We establish quantum analogues of double Markovity. For tripartite states, we characterize the simultaneous Markov conditions A-B-C and A-C-B via compatible projective measurements on B and C that induce a common classical label J yielding A-J-(BC). For strictly positive four-party states, we show that A-(BD)-C and A-(CD)-B hold if and only if A-D-(BC) holds. These results remove a key bottleneck in extending SDR-type arguments to quantum systems.", "AI": {"tldr": "Quantum analogues of double Markovity established for tripartite and four-party states, enabling extension of SDR technique to quantum systems.", "motivation": "The SDR technique is powerful for Gaussian optimality in classical information theory but relies on double Markovity. Extending SDR to quantum systems requires quantum analogues of double Markovity, which was a key bottleneck.", "method": "For tripartite states: characterize simultaneous Markov conditions A-B-C and A-C-B via compatible projective measurements on B and C inducing common classical label J. For four-party states: show A-(BD)-C and A-(CD)-B hold iff A-D-(BC) holds for strictly positive states.", "result": "Established quantum analogues of double Markovity: 1) For tripartite states, simultaneous Markov conditions characterized by compatible measurements inducing common classical label. 2) For four-party positive states, equivalence between different Markov chain conditions proven.", "conclusion": "These results remove the key bottleneck in extending SDR-type arguments to quantum systems by providing the necessary quantum analogues of double Markovity."}}
{"id": "2601.09997", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.09997", "abs": "https://arxiv.org/abs/2601.09997", "authors": ["Guo-Qing Zhang", "L. F. Quezada", "Shi-Hai Dong"], "title": "Reentrant topological phases and entanglement scalings in moir\u00e9-modulated extended Su-Schrieffer-Heeger Model", "comment": "10 pages, 7 figures", "summary": "Recent studies of moir\u00e9 physics have unveiled a wealth of opportunities for significantly advancing the field of quantum phase transitions. However, properties of reentrant phase transitions driven by moir\u00e9 strength are poorly understood. Here, we investigate the reentrant sequence of phase transitions and the invariant of universality class in moir\u00e9-modulated extended Su-Schrieffer-Heeger (SSH) model. For the simplified case with intercell hopping $w=0$, we analytically derive renormalization relations of Hamiltonian parameters to explain the reentrant phenomenon. For the general case, numerical phase boundaries are calculated in the thermodynamic limit. The bulk boundary correspondence between zero-energy edge modes and entanglement spectrum is revealed from the degeneracy of both quantities. We also address the correspondence between the central charge obtained from entanglement entropy and the change in winding number during the phase transition. Our results shed light on the understanding of universal characteristics and bulk-boundary correspondence for moir\u00e9 induced reentrant phase transitions in 1D condensed-matter systems.", "AI": {"tldr": "The paper studies reentrant phase transitions in moir\u00e9-modulated 1D SSH models, analyzing universality classes, bulk-boundary correspondence, and entanglement properties.", "motivation": "Moir\u00e9 physics offers opportunities for advancing quantum phase transitions, but reentrant phase transitions driven by moir\u00e9 strength are poorly understood. The paper aims to investigate these phenomena in 1D systems.", "method": "For the simplified case (w=0), analytical derivation of renormalization relations; for general cases, numerical calculation of phase boundaries in thermodynamic limit. Analysis of bulk-boundary correspondence via zero-energy edge modes and entanglement spectrum degeneracy, and correspondence between central charge from entanglement entropy and winding number changes.", "result": "Analytical explanation of reentrant phenomenon through renormalization relations, numerical phase boundaries, revelation of bulk-boundary correspondence via degeneracy patterns, and demonstration of correspondence between central charge and winding number changes during phase transitions.", "conclusion": "The results provide insights into universal characteristics and bulk-boundary correspondence for moir\u00e9-induced reentrant phase transitions in 1D condensed matter systems, advancing understanding of these phenomena."}}
{"id": "2601.10034", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10034", "abs": "https://arxiv.org/abs/2601.10034", "authors": ["Song-Ju Kim"], "title": "Contextuality Derived from Minimal Decision Dynamics: Quantum Tug-of-War Decision Making", "comment": "This work addresses contextuality and non-Kolmogorovian probability as structural properties of decision dynamics, without assuming quantum physical substrates", "summary": "Decision making often exhibits context dependence that challenges classical probability theory. While quantum cognition has successfully modeled such phenomena, it remains unclear whether quantum probability is merely a convenient assumption or a necessary consequence of decision dynamics. Here we present a theoretical framework in which contextuality arises generatively from physically grounded constraints on decision making. By developing a quantum extension of the Tug-of-War (TOW) model, we show that conservation-based internal state updates and measurement-induced disturbance preclude any non-contextual classical description with a single, unified internal state. Contextuality therefore emerges as a structural consequence of adaptive learning dynamics. We further show that the resulting measurement structure admits Klyachko-Can-Binicioglu-Shumovsky (KCBS)-type contextuality witnesses in a minimal single-system setting. These results indicate that quantum probability is not merely a descriptive convenience, but an unavoidable effective theory for adaptive decision dynamics.", "AI": {"tldr": "Quantum probability emerges as necessary for adaptive decision making due to conservation-based state updates and measurement disturbance, not just as descriptive convenience.", "motivation": "To determine whether quantum probability in decision making is merely a convenient modeling assumption or a necessary consequence of underlying decision dynamics, addressing the fundamental question of why context dependence requires quantum formalisms.", "method": "Developed a quantum extension of the Tug-of-War (TOW) model, incorporating conservation-based internal state updates and measurement-induced disturbance to show these physical constraints preclude non-contextual classical descriptions with unified internal states.", "result": "Contextuality arises generatively from adaptive learning dynamics, and the resulting measurement structure admits KCBS-type contextuality witnesses in minimal single-system settings, demonstrating quantum probability is unavoidable for such systems.", "conclusion": "Quantum probability is not merely a descriptive convenience but an unavoidable effective theory for adaptive decision dynamics, emerging as a structural consequence of physically grounded constraints on decision making."}}
{"id": "2601.10042", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10042", "abs": "https://arxiv.org/abs/2601.10042", "authors": ["Sha Shi", "Xiao-Yang Xu", "Min-Quan Cheng", "Dong-Sheng Wang", "Yun-Jiang Wang"], "title": "Towards Minimal Fault-tolerant Error-Correction Sequence with Quantum Hamming Codes", "comment": "11pages, 1 figure", "summary": "The high overhead of fault-tolerant measurement sequences (FTMSs) poses a major challenge for implementing quantum stabilizer codes. Here, we address this problem by constructing efficient FTMSs for the class of quantum Hamming codes $[\\![2^r-1, 2^r-1-2r, 3]\\!]$ with $r=3k+1$ ($k \\in \\mathbb{Z}^+$). Our key result demonstrates that the sequence length can be reduced to exactly $2r+1$-only one additional measurement beyond the original non-fault-tolerant sequence, establishing a tight lower bound. The proposed method leverages cyclic matrix transformations to systematically combine rows of the initial stabilizer matrix and preserving a self-dual CSS-like symmetry analogous to that of the original quantum Hamming codes. This induced symmetry enables hardware-efficient circuit reuse: the measurement circuits for the first $r$ stabilizers are transformed into circuits for the remaining $r$ stabilizers simply by toggling boundary Hadamard gates, eliminating redundant hardware. For distance-3 fault-tolerant error correction, our approach simultaneously reduces the time overhead via shorting the FTMS length and the hardware overhead through symmetry-enabled circuit multiplexing. These results provide an important advance towards the important open problem regarding the design of minimal FTMSs for quantum Hamming codes and may shed light on similar challenges in other quantum stabilizer codes.", "AI": {"tldr": "The paper presents a method to construct efficient fault-tolerant measurement sequences for quantum Hamming codes, reducing sequence length to 2r+1 (just one extra measurement beyond non-fault-tolerant) while enabling hardware-efficient circuit reuse through symmetry transformations.", "motivation": "The high overhead of fault-tolerant measurement sequences poses a major challenge for implementing quantum stabilizer codes, particularly for quantum Hamming codes. There's a need to reduce both time and hardware overhead for practical quantum error correction.", "method": "The method leverages cyclic matrix transformations to systematically combine rows of the initial stabilizer matrix while preserving a self-dual CSS-like symmetry analogous to the original quantum Hamming codes. This symmetry enables hardware-efficient circuit reuse where measurement circuits for the first r stabilizers are transformed into circuits for the remaining r stabilizers simply by toggling boundary Hadamard gates.", "result": "The sequence length is reduced to exactly 2r+1 - only one additional measurement beyond the original non-fault-tolerant sequence, establishing a tight lower bound. This approach simultaneously reduces time overhead via shortened FTMS length and hardware overhead through symmetry-enabled circuit multiplexing.", "conclusion": "The results provide an important advance toward designing minimal fault-tolerant measurement sequences for quantum Hamming codes and may shed light on similar challenges in other quantum stabilizer codes, offering both time and hardware efficiency improvements for distance-3 fault-tolerant error correction."}}
{"id": "2601.10059", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10059", "abs": "https://arxiv.org/abs/2601.10059", "authors": ["Shuowei Ma", "Qianfan Wang", "Lvzhou Li", "Fei Shi"], "title": "Optimal qudit overlapping tomography and optimal measurement order", "comment": null, "summary": "Quantum state tomography is essential for characterizing quantum systems, but it becomes infeasible for large systems due to exponential resource scaling. Overlapping tomography addresses this challenge by reconstructing all $k$-body marginals using few measurement settings, enabling the efficient extraction of key information for many quantum tasks. While optimal schemes are known for qubits, the extension to higher-dimensional qudit systems remains largely unexplored. Here, we investigate optimal qudit overlapping tomography, constructing local measurement settings from generalized Gell-Mann matrices. By establishing a correspondence with combinatorial covering arrays, we present two explicit constructions of optimal measurement schemes. For $n$-qutrit systems, we prove that pairwise tomography requires at most $8 + 56\\left\\lceil \\log_{8} n \\right\\rceil$ measurement settings, and provide an explicit scheme achieving this bound. Furthermore, we develop an efficient algorithm to determine the optimal order of these measurement settings, minimizing the experimental overhead associated with switching configurations. Compared to the worst-case ordering, our optimized schedule reduces switching costs by approximately 50\\%. These results provide a practical pathway for efficient characterization of qudit systems, facilitating their application in quantum communication and computation.", "AI": {"tldr": "Optimal overlapping tomography for qudit systems using generalized Gell-Mann matrices and combinatorial covering arrays, with explicit constructions for qutrits and efficient measurement scheduling to minimize switching overhead.", "motivation": "Quantum state tomography becomes infeasible for large systems due to exponential scaling. While overlapping tomography addresses this for qubits, extension to higher-dimensional qudit systems remains largely unexplored, limiting efficient characterization of qudit-based quantum systems.", "method": "Construct local measurement settings from generalized Gell-Mann matrices, establish correspondence with combinatorial covering arrays, present two explicit constructions of optimal measurement schemes, and develop efficient algorithm to determine optimal measurement ordering to minimize switching overhead.", "result": "For n-qutrit systems, pairwise tomography requires at most 8 + 56\u2308log\u2088 n\u2309 measurement settings with explicit scheme achieving this bound. Optimized scheduling reduces switching costs by ~50% compared to worst-case ordering.", "conclusion": "Provides practical pathway for efficient characterization of qudit systems using optimal overlapping tomography with minimal measurement settings and reduced experimental overhead, facilitating qudit applications in quantum communication and computation."}}
{"id": "2601.10066", "categories": ["quant-ph", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10066", "abs": "https://arxiv.org/abs/2601.10066", "authors": ["Awanish Pandey"], "title": "Geometric Criteria for Complete Mode Conversion in Detuned Systems via Piecewise-Coherent Modulation", "comment": "6 pages, 4 figures", "summary": "Static phase detuning fundamentally constrains coherent state transfer in asymmetric classical and quantum systems. We introduce a Bloch-sphere formulation for piecewise-coherent modulation that recasts coupled-mode dynamics as geometric trajectories, transforming algebraic control into path optimization. The approach reveals a cone of inaccessibility at the target pole and yields exact geodesic criteria for complete mode conversion in detuned systems. Leveraging this framework, we break time-reversal symmetry to realize a magnet-free optical isolator with near-unity contrast. Furthermore, for detuning larger than coupling between modes, we develop a recursive multi-step protocol enabling deterministic transfer for arbitrary detunings and derive a universal geometric lower bound on the required number of coupling-switching events.", "AI": {"tldr": "Geometric control framework enables complete state transfer in detuned systems via piecewise-coherent modulation, with applications to optical isolation and universal protocols for arbitrary detunings.", "motivation": "Static phase detuning fundamentally constrains coherent state transfer in asymmetric classical and quantum systems, creating a need for control strategies that overcome this limitation.", "method": "Introduces Bloch-sphere formulation for piecewise-coherent modulation that recasts coupled-mode dynamics as geometric trajectories, transforming algebraic control into path optimization. This reveals a cone of inaccessibility and yields exact geodesic criteria for complete mode conversion.", "result": "Framework enables breaking time-reversal symmetry to realize magnet-free optical isolator with near-unity contrast. For large detuning, develops recursive multi-step protocol enabling deterministic transfer for arbitrary detunings and derives universal geometric lower bound on required coupling-switching events.", "conclusion": "Geometric control approach provides fundamental insights into state transfer limitations in detuned systems and enables practical applications including optical isolation and universal protocols for arbitrary detuning regimes."}}
{"id": "2601.10087", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10087", "abs": "https://arxiv.org/abs/2601.10087", "authors": ["Kazuki Kobayashi", "Tatsuro Yuge"], "title": "Pseudomode approach to Fano effect in dissipative cavity quantum electrodynamics", "comment": "9 pages, 2 figures", "summary": "We study the Fano effect in dissipative cavity quantum electrodynamics, which originates from the interference between the emitter's direct radiation and that mediated by a cavity mode. Starting from a two-level system coupled to a structured reservoir, we show that a quantum master equation previously derived within the Born-Markov approximation can be rederived by introducing a single auxiliary mode via pseudomode approach. We identify the corresponding spectral function of the system--environment interaction and demonstrate that it consists of a constant and a non-Lorentzian contribution forming the Fano profile. The constant term is shown to be essential for obtaining a Lindblad master equation and is directly related to the rate associated with this Fano interference. Furthermore, by applying Fano diagonalization to a common-environment setup including an explicit cavity mode, we independently derive the same spectral function in the strongest-interference regime. Our results establish a unified framework for describing the Fano effect in single-mode cavity QED systems and clarify its non-Markovian origin encoded in the spectral function.", "AI": {"tldr": "The paper establishes a unified framework for describing the Fano effect in dissipative cavity QED systems, showing how Fano interference emerges from system-environment interactions and clarifying its non-Markovian origins.", "motivation": "To understand the Fano effect in dissipative cavity quantum electrodynamics, which arises from interference between direct emitter radiation and cavity-mediated radiation, and to develop a unified theoretical framework for describing this phenomenon.", "method": "1) Starting from a two-level system coupled to a structured reservoir, rederiving a quantum master equation via pseudomode approach with a single auxiliary mode; 2) Identifying the spectral function of system-environment interaction; 3) Applying Fano diagonalization to a common-environment setup with explicit cavity mode in the strongest-interference regime.", "result": "The spectral function consists of a constant term and a non-Lorentzian contribution forming a Fano profile. The constant term is essential for obtaining a Lindblad master equation and directly relates to the Fano interference rate. The same spectral function is independently derived via Fano diagonalization, establishing consistency across different approaches.", "conclusion": "The study establishes a unified framework for describing the Fano effect in single-mode cavity QED systems and clarifies that its non-Markovian origin is encoded in the spectral function of system-environment interactions."}}
{"id": "2601.10111", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10111", "abs": "https://arxiv.org/abs/2601.10111", "authors": ["Jiwon Heo", "Sojeong Park", "Changhun Oh"], "title": "Classical simulation of a quantum circuit with noisy magic inputs", "comment": "21 pages, 5 figures", "summary": "Magic states are essential for universal quantum computation and are widely viewed as a key source of quantum advantage, yet in realistic devices they are inevitably noisy. In this work, we characterize how noise on injected magic resources changes the classical simulability of quantum circuits and when it induces a transition from classically intractable behavior to efficient classical simulation. We adopt a resource-centric noise model in which only the injected magic components are noisy, while the baseline states, operations, and measurements belong to an efficiently simulable family. Within this setting, we develop an approximate classical sampling algorithm with controlled error and prove explicit noise-dependent conditions under which the algorithm runs in polynomial time. Our framework applies to both qubit circuits with Clifford baselines and fermionic circuits with matchgate baselines, covering representative noise channels such as dephasing and particle loss. We complement the analysis with numerical estimates of the simulation cost, providing concrete thresholds and runtime scaling across practically relevant parameter regimes.", "AI": {"tldr": "The paper analyzes how noise on magic states affects classical simulability of quantum circuits, developing conditions under which noisy magic resources enable efficient classical simulation.", "motivation": "Magic states are crucial for universal quantum computation but inevitably noisy in real devices. Understanding how this noise affects classical simulability thresholds is essential for determining when quantum advantage can be maintained versus when circuits become classically tractable.", "method": "Adopts a resource-centric noise model where only injected magic components are noisy while baseline operations remain efficiently simulable. Develops an approximate classical sampling algorithm with controlled error and proves explicit noise-dependent conditions for polynomial-time simulation. Applies framework to both qubit circuits with Clifford baselines and fermionic circuits with matchgate baselines.", "result": "Establishes noise thresholds and conditions under which quantum circuits with noisy magic states become efficiently classically simulable. Provides numerical estimates of simulation cost, concrete thresholds, and runtime scaling across relevant parameter regimes for practical noise channels like dephasing and particle loss.", "conclusion": "Noise on magic resources can induce transitions from classically intractable to efficiently simulable behavior. The developed framework provides explicit noise thresholds that determine when quantum advantage is lost due to noise, offering practical guidance for assessing classical simulability in realistic quantum devices."}}
{"id": "2601.10118", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.10118", "abs": "https://arxiv.org/abs/2601.10118", "authors": ["Calum F. Shelden", "Jeremy N. Munday"], "title": "Casimir interactions as a probe of broadband optical response", "comment": "13 pages, 4 figures", "summary": "Casimir forces arise from quantum electromagnetic fluctuations and depend on the dielectric response of interacting materials across the entire frequency spectrum. Although this dependence is central to Lifshitz theory of the Casimir effect, the formulation of the force in terms of dielectric functions evaluated at imaginary frequencies has largely obscured its connection to real-frequency optical properties, limiting the use of Casimir interactions as a probe of materials. Here we demonstrate that Casimir force measurements encode sufficient information to reconstruct a material's broadband optical response. Using supervised machine learning to invert Lifshitz theory, we determine the complex permittivity of a material over more than seven orders of magnitude in frequency from a single force-distance curve. We show that measurements at different separations selectively constrain distinct frequency ranges of the dielectric response, providing direct physical insight into how quantum fluctuations sample the electromagnetic spectrum. These results establish Casimir interactions as a physically constrained, broadband spectroscopic tool and open new opportunities for optical characterization in regimes inaccessible to conventional techniques.", "AI": {"tldr": "Machine learning inversion of Lifshitz theory enables reconstruction of broadband optical permittivity from Casimir force measurements, establishing Casimir interactions as a spectroscopic tool.", "motivation": "The connection between Casimir forces and real-frequency optical properties has been obscured by Lifshitz theory's formulation in terms of imaginary frequencies, limiting Casimir interactions as a materials probe.", "method": "Supervised machine learning to invert Lifshitz theory, using Casimir force-distance measurements to reconstruct complex permittivity across seven orders of magnitude in frequency.", "result": "Demonstrated that Casimir force measurements encode sufficient information to reconstruct broadband optical response; measurements at different separations selectively constrain distinct frequency ranges of dielectric response.", "conclusion": "Establishes Casimir interactions as a physically constrained, broadband spectroscopic tool for optical characterization in regimes inaccessible to conventional techniques."}}
{"id": "2601.10144", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10144", "abs": "https://arxiv.org/abs/2601.10144", "authors": ["Xiang Fang", "Jixuan Ruan", "Sharanya Prabhu", "Ang Li", "Travis Humble", "Dean Tullsen", "Yufei Ding"], "title": "Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures", "comment": "15 pages, 7 figures", "summary": "The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers.", "AI": {"tldr": "Heterogeneous quantum architectures combining superconducting and neutral atom platforms achieve 752\u00d7 speedup over neutral atom-only systems and 10\u00d7 physical qubit reduction compared to superconducting-only systems by strategically assigning computational roles based on hardware strengths.", "motivation": "Homogeneous quantum systems have limitations where no single qubit modality offers optimal operation speed, connectivity, and scalability simultaneously. The transition to fault-tolerant quantum computing exposes these limitations, necessitating a strategic approach to leverage different hardware strengths.", "method": "Proposes Heterogeneous Quantum Architectures (HQA) combining superconducting (SC) and neutral atom (NA) platforms with two architectural strategies: (1) MagicAcc - offloads latency-critical Magic State Factory to fast SC devices while performing computation on scalable NA arrays; (2) Memory-Compute Separation (MCSep) - uses NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Evaluation uses comprehensive end-to-end cost model.", "result": "Principled heterogeneity yields significant performance gains: designs achieve 752\u00d7 speedup over NA-only baselines on average and reduce physical qubit footprint by over 10\u00d7 compared to SC-only systems.", "conclusion": "Heterogeneous quantum architectures leveraging cross-modality interconnects provide a clear pathway to optimize space-time efficiency of future fault-tolerant quantum computers by strategically combining the complementary strengths of different qubit modalities."}}
{"id": "2601.10147", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10147", "abs": "https://arxiv.org/abs/2601.10147", "authors": ["Mei-Qi Gao", "Song-hai Li", "Xun Li", "Xingli Li", "Jiong Cheng", "Wenlin Li"], "title": "Fluctuation-induced quenching of chaos in quantum optics", "comment": null, "summary": "Recent studies have extensively explored chaotic dynamics in quantum optical systems through the mean-field approximation, which corresponds to an ideal, fluctuation-free scenario. However, the inherent sensitivity of chaos to initial conditions implies that even minute fluctuations can be amplified, thereby questioning the applicability of this approximation. Here, we analyze these chaotic effects using stochastic Langevin equations or the Lindblad master equation. For systems operating at frequencies of $10^5$ to $10^7$ Hz, we demonstrate that room-temperature thermal fluctuations are sufficient to suppress chaos at the level of expectation values, even under weak nonlinearity. Furthermore, nonlinearity induces deviations from Gaussian phase-space distributions of the quantum state, revealing attractor-like features in the Wigner function. With increasing nonlinearity, the noise threshold for chaos suppression decreases, approaching the scale of vacuum fluctuations. These results provide a bidirectional validation of the quantum mechanical suppression of chaos.", "AI": {"tldr": "Thermal fluctuations at room temperature suppress chaos in quantum optical systems, with noise threshold decreasing as nonlinearity increases.", "motivation": "To investigate whether mean-field approximations in quantum optical chaos studies are valid given chaos's sensitivity to initial conditions and the presence of quantum fluctuations.", "method": "Analyzed chaotic effects using stochastic Langevin equations and Lindblad master equation for systems operating at 10^5-10^7 Hz frequencies.", "result": "Room-temperature thermal fluctuations suppress chaos at expectation value level even with weak nonlinearity; nonlinearity induces non-Gaussian phase-space distributions with attractor-like Wigner functions; noise threshold for chaos suppression decreases with increasing nonlinearity.", "conclusion": "Quantum mechanical suppression of chaos is validated bidirectionally, with vacuum fluctuations becoming sufficient for suppression at high nonlinearity."}}
{"id": "2601.10166", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.10166", "abs": "https://arxiv.org/abs/2601.10166", "authors": ["Miriam Goldack", "Yosi Atia", "Ori Alberton", "Karl Jansen"], "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware", "comment": "25 pages, 16 figures", "summary": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez.", "AI": {"tldr": "Quantum algorithms for CFD enable efficient representation of spatial fields using qubits, with methods to extract statistical properties directly from quantum circuits without full tomography.", "motivation": "Quantum CFD offers favorable scaling for representing physical fields, but efficient readout of simulation results remains a key challenge that has received limited attention in literature.", "method": "Develop methods to extract statistical properties (central moments and structure functions) of spatial velocity fields directly from parameterized ansatz circuits, avoiding full quantum state tomography. Implement approach for 1D velocity fields encoding 16 spatial points with 4 qubits.", "result": "Demonstrated high accuracy on current quantum devices (IBMQ's Heron2 system ibm_fez) using Qedma's error mitigation software QESEM, analyzing both sine wave signals and Burgers' equation snapshots.", "conclusion": "The presented methods enable efficient extraction of statistical properties from quantum CFD simulations without full tomography, demonstrating practical feasibility on current quantum hardware with error mitigation."}}
{"id": "2601.10190", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10190", "abs": "https://arxiv.org/abs/2601.10190", "authors": ["Zhiwen Lin", "Ke Li", "Kun Fang"], "title": "Exponential Analysis for Entanglement Distillation", "comment": null, "summary": "Historically, the focus in entanglement distillation has predominantly been on the distillable entanglement, and the framework assumes complete knowledge of the initial state. In this paper, we study the reliability function of entanglement distillation, which specifies the optimal exponent of the decay of the distillation error when the distillation rate is below the distillable entanglement. Furthermore, to capture greater operational significance, we extend the framework from the standard setting of known states to a black-box setting, where distillation is performed from a set of possible states. We establish an exact finite blocklength result connecting to composite correlated hypothesis testing without any redundant correction terms. Based on this, the reliability function of entanglement distillation is characterized by the regularized quantum Hoeffding divergence. In the special case of a pure initial state, our result reduces to the error exponent for entanglement concentration derived by Hayashi et al. in 2003. Given full prior knowledge of the state, we construct a concrete optimal distillation protocol. Additionally, we analyze the strong converse exponent of entanglement distillation. While all the above results assume the free operations to be non-entangling, we also investigate other free operation classes, including PPT-preserving, dually non-entangling, and dually PPT-preserving operations.", "AI": {"tldr": "The paper studies the reliability function of entanglement distillation, extending from known states to black-box settings, connecting it to composite correlated hypothesis testing and characterizing it via regularized quantum Hoeffding divergence.", "motivation": "Previous entanglement distillation research focused mainly on distillable entanglement assuming complete knowledge of initial states. This work aims to study the reliability function (optimal error exponent) when distillation rate is below distillable entanglement, and extend the framework to more operationally significant black-box settings where distillation is performed from a set of possible states.", "method": "Establishes an exact finite blocklength result connecting to composite correlated hypothesis testing without redundant correction terms. Characterizes the reliability function via regularized quantum Hoeffding divergence. Constructs concrete optimal distillation protocols for known states. Analyzes strong converse exponent and investigates various free operation classes including PPT-preserving, dually non-entangling, and dually PPT-preserving operations.", "result": "The reliability function of entanglement distillation is characterized by the regularized quantum Hoeffding divergence. For pure initial states, the result reduces to Hayashi et al.'s 2003 error exponent for entanglement concentration. An optimal distillation protocol is constructed for known states. Strong converse exponent analysis is provided, and results are extended to various free operation classes beyond non-entangling operations.", "conclusion": "The paper provides a comprehensive characterization of the reliability function for entanglement distillation in both known-state and black-box settings, connecting it to composite hypothesis testing and establishing optimal protocols. The framework extends beyond traditional non-entangling operations to include other physically relevant operation classes."}}
{"id": "2601.10194", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.10194", "abs": "https://arxiv.org/abs/2601.10194", "authors": ["Weitang Li", "Jiajun Ren", "Lixue Cheng", "Cunxi Gong"], "title": "Autonomous Quantum Simulation through Large Language Model Agents", "comment": null, "summary": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training. By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes. We benchmark three configurations (baseline, single-agent with in-context learning, and multi-agent with in-context learning) on problems spanning quantum phase transitions, open quantum system dynamics, and photochemical reactions. Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures.", "AI": {"tldr": "LLM agents can autonomously perform tensor network simulations of quantum many-body systems with ~90% success rate, using in-context learning and multi-agent decomposition to overcome the expertise barrier.", "motivation": "Tensor network methods are powerful for quantum simulation but require specialized expertise typically acquired through years of graduate training, creating a significant barrier to their effective use.", "method": "Combines in-context learning with curated documentation and multi-agent decomposition to create autonomous AI agents trained in specialized computational domains within minutes. Benchmarks three configurations: baseline, single-agent with in-context learning, and multi-agent with in-context learning on quantum phase transitions, open quantum system dynamics, and photochemical reactions.", "result": "Achieves approximately 90% success rate across representative benchmark tasks. Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Multi-agent configuration substantially reduces implementation errors and hallucinations compared to simpler architectures.", "conclusion": "LLM agents can autonomously perform complex tensor network simulations with high success rates, making quantum simulation expertise more accessible. The multi-agent architecture with in-context learning is crucial for reducing errors and hallucinations in specialized computational domains."}}
{"id": "2601.10197", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10197", "abs": "https://arxiv.org/abs/2601.10197", "authors": ["Maxwell West"], "title": "On the average-case complexity of learning states from the circular and Gaussian ensembles", "comment": "22 pages", "summary": "Studying the complexity of states sampled from various ensembles is a central component of quantum information theory. In this work we establish the average-case hardness of learning, in the statistical query model, the Born distributions of states sampled uniformly from the circular and (fermionic) Gaussian ensembles. These ensembles of states are induced variously by the uniform measures on the compact symmetric spaces of type AI, AII, and DIII. This finding complements analogous recent results for states sampled from the classical compact groups. On the technical side, we employ a somewhat unconventional approach to integrating over the compact groups which may be of some independent interest. For example, our approach allows us to exactly evaluate the total variation distances between the output distributions of Haar random unitary and orthogonal circuits and the constant distribution, which were previously known only approximately.", "AI": {"tldr": "The paper establishes average-case hardness of learning Born distributions from quantum states sampled from circular and Gaussian ensembles, complementing previous results for classical compact groups.", "motivation": "To study the complexity of states sampled from various ensembles in quantum information theory, specifically establishing the computational hardness of learning Born distributions from certain quantum state ensembles.", "method": "Uses statistical query model analysis and an unconventional approach to integrating over compact groups, focusing on symmetric spaces of type AI, AII, and DIII corresponding to circular and fermionic Gaussian ensembles.", "result": "Proves average-case hardness of learning Born distributions from states sampled uniformly from circular and Gaussian ensembles, and exactly evaluates total variation distances between output distributions of Haar random unitary/orthogonal circuits and constant distribution.", "conclusion": "The work establishes computational hardness results for learning quantum state distributions from important ensembles, providing technical tools for group integration that yield exact results where only approximations were previously known."}}
{"id": "2601.10203", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10203", "abs": "https://arxiv.org/abs/2601.10203", "authors": ["Zheng Zhao", "Weifeng Zhuang", "Yanwu Gu", "Peng Qian", "Xiao Xiao", "Dong E. Liu"], "title": "Topology-Aware Block Coordinate Descent for Qubit Frequency Calibration of Superconducting Quantum Processors", "comment": "17 pages,6 figures", "summary": "Pre-execution calibration is a major bottleneck for operating superconducting quantum processors, and qubit frequency allocation is especially challenging due to crosstalk-coupled objectives. We establish that the widely-used Snake optimizer is mathematically equivalent to Block Coordinate Descent (BCD), providing a rigorous theoretical foundation for this calibration strategy. Building on this formalization, we present a topology-aware block ordering obtained by casting order selection as a Sequence-Dependent Traveling Salesman Problem (SD-TSP) and solving it efficiently with a nearest-neighbor heuristic. The SD-TSP cost reflects how a given block choice expands the reduced-circuit footprint required to evaluate the block-local objective, enabling orders that minimize per-epoch evaluation time. Under local crosstalk/bounded-degree assumptions, the method achieves linear complexity in qubit count per epoch, while retaining calibration quality. We formalize the calibration objective, clarify when reduced experiments are equivalent or approximate to the full objective, and analyze convergence of the resulting inexact BCD with noisy measurements. Simulations on multi-qubit models show that the proposed BCD-NNA ordering attains the same optimization accuracy at markedly lower runtime than graph-based heuristics (BFS, DFS) and random orders, and is robust to measurement noise and tolerant to moderate non-local crosstalk. These results provide a scalable, implementation-ready workflow for frequency calibration on NISQ-era processors.", "AI": {"tldr": "The paper establishes that the Snake optimizer for qubit frequency calibration is equivalent to Block Coordinate Descent (BCD), proposes a topology-aware block ordering via SD-TSP with nearest-neighbor heuristic for efficiency, and demonstrates improved runtime while maintaining calibration quality.", "motivation": "Pre-execution calibration is a major bottleneck for superconducting quantum processors, with qubit frequency allocation being particularly challenging due to crosstalk-coupled objectives. Existing methods lack rigorous theoretical foundations and efficient block ordering strategies.", "method": "Formalizes the Snake optimizer as Block Coordinate Descent (BCD), casts block order selection as a Sequence-Dependent Traveling Salesman Problem (SD-TSP), solves it efficiently with a nearest-neighbor heuristic (BCD-NNA), and analyzes convergence under noisy measurements.", "result": "The proposed BCD-NNA ordering achieves linear complexity in qubit count per epoch under local crosstalk assumptions, attains same optimization accuracy at markedly lower runtime than graph-based heuristics (BFS, DFS) and random orders, and is robust to measurement noise and moderate non-local crosstalk.", "conclusion": "The work provides a scalable, implementation-ready workflow for frequency calibration on NISQ-era processors by establishing theoretical foundations for Snake optimizer, developing efficient topology-aware block ordering, and demonstrating practical advantages over existing heuristics."}}
{"id": "2601.10206", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10206", "abs": "https://arxiv.org/abs/2601.10206", "authors": ["Nirupam Basak", "Goutam Paul", "Pritam Chattopadhyay"], "title": "Noise-Resilient Quantum Evolution in Open Systems through Error-Correcting Frameworks", "comment": null, "summary": "We analyze quantum state preservation in open quantum systems using quantum error-correcting (QEC) codes that are explicitly embedded into microscopic system-bath models. Instead of abstract quantum channels, we consider multi-qubit registers coupled to bosonic thermal environments, derive a second-order master equation for the reduced dynamics, and use it to benchmark the five-qubit, Steane, and toric codes under local and collective noise. We compute state fidelities for logical qubits as functions of coupling strength, bath temperature, and the number of correction cycles. In the low-temperature regime, we find that repeated error-correction with the five-qubit code strongly suppresses decoherence and relaxation, while in the high-temperature regime, thermal excitations dominate the dynamics and reduce the benefit of all codes, though the five-qubit code still outperforms the Steane and toric codes. For two-qubit Werner states, we identify a critical evolution time before which QEC does not improve fidelity, and this time increases as entanglement grows. After this critical time, QEC does improve fidelity. Comparative analysis further reveals that the five-qubit code (the smallest perfect code) offers consistently higher fidelities than topological and concatenated architectures in these open-system settings. These findings establish a quantitative framework for evaluating QEC under realistic noise environments and provide guidance for developing noise-resilient quantum architectures in near-term quantum technologies.", "AI": {"tldr": "The paper analyzes quantum error correction (QEC) performance in realistic open quantum systems with bosonic thermal baths, comparing five-qubit, Steane, and toric codes under various temperature regimes and noise conditions.", "motivation": "To move beyond abstract quantum channel models and evaluate QEC codes in realistic microscopic system-bath environments, providing quantitative guidance for noise-resilient quantum architectures in near-term technologies.", "method": "Use multi-qubit registers coupled to bosonic thermal environments, derive second-order master equations for reduced dynamics, and benchmark five-qubit, Steane, and toric codes under local and collective noise. Compute state fidelities as functions of coupling strength, bath temperature, and correction cycles.", "result": "In low-temperature regimes, repeated error correction with five-qubit code strongly suppresses decoherence and relaxation. In high-temperature regimes, thermal excitations reduce QEC benefits, though five-qubit code still outperforms Steane and toric codes. For Werner states, identify critical evolution time before which QEC doesn't improve fidelity, increasing with entanglement. Five-qubit code consistently offers higher fidelities than topological and concatenated architectures.", "conclusion": "Establishes quantitative framework for evaluating QEC under realistic noise environments, showing five-qubit code's superior performance in open-system settings and providing guidance for developing noise-resilient quantum architectures."}}
{"id": "2601.10209", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10209", "abs": "https://arxiv.org/abs/2601.10209", "authors": ["S. Messelot", "A. Leblanc", "J. -S. Tettekpoe", "F. Lefloch", "Q. Ficheux", "J. Renard", "\u00c9. Dumur"], "title": "Coherence Limits in Interference-Based cos(2$\\varphi$) Qubits", "comment": "19 pages, 14 figures", "summary": "We investigate the coherence properties of parity-protected $\\cos(2\\varphi)$ qubits based on interferences between two Josephson elements in a superconducting loop. We show that qubit implementations of a $\\cos(2\\varphi)$ potential using a single loop, such as those employing semiconducting junctions, rhombus circuits, flowermon and KITE structures, can be described by the same Hamiltonian as two multi-harmonic Josephson junctions in a SQUID geometry. We find that, despite the parity protection arising from the suppression of single Cooper pair tunneling, there exists a fundamental trade-off between charge and flux noise dephasing channels. Using numerical simulations, we examine how relaxation and dephasing rates depend on external flux and circuit parameters, and we identify the best compromise for maximum coherence. With currently existing circuit parameters, the qubit lifetime $T_1$ can exceed milliseconds while the dephasing time $T_\\varphi$ remains limited to only a few microseconds due to either flux or charge noise. Our findings establish practical limits on the coherence of this class of qubits and raise questions about the long-term potential of this approach.", "AI": {"tldr": "Parity-protected cos(2\u03c6) qubits face fundamental trade-off between charge and flux noise dephasing, limiting T_\u03c6 to microseconds despite millisecond T_1 lifetimes.", "motivation": "Investigate coherence properties of parity-protected cos(2\u03c6) qubits based on Josephson interference, understanding practical limits of this promising qubit class.", "method": "Numerical simulations analyzing relaxation and dephasing rates as functions of external flux and circuit parameters; unified Hamiltonian description for various implementations (semiconducting junctions, rhombus circuits, flowermon, KITE structures).", "result": "Fundamental trade-off between charge and flux noise dephasing channels; T_1 can exceed milliseconds but T_\u03c6 limited to few microseconds; best compromise parameters identified for maximum coherence.", "conclusion": "Establishes practical coherence limits for parity-protected cos(2\u03c6) qubits, raising questions about long-term potential of this approach despite parity protection from suppressed single Cooper pair tunneling."}}
{"id": "2601.10210", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10210", "abs": "https://arxiv.org/abs/2601.10210", "authors": ["J. Leibig", "M. H\u00f6rmann", "A. Langheld", "A. Schellenberger", "K. P. Schmidt"], "title": "Quantitative approach for the Dicke-Ising chain with an effective self-consistent matter Hamiltonian", "comment": "23 pages, 8 figures", "summary": "In the thermodynamic limit, the Dicke-Ising chain maps exactly onto an effective self-consistent matter Hamiltonian with the photon field acting solely as a self-consistent effective field. As a consequence, no quantum correlations between photons and spins are needed to understand the quantum phase diagram. This enables us to determine the quantum phase diagram in the thermodynamic limit using numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) to solve the resulting self-consistent matter Hamiltonian. This includes magnetically ordered phases with significantly improved accuracy compared to previous estimates. For ferromagnetic Ising couplings, we refine the location of the multicritical point governing the change in the order of the superradiant phase transition, reaching a relative accuracy of $10^{-4}$. For antiferromagnetic Ising couplings, we confirm the existence of the narrow antiferromagnetic superradiant phase in the thermodynamic limit. The effective matter Hamiltonian framework identifies the antiferromagnetic superradiant phase as the many-body ground state of an antiferromagnetic transverse-field Ising model with longitudinal field. This phase emerges through continuous Dicke-type polariton condensation from the antiferromagnetic normal phase, followed by a first-order transition to the paramagnetic superradiant phase. Thus, NLCE+DMRG provides a precise determination of the Dicke-Ising phase diagram in one dimension by solving the self-consistent effective matter Hamiltonian.", "AI": {"tldr": "The Dicke-Ising chain maps to an effective self-consistent matter Hamiltonian in the thermodynamic limit, enabling precise quantum phase diagram determination using NLCE+DMRG without needing photon-spin quantum correlations.", "motivation": "To understand the quantum phase diagram of the Dicke-Ising chain with high accuracy by exploiting that in the thermodynamic limit, the system reduces to an effective matter Hamiltonian where photons act as a self-consistent field, eliminating the need to consider photon-spin quantum correlations.", "method": "Numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) applied to the self-consistent effective matter Hamiltonian derived from the Dicke-Ising chain in the thermodynamic limit.", "result": "For ferromagnetic Ising couplings: refined location of multicritical point governing superradiant phase transition order change with 10^-4 relative accuracy. For antiferromagnetic couplings: confirmed existence of narrow antiferromagnetic superradiant phase in thermodynamic limit, identified as ground state of antiferromagnetic transverse-field Ising model with longitudinal field, emerging via continuous Dicke-type polariton condensation from antiferromagnetic normal phase followed by first-order transition to paramagnetic superradiant phase.", "conclusion": "NLCE+DMRG provides precise determination of the 1D Dicke-Ising phase diagram by solving the self-consistent effective matter Hamiltonian, demonstrating that quantum correlations between photons and spins are not needed to understand the quantum phase diagram in the thermodynamic limit."}}
{"id": "2601.10281", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10281", "abs": "https://arxiv.org/abs/2601.10281", "authors": ["Maristella Crotti", "Luca Razzoli", "Luigi Giannelli", "Giuseppe A. Falci", "Giuliano Benenti"], "title": "Optimal control of a dissipative micromaser quantum battery in the ultrastrong coupling regime", "comment": "13 pages, 6 figures", "summary": "We investigate the open system dynamics of a micromaser quantum battery operating in the ultrastrong coupling (USC) regime under environmental dissipation. The battery consists of a single-mode electromagnetic cavity sequentially interacting, via the Rabi Hamiltonian, with a stream of qubits acting as chargers. Dissipative effects arise from the weak coupling of the qubit-cavity system to a thermal bath. Non-negligible in the USC regime, the counter-rotating terms substantially improve the charging speed, but also lead, in the absence of dissipation, to unbounded energy growth and highly mixed cavity states. Dissipation during each qubit-cavity interaction mitigates these detrimental effects, yielding steady-state of finite energy and ergotropy. Optimal control on qubit preparation and interaction times enhances battery's performance in: (i) Maximizing the stored ergotropy trhough an optimized charging protocol; (ii) Stabilizing the stored ergotropy against dissipative losses through an optimized measurement-based passive-feedback strategy. Overall, our numerical results demonstrate that the interplay of ultrastrong light-matter coupling, controlled dissipation, and optimized control strategies enables micromaser quantum batteries to achieve both enhanced charging performance and long-term stability under realistic conditions.", "AI": {"tldr": "Micromaser quantum battery in ultrastrong coupling regime achieves enhanced charging and stability through optimized control and dissipation management.", "motivation": "Investigate quantum battery performance in ultrastrong coupling regime where counter-rotating terms improve charging speed but cause unbounded energy growth and mixed states without dissipation.", "method": "Single-mode cavity sequentially interacts with qubit chargers via Rabi Hamiltonian in USC regime. Dissipation from weak coupling to thermal bath. Optimal control on qubit preparation and interaction times with measurement-based passive-feedback strategy.", "result": "Dissipation mitigates detrimental effects, yielding steady-state of finite energy and ergotropy. Optimized protocols maximize stored ergotropy and stabilize it against dissipative losses. USC enables enhanced charging performance with long-term stability.", "conclusion": "Interplay of ultrastrong light-matter coupling, controlled dissipation, and optimized control strategies enables micromaser quantum batteries to achieve both enhanced charging performance and long-term stability under realistic conditions."}}
{"id": "2601.10289", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10289", "abs": "https://arxiv.org/abs/2601.10289", "authors": ["Rodrigo M. Sanz", "Emilio Annoni", "Stephen C. Wein", "Carmen G. Almudever", "Shane Mansfield", "Ellen Derbyshire", "Rawad Mezher"], "title": "Exponential improvement in benchmarking multiphoton interference", "comment": "7 pages + 20 pages appendix, comments welcome !", "summary": "Several photonic quantum technologies rely on the ability to generate multiple indistinguishable photons. Benchmarking the level of indistinguishability of these photons is essential for scalability. The Hong-Ou-Mandel dip provides a benchmark for the indistinguishability between two photons, and extending this test to the multi-photon setting has so far resulted in a protocol that computes the genuine n-photon indistinguishability (GI). However, this protocol has a sample complexity that increases exponentially with the number of input photons for an estimation of GI up to a given additive error. To address this problem, we introduce new theorems that strengthen our understanding of the relationship between distinguishability and the suppression laws of the quantum Fourier transform interferometer (QFT). Building on this, we propose a protocol using the QFT for benchmarking GI that achieves constant sample complexity for the estimation of GI up to a given additive error for prime photon numbers, and sub-polynomial scaling otherwise, representing an exponential improvement over the state of the art. We prove the optimality of our protocol in many relevant scenarios and validate our approach experimentally on Quandela's reconfigurable photonic quantum processor, where we observe a clear advantage in runtime and precision over the state of the art. We therefore establish the first scalable method for computing multi-photon indistinguishability, which applies naturally to current and near-term photonic quantum hardware.", "AI": {"tldr": "New protocol using quantum Fourier transform achieves constant sample complexity for estimating genuine n-photon indistinguishability, representing exponential improvement over previous exponential-scaling methods.", "motivation": "Existing methods for benchmarking multi-photon indistinguishability have exponential sample complexity, making them impractical for scalable photonic quantum technologies that require multiple indistinguishable photons.", "method": "Introduces new theorems linking distinguishability to suppression laws of quantum Fourier transform interferometer, then proposes protocol using QFT for benchmarking genuine n-photon indistinguishability.", "result": "Protocol achieves constant sample complexity for prime photon numbers and sub-polynomial scaling otherwise, validated experimentally on Quandela's photonic quantum processor with runtime and precision advantages.", "conclusion": "Establishes first scalable method for computing multi-photon indistinguishability applicable to current and near-term photonic quantum hardware."}}
{"id": "2601.10302", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10302", "abs": "https://arxiv.org/abs/2601.10302", "authors": ["Yu. M. Poluektov"], "title": "Complex scalar relativistic field as a probability amplitude", "comment": "11 pages", "summary": "A relativistic equation for a neutral complex field as a probability amplitude is proposed. The continuity equation for the probability density is obtained. It is shown that there are two types of excitations of this field, which describe particles with positive energy and different dispersion laws. Based on the Lagrangian formalism, conservation laws are obtained. The transition to secondary quantization is considered.", "AI": {"tldr": "Proposes a relativistic equation for a neutral complex field as a probability amplitude, derives continuity equation, identifies two particle types with positive energy and different dispersion laws, obtains conservation laws via Lagrangian formalism, and considers secondary quantization.", "motivation": "To develop a relativistic framework for a neutral complex field that can serve as a probability amplitude, establishing its quantum mechanical interpretation and exploring its particle-like excitations within a field-theoretic approach.", "method": "Proposes a relativistic equation for the neutral complex field, derives the continuity equation for probability density, analyzes field excitations to identify particle types with different dispersion laws, applies Lagrangian formalism to obtain conservation laws, and considers transition to secondary quantization.", "result": "Shows that the field has two types of excitations describing particles with positive energy but different dispersion laws, obtains conservation laws from the Lagrangian, and establishes the framework for secondary quantization of the field.", "conclusion": "The proposed relativistic equation successfully describes a neutral complex field as a probability amplitude, with well-defined particle excitations and conservation laws, providing a foundation for quantum field theory treatment through secondary quantization."}}
{"id": "2601.10319", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10319", "abs": "https://arxiv.org/abs/2601.10319", "authors": ["Gavriil Voloshin", "Konstantin Barantsev", "Andrey Litvinov"], "title": "Addition to the dynamic Stark shift of the coherent population trapping resonance", "comment": "11 pages, 7 figures", "summary": "This paper presents a theoretical study of the light-induced shift of the coherent population trapping resonance. An analytical model is proposed that describes the interaction of two radiation components with an atomic system using a $\u039b$ scheme and takes into account an additional level of excited state. Both weak and strong coupling regimes with off-resonant transitions are considered. It is shown that, in addition to the conventional dynamic Stark shift, an extra shift arises due to the distortion of the resonance line shape when bichromatic laser radiation interacts with off-resonant atomic transitions. An analytical expression for this additional shift is derived in the weak-coupling limit, and its significant impact on the resonance shape and sensitivity to the intensities of the laser field components is demonstrated. It is found that under strong coupling conditions, the additional shift can deviate substantially from a linear dependence on light intensity, suggesting new opportunities for controlling light shifts in precision atomic devices such as quantum frequency standards.", "AI": {"tldr": "Theoretical study of light-induced shift in coherent population trapping resonance, showing additional shift beyond conventional Stark shift due to off-resonant transitions in \u039b-scheme atoms with extra excited level.", "motivation": "To understand and model the light-induced frequency shifts in coherent population trapping resonances, particularly the additional shift beyond conventional dynamic Stark shift that arises from bichromatic laser radiation interacting with off-resonant atomic transitions, which is important for precision atomic devices like quantum frequency standards.", "method": "Developed an analytical model describing interaction of two radiation components with atomic system using \u039b scheme with additional excited state level. Considered both weak and strong coupling regimes with off-resonant transitions. Derived analytical expression for additional shift in weak-coupling limit.", "result": "Shows that in addition to conventional dynamic Stark shift, an extra shift arises due to resonance line shape distortion when bichromatic laser interacts with off-resonant transitions. Derived analytical expression for this additional shift in weak-coupling limit. Demonstrated significant impact on resonance shape and sensitivity to laser intensities. Found that under strong coupling, additional shift deviates substantially from linear intensity dependence.", "conclusion": "The additional light-induced shift beyond conventional Stark shift, particularly its non-linear behavior under strong coupling, suggests new opportunities for controlling light shifts in precision atomic devices such as quantum frequency standards."}}
{"id": "2601.10325", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10325", "abs": "https://arxiv.org/abs/2601.10325", "authors": ["Yifang Xu", "Yilong Zhou", "Ziyue Hua", "Lida Sun", "Jie Zhou", "Weiting Wang", "Weizhou Cai", "Hongwei Huang", "Lintao Xiao", "Guangming Xue", "Haifeng Yu", "Ming Li", "Chang-Ling Zou", "Luyan Sun"], "title": "Principles of Optics in the Fock Space: Scalable Manipulation of Giant Quantum States", "comment": "25 pages, 15 figures, 1 table", "summary": "The manipulation of distinct degrees of freedom of photons plays a critical role in both classical and quantum information processing. While the principles of wave optics provide elegant and scalable control over classical light in spatial and temporal domains, engineering quantum states in Fock space has been largely restricted to few-photon regimes, hindered by the computational and experimental challenges of large Hilbert spaces. Here, we introduce ``Fock-space optics\", establishing a conceptual framework of wave propagation in the quantum domain by treating photon number as a synthetic dimension. Using a superconducting microwave resonator, we experimentally demonstrate Fock-space analogues of optical propagation, refraction, lensing, dispersion, and interference with up to 180 photons. These results establish a fundamental correspondence between Schr\u00f6dinger evolution in a single bosonic mode and classical paraxial wave propagation. By mapping intuitive optical concepts onto high-dimensional quantum state engineering, our work opens a path toward scalable control of large-scale quantum systems with thousands of photons and advanced bosonic information processing.", "AI": {"tldr": "Fock-space optics establishes wave propagation in quantum domain using photon number as synthetic dimension, enabling optical analogies (propagation, refraction, lensing, dispersion, interference) with up to 180 photons in superconducting microwave resonator.", "motivation": "While classical optics provides scalable control over spatial/temporal degrees of freedom, quantum state engineering in Fock space has been limited to few-photon regimes due to computational and experimental challenges of large Hilbert spaces.", "method": "Introduces \"Fock-space optics\" framework treating photon number as synthetic dimension, experimentally demonstrated using superconducting microwave resonator to implement Fock-space analogues of optical propagation, refraction, lensing, dispersion, and interference.", "result": "Successfully demonstrated Fock-space optical phenomena with up to 180 photons, establishing fundamental correspondence between Schr\u00f6dinger evolution in single bosonic mode and classical paraxial wave propagation.", "conclusion": "Mapping intuitive optical concepts onto high-dimensional quantum state engineering opens path toward scalable control of large-scale quantum systems with thousands of photons and advanced bosonic information processing."}}
{"id": "2601.10354", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10354", "abs": "https://arxiv.org/abs/2601.10354", "authors": ["Riccardo Falcone", "Claudio Conti"], "title": "Realistic prospects for testing a relativistic local quantum measurement inequality", "comment": null, "summary": "We investigate the experimental prospects for testing a relativistic local quantum measurement inequality that quantifies the trade-off between vacuum insensitivity and responsiveness to excitations for finite-size detectors. Building on the Reeh--Schlieder approximation for coherent states, we derive an explicit and practically applicable bound for arbitrary coherent states. To connect with realistic photodetection scenarios, we model the detection region as a square prism operating over a finite time window and consider a normally incident single-mode coherent state. Numerical results exhibit the expected qualitative behavior: suppressing dark counts necessarily tightens the achievable click probability.", "AI": {"tldr": "Paper investigates experimental testing of a relativistic quantum measurement inequality that quantifies trade-off between vacuum insensitivity and excitation responsiveness for finite-size detectors, deriving explicit bounds for coherent states and modeling realistic photodetection scenarios.", "motivation": "To bridge the gap between theoretical relativistic quantum measurement inequalities and practical experimental testing, particularly for finite-size detectors in realistic photodetection scenarios, addressing the fundamental trade-off between vacuum insensitivity and responsiveness to excitations.", "method": "Builds on Reeh-Schlieder approximation for coherent states to derive explicit bounds for arbitrary coherent states. Models detection region as square prism operating over finite time window, considers normally incident single-mode coherent state, and performs numerical analysis.", "result": "Numerical results show expected qualitative behavior: suppressing dark counts (vacuum insensitivity) necessarily tightens the achievable click probability (responsiveness to excitations), demonstrating the fundamental trade-off quantified by the inequality.", "conclusion": "The derived explicit bound provides a practically applicable framework for testing relativistic quantum measurement inequalities in realistic experimental settings, confirming the fundamental trade-off between detector sensitivity to vacuum fluctuations and responsiveness to actual excitations."}}
{"id": "2601.10380", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10380", "abs": "https://arxiv.org/abs/2601.10380", "authors": ["Shrigyan Brahmachari", "Shuchen Zhu", "Iman Marvian", "Yu Tong"], "title": "Learning Hamiltonians in the Heisenberg limit with static single-qubit fields", "comment": null, "summary": "Learning the Hamiltonian governing a quantum system is a central task in quantum metrology, sensing, and device characterization. Existing Heisenberg-limited Hamiltonian learning protocols either require multi-qubit operations that are prone to noise, or single-qubit operations whose frequency or strength increases with the desired precision. These two requirements limit the applicability of Hamiltonian learning on near-term quantum platforms. We present a protocol that learns a quantum Hamiltonian with the optimal Heisenberg-limited scaling using only single-qubit control in the form of static fields with strengths that are independent of the target precision. Our protocol is robust against the state preparation and measurement (SPAM) error. By overcoming these limitations, our protocol provides new tools for device characterization and quantum sensing. We demonstrate that our method achieves the Heisenberg-limited scaling through rigorous mathematical proof and numerical experiments. We also prove an information-theoretic lower bound showing that a non-vanishing static field strength is necessary for achieving the Heisenberg limit unless one employs an extensive number of discrete control operations.", "AI": {"tldr": "A Heisenberg-limited Hamiltonian learning protocol using only static single-qubit control fields with strength independent of target precision, robust to SPAM errors.", "motivation": "Existing Hamiltonian learning protocols require either noisy multi-qubit operations or single-qubit operations whose frequency/strength increases with precision, limiting applicability on near-term quantum platforms.", "method": "Protocol learns quantum Hamiltonian with optimal Heisenberg-limited scaling using only single-qubit control in form of static fields with strengths independent of target precision; robust to SPAM errors.", "result": "Method achieves Heisenberg-limited scaling through rigorous mathematical proof and numerical experiments; proves information-theoretic lower bound showing non-vanishing static field strength is necessary for Heisenberg limit without extensive discrete control operations.", "conclusion": "Protocol overcomes limitations of existing methods, provides new tools for device characterization and quantum sensing on near-term quantum platforms."}}
{"id": "2601.10385", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10385", "abs": "https://arxiv.org/abs/2601.10385", "authors": ["Eliya Blumenthal", "Natan Karaev", "Shay Hacohen-Gourgy"], "title": "Experimental Realization of Rabi-Driven Reset for Fast Cooling of a High-Q Cavity", "comment": null, "summary": "High-Q bosonic memories are central to hardware-efficient quantum error correction, but their isolation makes fast, high-fidelity reset a persistent bottleneck. Existing approaches either rely on weak intermode cross-Kerr conversion or on measurement-based sequences with substantial latency. Here we demonstrate a hardware-efficient Rabi-Driven Reset (RDR) that implements continuous, measurement-free cooling of a superconducting cavity mode. A strong resonant Rabi drive on a transmon, together with sideband drives on the memory and readout modes detuned by the Rabi frequency, converts the dispersive interaction into an effective Jaynes-Cummings coupling between the qubit dressed states and each mode. This realizes a tunable dissipation channel from the memory to the cold readout bath. Crucially, the engineered coupling scales with the qubit-mode dispersive interaction and the drive amplitude, rather than with the intermode cross-Kerr, enabling fast cooling even in very weakly coupled architectures that deliberately suppress direct mode-mode coupling. We demonstrate RDR of a single photon with a decay time of $1.2 \u03bcs$, more than two orders of magnitude faster than the intrinsic lifetime. Furthermore, we reset about 30 thermal photons in about $80 \u03bcs$ to a steady-state average photon number of $\\bar{n} = 0.045 \\pm 0.025$.", "AI": {"tldr": "Hardware-efficient Rabi-Driven Reset (RDR) enables fast, measurement-free cooling of superconducting cavity modes using dressed qubit states and engineered dissipation channels, achieving two orders of magnitude faster reset than intrinsic lifetime.", "motivation": "High-Q bosonic memories are essential for quantum error correction but suffer from slow reset bottlenecks due to their isolation. Existing approaches rely on weak intermode cross-Kerr conversion or measurement-based sequences with substantial latency, limiting reset speed and efficiency.", "method": "Rabi-Driven Reset (RDR) uses a strong resonant Rabi drive on a transmon qubit combined with sideband drives on memory and readout modes detuned by the Rabi frequency. This converts the dispersive interaction into an effective Jaynes-Cummings coupling between qubit dressed states and each mode, creating a tunable dissipation channel from memory to the cold readout bath. The engineered coupling scales with qubit-mode dispersive interaction and drive amplitude rather than intermode cross-Kerr.", "result": "Demonstrated RDR of a single photon with decay time of 1.2 \u03bcs (more than two orders of magnitude faster than intrinsic lifetime). Reset about 30 thermal photons in about 80 \u03bcs to steady-state average photon number of n\u0304 = 0.045 \u00b1 0.025.", "conclusion": "RDR provides a hardware-efficient, measurement-free approach for fast reset of high-Q bosonic memories, overcoming limitations of existing methods and enabling practical quantum error correction in weakly coupled architectures."}}
{"id": "2601.10395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10395", "abs": "https://arxiv.org/abs/2601.10395", "authors": ["Kl\u00e4re Wienecke", "Gereon Ko\u00dfmann", "Ren\u00e9 Schwonnek"], "title": "A Collection of Pinsker-type Inequalities for Quantum Divergences", "comment": "14 pages, 7 figures", "summary": "Pinsker's inequality sets a lower bound on the Umegaki divergence of two quantum states in terms of their trace distance. In this work, we formulate corresponding estimates for a variety of quantum and classical divergences including $f$-divergences like Hellinger and $\u03c7^2$-divergences as well as R\u00e9nyi divergences and special cases thereof like the Umegaki divergence, collision divergence, max divergence. We further provide a strategy on how to adapt these bounds to smoothed divergences.", "AI": {"tldr": "The paper establishes lower bounds on various quantum and classical divergences in terms of trace distance, extending Pinsker's inequality to f-divergences, R\u00e9nyi divergences, and providing adaptation to smoothed divergences.", "motivation": "Pinsker's inequality provides a fundamental lower bound on Umegaki divergence in terms of trace distance, but similar bounds for other important divergences (f-divergences, R\u00e9nyi divergences) are lacking. The work aims to extend this foundational result to a broader class of quantum and classical divergences.", "method": "The authors formulate corresponding estimates for various quantum and classical divergences including f-divergences (Hellinger, \u03c7\u00b2-divergences), R\u00e9nyi divergences (Umegaki, collision, max divergences), and develop strategies to adapt these bounds to smoothed divergences.", "result": "The paper establishes new lower bounds connecting various divergences to trace distance, extending Pinsker's inequality to a comprehensive set of quantum and classical divergences, with adaptation methods for smoothed versions.", "conclusion": "The work successfully generalizes Pinsker's inequality to a wide range of quantum and classical divergences, providing fundamental relationships between different distance measures and enabling applications to smoothed divergence scenarios."}}
{"id": "2601.10408", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10408", "abs": "https://arxiv.org/abs/2601.10408", "authors": ["Luke Mortimer", "Leonardo Zambrano", "Antonio Ac\u00edn", "Donato Farina"], "title": "Bounding many-body properties under partial information and finite measurement statistics", "comment": "12 pages, 7 figures", "summary": "Calculating bounds of properties of many-body quantum systems is of paramount importance, since they guide our understanding of emergent quantum phenomena and complement the insights obtained from estimation methods. Recent semidefinite programming approaches enable probabilistic bounds from finite-shot measurements of easily accessible, yet informationally incomplete, observables. Here we render these methods scalable in the number of qubits by instead utilizing moment-matrix relaxations. After introducing the general formalism, we show how the approach can be adapted with specific knowledge of the system, such as it being the ground state of a given Hamiltonian, possessing specific symmetries or being the steady state of a given Lindbladian. Our approach defines a scalable real-world certification scheme leveraging semidefinite programming relaxations and experimental estimations which, unavoidably, contain shot noise.", "AI": {"tldr": "Scalable certification of quantum many-body systems using moment-matrix relaxations and finite-shot measurements, adaptable to specific system knowledge.", "motivation": "To develop scalable methods for calculating bounds on quantum system properties that complement estimation methods and work with practical experimental constraints like finite-shot measurements.", "method": "Uses moment-matrix relaxations within semidefinite programming to render probabilistic bounds scalable in qubit number, adaptable to system-specific knowledge (ground states, symmetries, Lindbladian steady states).", "result": "Defines a scalable real-world certification scheme that leverages semidefinite programming relaxations while accounting for experimental shot noise from finite measurements.", "conclusion": "Provides a practical framework for certifying quantum many-body systems that scales with system size and accommodates experimental realities like shot noise and incomplete measurements."}}
{"id": "2601.10409", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10409", "abs": "https://arxiv.org/abs/2601.10409", "authors": ["Marcin Kotowski", "Micha\u0142 Oszmaniec"], "title": "Tight bounds on recurrence time in closed quantum systems", "comment": null, "summary": "The evolution of an isolated quantum system inevitably exhibits recurrence: the state returns to the vicinity of its initial condition after finite time. Despite its fundamental nature, a rigorous quantitative understanding of recurrence has been lacking. We establish upper bounds on the recurrence time, $t_{\\mathrm{rec}} \\lesssim t_{\\mathrm{exit}}(\u03b5)(1/\u03b5)^d$, where $d$ is the Hilbert-space dimension, $\u03b5$ the neighborhood size, and $t_{\\mathrm{exit}}(\u03b5)$ the escape time from this neighborhood. For pure states evolving under a Hamiltonian $H$, estimating $t_{\\mathrm{exit}}$ is equivalent to an inverse quantum speed limit problem: finding upper bounds on the time a time-evolved state $\u03c8_t$ needs to depart from the $\u03b5$-vicinity of the initial state $\u03c8_0$. We provide a partial solution, showing that under mild assumptions $t_{\\mathrm{exit}}(\u03b5) \\approx \u03b5/\\sqrt{ \u0394(H^2)}$, with $\u0394(H^2)$ the Hamiltonian variance in $\u03c8_0$. We show that our upper bound on $t_{\\mathrm{rec}}$ is generically saturated for random Hamiltonians. Finally, we analyze the impact of coherence of the initial state in the eigenbasis of $H$ on recurrence behavior.", "AI": {"tldr": "The paper establishes rigorous upper bounds on quantum recurrence times, showing t_rec \u2272 t_exit(\u03b5)(1/\u03b5)^d, and provides estimates for escape times from initial state neighborhoods based on Hamiltonian variance.", "motivation": "Despite the fundamental nature of quantum recurrence (Poincar\u00e9 recurrence theorem), there has been a lack of rigorous quantitative understanding of recurrence times in isolated quantum systems.", "method": "The authors establish upper bounds on recurrence time using Hilbert-space dimension, neighborhood size, and escape time. They formulate escape time estimation as an inverse quantum speed limit problem, deriving t_exit(\u03b5) \u2248 \u03b5/\u221a\u0394(H\u00b2) under mild assumptions. They analyze saturation of bounds for random Hamiltonians and study coherence effects.", "result": "The paper provides rigorous upper bounds on quantum recurrence times, shows these bounds are generically saturated for random Hamiltonians, and demonstrates that escape time scales inversely with the square root of Hamiltonian variance in the initial state.", "conclusion": "The work provides the first rigorous quantitative framework for understanding quantum recurrence times, establishing fundamental relationships between recurrence time, Hilbert-space dimension, neighborhood size, and Hamiltonian properties, with implications for quantum dynamics and thermalization."}}
{"id": "2601.10423", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10423", "abs": "https://arxiv.org/abs/2601.10423", "authors": ["Abdul Rahaman Shaikh", "Tabish Qureshi"], "title": "Unifying Quantum and Classical Dynamics", "comment": "4 pages", "summary": "Classical and quantum physics represent two distinct theories; however, quantum physics is regarded as the more fundamental of the two. It is posited that classical mechanics should arise from quantum mechanics under certain limiting conditions. Nevertheless, this remains a challenging objective. In this work, we explore the potential for unifying the dynamics of classical and quantum physics. This discussion does not suggest that classical behavior emerges from quantum mechanics; rather, it demonstrates the exact equivalence between the dynamics of quantum observables and their classical counterparts. It is shown that the Heisenberg equations of motion can be cast in a form that is identical to Newton's equations of motion, with $\\hbar$ being absent from the formulation. This implies that both quantum and classical dynamics are governed by the same equations, with the Heisenberg operators substituting the classical observables.", "AI": {"tldr": "The paper demonstrates exact equivalence between quantum and classical dynamics by reformulating Heisenberg equations to match Newton's equations without \u0127.", "motivation": "To address the challenge of deriving classical mechanics from quantum mechanics and explore unification of their dynamics, moving beyond the emergence paradigm.", "method": "Reformulating Heisenberg equations of motion into a form identical to Newton's equations, eliminating \u0127 from the formulation.", "result": "Shows exact equivalence between quantum and classical dynamics, with Heisenberg operators substituting classical observables in identical governing equations.", "conclusion": "Quantum and classical dynamics are governed by the same fundamental equations, providing a unified framework rather than emergence relationship."}}
{"id": "2601.10429", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10429", "abs": "https://arxiv.org/abs/2601.10429", "authors": ["Yang Li", "Fu-Lin Zhang"], "title": "Reduction of thermodynamic uncertainty by a virtual qubit", "comment": "23 pages (including 13 pages of appendices), 7 figures", "summary": "The thermodynamic uncertainty relation (TUR) imposes a fundamental constraint between current fluctuations and entropy production, providing a refined formulation of the second law for micro- and nanoscale systems. Quantum violations of the classical TUR reveal genuinely quantum thermodynamic effects, which are essential for improving performance and enabling optimization in quantum technologies. In this work, we analyze the TUR in a class of paradigmatic quantum thermal-machine models whose operation is enabled by coherent coupling between two energy levels forming a virtual qubit. Steady-state coherences are confined to this virtual-qubit subspace, while in the absence of coherent coupling the system satisfies detailed balance with the thermal reservoirs and supports no steady-state heat currents. We show that the steady-state currents and entropy production can be fully reproduced by an effective classical Markov process, whereas current fluctuations acquire an additional purely quantum correction originating from coherence. As a result, the thermodynamic uncertainty naturally decomposes into a classical (diagonal) contribution and a coherent contribution. The latter becomes negative under resonant conditions and reaches its minimum at the coupling strength that maximizes steady-state coherence. We further identify the optimization conditions and the criteria for surpassing the classical TUR bound in the vicinity of the reversible limit.", "AI": {"tldr": "Quantum thermal machines with coherent coupling between energy levels can violate the classical thermodynamic uncertainty relation (TUR) due to purely quantum corrections from coherence, enabling optimization beyond classical limits.", "motivation": "To understand how quantum coherence affects thermodynamic uncertainty relations in quantum thermal machines, particularly how quantum violations of classical TUR bounds reveal genuinely quantum thermodynamic effects essential for improving performance in quantum technologies.", "method": "Analysis of TUR in paradigmatic quantum thermal-machine models with coherent coupling between two energy levels forming a virtual qubit. The approach involves comparing steady-state behavior with and without coherent coupling, decomposing thermodynamic uncertainty into classical (diagonal) and coherent contributions.", "result": "Steady-state currents and entropy production can be reproduced by an effective classical Markov process, but current fluctuations acquire additional purely quantum corrections from coherence. The coherent contribution becomes negative under resonant conditions and reaches minimum at coupling strength maximizing steady-state coherence, enabling violation of classical TUR bounds near the reversible limit.", "conclusion": "Quantum coherence in thermal machines provides a mechanism to surpass classical thermodynamic uncertainty relation bounds, with coherent contributions becoming negative under optimal conditions, offering pathways for performance optimization in quantum technologies through quantum thermodynamic effects."}}
{"id": "2601.10435", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10435", "abs": "https://arxiv.org/abs/2601.10435", "authors": ["Beno\u00eet Vermersch", "Oscar Gravier", "Nathan Miscopein", "Julia Guignon", "Carlos Ramos Marim\u00f3n", "Jonathan Durandau", "Matthieu Dartiailh", "Tristan Meunier", "Valentin Savin"], "title": "The SpinPulse library for transpilation and noise-accurate simulation of spin qubit quantum computers", "comment": "Code available at https://quobly-sw.github.io/SpinPulse/", "summary": "We introduce SpinPulse, an open-source python package for simulating spin qubit-based quantum computers at the pulse-level. SpinPulse models the specific physics of spin qubits, particularly through the inclusion of classical non-Markovian noise. This enables realistic simulations of native gates and quantum circuits, in order to support hardware development. In SpinPulse, a quantum circuit is first transpiled into the native gate set of our model and then converted to a pulse sequence. This pulse sequence is subsequently integrated numerically in the presence of a simulated noisy experimental environment. We showcase workflows including transpilation, pulse-level compilation, hardware benchmarking, quantum error mitigation, and large-scale simulations via integration with the tensor-network library quimb. We expect SpinPulse to be a valuable open-source tool for the quantum computing community, fostering efforts to devise high-fidelity quantum circuits and improved strategies for quantum error mitigation and correction.", "AI": {"tldr": "SpinPulse is an open-source Python package for pulse-level simulation of spin qubit quantum computers with realistic noise modeling.", "motivation": "To provide a realistic simulation tool for spin qubit quantum computers that models specific physics including classical non-Markovian noise, supporting hardware development and circuit optimization.", "method": "Quantum circuits are transpiled into native gate sets, converted to pulse sequences, then numerically integrated in simulated noisy experimental environments with classical non-Markovian noise modeling.", "result": "Developed SpinPulse package showcasing workflows for transpilation, pulse-level compilation, hardware benchmarking, quantum error mitigation, and large-scale simulations via integration with quimb tensor-network library.", "conclusion": "SpinPulse is expected to be a valuable open-source tool for the quantum computing community, fostering development of high-fidelity quantum circuits and improved quantum error mitigation/correction strategies."}}
{"id": "2601.10446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10446", "abs": "https://arxiv.org/abs/2601.10446", "authors": ["Adonai Hil\u00e1rio da Silva", "Oct\u00e1vio da Motta", "Leonardo Kleber Castelano", "Reginaldo de Jesus Napolitano"], "title": "Minimal-Energy Optimal Control of Tunable Two-Qubit Gates in Superconducting Platforms Using Continuous Dynamical Decoupling", "comment": "17 pages, 4 figures, 1 table", "summary": "We present a unified scheme for generating high-fidelity entangling gates in superconducting platforms by continuous dynamical decoupling (CDD) combined with variational minimal-energy optimal control. During the CDD stage, we suppress residual couplings, calibration drifting, and quasistatic noise, resulting in a stable effective Hamiltonian that preserves the designed ZZ interaction intended for producing tunable couplers. In this stable $\\mathrm{SU}(4)$ manifold, we calculate smooth low-energy single-quibt control functions using a variational geodesic optimization process that directly minimizes gate infidelity. We illustrate the methodology by applying it to CZ, CX, and generic engangling gates, achieving virtually unit fidelity and robustness under restricted single-qubit action, with experimentally realistic control fields. These results establish CDD-enhanced variational geometric optimal control as a practical and noise-resilient scheme for designing superconducting entangling gates.", "AI": {"tldr": "A unified scheme for generating high-fidelity entangling gates in superconducting platforms using continuous dynamical decoupling combined with variational minimal-energy optimal control.", "motivation": "To develop a practical and noise-resilient scheme for designing superconducting entangling gates that can suppress residual couplings, calibration drifting, and quasistatic noise while achieving high fidelity.", "method": "Combines continuous dynamical decoupling (CDD) with variational minimal-energy optimal control. CDD suppresses noise and stabilizes the effective Hamiltonian, then variational geodesic optimization calculates smooth low-energy single-qubit control functions that directly minimize gate infidelity.", "result": "Achieves virtually unit fidelity for CZ, CX, and generic entangling gates with robustness under restricted single-qubit action, using experimentally realistic control fields.", "conclusion": "Establishes CDD-enhanced variational geometric optimal control as a practical and noise-resilient scheme for designing superconducting entangling gates."}}
{"id": "2601.10451", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2601.10451", "abs": "https://arxiv.org/abs/2601.10451", "authors": ["David Gu\u00e9ry-Odelin", "Fran\u00e7ois Impens"], "title": "Localization Landscape in Non-Hermitian and Floquet quantum systems", "comment": null, "summary": "We propose a generalization of the Filoche--Mayboroda localization landscape that extends the theory well beyond the static, elliptic and Hermitian settings while preserving its geometric interpretability. Using the positive operator $H^\\dagger H$, we obtain a landscape that predicts localization across non-Hermitian, Floquet, and topological systems without computing eigenstates. Singular-value collapse reveals spectral instabilities and skin effects, the Sambe formulation captures coherent destruction of tunneling, and topological zero modes emerge directly from the landscape. Applications to Hatano--Nelson chains, driven two-level systems, and driven Aubry--Andr\u00e9--Harper models confirm quantitative accuracy, establishing a unified predictor for localization in equilibrium and driven quantum matter.", "AI": {"tldr": "Generalization of localization landscape theory to non-Hermitian, Floquet, and topological systems using H\u2020H operator, predicting localization without eigenstate computation.", "motivation": "Extend the Filoche-Mayboroda localization landscape theory beyond static, elliptic, and Hermitian settings while preserving geometric interpretability, to address non-Hermitian, Floquet, and topological systems.", "method": "Use the positive operator H\u2020H to construct a generalized landscape that predicts localization across diverse systems. Employ singular-value collapse to reveal spectral instabilities and skin effects, use Sambe formulation for driven systems, and extract topological zero modes directly from landscape features.", "result": "The generalized landscape accurately predicts localization in Hatano-Nelson chains, driven two-level systems, and driven Aubry-Andr\u00e9-Harper models, demonstrating quantitative accuracy across equilibrium and driven quantum matter.", "conclusion": "Establishes a unified predictor for localization that works across Hermitian, non-Hermitian, Floquet, and topological systems without requiring eigenstate computation, preserving geometric interpretability while extending applicability."}}
{"id": "2601.10461", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10461", "abs": "https://arxiv.org/abs/2601.10461", "authors": ["Adam Siegel", "Simon Benjamin"], "title": "Erasure conversion for singlet-triplet spin qubits enables high-performance shuttling-based quantum error correction", "comment": null, "summary": "Fast and high fidelity shuttling of spin qubits has been demonstrated in semiconductor quantum dot devices. Several architectures based on shuttling have been proposed; it has been suggested that singlet-triplet (dual-spin) qubits could be optimal for the highest shuttling fidelities. Here we present a fault-tolerant framework for quantum error correction based on such dual-spin qubits, establishing them as a natural realisation of erasure qubits within semiconductor architectures. We introduce a hardware-efficient leakage-detection protocol that automatically projects leaked qubits back onto the computational subspace, without the need for measurement feedback or increased classical control overheads. When combined with the XZZX surface code and leakage-aware decoding, we demonstrate a twofold increase in the error correction threshold and achieve orders-of-magnitude reductions in logical error rates. This establishes the singlet-triplet encoding as a practical route toward high-fidelity shuttling and erasure-based, fault-tolerant quantum computation in semiconductor devices.", "AI": {"tldr": "Singlet-triplet (dual-spin) qubits enable high-fidelity shuttling and serve as natural erasure qubits in semiconductor quantum dot devices, with a fault-tolerant framework featuring automatic leakage detection and XZZX surface code achieving significantly improved error correction performance.", "motivation": "To establish singlet-triplet (dual-spin) qubits as optimal for high-fidelity shuttling in semiconductor quantum dot devices and develop a fault-tolerant quantum error correction framework that leverages their natural erasure qubit properties.", "method": "Proposes a fault-tolerant framework using dual-spin qubits as erasure qubits, introduces a hardware-efficient leakage-detection protocol that automatically projects leaked qubits back to computational subspace without measurement feedback, combines with XZZX surface code and leakage-aware decoding.", "result": "Demonstrates twofold increase in error correction threshold and orders-of-magnitude reductions in logical error rates compared to conventional approaches.", "conclusion": "Singlet-triplet encoding provides a practical route toward high-fidelity shuttling and erasure-based fault-tolerant quantum computation in semiconductor quantum dot devices."}}
{"id": "2601.10465", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.10465", "abs": "https://arxiv.org/abs/2601.10465", "authors": ["Johannes N. Kriel", "Emma C. King", "Michael Kastner"], "title": "Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature", "comment": "21 pages, 5+1 figures", "summary": "We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by the critical exponents $\u03bd$ and $z$) of an equilibrium quantum phase transition at zero temperature. Key to this is the identification of ramps in which both coherent and incoherent parts of the open-system dynamics affect the excitation density in a non-negligible way. We also identify the specific ramps for which subleading corrections to the asymptotic scaling laws are suppressed, which serves as a guide to dynamically probing quantum critical exponents in experimentally realistic finite-temperature situations.", "AI": {"tldr": "Simultaneous temperature and Hamiltonian parameter ramps toward quantum critical points enable probing quantum critical exponents (\u03bd and z) in out-of-equilibrium finite-temperature systems, using an open-system Kitaev quantum wire model.", "motivation": "To develop protocols that allow experimental probing of quantum critical exponents (\u03bd and z) in realistic finite-temperature, out-of-equilibrium conditions, overcoming limitations of fixed-temperature protocols.", "method": "Analyze quantum systems under simultaneous, nonlinear ramps of temperature and Hamiltonian control parameters toward quantum critical points, using an open-system version of Kitaev quantum wire as example model.", "result": "Identified ramps where both coherent and incoherent dynamics affect excitation density non-negligibly, enabling extraction of critical exponents \u03bd and z. Found specific ramps that suppress subleading corrections to asymptotic scaling laws.", "conclusion": "Simultaneous temperature-parameter ramps provide practical method to dynamically probe quantum critical exponents in experimentally realistic finite-temperature quantum systems, with identified optimal ramps minimizing corrections."}}
{"id": "2601.10473", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10473", "abs": "https://arxiv.org/abs/2601.10473", "authors": ["Daniel Koch", "Brian Pardo", "Kip Nieman"], "title": "Analysis and Experimental Demonstration of Amplitude Amplification for Combinatorial Optimization", "comment": null, "summary": "Quantum Amplitude Amplification (QAA), the generalization of Grover's algorithm, is capable of yielding optimal solutions to combinatorial optimization problems with high probabilities. In this work we extend the conventional 2-dimensional representation of Grover's (orthogonal collective states) to oracles which encode cost functions such as QUBO, and show that linear cost functions are a special case whereby an exact formula exists for determining optimal oracle parameter settings. Using simulations of problem sizes up to 40 qubits we demonstrate QAA's algorithmic performance across all possible solutions, with an emphasis on the closeness in Grover-like performance for solutions near the global optimum. We conclude with experimental demonstrations of generalized QAA on both IBMQ (superconducting) and IonQ (trapped ion) qubits, showing that the observed probabilities of each basis state match our equations as a function of varying the free parameters in the oracle and diffusion operators.", "AI": {"tldr": "QAA extends Grover's algorithm to optimization problems with cost functions like QUBO, provides exact formulas for linear costs, demonstrates performance via simulations up to 40 qubits, and validates experimentally on IBMQ and IonQ hardware.", "motivation": "Extend Quantum Amplitude Amplification beyond the conventional 2-dimensional representation to handle optimization problems with cost functions, particularly QUBO formulations, and establish theoretical foundations for parameter settings.", "method": "Generalize Grover's orthogonal collective states representation to oracles encoding cost functions; derive exact formulas for linear cost functions; simulate QAA performance across all solutions for problems up to 40 qubits; experimentally validate on IBMQ superconducting and IonQ trapped-ion quantum processors.", "result": "Exact formulas exist for determining optimal oracle parameter settings for linear cost functions; simulations show QAA's algorithmic performance across all solutions with Grover-like performance near global optimum; experimental results match theoretical equations as parameters vary in oracle and diffusion operators.", "conclusion": "QAA can be effectively extended to optimization problems with cost functions, with theoretical foundations established for linear cases and experimental validation on current quantum hardware demonstrating alignment between theory and practice."}}
{"id": "2601.10479", "categories": ["quant-ph", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10479", "abs": "https://arxiv.org/abs/2601.10479", "authors": ["Eyad I. B Hamid"], "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance", "comment": "7 pages, 5 figuers, Appendix", "summary": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial \u03b8] \\in \u03a9(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$.", "AI": {"tldr": "H-EFT-VA ansatz prevents barren plateaus via hierarchical UV-cutoff initialization, maintaining volume-law entanglement while guaranteeing polynomial gradient variance lower bounds.", "motivation": "Barren plateaus threaten variational quantum algorithms by causing exponentially vanishing gradients, making optimization infeasible for large systems. Existing solutions often sacrifice entanglement or expressibility.", "method": "Introduces H-EFT-VA ansatz inspired by Effective Field Theory, enforcing hierarchical UV-cutoff initialization to restrict state exploration and prevent formation of approximate unitary 2-designs.", "result": "Rigorous proof of inverse-polynomial lower bound on gradient variance; 109x improvement in energy convergence and 10.7x increase in ground-state fidelity over standard HEA across 16 experiments with p < 10^{-88} significance.", "conclusion": "H-EFT-VA successfully mitigates barren plateaus while preserving volume-law entanglement and near-Haar purity, enabling practical variational quantum algorithms without sacrificing expressibility."}}
{"id": "2601.10492", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10492", "abs": "https://arxiv.org/abs/2601.10492", "authors": ["Liang Chen", "Wen-Yi Zhu", "Zi-Jie Chen", "Zhu-Bo Wang", "Ya-Dong Hu", "Qing-Xuan Jie", "Guang-Can Guo", "Chang-Ling Zou"], "title": "Optimized readout strategies for neutral atom quantum processors", "comment": null, "summary": "Neutral atom quantum processors have emerged as a promising platform for scalable quantum information processing, offering high-fidelity operations and exceptional qubit scalability. A key challenge in realizing practical applications is efficiently extracting readout outcomes while maintaining high system throughput, i.e., the rate of quantum task executions. In this work, we develop a theoretical framework to quantify the trade-off between readout fidelity and atomic retention. Moreover, we introduce a metric of quantum circuit iteration rate (qCIR) and employ normalized quantum Fisher information to characterize system overall performance. Further, by carefully balancing fidelity and retention, we demonstrate a readout strategy for optimizing information acquisition efficiency. Considering the experimentally feasible parameters for 87Rb atoms, we demonstrate that qCIRs of 197.2Hz and 154.5Hz are achievable using single photon detectors and cameras, respectively. These results provide practical guidance for constructing scalable and high-throughput neutral atom quantum processors for applications in sensing, simulation, and near-term algorithm implementation.", "AI": {"tldr": "Theoretical framework for optimizing readout fidelity vs. atomic retention in neutral atom quantum processors, introducing quantum circuit iteration rate (qCIR) metric and demonstrating practical readout strategies achieving 197.2Hz (single photon) and 154.5Hz (camera) for 87Rb systems.", "motivation": "Neutral atom quantum processors offer high-fidelity operations and scalability, but face challenges in efficiently extracting readout outcomes while maintaining high system throughput for practical applications in sensing, simulation, and near-term algorithms.", "method": "Developed theoretical framework to quantify trade-off between readout fidelity and atomic retention, introduced quantum circuit iteration rate (qCIR) metric, employed normalized quantum Fisher information to characterize overall system performance, and designed readout strategy balancing fidelity and retention.", "result": "Demonstrated achievable qCIRs of 197.2Hz using single photon detectors and 154.5Hz using cameras for 87Rb atoms with experimentally feasible parameters, providing practical guidance for scalable, high-throughput neutral atom quantum processors.", "conclusion": "The framework and optimization strategy enable efficient information acquisition in neutral atom quantum processors, supporting scalable high-throughput systems for practical applications in quantum sensing, simulation, and near-term algorithm implementation."}}
{"id": "2601.10558", "categories": ["quant-ph", "cs.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10558", "abs": "https://arxiv.org/abs/2601.10558", "authors": ["Yu-Hong Lai", "Hao-Chung Cheng"], "title": "A Mirror-Descent Algorithm for Computing the Petz-R\u00e9nyi Capacity of Classical-Quantum Channels", "comment": "This paper is independent and concurrent to arXiv:2601.06492", "summary": "We study the computation of the $\u03b1$-R\u00e9nyi capacity of a classical-quantum (c-q) channel for $\u03b1\\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded.", "AI": {"tldr": "The paper proposes an exponentiated-gradient algorithm for computing \u03b1-R\u00e9nyi capacity of classical-quantum channels, generalizing Blahut-Arimoto, with proven global sublinear and local linear convergence under certain conditions.", "motivation": "To develop efficient computational methods for \u03b1-R\u00e9nyi capacity of classical-quantum channels, extending classical Blahut-Arimoto algorithm to quantum settings with rigorous convergence guarantees.", "method": "Proposes an exponentiated-gradient (mirror descent) iteration that generalizes Blahut-Arimoto algorithm, analyzed using relative smoothness with respect to entropy geometry, with convergence studied under tangent-space nondegeneracy conditions.", "result": "Establishes global sublinear convergence of objective values, and under tangent-space nondegeneracy condition (plus spectral lower bound in one regime), proves local linear convergence in Kullback-Leibler divergence on truncated probability simplex with explicit contraction factor.", "conclusion": "The proposed algorithm provides a computationally efficient method for \u03b1-R\u00e9nyi capacity computation with strong convergence guarantees, bridging classical information theory algorithms to quantum settings."}}
{"id": "2601.10559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10559", "abs": "https://arxiv.org/abs/2601.10559", "authors": ["Mo Xiong", "Jize Han", "Chuanzhen Cao", "Jinbin Li", "Qi Liu", "Zhiguo Huang", "Ming Xue"], "title": "Deterministic and scalable generation of large Fock states", "comment": "(6+2) pages, comments are welcome", "summary": "The scalable and deterministic preparation of large Fock-number states represents a long-standing frontier in quantum science, with direct implications for quantum metrology, communication, and simulation. Despite significant progress in small-scale implementations, extending such state generation to large excitation numbers while maintaining high fidelity remains a formidable challenge. Here, we present a scalable protocol for generating large Fock states with fidelities exceeding 0.9 up to photon numbers on the order of 100, achieved using only native control operations and, when desired, further enhanced by an optional post-selection step. Our method employs a hybrid Genetic-Adam optimization framework that combines the global search efficiency of genetic algorithms with the adaptive convergence of Adam to optimize multi-pulse control sequences comprising Jaynes-Cummings interactions and displacement operations, both of which are native to leading experimental platforms. The resulting control protocols achieve high fidelities with shallow circuit depths and strong robustness against parameter variations. These results establish an efficient and scalable pathway toward high-fidelity non-classical state generation for precision metrology and fault-tolerant quantum technologies.", "AI": {"tldr": "Scalable protocol generates large Fock states (up to ~100 photons) with >0.9 fidelity using hybrid Genetic-Adam optimization of native control operations, enabling high-fidelity non-classical state generation for quantum technologies.", "motivation": "Large Fock-number states are crucial for quantum metrology, communication, and simulation, but generating them with high fidelity at scale remains challenging despite progress with small states.", "method": "Hybrid Genetic-Adam optimization framework combines genetic algorithms' global search with Adam's adaptive convergence to optimize multi-pulse control sequences of native Jaynes-Cummings interactions and displacement operations, optionally enhanced by post-selection.", "result": "Achieved fidelities exceeding 0.9 for Fock states up to photon numbers on the order of 100, with shallow circuit depths and strong robustness against parameter variations.", "conclusion": "Establishes efficient and scalable pathway for high-fidelity non-classical state generation, advancing capabilities for precision metrology and fault-tolerant quantum technologies."}}
{"id": "2601.10588", "categories": ["quant-ph", "cs.LG", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.10588", "abs": "https://arxiv.org/abs/2601.10588", "authors": ["I. K. Kominis", "C. Xie", "S. Li", "M. Skotiniotis", "G. P. Tsironis"], "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders", "comment": "6 pages, 2 figures", "summary": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation.", "AI": {"tldr": "Proposes an information-theoretic test for nonclassicality in neural processing using autoencoders and Bell-type consistency tests in latent space, bypassing microscopic assumptions.", "motivation": "The fundamental question of whether neural information processing is classical or involves quantum-mechanical elements remains unresolved. Current approaches often rely on microscopic assumptions, creating a need for model-agnostic tests that probe the structure of neural representations directly.", "method": "Uses autoencoders as a transparent model system and introduces a Bell-type consistency test in latent space. Tests whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution, shifting from microscopic dynamics to information processing constraints.", "result": "The paper proposes a novel test but does not present experimental results in the abstract. The method establishes a framework for detecting nonclassical signatures in neural systems through information-theoretic constraints rather than physical measurements.", "conclusion": "This work opens a new route for probing the fundamental physics of neural computation by shifting the search for quantum-like signatures from microscopic dynamics to experimentally testable constraints on information processing, providing a model-agnostic approach to the classical vs quantum neural processing debate."}}
{"id": "2601.10594", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.10594", "abs": "https://arxiv.org/abs/2601.10594", "authors": ["Mariia Karabin", "Tanvir Sohail", "Dmytro Bykov", "Eduardo Antonio Coello P\u00e9rez", "Swarnava Ghosh", "Murali Gopalakrishnan Meena", "Seongmin Kim", "Amir Shehata", "In-Saeng Suh", "Hanna Terletska", "Markus Eisenbach"], "title": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "comment": null, "summary": "Quantum embedding methods, such as dynamical mean-field theory (DMFT), provide a powerful framework for investigating strongly correlated materials. A central computational bottleneck in DMFT is in solving the Anderson impurity model (AIM), whose exact solution is classically intractable for large bath sizes. In this work, we develop and benchmark a quantum-classical hybrid solver tailored for DMFT applications, using the variational quantum eigensolver (VQE) to prepare the ground state of the AIM with shallow quantum circuits. The solver uses a unified ansatz framework to prepare the particle and hole excitations of the ground-state from parameter-shifted circuits, enabling the reconstruction of the impurity Green's function through a continued-fraction expansion. We evaluate the performance of this approach across a few bath sizes and interaction strengths under noisy, shot-limited conditions. We compare three optimization routines (COBYLA, Adam, and L-BFGS-B) in terms of convergence and fidelity, assess the benefits of estimating a quantum-computed moment (QCM) correction to the variational energies, and benchmark the approach by comparing the reconstructed density of states (DOS) against that obtained using a classical pipeline. Our results demonstrate the feasibility of Green's function reconstruction on near-term devices and establish practical benchmarks for quantum impurity solvers embedded within self-consistent DMFT loops.", "AI": {"tldr": "Quantum-classical hybrid solver using VQE to solve Anderson impurity model for DMFT, enabling Green's function reconstruction on near-term quantum devices under noisy conditions.", "motivation": "Solving the Anderson impurity model (AIM) is computationally expensive for large bath sizes in dynamical mean-field theory (DMFT), requiring quantum methods to overcome classical intractability.", "method": "Variational quantum eigensolver (VQE) with shallow circuits prepares AIM ground state; unified ansatz generates particle/hole excitations via parameter-shifted circuits; Green's function reconstructed through continued-fraction expansion.", "result": "Evaluated performance across bath sizes and interaction strengths under noisy conditions; compared optimization routines (COBYLA, Adam, L-BFGS-B); assessed quantum-computed moment correction; benchmarked reconstructed density of states against classical pipeline.", "conclusion": "Demonstrates feasibility of Green's function reconstruction on near-term quantum devices and establishes practical benchmarks for quantum impurity solvers in self-consistent DMFT loops."}}
{"id": "2601.10650", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10650", "abs": "https://arxiv.org/abs/2601.10650", "authors": ["M. P. Tonne", "Kh. P. Gnatenko"], "title": "Quantifying the properties of evolutionary quantum states of the XXZ spin model using quantum computing", "comment": null, "summary": "The entanglement distance of evolutionary quantum states of a two-spin system with the XXZ model has been studied. The analysis has been conducted both analytically and using quantum computing. An analytical dependence of the entanglement distance on the values of the model coupling constants and the parameters of the initial states has been obtained. The speed of evolution of a two-spin system has been investigated. The analysis has been performed analytically and using quantum computing. An explicit dependence of the speed of evolution on the coupling constants and on the parameters of the initial state has been obtained. The results of quantum computations are in good agreement with the theoretical predictions.", "AI": {"tldr": "Study of entanglement distance and evolution speed in a two-spin XXZ system using analytical methods and quantum computing, showing agreement between theory and quantum computations.", "motivation": "To investigate entanglement dynamics and evolution speed in quantum spin systems, specifically analyzing how entanglement distance and evolution speed depend on system parameters in the XXZ model, and to validate theoretical predictions using quantum computing.", "method": "Combined analytical approach and quantum computing simulations of a two-spin system with the XXZ model. Analytical derivation of entanglement distance and evolution speed dependencies on coupling constants and initial state parameters, followed by verification through quantum computations.", "result": "Obtained explicit analytical dependencies: entanglement distance depends on XXZ model coupling constants and initial state parameters; evolution speed also depends on these parameters. Quantum computation results show good agreement with theoretical predictions, validating the analytical models.", "conclusion": "Successfully characterized entanglement dynamics and evolution speed in two-spin XXZ systems, establishing clear parameter dependencies and demonstrating consistency between analytical theory and quantum computational approaches."}}
{"id": "2601.10655", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10655", "abs": "https://arxiv.org/abs/2601.10655", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Symmetry-based Perspectives on Hamiltonian Quantum Search Algorithms and Schrodinger's Dynamics between Orthogonal States", "comment": "21 pages, 3 figures, 2 tables", "summary": "It is known that the continuous-time variant of Grover's search algorithm is characterized by quantum search frameworks that are governed by stationary Hamiltonians, which result in search trajectories confined to the two-dimensional subspace of the complete Hilbert space formed by the source and target states. Specifically, the search approach is ineffective when the source and target states are orthogonal. In this paper, we employ normalization, orthogonality, and energy limitations to demonstrate that it is unfeasible to breach time-optimality between orthogonal states with constant Hamiltonians when the evolution is limited to the two-dimensional space spanned by the initial and final states. Deviations from time-optimality for unitary evolutions between orthogonal states can only occur with time-dependent Hamiltonian evolutions or, alternatively, with constant Hamiltonian evolutions in higher-dimensional subspaces of the entire Hilbert space. Ultimately, we employ our quantitative analysis to provide meaningful insights regarding the relationship between time-optimal evolutions and analog quantum search methods. We determine that the challenge of transitioning between orthogonal states with a constant Hamiltonian in a sub-optimal time is closely linked to the shortcomings of analog quantum search when the source and target states are orthogonal and not interconnected by the search Hamiltonian. In both scenarios, the fundamental cause of the failure lies in the existence of an inherent symmetry within the system.", "AI": {"tldr": "Constant Hamiltonians cannot achieve time-optimal evolution between orthogonal states when confined to the 2D subspace spanned by initial and final states; time-dependent Hamiltonians or higher-dimensional subspaces are required.", "motivation": "To understand the limitations of constant Hamiltonians in achieving time-optimal quantum evolution between orthogonal states, particularly in the context of analog quantum search algorithms where orthogonal source-target states cause search failures.", "method": "Employ normalization, orthogonality, and energy constraints to mathematically prove the impossibility of breaching time-optimality between orthogonal states with constant Hamiltonians in the 2D subspace spanned by initial and final states.", "result": "Time-optimal evolution between orthogonal states cannot be achieved with constant Hamiltonians when restricted to the 2D subspace; deviations from time-optimality require either time-dependent Hamiltonians or constant Hamiltonians operating in higher-dimensional subspaces.", "conclusion": "The failure of analog quantum search with orthogonal source-target states and the impossibility of time-optimal evolution with constant Hamiltonians in 2D subspaces both stem from inherent system symmetries, providing fundamental insights into quantum search limitations."}}
{"id": "2601.10659", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.10659", "abs": "https://arxiv.org/abs/2601.10659", "authors": ["Georgios Theologou", "Mikkel F. Andersen", "Sandro Wimberger"], "title": "Counterdiabatic driving for random-gap Landau-Zener transitions", "comment": "Keywords: Shortcuts to adiabaticity; Landau-Zener problem; quantum control; random-gap distribution; adiabatic quantum computing", "summary": "The Landau--Zener (LZ) model describes a two-level quantum system that undergoes an avoided crossing. In the adiabatic limit, the transition probability vanishes. An auxiliary control field $H_\\text{CD}$ can be reverse-engineered so that the full Hamiltonian $H_0 + H_\\text{CD}$ reproduces adiabaticity for all parameter values. Our aim is to construct a single control field $H_1$ that drives an ensemble of LZ-type Hamiltonians with a distribution of energy gaps. $H_1$ works best statistically, minimizing the average transition probability. We restrict our attention to a special class of $H_1$ controls, motivated by $H_\\text{CD}$. We found a systematic trade-off between instantaneous adiabaticity and the final transition probability. Certain limiting cases with a linear sweep can be treated analytically; one of them being the LZ system with Dirac $\u03b4(t)$ function. Comprehensive and systematic numerical simulations support and extend the analytic results.", "AI": {"tldr": "The paper develops a single control field to drive an ensemble of Landau-Zener systems with distributed energy gaps, minimizing average transition probability through statistical optimization.", "motivation": "To address the challenge of controlling multiple quantum systems with varying parameters simultaneously, specifically an ensemble of LZ-type Hamiltonians with different energy gaps, where traditional counterdiabatic driving requires system-specific controls.", "method": "Construct a single control field H\u2081 that works statistically for the ensemble, restricting to a special class of controls motivated by counterdiabatic driving H_CD. Use analytical treatment for limiting cases (linear sweep, Dirac \u03b4-function) and comprehensive numerical simulations.", "result": "Found systematic trade-off between instantaneous adiabaticity and final transition probability. Analytical solutions exist for certain limiting cases, with numerical simulations supporting and extending these results.", "conclusion": "A single control field can be designed to statistically minimize transition probabilities across an ensemble of LZ systems with distributed energy gaps, revealing fundamental trade-offs in ensemble quantum control."}}
{"id": "2601.10662", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10662", "abs": "https://arxiv.org/abs/2601.10662", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Geometric Aspects of Entanglement Generating Hamiltonian Evolutions", "comment": "24 pages, 2 figures, 3 tables", "summary": "We examine the pertinent geometric characteristics of entanglement that arise from stationary Hamiltonian evolutions transitioning from separable to maximally entangled two-qubit quantum states. From a geometric perspective, each evolution is characterized by means of geodesic efficiency, speed efficiency, and curvature coefficient. Conversely, from the standpoint of entanglement, these evolutions are quantified using various metrics, such as concurrence, entanglement power, and entangling capability. Overall, our findings indicate that time-optimal evolution trajectories are marked by high geodesic efficiency, with no energy resource wastage, no curvature (i.e., zero bending), and an average path entanglement that is less than that observed in time-suboptimal evolutions. Additionally, when analyzing separable-to-maximally entangled evolutions between nonorthogonal states, time-optimal evolutions demonstrate a greater short-time degree of nonlocality compared to time-suboptimal evolutions between the same initial and final states. Interestingly, the reverse is generally true for separable-to-maximally entangled evolutions involving orthogonal states. Our investigation suggests that this phenomenon arises because suboptimal trajectories between orthogonal states are characterized by longer path lengths with smaller curvature, which are traversed with a higher energy resource wastage compared to suboptimal trajectories between nonorthogonal states. Consequently, a higher initial degree of nonlocality in the unitary time propagators appears to be essential for achieving the maximally entangled state from a separable state. Furthermore, when assessing optimal and suboptimal evolutions...", "AI": {"tldr": "The paper analyzes geometric properties of entanglement in Hamiltonian-driven quantum state evolutions from separable to maximally entangled two-qubit states, comparing time-optimal and time-suboptimal trajectories using geometric metrics (geodesic efficiency, speed efficiency, curvature) and entanglement metrics (concurrence, entanglement power, entangling capability).", "motivation": "To understand the relationship between geometric characteristics of quantum evolution trajectories and entanglement generation, specifically comparing time-optimal versus time-suboptimal paths for creating maximally entangled states from separable states in two-qubit systems.", "method": "The study examines Hamiltonian-driven evolutions using geometric analysis (geodesic efficiency, speed efficiency, curvature coefficient) and entanglement quantification (concurrence, entanglement power, entangling capability) for both time-optimal and time-suboptimal trajectories between separable and maximally entangled states.", "result": "Time-optimal evolutions show high geodesic efficiency, zero curvature, no energy waste, but lower average path entanglement than time-suboptimal evolutions. For nonorthogonal states, time-optimal evolutions exhibit greater short-time nonlocality, while for orthogonal states, time-suboptimal evolutions show greater short-time nonlocality due to longer paths with smaller curvature and higher energy waste.", "conclusion": "The geometric properties of quantum evolution trajectories significantly influence entanglement generation, with time-optimal paths being geometrically efficient but producing less entanglement along the path, while the relationship between optimality and nonlocality depends on whether initial and final states are orthogonal or nonorthogonal."}}
{"id": "2601.10672", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10672", "abs": "https://arxiv.org/abs/2601.10672", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Efficiency, Curvature, and Complexity of Quantum Evolutions for Qubits in Nonstationary Magnetic Fields", "comment": "27 pages, 4 figures, 1 table", "summary": "In optimal quantum-mechanical evolutions, motion can take place along paths of minimal length within an optimal time frame. Alternatively, optimal evolutions may occur along established paths without any waste of energy resources and achieving 100% speed efficiency. Unfortunately, realistic physical scenarios often lead to less-than-ideal evolutions that demonstrate suboptimal efficiency, nonzero curvature, and a high level of complexity. In this paper, we provide an exact analytical expression for the curvature of a quantum evolution pertaining to a two-level quantum system subjected to various time-dependent magnetic fields. Specifically, we examine the dynamics produced by a two-parameter nonstationary Hermitian Hamiltonian with unit speed efficiency. To enhance our understanding of the physical implications of the curvature coefficient, we analyze the curvature behavior in relation to geodesic efficiency, speed efficiency, and the complexity of the quantum evolution (as described by the ratio of the difference between accessible and accessed Bloch-sphere volumes for the evolution from initial to final state to the accessible volume for the given quantum evolution). Our findings indicate that, generally, efficient quantum evolutions exhibit lower complexity compared to inefficient ones. However, we also note that complexity transcends mere length. In fact, longer paths that are sufficiently curved can demonstrate a complexity that is less than that of shorter paths with a lower curvature coefficient.", "AI": {"tldr": "The paper provides exact analytical expressions for curvature in quantum evolutions of two-level systems under time-dependent magnetic fields, analyzing relationships between curvature, geodesic efficiency, speed efficiency, and complexity.", "motivation": "Realistic quantum evolutions often deviate from ideal optimal paths, exhibiting suboptimal efficiency, nonzero curvature, and high complexity. The paper aims to quantify these deviations through analytical curvature expressions for two-level systems to better understand the physical implications of curvature in quantum dynamics.", "method": "The authors derive exact analytical expressions for curvature in quantum evolutions of two-level systems subjected to various time-dependent magnetic fields. They examine dynamics produced by a two-parameter nonstationary Hermitian Hamiltonian with unit speed efficiency. They analyze curvature behavior in relation to geodesic efficiency, speed efficiency, and complexity (quantified as the ratio of difference between accessible and accessed Bloch-sphere volumes to accessible volume).", "result": "Efficient quantum evolutions generally exhibit lower complexity compared to inefficient ones. However, complexity transcends mere path length: longer paths with sufficient curvature can demonstrate lower complexity than shorter paths with lower curvature coefficients.", "conclusion": "The analytical curvature expressions provide insights into quantum evolution efficiency and complexity relationships. The findings reveal that curvature plays a crucial role in determining complexity, with sufficiently curved longer paths potentially being less complex than shorter, less curved paths, challenging simple length-based complexity assumptions."}}
{"id": "2601.10683", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10683", "abs": "https://arxiv.org/abs/2601.10683", "authors": ["Kean Chen", "Zhicheng Zhang", "Nengkun Yu"], "title": "Optimal lower bound for quantum channel tomography in away-from-boundary regime", "comment": "23 pages", "summary": "Consider quantum channels with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. Any such channel must satisfy the constraint $rd_2\\geq d_1$, and the parameter regime $rd_2=d_1$ is called the boundary regime. In this paper, we show an optimal query lower bound $\u03a9(rd_1d_2/\\varepsilon^2)$ for quantum channel tomography to within diamond norm error $\\varepsilon$ in the away-from-boundary regime $rd_2\\geq 2d_1$, matching the existing upper bound $O(rd_1d_2/\\varepsilon^2)$. In particular, this lower bound fully settles the query complexity for the commonly studied case of equal input and output dimensions $d_1=d_2=d$ with $r\\geq 2$, in sharp contrast to the unitary case $r=1$ where Heisenberg scaling $\u0398(d^2/\\varepsilon)$ is achievable.", "AI": {"tldr": "Optimal query lower bound \u03a9(rd\u2081d\u2082/\u03b5\u00b2) for quantum channel tomography in away-from-boundary regime (rd\u2082 \u2265 2d\u2081), matching existing upper bound and settling query complexity for equal dimensions with r \u2265 2.", "motivation": "To establish fundamental limits on quantum channel tomography, particularly contrasting with unitary case where Heisenberg scaling is achievable, and to settle query complexity in the away-from-boundary regime.", "method": "Theoretical analysis establishing query lower bounds for quantum channel tomography using information-theoretic techniques, focusing on the parameter regime where rd\u2082 \u2265 2d\u2081 (away-from-boundary).", "result": "Proves optimal query lower bound \u03a9(rd\u2081d\u2082/\u03b5\u00b2) matching existing upper bound O(rd\u2081d\u2082/\u03b5\u00b2), fully settling query complexity for equal dimensions d\u2081=d\u2082=d with r \u2265 2, showing sharp contrast to unitary case with Heisenberg scaling \u0398(d\u00b2/\u03b5).", "conclusion": "The paper establishes fundamental limits on quantum channel tomography, showing that in the away-from-boundary regime, the query complexity scales as \u0398(rd\u2081d\u2082/\u03b5\u00b2), which is strictly worse than the Heisenberg scaling achievable for unitary channels."}}
{"id": "2601.10689", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10689", "abs": "https://arxiv.org/abs/2601.10689", "authors": ["Daniel Allepuz-Requena", "Zohran Ali", "Dennis H\u00f8j", "Yingxuan Chen", "Luiz Couto Correa Pinto Filho", "Alexander Huck", "Ulrik L. Andersen"], "title": "Mitigating nonlinear transduction noise in high-cooperativity cavity optomechanics", "comment": null, "summary": "Coupling mechanical motion to an optical resonator enables displacement measurements approaching the standard quantum limit (SQL). However, increasing the optomechanical coupling strength will inevitably lead to probing of the nonlinear response of the optical resonator. Thermal intermodulation noise (TIN) arising from the nonlinear mixing of thermomechanical motion can further increase the imprecision well above the SQL and has hitherto been canceled up to second order of nonlinearity via operation at the \"magic detuning\". In this work, we record the output of a membrane-in-the-middle microcavity system operating at room temperature and achieving high cooperativity, $C>n_\\text{th}$, and apply a nonlinear transform that removes all orders of TIN, improving the mechanical signal-to-noise ratio by nearly 10 dB. Our results can be applied to experiments affected by third-order TIN, which we expect to be the dominating intrinsic source of noise in high-cooperativity room-temperature cavity optomechanical systems.", "AI": {"tldr": "A nonlinear transform method is developed to remove all orders of thermal intermodulation noise in high-cooperativity room-temperature cavity optomechanical systems, improving mechanical signal-to-noise ratio by nearly 10 dB.", "motivation": "Thermal intermodulation noise (TIN) arising from nonlinear mixing of thermomechanical motion can increase measurement imprecision well above the standard quantum limit, and existing methods only cancel TIN up to second order via \"magic detuning\" operation.", "method": "Record output of a membrane-in-the-middle microcavity system operating at room temperature with high cooperativity (C > n_th), then apply a nonlinear transform that removes all orders of TIN.", "result": "The nonlinear transform improves mechanical signal-to-noise ratio by nearly 10 dB by removing all orders of TIN, addressing third-order TIN which is expected to dominate in high-cooperativity room-temperature systems.", "conclusion": "The developed nonlinear transform method effectively eliminates thermal intermodulation noise at all orders, enabling improved displacement measurements in high-cooperativity room-temperature cavity optomechanical systems where third-order TIN is the dominant intrinsic noise source."}}
{"id": "2601.10693", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2601.10693", "abs": "https://arxiv.org/abs/2601.10693", "authors": ["Francisca Vasconcelos", "Malvika Raj Joshi"], "title": "Constant-Depth Unitary Preparation of Dicke States", "comment": null, "summary": "Dicke states serve as a critical resource in quantum metrology, communication, and computation. However, unitary preparation of Dicke states is limited to logarithmic depth in standard circuit models and existing constant-depth protocols require measurement and feed-forward. In this work, we present the first unitary, constant-depth protocols for exact Dicke state preparation. We overcome the logarithmic-depth barrier by moving beyond the standard circuit model and leveraging global interactions (native to architectures such as neutral atoms and trapped ions). Specifically, utilizing unbounded CZ gates (i.e. within the QAC$^0$ circuit class), we offer circuits for exact computation of constant-weight Dicke states, using polynomial ancillae, and approximation of weight-1 Dicke states (i.e. $W$ states), using only constant ancillae. Granted additional access to the quantum FAN-OUT operation (i.e. upgrading to the QAC$_f^0$ circuit class), we also achieve exact preparation of arbitrary-weight Dicke states, with polynomial ancillae. These protocols distinguish the constant-depth capabilities of quantum architectures based on connectivity and offer a novel path toward resolving a long-standing quantum complexity conjecture.", "AI": {"tldr": "First unitary constant-depth protocols for exact Dicke state preparation using global interactions beyond standard circuit models.", "motivation": "Dicke states are crucial for quantum applications but existing preparation methods have limitations: unitary preparation requires logarithmic depth in standard circuits, and constant-depth protocols need measurement and feed-forward.", "method": "Overcome logarithmic-depth barrier by leveraging global interactions native to neutral atoms and trapped ions architectures. Use unbounded CZ gates (QAC\u2070 circuit class) for constant-weight Dicke states with polynomial ancillae, and approximate weight-1 Dicke states with constant ancillae. With quantum FAN-OUT operation (QAC_f\u2070 circuit class), achieve exact preparation of arbitrary-weight Dicke states with polynomial ancillae.", "result": "First unitary constant-depth protocols for exact Dicke state preparation. Constant-weight Dicke states prepared exactly using polynomial ancillae, weight-1 Dicke states approximated with constant ancillae, and arbitrary-weight Dicke states prepared exactly with quantum FAN-OUT operation.", "conclusion": "These protocols demonstrate constant-depth capabilities of quantum architectures based on connectivity and offer a path toward resolving a long-standing quantum complexity conjecture."}}
{"id": "2601.10698", "categories": ["quant-ph", "cond-mat.other", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10698", "abs": "https://arxiv.org/abs/2601.10698", "authors": ["Cesare Tronci"], "title": "Madelung hydrodynamics of spin-orbit coupling: action principles, currents, and correlations", "comment": "First version. Comments welcome", "summary": "We exploit the variational and Hamiltonian structures of quantum hydrodynamics with spin to unfold the correlation and torque mechanisms accompanying spin-orbit coupling (SOC) in electronic motion. Using Hamilton's action principle for the Pauli equation, we isolate SOC-induced quantum forces that act on the orbital Madelung--Bohm trajectories and complement the usual force terms known to appear in quantum hydrodynamics with spin. While the latter spin-hydrodynamic forces relate to the quantum geometric tensor (QGT), SOC-induced orbital forces originate from a particular current operator that contributes prominently to the spin current and whose contribution was overlooked in the past. The distinction between different force terms reveals two fundamentally different mechanisms generating quantum spin-orbit correlations. Leveraging the Hamiltonian structure of the hydrodynamic system, we also elucidate spin transport features such as the current shift in the spin Hall effect and the correlation-induced quantum torques. Finally, we illustrate the framework via the Madelung--Rashba equations for planar SOC configurations and propose a particle-based scheme for numerical implementation.", "AI": {"tldr": "The paper develops a quantum hydrodynamic framework for spin-orbit coupling, identifying distinct SOC-induced orbital forces and spin-hydrodynamic forces, revealing two mechanisms for quantum spin-orbit correlations, and applying the theory to planar SOC configurations.", "motivation": "To understand the correlation and torque mechanisms accompanying spin-orbit coupling in electronic motion by exploiting the variational and Hamiltonian structures of quantum hydrodynamics with spin, isolating previously overlooked SOC-induced forces.", "method": "Using Hamilton's action principle for the Pauli equation to develop a quantum hydrodynamic framework with spin, distinguishing between SOC-induced orbital forces and spin-hydrodynamic forces related to the quantum geometric tensor, and analyzing spin transport features through the Hamiltonian structure.", "result": "Identified distinct SOC-induced quantum forces acting on orbital trajectories, revealed two fundamentally different mechanisms generating quantum spin-orbit correlations, elucidated spin transport features including current shift in spin Hall effect and correlation-induced quantum torques, and developed Madelung--Rashba equations for planar SOC with particle-based numerical scheme.", "conclusion": "The variational and Hamiltonian approach to quantum hydrodynamics with spin provides a comprehensive framework for understanding SOC mechanisms, distinguishing between orbital and spin forces, and offers practical applications for analyzing spin transport phenomena and numerical implementation."}}
{"id": "2601.10703", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.10703", "abs": "https://arxiv.org/abs/2601.10703", "authors": ["Samuel E. Begg", "Bishal K. Ghosh", "Chong Zu", "Chuanwei Zhang", "Michael Kolodrubetz"], "title": "Scalable Spin Squeezing in Power-Law Interacting XXZ Models with Disorder", "comment": "5 + 4 pages", "summary": "While spin squeezing has been traditionally considered in all-to-all interacting models, recent works have shown that spin squeezing can occur in systems with power-law interactions, leading to direct testing in Rydberg atoms, trapped ions, ultracold atoms and nitrogen vacancy (NV) centers in diamond. For the latter, Wu. et al. Nature 646 (2025) demonstrated that spin squeezing is heavily affected by positional disorder, reducing any capacity for a practical squeezing advantage, which requires scalability with the system size. In this Letter we explore the robustness of spin-squeezing in two-dimensional lattices with a fraction of unoccupied lattice sites. Using semi-classical modeling, we demonstrate the existence of scalable squeezing in power-law interacting XXZ models up to a disorder threshold, above which squeezing is not scalable. We produce a phase diagram for scalable squeezing, and explain its absence in the aforementioned NV experiment. Our work illustrates the maximum disorder allowed for realizing scalable spin squeezing in a host of quantum simulators, highlights a regime with substantial tolerance to disorder, and identifies controlled defect creation as a promising route for scalable squeezing in solid-state systems.", "AI": {"tldr": "Spin squeezing in 2D lattices with power-law interactions remains scalable up to a disorder threshold despite positional defects, explaining limitations in NV center experiments.", "motivation": "Recent experiments with NV centers showed that positional disorder severely limits spin squeezing scalability, contradicting expectations from all-to-all interacting models and raising questions about practical implementation in quantum simulators with defects.", "method": "Semi-classical modeling of two-dimensional lattices with power-law interacting XXZ models containing a fraction of unoccupied lattice sites to study disorder effects on spin squeezing.", "result": "Demonstrated existence of scalable squeezing up to a disorder threshold, beyond which squeezing loses scalability; produced phase diagram for scalable squeezing and explained absence of scalability in NV center experiments.", "conclusion": "Identified maximum disorder tolerance for scalable spin squeezing in quantum simulators, highlighted regimes with substantial disorder tolerance, and proposed controlled defect creation as a promising approach for scalable squeezing in solid-state systems."}}
{"id": "2601.10713", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10713", "abs": "https://arxiv.org/abs/2601.10713", "authors": ["Bruno Costa Alves Freire", "Fran\u00e7ois-Marie Le R\u00e9gent", "Anthony Leverrier"], "title": "Quantum Maxwell Erasure Decoder for qLDPC codes", "comment": "8 pages, 3 figures, submitted to the IEEE ISIT 2026", "summary": "We introduce a quantum Maxwell erasure decoder for CSS quantum low-density parity-check (qLDPC) codes that extends peeling with bounded guessing. Guesses are tracked symbolically and can be eliminated by restrictive checks, giving a tunable tradeoff between complexity and performance via a guessing budget: an unconstrained budget recovers Maximum-Likelihood (ML) performance, while a constant budget yields linear-time decoding and approximates ML. We provide theoretical guarantees on asymptotic performance and demonstrate strong performance on bivariate bicycle and quantum Tanner codes.", "AI": {"tldr": "Quantum Maxwell erasure decoder for CSS qLDPC codes extends peeling with bounded symbolic guessing, offering tunable complexity-performance tradeoff via guessing budget.", "motivation": "To develop an efficient decoder for CSS quantum LDPC codes that bridges the gap between linear-time decoding and Maximum-Likelihood performance through a tunable parameter.", "method": "Extends peeling decoder with bounded symbolic guessing, where guesses are tracked symbolically and eliminated by restrictive checks; uses a guessing budget parameter to control complexity-performance tradeoff.", "result": "Provides theoretical asymptotic performance guarantees and demonstrates strong performance on bivariate bicycle and quantum Tanner codes; unconstrained budget recovers ML performance, constant budget yields linear-time decoding approximating ML.", "conclusion": "The quantum Maxwell erasure decoder offers a flexible framework for CSS qLDPC decoding with tunable tradeoffs between computational complexity and decoding performance."}}
