<div id=toc></div>

# Table of Contents

- [quant-ph](#quant-ph) [Total: 38]


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [1] [LiDMaS: Architecture-Level Modeling of Fault-Tolerant Magic-State Injection in GKP Photonic Qubits](https://arxiv.org/abs/2601.16244)
*Dennis Delali Kwesi Wayo*

Main category: quant-ph

TL;DR: Logical T-gate magic-state preparation in GKP-encoded photonic qubits using repeat-until-success injection with surface-code protection, showing high success probabilities (>0.94) and logical fidelities (0.77-0.80) with strong dependence on squeezing.


<details>
  <summary>Details</summary>
Motivation: Fault-tolerant quantum computation in photonic architectures requires efficient preparation of high-fidelity logical magic states under realistic constraints of finite squeezing and photon loss, necessitating quantitative design guidance for scalable architectures.

Method: Developed architecture-level modeling framework using lightweight density-matrix simulator with standard numerical linear algebra. Finite squeezing mapped to effective logical dephasing, depolarizing noise included at logical level, photon loss treated as heralded erasure. Systematic parameter sweeps over squeezing (8-16 dB), loss probabilities (0.01-0.03), and surface-code distances (d=1,3,5,7).

Result: Success probabilities exceed 0.94 across all parameters with average overhead close to unity. After outer-code protection, logical fidelities reach 0.77-0.80, showing weak sensitivity to moderate photon loss but strong dependence on squeezing. Phase-boundary analysis identifies minimum squeezing requirements for simultaneous high success probability and logical fidelity.

Conclusion: The results provide quantitative design guidance for scalable photonic fault-tolerant quantum architectures, demonstrating that repeat-until-success injection with surface-code protection can achieve high logical magic-state fidelities under realistic constraints, with squeezing being the dominant limiting factor.

Abstract: Fault-tolerant quantum computation in photonic architectures relies on the efficient preparation of high-fidelity logical magic states under realistic constraints imposed by finite squeezing and photon loss. In this work, we study logical T-gate magic-state preparation in GKP-encoded photonic qubits using a repeat-until-success injection protocol combined with outer surface-code protection. We develop an architecture-level modeling framework based on a lightweight density-matrix simulator implemented with standard numerical linear algebra. Finite squeezing is mapped to effective logical dephasing, depolarizing noise is included at the logical level, and photon loss is treated as a heralded erasure process. This approach avoids explicit continuous-variable wavefunction simulation, hardware-specific photonic models, and quantum software frameworks, enabling transparent and computationally efficient exploration of architectural trade-offs. We perform systematic parameter sweeps over squeezing values from 8 to 16 dB, baseline loss probabilities between 0.01 and 0.03, and surface-code distances d = 1, 3, 5, and 7. Across this regime, we evaluate repeat-until-success probability, average injection overhead, and logical magic-state fidelity. We find that success probabilities exceed 0.94 across all studied parameters, with an average overhead close to unity. After outer-code protection, logical fidelities reach approximately 0.77 to 0.80 and show weak sensitivity to moderate photon loss but a strong dependence on squeezing. Phase-boundary analysis identifies minimum squeezing requirements needed to simultaneously achieve high success probability and logical fidelity. These results provide quantitative design guidance for scalable photonic fault-tolerant quantum architectures.

</details>


### [2] [Quantum Cellular Automata on a Dual-Species Rydberg Processor](https://arxiv.org/abs/2601.16257)
*Ryan White,Vikram Ramesh,Alexander Impertro,Shraddha Anand,Francesco Cesa,Giuliano Giudici,Thomas Iadecola,Hannes Pichler,Hannes Bernien*

Main category: quant-ph

TL;DR: Quantum cellular automata (QCAs) enable universal quantum dynamics using only static qubit arrays and global controls, demonstrated on dual-species Rydberg arrays with high-fidelity entangled state generation.


<details>
  <summary>Details</summary>
Motivation: To address the scaling challenge of coherent controls in quantum devices by developing a framework that requires only static qubit arrays and global control operations, bypassing the need for complex individual qubit addressing.

Method: Implementation of quantum cellular automata on a dual-species Rydberg array of rubidium and cesium atoms, leveraging independent global control of each species to execute various quantum protocols through simple pulse sequences.

Result: Successful generation of diverse entangled states including GHZ states, 96.7(1.7)%-fidelity Bell states, 17-qubit cluster states, and high-connectivity graph states, demonstrating versatile many-body dynamics.

Conclusion: QCAs offer a scalable and versatile approach for quantum information systems with global controls, providing both practical routes for scaling quantum devices and new perspectives on quantum many-body dynamics.

Abstract: As quantum devices scale to larger and larger sizes, a significant challenge emerges in scaling their coherent controls accordingly. Quantum cellular automata (QCAs) constitute a promising framework that bypasses this control problem: universal dynamics can be achieved using only a static qubit array and global control operations. We realize QCAs on a dual-species Rydberg array of rubidium and cesium atoms, leveraging independent global control of each species to perform a myriad of quantum protocols. With simple pulse sequences, we explore many-body dynamics and generate a variety of entangled states, including GHZ states, 96.7(1.7)%-fidelity Bell states, 17-qubit cluster states, and high-connectivity graph states. The versatility and scalability of QCAs offers compelling routes for scaling quantum information systems with global controls, as well as new perspectives on quantum many-body dynamics.

</details>


### [3] [Multi-invariants in stabilizer states](https://arxiv.org/abs/2601.16258)
*Sriram Akella,Abhijit Gadde,Jay Pandey*

Main category: quant-ph

TL;DR: Efficient computation of multipartite entanglement measures (multi-invariants) for stabilizer states, with explicit formulas for tripartite cases and counting arguments for general q-partite cases, revealing connections to topology.


<details>
  <summary>Details</summary>
Motivation: Multipartite entanglement is poorly understood compared to bipartite entanglement, and there's a need for tools to calculate multipartite entanglement measures (multi-invariants) specifically for stabilizer states, which are important in quantum information and many-body physics.

Method: Develop efficient numerical algorithm for computing multi-invariants for stabilizer states; use GHZ-extraction theorem to derive explicit formulas for tripartite stabilizer states; employ counting arguments to calculate Coxeter multi-invariants for q-partite stabilizer states; analyze restricted stabilizer states from models like toric code and X-cube.

Result: Efficient numerical algorithm for multi-invariants; explicit formula for any multi-invariant of tripartite stabilizer states; counting argument for Coxeter multi-invariants of q-partite stabilizer states; simplified formulas for restricted stabilizer states; discovery of connections between multi-invariants, stabilizer states and topology.

Conclusion: The paper provides powerful tools for analyzing multipartite entanglement in stabilizer states, establishes explicit formulas for important cases, reveals topological connections, and offers simplified results for physically relevant models, advancing understanding of multipartite entanglement.

Abstract: Multipartite entanglement is a natural generalization of bipartite entanglement, but is relatively poorly understood. In this paper, we develop tools to calculate a class of multipartite entanglement measures - known as multi-invariants - for stabilizer states. We give an efficient numerical algorithm that computes multi-invariants for stabilizer states. For tripartite stabilizer states, we also obtain an explicit formula for any multi-invariant using the GHZ-extraction theorem. We then present a counting argument that calculates any Coxeter multi-invariant of a q-partite stabilizer state. We conjecture a closed form expression for the same. We uncover hints of an interesting connection between multi-invariants, stabilizer states and topology. We show how our formulas are further simplified for a restricted class of stabilizer states that appear as ground states of interesting models like the toric code and the X-cube model.

</details>


### [4] [Quantum algorithm for simulating non-adiabatic dynamics at metallic surfaces](https://arxiv.org/abs/2601.16264)
*Robert A. Lang,Paarth Jain,Juan Miguel Arrazola,Danial Motlagh*

Main category: quant-ph

TL;DR: A quantum algorithm for simulating non-adiabatic dynamics at molecule-metal interfaces with low resource requirements, making it suitable for early fault-tolerant quantum computers.


<details>
  <summary>Details</summary>
Motivation: Non-adiabatic dynamics at molecule-metal interfaces are crucial for many technological applications (heterogeneous catalysis, solar energy conversion, molecular junctions), but classical computational methods are prohibitively expensive due to the need to model coupling between nuclear motion and numerous electronic states.

Method: Developed a generalization of the Anderson-Newns Hamiltonian and created a highly optimized quantum algorithm for simulating non-adiabatic dynamics. Used PennyLane software platform for resource estimation and demonstrated low implementation costs.

Result: The algorithm requires remarkably low resources: only 271 qubits and 7.9 × 10⁷ Toffoli gates for 1000 Trotter steps to simulate models with 100 metal orbitals, 8 molecular orbitals, and 20 nuclear degrees of freedom.

Conclusion: Non-adiabatic molecule-metal dynamics represents a promising application for first-generation fault-tolerant quantum computers due to the algorithm's low resource requirements and relevance to scientifically and industrially important systems.

Abstract: Non-adiabatic dynamics at molecule-metal interfaces govern diverse and technologically important phenomena, from heterogeneous catalysis to dye-sensitized solar energy conversion and charge transport across molecular junctions. Realistic modeling of such dynamics necessitates taking into account various charge and energy transfer channels involving the coupling of nuclear motion with a very large number of electronic states, leading to prohibitive cost using classical computational methods. In this work we introduce a generalization of the Anderson-Newns Hamiltonian and develop a highly optimized quantum algorithm for simulating the non-adiabatic dynamics of realistic molecule-metal interfaces. Using the PennyLane software platform, we perform resource estimations of our algorithm, showing its remarkably low implementation cost for model systems representative of various scientifically and industrially relevant molecule-metal systems. Specifically, we find that time evolution for models including $100$ metal orbitals, $8$ molecular orbitals, and $20$ nuclear degrees of freedom, requires only $271$ qubits and $7.9 \times 10^7$ Toffoli gates for $1000$ Trotter steps, suggesting non-adiabatic molecule-metal dynamics as a fruitful application of first-generation fault-tolerant quantum computers.

</details>


### [5] [Post-processing optimization and optimal bounds for non-adaptive shadow tomography](https://arxiv.org/abs/2601.16266)
*Andrea Caprotti,Joshua Morris,Borivoje Dakić*

Main category: quant-ph

TL;DR: Optimizing reconstruction coefficients for informationally overcomplete POVMs reduces shadow tomography variance, improving sampling efficiency and scaling with system size.


<details>
  <summary>Details</summary>
Motivation: Informationally overcomplete POVMs outperform minimally complete measurements in tomography but leave classical freedom in shadow tomography - the same observable admits infinitely many unbiased linear reconstructions from identical measurement data. This freedom can be exploited to reduce variance.

Method: Formulate choice of reconstruction coefficients as convex minimax problem and develop algorithm with guaranteed convergence that returns tightest state-independent variance bound achievable by post-processing for fixed POVM and observable.

Result: Resulting estimators dramatically reduce sampling complexity relative to standard canonical reconstructions, and can even improve qualitative scaling with system size for structured noncommuting targets.

Conclusion: Optimizing reconstruction coefficients for informationally overcomplete POVMs provides significant practical advantages in shadow tomography by reducing variance and improving sampling efficiency through post-processing optimization.

Abstract: Informationally overcomplete POVMs are known to outperform minimally complete measurements in many tomography and estimation tasks, and they also leave a purely classical freedom in shadow tomography: the same observable admits infinitely many unbiased linear reconstructions from identical measurement data. We formulate the choice of reconstruction coefficients as a convex minimax problem and give an algorithm with guaranteed convergence that returns the tightest state-independent variance bound achievable by post-processing for a fixed POVM and observable. Numerical examples show that the resulting estimators can dramatically reduce sampling complexity relative to standard (canonical) reconstructions, and can even improve the qualitative scaling with system size for structured noncommuting targets.

</details>


### [6] [Engineering Near-Infrared Two-Level Systems in Confined Alkali Vapors](https://arxiv.org/abs/2601.16269)
*Gilad Orr,Golan Ben-Ari,Eliran Talker*

Main category: quant-ph

TL;DR: Experimental demonstration of telecom-wavelength atomic two-level system in sub-micron vapor cell using rubidium, where wall collisions enable closed cycling transition isolation despite hyperfine structure.


<details>
  <summary>Details</summary>
Motivation: To create practical, compact atomic two-level systems operating at telecom wavelengths for integrated quantum photonic technologies, overcoming challenges of hyperfine structure and optical pumping in conventional atomic systems.

Method: Combined experimental and theoretical investigation using hot rubidium vapor confined in sub-micron-thick cell, analyzing absorption and fluorescence spectra to study wall-induced relaxation effects on atomic coherence.

Result: Demonstrated that strong confinement induces closed cycling transition that effectively isolates atomic dynamics to two-level configuration, suppressing optical pumping into uncoupled states and enabling robust telecom-wavelength light-matter interaction.

Conclusion: Establishes practical route for realizing near-infrared atomic two-level systems in compact vapor-cell devices, opening opportunities for integrated quantum memories, telecom-band frequency references, and scalable quantum information processing.

Abstract: We combined experimental and theoretical investigations of an effective two-level atomic system operating in the near-infrared telecom wavelength regime, realized using hot rubidium vapor confined within a sub-micron-thick cell. In this strongly confined geometry, atomic coherence is profoundly influenced by wall-induced relaxation arising from frequent atom-surface collisions. By analyzing both absorption and fluorescence spectra, we demonstrate that the optical response is dominated by a closed cycling transition, which effectively isolates the atomic dynamics to a two-level configuration despite the presence of multiple hyperfine states. This confinement-induced selection suppresses optical pumping into uncoupled states and enables robust, controllable light-matter interaction at telecom wavelengths within a miniature atomic platform. Our results establish a practical route to realizing near-infrared atomic two-level systems in compact vapor-cell devices, opening new opportunities for integrated quantum photonic technologies, including on-chip quantum memories, telecom-band frequency references, and scalable quantum information processing.

</details>


### [7] [Experimental observation of conformal field theory spectra](https://arxiv.org/abs/2601.16275)
*Xiangkai Sun,Yuan Le,Stephen Naus,Richard Bing-Shiun Tsai,Lewis R. B. Picard,Sara Murciano,Michael Knap,Jason Alicea,Manuel Endres*

Main category: quant-ph

TL;DR: Experimental observation of energy excitation spectra in emergent conformal field theories at quantum phase transitions using Rydberg chains and modulation techniques.


<details>
  <summary>Details</summary>
Motivation: Conformal field theories (CFTs) describe universal properties of quantum phase transitions, but much of their rich structure remains unobserved experimentally. The paper aims to directly observe energy excitation spectra of emergent CFTs at quantum phase transitions.

Method: Developed and implemented a modulation technique to resolve finite-size spectra of Rydberg chains tuned to quantum phase transitions described by Ising or tricritical Ising CFTs. Used local control to distinguish excitation parities under reflection and induce transitions between distinct CFT spectra by changing boundary conditions. Also employed a variant of the modulation technique to study dynamical structure factor.

Result: Directly observed energy excitation spectra of emergent CFTs at quantum phase transitions, recovering universal energy ratios characteristic of underlying field theories. Successfully distinguished excitation parities and induced transitions between distinct CFT spectra in tricritical Ising chain. Studied dynamical structure factor related to correlation of underlying Ising conformal field.

Conclusion: The work not only probes emergence of CFT features in a quantum simulator but also provides a technique for diagnosing a priori unknown universality classes in future experiments, bridging theoretical predictions with experimental observations of CFT properties.

Abstract: Conformal field theories (CFTs) feature prominently in high-energy physics, statistical mechanics, and condensed matter. For example, CFTs govern emergent universal properties of systems tuned to quantum phase transitions, including their entanglement, correlations, and low-energy excitation spectra. Much of the rich structure predicted by CFTs nevertheless remains unobserved in experiment. Here we directly observe the energy excitation spectra of emergent CFTs at quantum phase transitions -- recovering universal energy ratios characteristic of the underlying field theories. Specifically, we develop and implement a modulation technique to resolve a Rydberg chain's finite-size spectra, variably tuned to quantum phase transitions described by either Ising or tricritical Ising CFTs. We also employ local control to distinguish parities of excitations under reflection and, in the tricritical Ising chain, to induce transitions between distinct CFT spectra associated with changing boundary conditions. By utilizing a variant of the modulation technique, we furthermore study the dynamical structure factor of the critical system, which is closely related to the correlation of an underlying Ising conformal field. Our work not only probes the emergence of CFT features in a quantum simulator, but also provides a technique for diagnosing a priori unknown universality classes in future experiments.

</details>


### [8] [Exploring Noisy Quantum Thermodynamical Processes via the Depolarizing-Channel Approximation](https://arxiv.org/abs/2601.16317)
*Jian Li,Xiaoyang Wang,Marcus Huber,Nicolai Friis,Pharnam Bakhshinezhad*

Main category: quant-ph

TL;DR: The paper introduces a framework to approximate gate-dependent noise in quantum circuits using a global depolarizing channel, applies it to analyze the noisy two-sort algorithmic cooling protocol, and derives fundamental bounds on cooling performance.


<details>
  <summary>Details</summary>
Motivation: Quantum thermodynamical protocols like cooling are significantly affected by unavoidable noise and errors, but analytical characterization becomes increasingly challenging with system size and deep quantum circuits where noise accumulates in complex ways.

Method: Introduces a general framework for approximating cumulative gate-dependent noise using a global depolarizing channel, specifies the regime where this approximation reliably describes noisy dynamics, and applies it to the thermodynamical two-sort algorithmic cooling protocol.

Result: Analytically derives the asymptotic cooling limit of TSAC in the presence of noise, shows optimal cooling is achieved with finite rather than infinite qubits (unlike noiseless case), and derives fundamental bounds on achievable ground-state population.

Conclusion: The framework provides a new approach for exploring noisy quantum thermodynamical processes, offering analytical insights into noise effects on cooling protocols and establishing fundamental performance limits.

Abstract: Noise and errors are unavoidable in any realistic quantum process, including processes designed to reduce noise and errors in the first place. In particular, quantum thermodynamical protocols for cooling can be significantly affected, potentially altering both their performance and efficiency. Analytically characterizing the impact of such errors becomes increasingly challenging as the system size grows, particularly in deep quantum circuits where noise can accumulate in complex ways. To address this, we introduce a general framework for approximating the cumulative effect of gate-dependent noise using a global depolarizing channel. We specify the regime in which this approximation provides a reliable description of the noisy dynamics. Applying our framework to the thermodynamical two-sort algorithmic cooling (TSAC) protocol, we analytically derive its asymptotic cooling limit in the presence of noise. Using the cooling limit, the optimal cooling performance is achieved by a finite number of qubits--distinguished from the conventional noiseless TSAC protocol by an infinite number of qubits--and fundamental bounds on the achievable ground-state population are derived. This approach opens new avenues for exploring noisy quantum thermodynamical processes.

</details>


### [9] [Unambiguous randomness from a quantum state](https://arxiv.org/abs/2601.16343)
*Fionnuala Curran*

Main category: quant-ph

TL;DR: The paper introduces and analyzes unambiguous randomness in quantum measurements, quantifying randomness when an eavesdropper can return inconclusive outcomes, and solves these problems for specific quantum scenarios.


<details>
  <summary>Details</summary>
Motivation: To quantify quantum randomness in adversarial scenarios where an eavesdropper can sometimes return inconclusive outcomes rather than being wrong, inspired by concepts from quantum state discrimination.

Method: Introduces unambiguous randomness and randomness with fixed inconclusive rates, solves for any state and projective measurement in dimension two, and for isotropically noisy states measured in unbiased bases of any dimension.

Result: Found that eavesdroppers correlated to both noisy states and measurements outperform those correlated only to noisy states, identifying a critical error parameter beyond which joint eavesdroppers achieve perfect guessing probability, eliminating private randomness.

Conclusion: The analysis reveals fundamental limitations on private randomness extraction when considering joint correlations between eavesdroppers and both quantum states and measurements, with implications for quantum cryptography and randomness certification.

Abstract: Intrinsic randomness is generated when a quantum state is measured in any basis in which it is not diagonal. In an adversarial scenario, we quantify this randomness by the probability that a correlated eavesdropper could correctly guess the measurement outcomes. What if the eavesdropper is never wrong, but can sometimes return an inconclusive outcome? Inspired by analogous concepts in quantum state discrimination, we introduce the unambiguous randomness of a quantum state and measurement, and, relaxing the assumption of perfect accuracy, randomness with a fixed rate of inconclusive outcomes. We solve these problems for any state and projective measurement in dimension two, as well as for an isotropically noisy state measured in an unbiased basis of any dimension. In the latter case, we find that, given a fixed amount of total noise, an eavesdropper correlated only to the noisy state is always outperformed by an eavesdropper with joint correlations to both a noisy state and a noisy measurement. In fact, we identify a critical error parameter beyond which the joint eavesdropper achieves perfect guessing probability, ruling out any possibility of private randomness.

</details>


### [10] [Reducing TLS loss in tantalum CPW resonators using titanium sacrificial layers](https://arxiv.org/abs/2601.16369)
*Zachary Degnan,Chun-Ching Chiu,Yi-Hsun Chen,David Sommers,Leonid Abdurakhimov,Lihuang Zhu,Arkady Fedorov,Peter Jacobson*

Main category: quant-ph

TL;DR: Using a 0.2nm titanium sacrificial layer as an oxygen getter to reduce tantalum oxide at metal-air interfaces improves superconducting resonator quality factors by over 3x to >1.5 million in single-photon regime.


<details>
  <summary>Details</summary>
Motivation: Two-level system (TLS) loss at metal-air interfaces limits coherence in superconducting quantum circuits, particularly in tantalum-based devices where native oxide formation contributes to TLS loss.

Method: Deposit 0.2nm titanium sacrificial layer on pre-sputtered α-tantalum, use it as solid-state oxygen getter to chemically modify native Ta oxide, remove titanium with buffered oxide etchant, then perform high-vacuum annealing to further suppress TLS loss.

Result: Resonators treated with this process show internal quality factors Qi exceeding average of 1.5 million in single-photon regime across ten devices, over three times higher than identical devices without titanium layer.

Conclusion: Interfacial oxide chemistry plays critical role in superconducting loss, and atomic-scale surface engineering via titanium sacrificial layer offers practical, fabrication-compatible approach to improve coherence in tantalum-based quantum circuits.

Abstract: We demonstrate a substantial reduction in two-level system loss in tantalum coplanar waveguide resonators fabricated on high-resistivity silicon substrates through the use of an ultrathin titanium sacrificial layer. A 0.2nm titanium film, deposited atop pre-sputtered α-tantalum, acts as a solid-state oxygen getter that chemically modifies the native Ta oxide at the metal-air interface. After device fabrication, the titanium layer is removed using buffered oxide etchant, leaving behind a chemically reduced Ta oxide surface. Subsequent high-vacuum annealing further suppresses two-level system loss. Resonators treated with this process exhibit internal quality factors Qi exceeding an average of 1.5 million in the single-photon regime across ten devices, over three times higher than otherwise identical devices lacking the titanium layer. These results highlight the critical role of interfacial oxide chemistry in superconducting loss and reinforce atomic-scale surface engineering as an effective approach to improving coherence in tantalum-based quantum circuits. The method is compatible with existing fabrication workflows applicable to tantalum films, offering a practical route to further extending T1 lifetimes in superconducting qubits.

</details>


### [11] [Subspace-Confined QAOA with Generalized Dicke States for Multi-Channel Allocation in 5G CBRS Networks](https://arxiv.org/abs/2601.16396)
*Gunsik Min,Youngjin Seo,Jun Heo*

Main category: quant-ph

TL;DR: Subspace-confined QAOA for CBRS multi-channel allocation using Generalized Dicke states and XY mixers to enforce per-node channel constraints, reducing search space from 2²⁴ to 2916 feasible configurations.


<details>
  <summary>Details</summary>
Motivation: Standard QAOA formulations for CBRS spectrum sharing use penalty terms for multi-channel constraints, making most of the Hilbert space correspond to invalid assignments, which is inefficient.

Method: Propose subspace-confined QAOA where each node-wise channel register is initialized in a Generalized Dicke state and evolved under an intra-register XY mixer, confining dynamics to tensor product of Johnson graphs that exactly encode per-node Hamming-weight constraints.

Result: For 8-node CBRS interference graph with 24 qubits, search space reduced from 2²⁴ to 2916 feasible configurations; algorithm converges rapidly to low-conflict assignments without large penalty coefficients, outperforming standard penalty-based QAOA and greedy classical heuristic in feasibility.

Conclusion: Constraint-preserving ansatz enables efficient CBRS multi-channel allocation with reduced search space, better convergence, and maintains high feasibility ratio under NISQ-relevant noise regimes.

Abstract: Efficient spectrum sharing in the Citizens Broadband Radio Service (CBRS) band is essential for maximizing 5G network capacity, particularly when high-traffic base stations require simultaneous access to multiple channels. Standard formulations of the Quantum Approximate Optimization Algorithm (QAOA) impose such multi-channel constraints using penalty terms, so most of the explored Hilbert space corresponds to invalid assignments. We propose a subspace-confined QAOA tailored to CBRS multi-channel allocation, in which each node-wise channel register is initialized in a Generalized Dicke state and evolved under an intra-register XY mixer. This ansatz confines the dynamics to a tensor product of Johnson graphs that exactly encode per-node Hamming-weight constraints. For an 8-node CBRS interference graph with 24 qubits, the effective search space is reduced from the full Hilbert space of size $2^{24}$ to 2916 feasible configurations. Within this subspace, the algorithm converges rapidly to low-conflict assignments without large penalty coefficients. Simulations on instances with up to eight nodes show that the proposed ansatz achieves near-optimal conflict levels and consistently outperforms standard penalty-based QAOA and a greedy classical heuristic in terms of feasibility. Noise simulations with depolarizing channels further indicate that the constraint-preserving structure maintains a high feasibility ratio in NISQ-relevant error regimes.

</details>


### [12] [Low-Loss, High-Coherence Airbridge Interconnects Fabricated by Single-Step Lithography](https://arxiv.org/abs/2601.16416)
*Jibang Fu,Bo Ren,Jiandong Ouyang,Cong Li,Kechengqi Zhu,Yonggang Che,Xiang Fu,Shichuan Xue,Zhaohua Yang,Mingtang Deng,Junjie Wu*

Main category: quant-ph

TL;DR: Single-step e-beam lithography process for nanoscale airbridges enables high-performance 3D interconnects with improved quantum coherence times.


<details>
  <summary>Details</summary>
Motivation: Conventional multi-step airbridge fabrication methods hinder miniaturization and introduce process-related defects, limiting performance in integrated circuits and quantum devices.

Method: Simplified single electron-beam lithography step using optimized multilayer resist stack with triple-exposure-dose scheme and thermal reflow to create smooth, suspended metallic bridges with sub-200-nm features.

Result: Fabricated airbridges in gradiometric SQUID design for superconducting transmon qubits show no measurable additional loss in relaxation time T1 while enabling 2.5-fold enhancement of dephasing time T2*.

Conclusion: The efficient single-step method offers practical route for integrating high-performance three-dimensional interconnects in advanced quantum and nano-electronic devices.

Abstract: Airbridges are essential for creating high-performance, low-parasitic interconnects in integrated circuits and quantum devices. Conventional multi-step fabrication methods hinder miniaturization and introduce process-related defects. We report a simplified process for fabricating nanoscale airbridges using only a single electron-beam lithography step. By optimizing a multilayer resist stack with a triple-exposure-dose scheme and a thermal reflow step, we achieve smooth, suspended metallic bridges with sub-200-nm features that exhibit robust mechanical stability. Fabricated within a gradiometric SQUID design for superconducting transmon qubits, these airbridges introduce no measurable additional loss in the relaxation time $T_1$, while enabling a 2.5-fold enhancement of the dephasing time $T_2^*$. This efficient method offers a practical route toward integrating high-performance three-dimensional interconnects in advanced quantum and nano-electronic devices.

</details>


### [13] [Circulant quantum channels and its applications](https://arxiv.org/abs/2601.16435)
*Bing Xie,Lin Zhang*

Main category: quant-ph

TL;DR: Introduces circulant quantum channels (a subclass of mixed-permutation channels), shows their image is circulant matrices, proves they're entanglement-breaking, and discusses applications including Bargmann invariants analysis and coherence bounds.


<details>
  <summary>Details</summary>
Motivation: To study a specific family of circulant quantum channels that are computationally tractable and have desirable operational properties, particularly for analyzing quantum correlations and coherence measures.

Method: Introduces circulant quantum channels as a subclass of mixed-permutation channels, characterizes their image as circulant matrices, analyzes their properties including entanglement-breaking nature, and applies them to Bargmann invariants and coherence measures.

Result: Proves that circulant quantum channels have image precisely equal to circulant matrices, are entanglement-breaking (reducing resource cost for erasing quantum correlations), and provides applications including tighter lower bounds for ℓp-norm coherence and characterization of bipartite system action.

Conclusion: Circulant quantum channels form a mathematically tractable subclass with practical advantages for quantum information processing, particularly for analyzing quantum correlations and coherence, with reduced resource requirements compared to general mixed-permutation channels.

Abstract: This note introduces a family of circulant quantum channels -- a subclass of the mixed-permutation channels -- and investigates its key structural and operational properties. We show that the image of the circulant quantum channel is precisely the set of circulant matrices. This characterization facilitates the analysis of arbitrary $n$-th order Bargmann invariants. Furthermore, we prove that the channel is entanglement-breaking, implying a substantially reduced resource cost for erasing quantum correlations compared to a general mixed-permutation channel. Applications of this channel are also discussed, including the derivation of tighter lower bounds for $\ell_p$-norm coherence and a characterization of its action in bipartite systems.

</details>


### [14] [Gluing Randomness via Entanglement: Tight Bound from Second Rényi Entropy](https://arxiv.org/abs/2601.16454)
*Wonjun Lee,Hyukjoon Kwon,Gil Young Cho*

Main category: quant-ph

TL;DR: Local random unitaries applied to entangled states generate approximate random states, with error scaling as Θ(e^{-N₂(ψ)}) where N₂(ψ) is the second Rényi entanglement entropy, establishing entanglement as the key resource for randomness generation.


<details>
  <summary>Details</summary>
Motivation: Efficient generation of random quantum states is challenging but crucial for quantum information processing tasks. The paper aims to identify the fundamental resource enabling local operations to generate global randomness.

Method: Apply local random unitaries to an entangled state |ψ⟩ to generate random states. Analyze the resulting ensemble as approximate state designs, derive error bounds using second Rényi entanglement entropy, and extend to coherence-free operations and pseudorandom state generation.

Result: The ensemble forms approximate state designs with error Θ(e^{-N₂(ψ)}), where N₂(ψ) is second Rényi entanglement entropy. This bound is tight and also applies to second Rényi coherence entropy. Second Rényi entropies provide maximal capacities for randomness generation using resource-free operations.

Conclusion: Entanglement enables local random unitaries to generate global random states by "gluing" randomness across systems. The second Rényi entropy quantifies the maximal randomness generation capacity, with applications to pseudorandom state generation in multipartite systems.

Abstract: The efficient generation of random quantum states is a long-standing challenge, motivated by their diverse applications in quantum information processing tasks. In this work, we identify entanglement as the key resource that enables local random unitaries to generate global random states by effectively gluing randomness across the system. Specifically, we demonstrate that approximate random states can be produced from an entangled state $|ψ\rangle$ through the application of local random unitaries. We show that the resulting ensemble forms an approximate state design with an error saturating as $Θ(e^{-\mathcal{N}_2(ψ)})$, where $\mathcal{N}_2(ψ)$ is the second Rényi entanglement entropy of $|ψ\rangle$. Furthermore, we prove that this tight bound also applies to the second Rényi entropy of coherence when the ensemble is constructed using coherence-free operations. These results imply that, when restricted to resource-free gates, the quality of the generated random states is determined entirely by the resource content of the initial state. Notably, we find that among all $α$-Rényi entropeis, the second Rényi entropy yields the tightest bounds. Consequently, these second Rényi entropies can be interpreted as the maximal capacities for generating randomness using resource-free operations. Finally, moving beyond approximate state designs, we utilize this entanglement-assisted gluing mechanism to present a novel method for generating pseudorandom states in multipartite systems from a locally entangled state via pseudorandom unitaries in each of parties.

</details>


### [15] [Quantum phase estimation with optimal confidence interval using three control qubits](https://arxiv.org/abs/2601.16474)
*Kaur Kristjuhan,Dominic W. Berry*

Main category: quant-ph

TL;DR: Efficient preparation of optimal quantum phase estimation states using matrix product states with bond dimension 4, enabling implementation with only 3 control qubits for power-of-2 dimensions.


<details>
  <summary>Details</summary>
Motivation: Quantum phase estimation is crucial for quantum algorithms, especially in quantum chemistry for ground state energy estimation. Current methods for preparing optimal confidence interval states (discrete prolate spheroidal sequences) are inefficient, limiting practical implementation on early fault-tolerant quantum computers with limited logical qubits.

Method: Develop a matrix product state (MPS) representation with bond dimension 4 that accurately approximates the discrete prolate spheroidal sequence states. This MPS can be efficiently prepared using a sequence of simple three-qubit operations. For dimensions that are powers of 2, the phase estimation requires only three qubits in the control register.

Result: The MPS representation with bond dimension 4 provides highly accurate approximations for all dimensions tested up to 2^24. The method enables efficient state preparation with simple three-qubit operations, making it suitable for early-generation fault-tolerant quantum computers with limited logical qubits.

Conclusion: This work presents a significantly more efficient method for preparing optimal quantum phase estimation states compared to prior approaches. The technique enables practical implementation of quantum phase estimation with minimal qubit requirements, particularly beneficial for early fault-tolerant quantum computing architectures.

Abstract: Quantum phase estimation is an important routine in many quantum algorithms, particularly for estimating the ground state energy in quantum chemistry simulations. This estimation involves applying powers of a unitary to the ground state, controlled by an auxiliary state prepared on a control register. In many applications the goal is to provide a confidence interval for the phase estimate, and optimal performance is provided by a discrete prolate spheroidal sequence. We show how to prepare the corresponding state in a far more efficient way than prior work. We find that a matrix product state representation with a bond dimension of 4 is sufficient to give a highly accurate approximation for all dimensions tested, up to $2^{24}$. This matrix product state can be efficiently prepared using a sequence of simple three-qubit operations. When the dimension is a power of 2, the phase estimation can be performed with only three qubits for the control register, making it suitable for early-generation fault-tolerant quantum computers with a limited number of logical qubits.

</details>


### [16] [Indefinite Causal Order from Failure-to-Glue: Contextual Semantics and Parametric Time](https://arxiv.org/abs/2601.16494)
*Partha Ghose*

Main category: quant-ph

TL;DR: This two-part paper develops a category-theoretic framework to analyze indefinite causal order (ICO), treating definite-order explainability as a gluing problem, then applies it to quantum gravity to interpret ICO as parametric order indeterminacy in coarse-grained relational interventions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to clarify the opaque meaning of "indefiniteness" in indefinite causal order studies and establish precise criteria for comparing ICO across different frameworks (quantum processes, process matrices, quantum gravity). The authors aim to provide a common language for stating what "no hidden definite order" means.

Method: Part I: Category-theoretic formulation where definite causal orderings are treated as contexts; causal separability becomes a gluing problem with consistent global sections, while causal nonseparability indicates failure-to-glue. Introduces a seven-valued contextual classifier to separate contextual variation from genuine indeterminacy. Part II: Applies this framework to quantum gravity by distinguishing parametric ordering variable τ from geometric time, using stochastic quantization of spin-network dynamics and interpreting Wheeler-DeWitt condition as equilibrium constraint.

Result: The framework provides a unified approach to analyze ICO: definite-order explainability is formalized as a gluing problem, and ICO in quantum gravity is interpreted as indeterminacy of parametric order in coarse-grained relational interventions, even when microscopic processes are globally ordered by τ.

Conclusion: The two parts together establish a common language for comparing ICO criteria across different frameworks and precisely define what "no hidden definite order" means, bridging quantum information and quantum gravity perspectives on indefinite causal order.

Abstract: Indefinite causal order (ICO) has been studied via higher-order quantum processes (e.g.\ the quantum switch), process matrices, and quantum-gravity proposals involving superposed causal structure, yet the meaning of ``indefiniteness'' and its relation to definite-order explanations often remain opaque.
  Part~I develops a category-theoretic formulation of definite-order explainability as a gluing problem: each definite causal ordering (a partial order/DAG type) is treated as a context, and causal separability amounts to a consistent global section (possibly after convex mixing), whereas causal nonseparability is a failure-to-glue. We also introduce a compact seven-valued contextual classifier -- an intuitionistic elaboration -- that separates variation across contexts from genuine indeterminacy.
  Part~II applies this framework to a quantum-gravity motivated setting where the fundamental time is a parametric ordering variable $τ$, distinct from geometric (spacetime) time. Adopting a stochastic-quantization perspective on spin-network dynamics (Hilbert space not assumed fundamental) and reading the Wheeler--DeWitt condition as an equilibrium/stationarity constraint, we interpret ICO as indeterminacy of the parametric order of coarse-grained relational interventions, even when the microscopic update process is globally ordered by $τ$. Together, the two parts provide a common language for comparing ICO criteria and for stating precisely what ``no hidden definite order'' means.

</details>


### [17] [The optimal strategy of two-photon interferometric sensing in diverse noise environments](https://arxiv.org/abs/2601.16517)
*Teng-fei Yan,Zhuo-zhuo Wang,Qi-qi Li,Peng-long Wang,Rui-Bo Jin,Bai-hong Li*

Main category: quant-ph

TL;DR: Two-photon interferometry (HOM and N00N state) shows quantum superiority in sensing, but noise diminishes this advantage. HOM interferometry (based on biphoton frequency difference) is insensitive to phase noise, while N00N state interferometry (based on biphoton frequency sum) is sensitive to phase noise. Spectrally resolved detection outperforms spectrally non-resolved detection, especially beyond biphoton coherence time.


<details>
  <summary>Details</summary>
Motivation: Quantum sensing using two-photon interferometry offers precision beyond classical limits, but practical applications are hindered by noise. Understanding how different interferometric schemes (HOM vs N00N state) respond to noise is crucial for developing optimal sensing strategies in real-world noisy environments.

Method: Analysis of sensitivity to noise in two typical two-photon interferometries: Hong-Ou-Mandel (HOM) and N00N state interferometry. Examined both spectrally non-resolved and spectrally resolved detection schemes. Investigated how these interferometries respond to phase noise based on their dependence on biphoton frequency difference (HOM) versus sum (N00N state).

Result: HOM interferometry is insensitive to phase noise in both spectrally non-resolved and resolved detection schemes, while N00N state interferometry is sensitive to phase noise. Spectrally resolved detection outperforms spectrally non-resolved detection for both interferometries, particularly when operating beyond the coherence time of biphotons.

Conclusion: The study provides an optimal strategy for practical two-photon interferometric sensing: HOM interferometry is suitable for noisy environments due to its noise insensitivity, while N00N state interferometry requires careful noise management. Spectrally resolved detection should be preferred over spectrally non-resolved detection, especially for measurements exceeding biphoton coherence time.

Abstract: Quantum sensing based on two-photon interferometry manifests quantum superiority beyond the classical precision limit. However, this superiority is usually diminished inevitably by the noise. Here, we analyze the sensitivity of two typical two-photon interferometries to the noise, that is, Hong-Ou-Mandel (HOM) and N00N state interferometry. It is found that HOM (N00N state) interference, which depends on the biphoton frequency difference (sum), is insensitive (sensitive) to the phase noise in both the manners of spectrally non-resolved and resolved detections in practice, suggesting their potential applications of sensing for different noise scenarios. Furthermore, spectrally resolved detection outperforms spectrally non-resolved one for the two interferometries, especially for the scope that exceeds the coherence time of biphotons. The findings provide an optimal strategy for the practical applications of two-photon interferometric sensing in diverse noise environments.

</details>


### [18] [Drive-Through Quantum Gate: Non-Stop Entangling a Mobile Ion Qubit with a Stationary One](https://arxiv.org/abs/2601.16537)
*Ting Hsu,Wen-Han Png,Kuan-Ting Lin,Ming-Shien Chang,Guin-Dar Lin*

Main category: quant-ph

TL;DR: Novel entangling scheme between stationary and uniformly moving mobile ions minimizes heating in trapped-ion quantum computing, achieving 0.01% gate error and enabling resource-efficient operations beyond QCCD limitations.


<details>
  <summary>Details</summary>
Motivation: QCCD architectures based on ion shuttling suffer from severe heating during detachment, reintegration, and non-uniform motion, requiring extensive cooling and stabilization resources. This limits scalability and efficiency of trapped-ion quantum computers.

Method: Proposes entangling scheme between stationary ion qubits and continuously transported mobile ions that remain in uniform motion. Mobile ions act as communication qubits passing beside stationary memory arrays, minimizing motional heating.

Result: Theoretical demonstration of gate error on the order of 0.01%, achievable with current technology. Enables resource-efficient quantum operations and long-distance entanglement distribution.

Conclusion: This approach provides an alternative trapped-ion architecture that overcomes QCCD limitations, paving the way for scalable quantum computing with reduced heating and improved resource efficiency.

Abstract: Towards the scalable realization of a quantum computer, a quantum charge-coupled device (QCCD) based on ion shuttling has been considered a promising approach. However, the processes of detaching an ion from an array, reintegrating it, and driving non-uniform motion introduce severe heating, requiring significant time and laser power for re-cooling and stabilization. To mitigate these challenges, we propose a novel entangling scheme between a stationary ion qubit and a continuously transported mobile ion, which remains in uniform motion and minimizes motional heating. We theoretically demonstrate a gate error on the order of 0.01%, within reach of current technology. This approach enables resource-efficient quantum operations and facilitates long-distance entanglement distribution, where stationary trapped-ion arrays serve as memory units and mobile ions act as communication qubits passing beside them. Our results pave the way for an alternative trapped-ion architecture beyond the QCCD paradigm.

</details>


### [19] [Quantum graph resonances by cut-off technique](https://arxiv.org/abs/2601.16545)
*Pavel Exner,Jiří Lipovský,Jan Pekař*

Main category: quant-ph

TL;DR: Quantum graph resonances identified from eigenvalue behavior of cut-off system with compact core and semi-infinite leads


<details>
  <summary>Details</summary>
Motivation: To develop a method for identifying resonances in quantum graphs with semi-infinite leads by analyzing the eigenvalue behavior of finite cut-off systems

Method: Study eigenvalue behavior of cut-off quantum graph systems (finite approximation) to identify resonances in the original system with semi-infinite leads

Result: Demonstrated that resonances can be identified from the eigenvalue patterns of the cut-off system, providing a computational approach for resonance analysis

Conclusion: The eigenvalue behavior of finite cut-off systems provides a practical method for identifying resonances in quantum graphs with semi-infinite leads

Abstract: We demonstrate how resonances in a quantum graph consisting of a compact core and semi-infinite leads can be identified from the eigenvalue behavior of the cut-off system.

</details>


### [20] [Certification of quantum properties with imperfect measurements](https://arxiv.org/abs/2601.16570)
*Leonardo Zambrano,Teodor Parella-Dilmé,Antonio Acín,Donato Farina*

Main category: quant-ph

TL;DR: A robust certification method for quantum states that accounts for both shot noise and measurement imperfections, extending confidence regions to handle imperfect measurement control.


<details>
  <summary>Details</summary>
Motivation: Accurate characterization of quantum systems is essential for quantum technology advancement, and certifying convex functions of quantum states plays a central role in many applications, but existing methods need to account for both statistical noise and systematic measurement imperfections.

Method: Extends confidence regions to accommodate imperfect measurement control, provides explicit prescriptions for quantifying shot noise from finite statistics and estimating measurement imperfections, and uses convex optimization techniques to bound function values.

Result: Develops a robust certification framework that jointly incorporates statistical errors (shot noise) and systematic errors (measurement imperfections) for quantum experiments.

Conclusion: The method provides a comprehensive certification approach that handles both statistical and systematic uncertainties, enabling more reliable characterization of experimentally prepared quantum states.

Abstract: The accurate characterization of quantum systems is essential for the advancement of quantum technologies. In particular, certifying convex functions of quantum states plays a central role in many applications. We present a certification method for experimentally prepared quantum states that accounts for both shot noise and measurement imperfections in the data-acquisition stage. Building upon previous work, our method extends confidence regions to accommodate imperfect control over measurements. The values of the functions can then be bounded using convex optimization techniques. We provide explicit prescriptions for quantifying the noise contribution from finite statistics and for estimating the effect of measurement imperfections. By jointly incorporating statistical and systematic errors, the method yields a robust certification framework for quantum experiments.

</details>


### [21] [Efficient quantum machine learning with inverse-probability algebraic corrections](https://arxiv.org/abs/2601.16665)
*Jaemin Seo*

Main category: quant-ph

TL;DR: Proposes inverse-probability algebraic learning as an alternative to gradient-based optimization for quantum neural networks, offering faster convergence, no learning-rate tuning, and robustness to noise.


<details>
  <summary>Details</summary>
Motivation: Gradient-based optimization for QNNs suffers from slow convergence, sensitivity to hyperparameters, instability near sharp minima, and vulnerability to quantum noise in near-term devices.

Method: Treats learning as a local inverse problem in probability space, directly mapping discrepancies between predicted and target Born-rule probabilities to parameter corrections via pseudo-inverse of the Jacobian, providing covariant algebraic updates without learning-rate tuning.

Result: Algebraic learning converges significantly faster than gradient descent and Adam, escapes loss plateaus, achieves lower final errors, shows near-optimal error scaling under finite-shot sampling, and remains robust against hardware noise like dephasing.

Conclusion: Inverse-probability algebraic learning offers a principled and practical alternative to procedural optimization for QNN training, particularly suitable for resource-constrained near-term quantum devices.

Abstract: Quantum neural networks (QNNs) provide expressive probabilistic models by leveraging quantum superposition and entanglement, yet their practical training remains challenging due to highly oscillatory loss landscapes and noise inherent to near-term quantum devices. Existing training approaches largely rely on gradient-based procedural optimization, which often suffers from slow convergence, sensitivity to hyperparameters, and instability near sharp minima. In this work, we propose an alternative inverse-probability algebraic learning framework for QNNs. Instead of updating parameters through incremental gradient descent, our method treats learning as a local inverse problem in probability space, directly mapping discrepancies between predicted and target Born-rule probabilities to parameter corrections via a pseudo-inverse of the Jacobian. This algebraic update is covariant, does not require learning-rate tuning, and enables rapid movement toward the vicinity of a loss minimum in a single step. We systematically compare the proposed method with gradient descent and Adam optimization in both regression and classification tasks using a teacher-student QNN benchmark. Our results show that algebraic learning converges significantly faster, escapes loss plateaus, and achieves lower final errors. Under finite-shot sampling, the method exhibits near-optimal error scaling, while remaining robust against intrinsic hardware noise such as dephasing. These findings suggest that inverse-probability algebraic learning offers a principled and practical alternative to procedural optimization for QNN training, particularly in resource-constrained near-term quantum devices.

</details>


### [22] [Charging of a Quantum Battery by a Single-Photon Quantum Pulse](https://arxiv.org/abs/2601.16671)
*Elnaz Darsheshdar,Seyed Mostafa Moniri*

Main category: quant-ph

TL;DR: A quantum battery model with TLS charger and harmonic oscillator battery achieves optimal charging via single-photon pulse, saturating universal energy bounds and establishing quantum speed limits at exceptional points.


<details>
  <summary>Details</summary>
Motivation: To develop a minimal quantum battery model that enables analytical understanding of optimal charging protocols, energy storage limits, and quantum speed limits in open quantum systems.

Method: Two-level system (TLS) charger coupled to harmonic oscillator battery, excited by single-photon quantum pulse; analytical solutions for dynamics; optimization of pulse shape; analysis at exceptional points.

Result: Optimal pulse shape maximizes stored energy and saturates universal bound determined by TLS decay rates; minimum charging time established; quantum speed limit derived at exceptional point; analytical expressions for charging power obtained.

Conclusion: The minimal quantum battery model provides fundamental insights into optimal quantum energy transfer, establishes universal bounds on stored energy, and reveals quantum speed limits at critical dynamical transitions.

Abstract: We study a minimal model for charging a quantum battery consisting of a two-level system (TLS) acting as a charger, coupled to a harmonic oscillator that serves as the quantum battery. A single-photon quantum pulse of light excites the TLS, which subsequently transfers its excitation to the isolated battery. The TLS may also decay into the electromagnetic environment. We obtain analytical solutions for the dynamics of the battery and determine the optimal pulse shape that maximizes the stored energy. The optimal pulse saturates a universal bound for the stored energy, determined by the TLS decay rates into the pulse and the environment. Furthermore, we derive the minimum charging time and establish a quantum speed limit at the exceptional point, where a critical transition occurs in the system's dynamics. We also present analytical expressions for the charging power and investigate the pulse duration that maximizes it.

</details>


### [23] [Classical Regularization in Variational Quantum Eigensolvers](https://arxiv.org/abs/2601.16679)
*Yury Chernyak,Ijaz Ahamed Mohammad,Martin Plesch*

Main category: quant-ph

TL;DR: Classical L2 regularization stabilizes Variational Quantum Eigensolver (VQE) optimization by mitigating barren plateaus and ill-conditioned landscapes, improving performance across multiple quantum systems without modifying quantum circuits.


<details>
  <summary>Details</summary>
Motivation: Current quantum computers are limited in size and quality, requiring hybrid quantum-classical algorithms like VQAs. However, VQAs suffer from barren plateaus and ill-conditioned optimization landscapes that lead to unstable convergence and sensitivity to initialization. The authors investigate whether classical regularization can systematically stabilize these hybrid optimizations.

Method: Augment the VQE objective function with standard L2 squared-norm regularization (quadratic penalty proportional to squared norm of parameters) without modifying the quantum circuit or measurement process. Test across multiple Hamiltonians: H2, LiH, and Random Field Ising Model (RFIM).

Result: Improved performance observed across all tested Hamiltonians over a broad window of regularization strengths. Large-scale numerical results demonstrate that classical regularization provides a robust, system-independent mechanism for mitigating VQE instability.

Conclusion: Classical L2 regularization enhances the reliability and reproducibility of variational quantum optimization without altering the underlying quantum circuit, offering a practical solution to VQA optimization challenges.

Abstract: While quantum computers are a very promising tool for the far future, in their current state of the art they remain limited both in size and quality. This has given rise to hybrid quantum-classical algorithms, where the quantum device performs only a small but vital part of the overall computation. Among these, variational quantum algorithms (VQAs), which combine a classical optimization procedure with quantum evaluation of a cost function, have emerged as particularly promising. However, barren plateaus and ill-conditioned optimization landscapes remain among the primary obstacles faced by VQAs, often leading to unstable convergence and high sensitivity to initialization. Motivated by this challenge, we investigate whether a purely classical remedy, standard L2 squared-norm regularization, can systematically stabilize hybrid quantum-classical optimization. Specifically, we augment the Variational Quantum Eigensolver (VQE) objective with a quadratic penalty proportional to the squared norm of the parameters, without modifying the quantum circuit or measurement process. Across all tested Hamiltonians, H2, LiH, and the Random Field Ising Model (RFIM), we observe improved performance over a broad window of the regularization strength. Our large-scale numerical results demonstrate that classical regularization provides a robust, system-independent mechanism for mitigating VQE instability, enhancing the reliability and reproducibility of variational quantum optimization without altering the underlying quantum circuit.

</details>


### [24] [Sparsity-dependent Complexity Lower Bound of Quantum Linear System Solvers](https://arxiv.org/abs/2601.16697)
*Hitomi Mori,Yuta Kikuchi,Marcello Benedetti,Matthias Rosenkranz*

Main category: quant-ph

TL;DR: The paper establishes a rigorous lower bound of Ω(κ√s) for quantum linear system solvers with constant error, addressing a previously unproven folklore result about sparsity dependence.


<details>
  <summary>Details</summary>
Motivation: There is a gap in the theoretical understanding of quantum linear system (QLS) solver complexity. While a lower bound of Ω(κ log(1/ε)) exists, the dependence on sparsity (s) has been folklore (Ω(κ√s log(1/ε))) without rigorous proof. The original proof by Harrow and Kothari is unpublished, and the complete characterization of QLS complexity including all parameters κ, s, ε remains an open problem.

Method: The authors provide a rigorous mathematical proof establishing the lower bound for quantum algorithms solving QLS. They likely use complexity-theoretic techniques and information-theoretic arguments to prove the dependence on condition number (κ) and sparsity (s), focusing on constant error cases.

Result: The paper proves a lower bound of Ω(κ√s) for any quantum algorithm that solves quantum linear systems with constant error. This provides the first rigorous proof of the sparsity dependence that was previously only folklore.

Conclusion: The work establishes a crucial stepping stone toward complete characterization of QLS complexity. While the dependence on all parameters κ, s, ε remains open, this result provides rigorous foundation for the sparsity dependence and advances the theoretical understanding of quantum linear system solver limitations.

Abstract: Quantum linear system (QLS) solvers are a fundamental class of quantum algorithms used in many potential quantum computing applications, including machine learning and solving differential equations. The performance of quantum algorithms is often measured by their query complexity, which quantifies the number of oracle calls required to access the input. The main parameters determining the complexity of QLS solvers are the condition number $κ$ and sparsity $s$ of the linear system, and the target error $ε$. To date, the best known query-complexity lower bound is $Ω(κ\log(1/ε))$, which establishes the optimality of the most recent QLS solvers. The original proof of this lower bound is attributed to Harrow and Kothari, but their result is unpublished. Furthermore, when discussing a more general lower bound including the sparsity $s$ of the linear system, it has become folklore that it should read as $Ω( κ\sqrt{s}\log(1/ε))$. In this work, we establish the rigorous lower bound capturing the sparsity dependence of QLS. We prove the lower bound of $Ω(κ\sqrt{s})$ for any quantum algorithm that solves QLS with constant error. While the dependence on all parameters $κ,s,ε$ remains an open problem, our result provides a crucial stepping stone toward the complete characterization of QLS complexity.

</details>


### [25] [Entanglement harvesting in the presence of cavities](https://arxiv.org/abs/2601.16698)
*Jannik Ströhle,Nikolija Momcilovic*

Main category: quant-ph

TL;DR: Analytical and numerical study of entanglement harvesting in cylindrical cavities using Gaussian detectors, revealing cavity length dependence, invariance to radius, different parameter scalings inside/outside light cone, and strong parity dependence.


<details>
  <summary>Details</summary>
Motivation: Previous entanglement harvesting studies focused on free space; this work extends to cavity environments to understand how confined electromagnetic fields affect entanglement extraction between detectors.

Method: Adiabatic coupling of quantized electromagnetic field to two identical Gaussian detectors on symmetry axis of cylindrical cavity; detailed analytical and numerical analysis.

Result: Strong dependence on cavity length but invariance to radius in maximal entanglement regimes; different parameter scalings inside vs. outside light cone; strong dependence on cavity-induced field parity.

Conclusion: Cavity geometry significantly impacts entanglement harvesting, with length being crucial, radius irrelevant at maximal entanglement, and field parity playing a major role, revealing fundamental differences from free-space harvesting.

Abstract: So far, entanglement harvesting has been extensively studied in free space setups. Here, we provide a detailed analytical and numerical analysis of entanglement harvesting in cavities. Specifically, we adiabatically couple the quantized electromagnetic field to two identical Gaussian detectors located on the symmetry axis of a cylindrical cavity. Our numerical investigations reveal a strong dependence on the cavity length, while showing invariance under changes in the cavity radius in regimes of maximal entanglement. Moreover, we identify different scalings of the detector system parameters for entanglement inside and outside the light cone. Finally, we uncover a strong dependence of the harvested correlations on the cavity induced parity of the electromagnetic field.

</details>


### [26] [SeeMPS: A Python-based Matrix Product State and Tensor Train Library](https://arxiv.org/abs/2601.16734)
*Paula García-Molina,Juan José Rodríguez-Aldavero,Jorge Gidi,Juan José García-Ripoll*

Main category: quant-ph

TL;DR: SeeMPS is a Python library implementing tensor network algorithms using Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms for efficient compression of exponentially large vector spaces.


<details>
  <summary>Details</summary>
Motivation: To provide a comprehensive Python library for tensor network algorithms that bridges quantum many-body physics applications with quantum-inspired numerical analysis, enabling efficient handling of exponentially large vector spaces through compression techniques.

Method: Implementation of a finite precision linear algebra package using MPS/TT formalism for compression of exponentially large vector spaces, supporting both low-level operations (vector addition, linear transformations, Hadamard products) and high-level algorithms (linear equation approximation, eigenvalue computations, Fourier transforms).

Result: Development of SeeMPS library that enables applications in traditional quantum many-body physics and quantum-inspired numerical analysis including PDE solving, multidimensional function interpolation/integration, and multivariate probability distribution sampling.

Conclusion: SeeMPS provides a versatile Python framework for tensor network computations that efficiently handles exponentially large state spaces while supporting both quantum physics applications and broader numerical analysis problems through MPS/QTT compression techniques.

Abstract: We introduce SeeMPS, a Python library dedicated to implementing tensor network algorithms based on the well-known Matrix Product States (MPS) and Quantized Tensor Train (QTT) formalisms. SeeMPS is implemented as a complete finite precision linear algebra package where exponentially large vector spaces are compressed using the MPS/TT formalism. It enables both low-level operations, such as vector addition, linear transformations, and Hadamard products, as well as high-level algorithms, including the approximation of linear equations, eigenvalue computations, and exponentially efficient Fourier transforms. This library can be used for traditional quantum many-body physics applications and also for quantum-inspired numerical analysis problems, such as solving PDEs, interpolating and integrating multidimensional functions, sampling multivariate probability distributions, etc.

</details>


### [27] [Noise Resilience and Robust Convergence Guarantees for the Variational Quantum Eigensolver](https://arxiv.org/abs/2601.16758)
*Mirko Legnini,Julian Berberich*

Main category: quant-ph

TL;DR: The paper analyzes how coherent and incoherent noise affects Variational Quantum Eigensolver (VQE) convergence, providing theoretical insights and numerical simulations via Pennylane.


<details>
  <summary>Details</summary>
Motivation: While global convergence guarantees exist for VQEs under ideal conditions, there's limited understanding of how noise affects convergence when quantum circuits are subject to coherent and incoherent noise processes.

Method: The authors characterize the effects of different noise processes on VQE optimal parameters and cost, study their influence on convergence guarantees, and accompany theoretical analysis with numerical simulations using Pennylane.

Result: The work provides novel theoretical insights into how noise impacts VQE convergence, characterizing the effects on both optimal parameters and optimal cost, with supporting numerical evidence.

Conclusion: The study advances understanding of noise effects on variational quantum algorithms, offering important insights for practical implementation of VQEs in noisy quantum hardware environments.

Abstract: Variational Quantum Algorithms (VQAs) are a class of hybrid quantum-classical algorithms that leverage on classical optimization tools to find the optimal parameters for a parameterized quantum circuit. One relevant application of VQAs is the Variational Quantum Eigensolver (VQE), which aims at steering the output of the quantum circuit to the ground state of a certain Hamiltonian. Recent works have provided global convergence guarantees for VQEs under suitable local surjectivity and smoothness hypotheses, but little has been done in characterizing convergence of these algorithms when the underlying quantum circuit is affected by noise. In this work, we characterize the effect of different coherent and incoherent noise processes on the optimal parameters and the optimal cost of the VQE, and we study their influence on the convergence guarantees of the algorithm. Our work provides novel theoretical insight into the behavior of parameterized quantum circuits. Furthermore, we accompany our results with numerical simulations implemented via Pennylane.

</details>


### [28] [Investigating Retargetability Claims for Quantum Compilers](https://arxiv.org/abs/2601.16779)
*Luke Southall,Joshua Ammermann,Rinor Kelmendi,Domenik Eichhorn,Ina Schaefer*

Main category: quant-ph

TL;DR: The paper develops a metric to assess retargetability of quantum compilers (Tket, Qiskit, ProjectQ) for NISQ-era hardware diversity, finding Tket most retargetable, followed by Qiskit, then ProjectQ.


<details>
  <summary>Details</summary>
Motivation: NISQ-era quantum hardware diversity from different manufacturers creates challenges for quantum software retargetability across platforms, necessitating evaluation of compiler retargetability capabilities.

Method: Developed a metric to assess compiler retargetability, then conducted a study analyzing Tket, Qiskit, and ProjectQ compilers using this metric.

Result: Tket demonstrated the highest level of retargetability, closely followed by Qiskit, while ProjectQ lagged behind in retargetability performance.

Conclusion: The study provides insights for quantum software developers in compiler selection and highlights areas for improvement in quantum compiler retargetability.

Abstract: In the NISQ-era, there is a wide variety of hardware manufacturers building quantum computers. Each of these companies may choose different approaches and hardware architectures for their machines. This poses a problem for quantum software engineering, as the retargetability of quantum programs across different hardware platforms becomes a non-trivial challenge. In response to this problem, various retargetable quantum compilers have been presented in the scientific literature. These promise the ability to compile software for different hardware platforms, enabling retargetability for quantum software. In this paper, we develop and apply a metric by which the retargetability of the quantum compilers can be assessed. We develop and run a study to analyze key aspects regarding the retargetability of the compilers Tket, Qiskit, and ProjectQ. Our findings indicate that Tket demonstrates the highest level of retargetability, closely followed by Qiskit, while ProjectQ lags behind. These results provide insights for quantum software developers in selecting appropriate compilers for their use-cases, and highlight areas for improvement in quantum compilers.

</details>


### [29] [Harnessing Quantum Computing for Energy Materials: Opportunities and Challenges](https://arxiv.org/abs/2601.16816)
*Seongmin Kim,In-Saeng Suh,Travis S. Humble,Thomas Beck,Eungkyu Lee,Tengfei Luo*

Main category: quant-ph

TL;DR: Quantum computing offers potential paradigm shift for energy materials research by addressing computational challenges intractable for classical methods, though practical implementation requires hybrid quantum-classical approaches and future fault-tolerant systems.


<details>
  <summary>Details</summary>
Motivation: Classical computational methods face scaling and time-complexity limitations for high-dimensional or strongly correlated material systems, hindering development of high-performance energy materials needed for increased efficiency, sustainability, and cost reduction.

Method: The paper discusses leveraging quantum computing's superposition and entanglement capabilities, combined with classical computing methods, for design and simulation of practical energy materials through hybrid quantum-classical approaches.

Result: Quantum computing presents opportunities to address challenging problems intractable for classical approaches, with cases demonstrating how QC can be used for energy materials design and simulation when integrated with classical methods.

Conclusion: The outlook points toward error-corrected, fault-tolerant quantum computing capable of achieving predictive accuracy and quantum advantage for complex material systems, representing a promising future direction for energy materials research.

Abstract: Developing high-performance materials is critical for diverse energy applications to increase efficiency, improve sustainability and reduce costs. Classical computational methods have enabled important breakthroughs in energy materials development, but they face scaling and time-complexity limitations, particularly for high-dimensional or strongly correlated material systems. Quantum computing (QC) promises to offer a paradigm shift by exploiting quantum bits with their superposition and entanglement to address challenging problems intractable for classical approaches. This perspective discusses the opportunities in leveraging QC to advance energy materials research and the challenges QC faces in solving complex and high-dimensional problems. We present cases on how QC, when combined with classical computing methods, can be used for the design and simulation of practical energy materials. We also outline the outlook for error-corrected, fault-tolerant QC capable of achieving predictive accuracy and quantum advantage for complex material systems.

</details>


### [30] [Protocols to share genuine multipartite entanglement employing copies of biseparable states](https://arxiv.org/abs/2601.16840)
*Swati Choudhary,Ujjwal Sen,Saronath Halder*

Main category: quant-ph

TL;DR: Two copies of biseparable three-qutrit states can generate genuine multipartite entanglement, contrasting with the qubit case requiring many copies.


<details>
  <summary>Details</summary>
Motivation: To investigate genuine multipartite entanglement activation - the phenomenon where multiple copies of biseparable states (entangled across all bipartitions but lacking genuine multipartite entanglement at single-copy level) can generate genuine multipartite entanglement through collective use.

Method: Developed a protocol for three-qutrit systems showing that two copies of rank-two biseparable states are sufficient to generate genuine multipartite entanglement with nonzero probability. The protocol doesn't require joint measurements on state copies and was generalized to arbitrary number of parties.

Result: Demonstrated that for three-qutrit systems, only two copies of biseparable states are needed for genuine multipartite entanglement activation, unlike the three-qubit scenario requiring many copies. The construction also activates genuinely nonlocal correlations, providing stronger results than entanglement activation alone.

Conclusion: The work establishes efficient genuine multipartite entanglement activation protocols for qutrit systems, showing fundamental differences between qubit and qutrit scenarios, and revealing connections between entanglement activation and nonlocal correlation generation.

Abstract: Sharing genuine multipartite entanglement by considering collective use of copies of biseparable states, which are entangled across all bipartitions but lack genuine multipartite entanglement at the single-copy level, plays a central role in several quantum information processing protocols, and has been referred as genuine multipartite entanglement activation. We present a protocol for three-qutrit systems showing that two copies of rank-two biseparable states, entangled across every bipartition, are sufficient to generate a genuinely multipartite entangled state with nonzero probability. This contrasts with the three-qubit scenario where many copies of biseparable states might be required for sharing genuine multipartite entanglement. We subsequently generalize our protocols to the case of an arbitrary number of parties. Our protocol does not rely on the implementation of joint measurements on the copies of states. Interestingly, the proposed construction naturally leads to the activation of genuinely nonlocal correlations, yielding a result that is stronger than genuine multipartite entanglement activation alone.

</details>


### [31] [Generation of fully phase controlled two-photon entangled states](https://arxiv.org/abs/2601.16875)
*Ian Ford,Adrien Amour,Matthias Keller*

Main category: quant-ph

TL;DR: Researchers demonstrate generation of two-photon entangled states with full phase control using a single calcium ion coupled to an optical cavity, achieving 82% fidelity.


<details>
  <summary>Details</summary>
Motivation: Trapped ions offer excellent control over internal states for generating single and two-photon states. Coupling ions to optical cavities enables efficient single-photon emission into a single spatial mode with control over temporal shape, phase, and frequency. The goal is to leverage ion-cavity systems to generate two-photon entangled states with full phase control.

Method: A single ⁴⁰Ca⁺ ion is coupled to an optical cavity. The approach uses the long coherence time of the ion's internal states and implements a scheme to protect the coherence of the ion-cavity interaction. The process involves: 1) generating ion-photon entanglement, 2) subsequently generating a second photon that maps the ion's state onto the photon, and 3) adjusting the drive field to achieve full control over the phase of the entangled state.

Result: The scheme successfully generates two-photon entangled states with full phase control. The implementation achieves a fidelity of up to 82% for the generated entangled state.

Conclusion: The work demonstrates a resource-efficient method for generating two-photon entangled states with complete phase control using a single trapped ion coupled to an optical cavity. The achieved 82% fidelity shows the viability of this approach for quantum information applications requiring controlled photon entanglement.

Abstract: Control over the internal states of trapped ions makes them the ideal system to generate single and two-photon states. Coupling a single ion to an optical cavity enables efficient emission of single photons into a single spatial mode and grants control over their temporal shape, phase and frequency. Using the long coherence time of the ion's internal states and employing a scheme to protect the coherence of the ion-cavity interaction, we demonstrate the generation of a two-photon entangled state with full control over the phase. Initially, ion-photon entanglement is generated. A second photon is subsequently generated, mapping the ion's state onto the second photon. By adjusting the drive field the phase of the entangled state can be fully controlled. We implement this scheme in the most resource efficient way by utilizing a single $^{40}$Ca$^+$ ion coupled to an optical cavity and demonstrate the generation of a two-photon entangled stated with full phase control with a fidelity of up to 82\%.

</details>


### [32] [Quantum Position Verification with Remote Untrusted Devices](https://arxiv.org/abs/2601.16892)
*Gautam A. Kavuri,Yanbao Zhang,Abigail R. Gookin,Soumyadip Patra,Joshua C. Bienfang,Honghao Fu,Yusuf Alnawakhtha,Dileep V. Reddy,Michael D. Mazurek,Carlos Abellán,Waldimar Amaya,Morgan W. Mitchell,Sae Woo Nam,Carl A. Miller,Richard P. Mirin,Martin J. Stevens,Scott Glancy,Emanuel Knill,Lynden K. Shalm*

Main category: quant-ph

TL;DR: Experimental demonstration of device-independent quantum position verification using loophole-free Bell tests across a quantum network, achieving 2.47× better localization than classical protocols.


<details>
  <summary>Details</summary>
Motivation: Secure localization of remote parties is fundamentally impossible in classical physics due to complete device knowledge by adversaries. Quantum technologies can overcome this limitation, but existing proposals require trusting vulnerable hardware.

Method: Device-independent quantum position verification protocol using observed correlations from a loophole-free Bell test across a quantum network. Security is guaranteed against adversaries with unlimited quantum computation and communication capabilities, who are only weakly entangled before each test instance.

Result: Experimental demonstration achieves 1D localization 2.47(2) times smaller than the best classical localization protocol (necessarily non-remote). Compared to classical protocols with identical latencies, localization is 4.53(5) times smaller.

Conclusion: The work anchors digital security in the physical world by providing a device-independent quantum approach to secure position verification that overcomes fundamental limitations of classical physics.

Abstract: Many applications require or benefit from being able to securely localize remote parties. In classical physics, adversaries can in principle have complete knowledge of such a party's devices, and secure localization is fundamentally impossible. This limitation can be overcome with quantum technologies, but proposals to date require trusting vulnerable hardware. Here we develop and experimentally demonstrate a protocol for device-independent quantum position verification that guarantees security with only observed correlations from a loophole-free Bell test across a quantum network. The protocol certifies the position of a remote party against adversaries who, before each instance of the test, are weakly entangled, but otherwise have unlimited quantum computation and communication capabilities. Our demonstration achieves a one-dimensional localization that is 2.47(2) times smaller than the best, necessarily non-remote, classical localization protocol. Compared to such a classical protocol having identical latencies, the localization is 4.53(5) times smaller. This work anchors digital security in the physical world.

</details>


### [33] [Upper bounds on the purity of Wigner positive quantum states that verify the Wigner entropy conjecture](https://arxiv.org/abs/2601.16898)
*Qipeng Qian,Christos Gagatsos*

Main category: quant-ph

TL;DR: The paper presents analytical progress on the Wigner entropy conjecture, establishing purity-based sufficient conditions for Wigner non-negative states to satisfy the conjecture that pure Gaussian states minimize Wigner entropy.


<details>
  <summary>Details</summary>
Motivation: The Wigner entropy conjecture posits that among all physical Wigner non-negative states, the Wigner entropy is minimized by pure Gaussian states, which attain the value 1+lnπ. This work aims to provide rigorous analytical results toward proving this conjecture under minimal constraints.

Method: The authors work under minimal constraints: Wigner function non-negativity, normalization, and the pointwise bound πW ≤ 1. They construct an explicit hierarchy of lower bounds B_n on S[W] by combining a truncated series lower bound for -ln x with moment identities of the Wigner function. This yields closed-form purity-based sufficient conditions. They also develop a systematic purity-only relaxation of the hierarchy.

Result: The main results include: 1) Proof that all Wigner non-negative states with purity μ ≤ 4-2√3 satisfy the Wigner entropy conjecture; 2) A systematic purity-only relaxation yielding the simple sufficient condition μ ≤ 2/e; 3) Clarification that additional physicality constraints are necessary for purity-based approaches to approach the extremal case μ ≤ 1.

Conclusion: The paper makes significant analytical progress on the Wigner entropy conjecture by establishing explicit purity-based sufficient conditions under minimal constraints, while also clarifying the limitations of purity-only approaches for approaching the extremal case.

Abstract: We present analytical results toward the Wigner entropy conjecture, which posits that among all physical Wigner non-negative states the Wigner entropy is minimized by pure Gaussian states for which it attains the value $1+\lnπ$.Working under a minimal set of constraints on the Wigner function, namely, non-negativity, normalization, and the pointwise bound $πW\le 1$, we construct an explicit hierarchy of lower bounds $B_n$ on $S[W]$ by combining a truncated series lower bound for $-\ln x$ with moment identities of the Wigner function.This yields closed-form purity-based sufficient conditions ensuring $S[W]\ge 1+\lnπ$.In particular, we first prove that all Wigner non-negative states with $μ\le 4-2\sqrt3$ satisfy the Wigner entropy conjecture. We further obtain a systematic purity-only relaxation of the hierarchy, yielding the simple sufficient condition $μ\le 2/e$. On top of aforesaid results, our analysis clarifies why additional physicality constraints are necessary for purity-based approaches that aim to approach the extremal case $μ\leq1$.

</details>


### [34] [Quantum Fisher information analysis for absorption measurements with undetected photons](https://arxiv.org/abs/2601.16941)
*Martin Houde,Franz Roeder,Christine Silberhorn,Benjamin Brecht,Nicolás Quesada*

Main category: quant-ph

TL;DR: Comparison of quantum Fisher information for three absorption spectroscopy configurations with undetected idler photons reveals optimal regimes: SU(1,1) interferometer best for losses <99% and low-moderate gain, induced-coherence scheme optimal at high gain with intermediate loss, and distributed-loss model superior under extreme attenuation (<1% transmission).


<details>
  <summary>Details</summary>
Motivation: To theoretically compare and identify optimal measurement regimes for three different configurations of absorption spectroscopy using undetected idler photons, determining which architecture provides the highest quantum Fisher information under various loss and gain conditions.

Method: Theoretical comparison of quantum Fisher information for three configurations: 1) SU(1,1) interferometer with inter-source idler loss, 2) induced-coherence setup where idler partially seeds a second squeezer with vacuum ancilla, and 3) distributed-loss scheme with in-medium attenuation. Calculations performed as function of parametric gain for both full and signal-only detection access.

Result: For losses below 99% and low to moderate gain, SU(1,1) configuration provides largest QFI. At high gain and intermediate loss, induced-coherence scheme performs best. Under extreme attenuation (transmission <1%), distributed-loss model becomes optimal. Results delineate measurement regimes where each architecture is information-theoretically optimal.

Conclusion: Different absorption spectroscopy configurations with undetected idler photons are optimal in distinct regimes based on loss levels and parametric gain, providing guidance for selecting appropriate architectures for specific measurement conditions in quantum-enhanced spectroscopy.

Abstract: We theoretically compare the quantum Fisher information (QFI) for three configurations of absorption spectroscopy with undetected idler photons: an SU(1,1) interferometer with inter-source idler loss, an induced-coherence (IC) setup in which the idler partially seeds a second squeezer together with a vacuum ancilla, and a distributed-loss (DL) scheme with in-medium attenuation. We calculate the QFI as a function of parametric gain for both full and signal-only detection access. For losses below 99% and low to moderate gain, the SU(1,1) configuration provides the largest QFI. At high gain and intermediate loss, the IC scheme performs best, while under extreme attenuation (transmission $<$ 1%) the DL model becomes optimal. These results delineate the measurement regimes in which each architecture is optimal in terms of information theory.

</details>


### [35] [Experimental investigation of nonclassicality in the simplest scenario via the degrees of freedom of light](https://arxiv.org/abs/2601.16952)
*João M. M. Gama,Guilherme T. C. Cruz,Massy Khoshbin,Lorenzo Catani,José A. O. Huguenin,Wagner F. Balthazar*

Main category: quant-ph

TL;DR: Classical light emulation of quantum nonclassicality concepts using polarization and transverse modes, showing violations of preparation noncontextuality and bounded ontological distinctness inequalities.


<details>
  <summary>Details</summary>
Motivation: To experimentally investigate classical-light emulation of different notions of nonclassicality in the simplest prepare-and-measure scenario, and to demonstrate relevance for quantum communication primitives like random access codes.

Method: Implemented prepare-and-measure scenario with 4 preparations and 2 binary-outcome measurements using two experimental setups: polarization and first-order Hermite-Gaussian transverse modes. Modeled experimental noise via all-optical depolarizing channel simulation.

Result: Experimental results consistent with Khoshbin et al. (2024): observed statistics violate noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations, despite using classical light.

Conclusion: Classical light can reproduce quantum statistics in simplest scenarios, making implementation directly relevant for semi-device-independent certification of nonclassicality in applications like two-bit quantum random access codes.

Abstract: In this work, we experimentally investigate the classical-light emulation of different notions of nonclassicality in the simplest scenario. We implement this prepare-and-measure scenario involving four preparations and two binary-outcome measurements using two distinct experimental setups that exploit different degrees of freedom of light: polarization and first-order Hermite-Gaussian transverse modes. We additionally model experimental noise through an all-optical setup that reproduces the operational effect of a depolarizing channel. Our experimental results are consistent with the findings of Khoshbin et al. [Phys. Rev. A 109, 032212 (2024)]: under the assumption that the two measurements performed form a tomographically complete set, the observed statistics violate their noise-robust inequalities, indicating inconsistencies with preparation noncontextuality and bounded ontological distinctness for preparations. Although our implementation uses classical light, it reproduces the statistics predicted for the simplest scenario. Since the states and measurements of this scenario underpin computational advantages in tasks such as two-bit quantum random access codes -- among the simplest communication primitives enabling semi-device-independent certification of nonclassicality -- our implementation is directly relevant for such applications.

</details>


### [36] [Engineering discrete local dynamics in globally driven dual-species atom arrays](https://arxiv.org/abs/2601.16961)
*Francesco Cesa,Andrea Di Fini,David Aram Korbany,Roberto Tricarico,Hannes Bernien,Hannes Pichler,Lorenzo Piroli*

Main category: quant-ph

TL;DR: A method for engineering discrete local dynamics in dual-species neutral atom experiments using uniform analog controls to study emergent digital models, focusing on Quantum Cellular Automata examples.


<details>
  <summary>Details</summary>
Motivation: To leverage the new opportunities offered by dual-species neutral atom systems (species-alternated driving, different inter- and intra-species interactions) for studying emergent digital models through simple Floquet protocols on static atom arrangements.

Method: Uses globally-driven dual-species neutral atom experiments with uniform analog controls, exploiting species-alternated driving and generalized blockade regimes. Implements simple Floquet protocols on static atom arrangements to engineer discrete local dynamics, focusing on Quantum Cellular Automata examples.

Result: The construction enables study of various discrete dynamical models including kicked-Ising model, Floquet Kitaev honeycomb model, and digitization of generic translation-invariant nearest-neighbor Hamiltonians. Demonstrates application to studying chaotic features of discretized many-body dynamics using only demonstrated experimental capabilities.

Conclusion: Dual-species neutral atom experiments with uniform analog controls provide a powerful platform for engineering and studying emergent digital models and Quantum Cellular Automata, with applications in detecting chaotic evolution in many-body systems.

Abstract: We introduce a method for engineering discrete local dynamics in globally-driven dual-species neutral atom experiments, allowing us to study emergent digital models through uniform analog controls. Leveraging the new opportunities offered by dual-species systems, such as species-alternated driving, our construction exploits simple Floquet protocols on static atom arrangements, and benefits of generalized blockade regimes (different inter- and intra-species interactions). We focus on discrete dynamical models that are special examples of Quantum Cellular Automata (QCA), and explicitly consider a number of relevant examples, including the kicked-Ising model, the Floquet Kitaev honeycomb model, and the digitization of generic translation-invariant nearest-neighbor Hamiltonians (e.g., for Trotterized evolution). As an application, we study chaotic features of discretized many-body dynamics that can be detected by leveraging only demonstrated capabilities of globally-driven experiments, and benchmark their ability to discriminate chaotic evolution.

</details>


### [37] [Autonomous Optical Alignment of Satellite-Based Entanglement Sources using Reinforcement Learning](https://arxiv.org/abs/2601.16968)
*Andrzej Gajewski,Robert Okuła,Marcin Pawłowski,Akshata Shenoy H*

Main category: quant-ph

TL;DR: Two automated alignment methods (heuristic algorithm and reinforcement learning) for satellite-based quantum entanglement sources outperform manual calibration, with RL achieving perfect alignment in 10 minutes vs 30 minutes for HA.


<details>
  <summary>Details</summary>
Motivation: Satellite-based quantum entanglement distribution enables global quantum communication, but onboard sources suffer from misalignment due to dynamic orbital conditions, requiring automated recalibration solutions.

Method: Two recalibration techniques for PPLN-based SPDC entanglement sources: 1) Heuristic algorithm mimicking manual laboratory alignment, and 2) Reinforcement learning approach. Both operate within satellite constraints.

Result: RL achieves AUC=0.9119 vs HA's 0.7042 in modified ROC analysis (60 min threshold). RL reaches perfect alignment in 10 minutes compared to HA's 30 minutes. Both methods offer scalable automation.

Conclusion: Reinforcement learning provides superior performance for automated satellite entanglement source alignment, enabling efficient high-quality entanglement generation with minimal intervention for global quantum communication networks.

Abstract: Quantum entanglement distributed via satellites enable global-scale quantum communication. However, onboard sources are susceptible to misalignment due to dynamical orbital conditions. Here, we present two recalibration techniques for efficient generation of high quality entanglement using a periodically poled lithium niobate (PPLN)-based spontaneous parametric down-conversion (SPDC) source with minimum intervention. The first is a heuristic algorithm (HA) which mimics the manual alignment process in a laboratory. The second is based on reinforcement learning (RL). Our simulation demonstrates superior performance of RL with AUC=0.9119 compared to HA's 0.7042 in the modified ROC analysis (60 min threshold). RL achieves perfect alignment in 10 min as opposed to HA's 30 min. Both the methods operate within feasible satellite constraints, offering scalable automation for complex quantum communication scenarios.

</details>


### [38] [Formalising an operational continuum limit of quantum combs](https://arxiv.org/abs/2601.16974)
*Clara Wassner,Jonáš Fuksa,Jens Eisert,Gregory A. L. White*

Main category: quant-ph

TL;DR: The paper introduces a fully continuous process tensor framework that bridges quantum combs with continuous-time quantum stochastic processes by translating discrete multi-partite Choi states into field-theoretic states in bosonic Fock space.


<details>
  <summary>Details</summary>
Motivation: Quantum combs lack meaningful physical connection to time despite their causal nature, and process tensors, while motivated by dynamics, lack a rigorous continuous mathematical formulation, creating a conceptual gap in connecting discrete quantum information tools with continuous quantum stochastic processes.

Method: The authors show how discrete multi-partite Choi states become field-theoretic states in bosonic Fock space, intrinsically defined in the continuum, and lay out the core structural elements and properties of this continuous process tensor framework.

Result: The translation enables information-theoretic treatment of multi-time correlations in the continuum via analysis of their continuous matrix product state representatives, providing a rigorous mathematical foundation for continuous quantum stochastic processes.

Conclusion: This work closes a gap in quantum information literature by providing a fully continuous process tensor framework, opening opportunities to apply many-body physics insights to understanding quantum stochastic processes in the continuum.

Abstract: Quantum combs are powerful conceptual tools for capturing multi-time processes in quantum information theory, constituting the most general quantum mechanical process. But, despite their causal nature, they lack a meaningful physical connection to time -- and are, by and large, arguably incompatible with it without extra structure. The subclass of quantum combs which assumes an underlying process is described by the so-called process tensor framework, which has been successfully used to study and characterise non-Markovian open quantum systems. But, although process tensors are motivated by an underlying dynamics, it is not a priori clear how to connect to a continuous process tensor object mathematically -- leaving an uncomfortable conceptual gap. In this work, we take a decisive step toward remedying this situation. We introduce a fully continuous process tensor framework by showing how the discrete multi-partite Choi state becomes a field-theoretic state in bosonic Fock space, which is intrinsically and rigorously defined in the continuum. With this equipped, we lay out the core structural elements of this framework and its properties. This translation allows for an information-theoretic treatment of multi-time correlations in the continuum via the analysis of their continuous matrix product state representatives. Our work closes a gap in the quantum information literature, and opens up the opportunity for the application of many-body physics insights to our understanding of quantum stochastic processes in the continuum.

</details>
