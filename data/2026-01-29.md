<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [quant-ph](#quant-ph) [Total: 40]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [A Unified Symmetry Classification of Many-Body Localized Phases](https://arxiv.org/abs/2601.20532)
*Yucheng Wang*

Main category: cond-mat.dis-nn

TL;DR: The paper develops a symmetry-based classification of many-body localization (MBL) phases using local integrals of motion (LIOMs), distinguishing which symmetries are compatible with stable MBL and constructing a complete classification table.


<details>
  <summary>Details</summary>
Motivation: While Anderson localization has a well-established symmetry classification (Altland-Zirnbauer tenfold scheme), a similar comprehensive framework for interacting many-body localization (MBL) has been lacking. The authors aim to develop a symmetry-based classification of MBL phases to understand how different symmetries constrain MBL stability.

Method: The classification is formulated at the level of local integrals of motion (LIOMs). The authors establish a criterion: a symmetry is compatible with stable MBL if and only if its action can be consistently represented within a quasi-local LIOM algebra without enforcing extensive degeneracies or nonlocal operator mixing. They systematically combine AZ symmetries with additional onsite symmetries to construct a complete classification table.

Result: The classification distinguishes symmetry classes: onsite Abelian symmetries are compatible with stable MBL and can host distinct symmetry-protected topological MBL phases, while continuous non-Abelian symmetries generically preclude stable MBL. The authors identify stable, fragile, and unstable MBL classes and provide representative lattice realizations.

Conclusion: The paper establishes a unified and physically transparent framework for understanding symmetry constraints on many-body localization, providing a complete classification of MBL phases analogous to the Altland-Zirnbauer scheme for Anderson localization.

Abstract: Anderson localization admits a complete symmetry classification given by the Altland-Zirnbauer (AZ) tenfold scheme, whereas an analogous framework for interacting many-body localization (MBL) has remained elusive. Here we develop a symmetry-based classification of static MBL phases formulated at the level of local integrals of motion (LIOMs). We show that a symmetry is compatible with stable MBL if and only if its action can be consistently represented within a quasi-local LIOM algebra, without enforcing extensive degeneracies or nonlocal operator mixing. This criterion sharply distinguishes symmetry classes: onsite Abelian symmetries are compatible with stable MBL and can host distinct symmetry-protected topological MBL phases, whereas continuous non-Abelian symmetries generically preclude stable MBL. By systematically combining AZ symmetries with additional onsite symmetries, we construct a complete classification table of MBL phases, identify stable, fragile, and unstable classes, and provide representative lattice realizations. Our results establish a unified and physically transparent framework for understanding symmetry constraints on MBL.

</details>


### [2] [Variational Monte Carlo (VMC) with row-update Projected Entangled-Pair States (PEPS) and its applications in quantum spin glasses](https://arxiv.org/abs/2601.20608)
*Tao Chen,Jing Liu,Yantao Wu,Pan Zhang,Youjin Deng*

Main category: cond-mat.dis-nn

TL;DR: The paper proposes an autoregressive row-wise sampling algorithm for PEPS-VMC that enables direct, rejection-free sampling via single-layer contractions to overcome slow convergence and critical slowing down in conventional local update methods.


<details>
  <summary>Details</summary>
Motivation: Standard PEPS-VMC algorithms rely on sequential local updates which suffer from slow convergence and critical slowing down near phase transitions or in frustrated landscapes, limiting their effectiveness for strongly correlated 2D quantum systems.

Method: An efficient autoregressive row-wise sampling algorithm for PEPS that enables direct, rejection-free sampling via single-layer contractions. The method uses autoregressive single-layer row updates to generate collective, non-local configuration proposals, reducing temporal correlations compared to local Metropolis moves.

Result: Benchmarking on the 2D transverse-field Ising model and quantum spin glass shows the row-wise scheme effectively mitigates critical slowing down near the Ising critical point, and yields improved optimization stability and lower ground-state energies in the rugged landscape of the quantum spin glass.

Conclusion: Single-layer autoregressive row updates provide a flexible and robust improvement to local PEPS-VMC sampling and may serve as a basis for more advanced sampling schemes for strongly correlated 2D quantum systems.

Abstract: Solving the quantum many-body ground state problem remains a central challenge in computational physics. In this context, the Variational Monte Carlo (VMC) framework based on Projected Entangled Pair States (PEPS) has witnessed rapid development, establishing itself as a vital approach for investigating strongly correlated two-dimensional systems. However, standard PEPS-VMC algorithms predominantly rely on sequential local updates. This conventional approach often suffers from slow convergence and critical slowing down, particularly in the vicinity of phase transitions or within frustrated landscapes. To address these limitations, we propose an efficient autoregressive row-wise sampling algorithm for PEPS that enables direct, rejection-free sampling via single-layer contractions. By utilizing autoregressive single-layer row updates to generate collective, non-local configuration proposals, our method significantly reduces temporal correlations compared to local Metropolis moves. We benchmark the algorithm on the two-dimensional transverse-field Ising model and the quantum spin glass. Our results demonstrate that the row-wise scheme effectively mitigates critical slowing down near the Ising critical point. Furthermore, in the rugged landscape of the quantum spin glass, it yields improved optimization stability and lower ground-state energies. These findings indicate that single-layer autoregressive row updates provide a flexible and robust improvement to local PEPS-VMC sampling and may serve as a basis for more advanced sampling schemes.

</details>


### [3] [Directionality and node heterogeneity reshape criticality in hypergraph percolation](https://arxiv.org/abs/2601.20726)
*Yunxue Sun,Xueming Liu,Ginestra Bianconi*

Main category: cond-mat.dis-nn

TL;DR: The paper develops a message-passing and statistical mechanics framework for percolation in directed, heterogeneous hypergraphs, revealing anomalous critical exponents that depend on network structure and percolation type.


<details>
  <summary>Details</summary>
Motivation: Directed and heterogeneous hypergraphs capture asymmetric functional dependencies in real-world systems like metabolic networks, where damage to certain nodes can have disproportionate effects. Current percolation theories don't adequately address directionality and node heterogeneity in higher-order interactions.

Method: Developed a message-passing and statistical mechanics framework for percolation in directed hypergraphs that explicitly incorporates directionality and node heterogeneity. The approach considers both node and hyperedge percolation in maximally correlated, heavy-tailed regimes.

Result: The framework reveals that hypergraph features fundamentally affect critical properties, reshaping criticality in a structure-dependent manner. Derived anomalous critical exponents that depend on whether node or hyperedge percolation is considered. Validated predictions on synthetic hypergraph models and a real directed metabolic network.

Conclusion: The developed framework provides new perspectives for characterizing robustness and resilience of real-world directed, heterogeneous higher-order networks, with applications to systems like metabolic reaction networks where asymmetric dependencies are crucial.

Abstract: Directed and heterogeneous hypergraphs capture directional higher-order interactions with intrinsically asymmetric functional dependencies among nodes. As a result, damage to certain nodes can suppress entire hyperedges, whereas failure of others only weakens interactions. Metabolic reaction networks offer an intuitive example of such asymmetric dependencies. Here we develop a message-passing and statistical mechanics framework for percolation in directed hypergraphs that explicitly incorporates directionality and node heterogeneity. Remarkably, we show that these hypergraph features have a fundamental effect on the critical properties of hypergraph percolation, reshaping criticality in a way that depends on network structure. Specifically, we derive anomalous critical exponents that depend on whether node or hyperedge percolation is considered in maximally correlated, heavy-tailed regimes. These theoretical predictions are validated on synthetic hypergraph models and on a real directed metabolic network, opening new perspectives for the characterization of the robustness and resilience of real-world directed, heterogeneous higher-order networks.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [4] [A Surface-Scaffolded Molecular Qubit](https://arxiv.org/abs/2601.19976)
*Tian-Xing Zheng,M. Iqbal Bakti Utama,Xingyu Gao,Moumita Kar,Xiaofei Yu,Sungsu Kang,Hanyan Cai,Tengyang Ruan,David Ovetsky,Uri Zvi,Guanming Lao,Yu-Xin Wang,Omri Raz,Sanskriti Chitransh,Grant T. Smith,Leah R. Weiss,Magdalena H. Czyz,Shengsong Yang,Alex J. Fairhall,Kenji Watanabe,Takashi Taniguchi,David D. Awschalom,A. Paul Alivisatos,Randall H. Goldsmith,George C. Schatz,Mark C. Hersam,Peter C. Maurer*

Main category: quant-ph

TL;DR: Surface molecular qubit using pentacene on hBN demonstrates stable fluorescence, ODMR, and record coherence times (214 μs under dynamical decoupling), outperforming NV centers while enabling surface integration for quantum applications.


<details>
  <summary>Details</summary>
Motivation: Surface-placed spin qubits maximize coupling to nearby spins and fields for nanoscale sensing and integration with photonic/superconducting devices, but reducing dimensions while maintaining performance and coherence remains challenging.

Method: Created surface molecular qubit by scaffolding pentacene molecules on hexagonal boron nitride (hBN) 2D material, using fully deuterated pentacene to enhance coherence, and employing optically detected magnetic resonance (ODMR) for characterization.

Result: Qubit exhibits stable fluorescence and ODMR from cryogenic to ambient conditions; Hahn-echo coherence reaches 22 μs, extending to 214 μs under dynamical decoupling (outperforming shallow NV centers); local spin environment mapping reveals couplings to nearby nuclear/electron spins.

Conclusion: Platform combines true surface integration, long qubit coherence, and scalable fabrication, opening routes to quantum sensing, simulation, and hybrid quantum devices while establishing a broader family of 2D material-supported molecular qubits.

Abstract: Fluorescent spin qubits are central building blocks of quantum technologies. Placing these qubits at surfaces maximizes coupling to nearby spins and fields, enabling nanoscale sensing and facilitating integration with photonic and superconducting devices. However, reducing the dimensions or size of established qubit systems without sacrificing the qubit performance or degrading the coherence lifetime remains challenging. Here, we introduce a surface molecular qubit formed by pentacene molecules scaffolded on a two-dimensional (2D) material, hexagonal boron nitride (hBN). The qubit exhibits stable fluorescence and optically detected magnetic resonance (ODMR) from cryogenic to ambient conditions. With fully deuterated pentacene, the Hahn-echo coherence reaches 22 $μ$s and further extends to 214 $μ$s under dynamical decoupling, outperforming state-of-the-art shallow NV centers in diamond, despite being positioned directly on the surface. We map the local spin environment, resolving couplings to nearby nuclear and electron spins that can serve as auxiliary quantum resources. This platform combines true surface integration, long qubit coherence, and scalable fabrication, opening routes to quantum sensing, quantum simulation, and hybrid quantum devices. It also paves the way for a broader family of 2D material-supported molecular qubits.

</details>


### [5] [The superradiant phase is a finite size effect in two-photon processes](https://arxiv.org/abs/2601.19986)
*Fabrizio Ramírez,David Villaseñor,Nahum Vázquez,Jorge G. Hirsch*

Main category: quant-ph

TL;DR: The superradiant phase in the two-photon Dicke model is not a genuine thermodynamic phase but a finite-size effect that disappears in the thermodynamic limit.


<details>
  <summary>Details</summary>
Motivation: Two-photon light-matter interactions show unique features like spectral collapse, and the reported superradiant phase in the two-photon Dicke model could be useful for quantum applications, but its true nature needs clarification.

Method: Combined analytical and numerical analyses to examine system size dependence of the superradiant phase.

Result: The superradiant region shrinks with increasing system size and disappears completely in the thermodynamic limit, while spectral collapse persists.

Conclusion: The superradiant phase is a finite-size artifact, not a genuine thermodynamic phase, which constrains its practical realization in quantum platforms despite the persistence of spectral collapse.

Abstract: Two-photon light-matter interactions exhibit distinctive features such as spectral collapse. The two-photon Dicke model has been reported to exhibit a superradiant phase which could be useful in quantum applications. Here we show that this superradiant phase is not a genuine thermodynamic phase but a finite-size effect. Combining analytical and numerical analyses, we demonstrate that the superradiant region shrinks with increasing system size and disappears in the thermodynamic limit, while spectral collapse remains. Our results clarify the nature of superradiant conditions in two-photon systems and constrain its realization in quantum platforms.

</details>


### [6] [Optically Addressable Molecular Spins at 2D Surfaces](https://arxiv.org/abs/2601.19988)
*Xuankai Zhou,Yan-Tung Kong,Cheuk Kit Cheung,Guodong Bian,Reda Moukaouine,King Cho Wong,Yumeng Sun,Cheng-I Ho,Vladislav Bushmakin,Nils Gross,Chun-Chieh Yen,Tim Priessnitz,Malik Lenger,Sreehari Jayaram,Takashi Taniguchi,Kenji Watanabe,Anton Pershin,Ruoming Peng,Ádám Gali,Jurgen Smet,Jörg Wrachtrup*

Main category: quant-ph

TL;DR: Hybrid molecular-2D architecture creates optically addressable quantum spin sensors directly on surfaces with long coherence times from 4K to room temperature, enabling surface quantum sensing beyond conventional solid-state platforms.


<details>
  <summary>Details</summary>
Motivation: Optically addressable spins at material surfaces have been a long-standing goal for quantum sensing with atomic resolution and quantum-limited sensitivity, but are constrained by finite depth limitations where quantum spins can be stabilized.

Method: Developed a hybrid molecular-2D architecture by anchoring spin-active molecules onto hexagonal boron nitride (hBN) to eliminate quantum sensor depth limitations. Used chemical tuning through deuteration to improve coherence times and applied dynamic decoupling techniques.

Result: Achieved robust spin properties from 4K to room temperature with Hahn-echo spin coherence time T₂ = 3.4 μs at 4K (outperforming bulk organic crystals). Deuteration improved T₂ by >10×, and dynamic decoupling extended coherence to intrinsic lifetime limit >300 μs. Demonstrated detection of proximal proton spins and magnetic response of 2D magnets at room temperature.

Conclusion: Molecular spins form surface quantum sensors with long coherence, optical addressability, and interfacial versatility, enabling scalable, adaptable architecture beyond conventional solid-state platforms for quantum sensing applications.

Abstract: Optically addressable spins at material surfaces have represented a long-standing ambition in quantum sensing, providing atomic resolution and quantum-limited sensitivity. However, they are constrained by a finite depth at which the quantum spins can be stabilized. Here, we demonstrate a hybrid molecular-2D architecture that realizes quantum spin sensors directly on top of the surface. By anchoring spin-active molecules onto hexagonal boron nitride (hBN), we eliminate the depth of the quantum sensor while also exhibiting robust spin properties from 4~K to room temperature (RT). The Hahn-echo spin coherence time exceeds \(T_2 = 3.4~\upmu\text{s}\) at 4~K, outperforming values in bulk organic crystals and overturning the prevailing expectation that spin inevitably deteriorates upon approaching the surface. By chemically tuning the molecule through deuteration, \(T_2\) improves by more than 10-fold, and under dynamic decoupling, coherence is prolonged to the intrinsic lifetime limit, exceeding 300~\(\upmu\text{s}\). Proximal proton spins and the magnetic response of two-dimensional magnets beneath the hBN layer have been detected at RT. These molecular spins form surface quantum sensors with long coherence, optical addressability, and interfacial versatility, enabling a scalable, adaptable architecture beyond what conventional solid-state platforms offer.

</details>


### [7] [Alternating ZX Circuit Extraction for Hardware-Adaptive Compilation](https://arxiv.org/abs/2601.20007)
*Ludwig Schmid,Korbinian Staudacher,Robert Wille*

Main category: quant-ph

TL;DR: A quantum circuit extraction scheme that integrates ZX diagrams with hardware-adaptive routing using feedback between extraction options and routing constraints.


<details>
  <summary>Details</summary>
Motivation: To develop a more versatile quantum compilation approach that tightly couples circuit extraction from ZX diagrams with hardware-specific routing constraints, overcoming limitations of separate extraction and routing stages.

Method: Alternates between generating multiple extraction options from graph-like ZX diagrams and evaluating them based on hardware constraints, creating a feedback loop where routing informs extraction. Supports modular integration of different extraction algorithms, routing strategies, and target hardware.

Result: Implemented a reference instance with SWAP-based routing for neutral atom hardware, evaluated on small-to mid-scale benchmark circuits. The code is open-source for community integration and improvement.

Conclusion: The scheme provides a versatile building block for quantum compilation that tightly integrates extraction and routing, with open-source implementation enabling further research and improvements.

Abstract: We present a novel quantum circuit extraction scheme that tightly integrates graph-like ZX diagrams with hardware-adaptive routing. The method utilizes the degrees of freedom during the conversion from a ZX diagram to a quantum circuit (extraction). It alternates between generating multiple extraction options and evaluating them based on hardware constraints, allowing the routing algorithm to inform and guide the extraction process. This feedback loop extends existing graph-like ZX extraction and supports modular integration of different extraction algorithms, routing strategies, and target hardware, making it a versatile building block during compilation. To perform numerical evaluations, a reference instance of the scheme is implemented with SWAP-based routing for neutral atom hardware and evaluated using various benchmark collections on small-to mid-scale circuits. The reference code is available as open-source, allowing fast integration of other extraction and/or routing tools to stimulate further research and foster improvements of the proposed scheme.

</details>


### [8] [Foundry-Enabled Patterning of Diamond Quantum Microchiplets for Scalable Quantum Photonics](https://arxiv.org/abs/2601.20025)
*Jawaher Almutlaq,Alessandro Buzzi,Anders Khaykin,Linsen Li,William Yzaguirre,Maxim Sirotin,Gerald Gilbert,Genevieve Clark,Dirk Englund*

Main category: quant-ph

TL;DR: A scalable manufacturing approach for diamond quantum photonics using silicon masks fabricated in commercial foundries and transferred to diamond via microtransfer printing, enabling mass production of quantum microchiplets.


<details>
  <summary>Details</summary>
Motivation: Building quantum systems at scale remains challenging. Diamond is attractive for quantum devices due to its atomic-scale defects that emit single photons and store quantum information, but current fabrication methods are slow, bespoke, and difficult to scale.

Method: Instead of direct lithography on diamond, fabricate high-precision silicon masks using commercial semiconductor foundries and transfer them onto diamond via microtransfer printing. This defines large arrays of nanoscale optical structures, shifting pattern-definition away from diamond substrate.

Result: Demonstrated hundreds of diamond "quantum microchiplets" with improved optical performance and controlled interaction with quantum emitters. The chiplet format allows defective device replacement and integration with existing photonic and electronic circuits.

Conclusion: High-quality diamond quantum devices can be produced using scalable, foundry-compatible techniques, providing a practical pathway toward large-scale quantum photonic systems and hybrid quantum-classical technologies using established semiconductor manufacturing infrastructure.

Abstract: Quantum technologies promise secure communication networks and powerful new forms of information processing, but building these systems at scale remains a major challenge. Diamond is an especially attractive material for quantum devices because it can host atomic-scale defects that emit single photons and store quantum information with exceptional stability. However, fabricating the optical structures needed to control light in diamond typically relies on slow, bespoke processes that are difficult to scale. In this work, we introduce a manufacturing approach that brings diamond quantum photonics closer to industrial production. Instead of sequentially defining each device by lithography written directly on diamond, we fabricate high-precision silicon masks using commercial semiconductor foundries and transfer them onto diamond via microtransfer printing. These masks define large arrays of nanoscale optical structures, shifting the most demanding pattern-definition steps away from the diamond substrate, improving uniformity, yield, and throughput. Using this method, we demonstrate hundreds of diamond "quantum microchiplets" with improved optical performance and controlled interaction with quantum emitters. The chiplet format allows defective devices to be replaced and enables integration with existing photonic and electronic circuits. Our results show that high-quality diamond quantum devices can be produced using scalable, foundry-compatible techniques. This approach provides a practical pathway toward large-scale quantum photonic systems and hybrid quantum-classical technologies built on established semiconductor manufacturing infrastructure.

</details>


### [9] [A Cyclic Layerwise QAOA Training](https://arxiv.org/abs/2601.20029)
*Enhyeok Jang,Zihan Chen,Dongho Ha,Seungwoo Choi,Yongju Lee,Jaewon Kwon,Eddy Z. Zhang,Yipeng Huang,Won Woo Ro*

Main category: quant-ph

TL;DR: Orbit-QAOA: A layerwise training method for Multi-angle QAOA that reduces classical computational overhead while maintaining approximation performance through cyclic layer revisiting and selective parameter freezing.


<details>
  <summary>Details</summary>
Motivation: MA-QAOA achieves better approximation than standard QAOA but has high classical computational cost due to many parameters. LMA-QAOA reduces overhead by training one layer at a time but may fail to find precise solutions due to fixed parameters. Need to balance parameter update granularity and final solution quality.

Method: Proposes Orbit-QAOA which: 1) uses layerwise training with one complete layer optimized per epoch as efficient granularity, 2) cyclically revisits layers, 3) selectively freezes stabilized parameters based on gradient variation tracking, and 4) implements selective retraining of layers.

Result: Across diverse graph benchmarks: reduces training steps by up to 81.8%, reduces approximation ratio error by up to 72x compared to enhanced LMA-QAOA, and achieves equivalent approximation performance to standard MA-QAOA.

Conclusion: Optimizing one complete layer per epoch is optimal granularity for MA-QAOA training. Selective retraining with gradient tracking and parameter freezing (Orbit-QAOA) achieves standard MA-QAOA performance with significantly reduced classical computational overhead.

Abstract: The quantum approximate optimization algorithm (QAOA) is a hybrid quantum-classical algorithm for solving combinatorial optimization problems. Multi-angle QAOA (MA-QAOA), which assigns independent parameters to each Hamiltonian operator term, achieves superior approximation performance even with fewer layers than standard QAOA. Unfortunately, this increased expressibility can raise the classical computational cost due to a greater number of parameters. The recently proposed Layerwise MA-QAOA (LMA-QAOA) reduces this overhead by training one layer at a time, but it may suffer from obtaining the precise solution due to the previously fixed parameters. This work addresses two questions for efficient MA-QAOA training: (i) What is the optimal granularity for parameter updates per epoch, and (ii) How can we get precise final cost function results while only partially updating the parameters per epoch? Despite the benefit of reducing the parameters that update per epoch can reduce the classical computation overhead, too fine or coarse a granularity of Hamiltonian update can degrade the MA-QAOA training efficiency. We find that optimizing one complete layer per epoch is an efficient granularity. Moreover, selectively retraining each layer by tracking gradient variations can achieve a final cost function equivalent to the standard MA-QAOA while lowering the parameter update overhead. Based on these insights, we propose Orbit-QAOA, which cyclically revisits layers and selectively freezes stabilized parameters. Across diverse graph benchmarks, Orbit-QAOA reduces training steps by up to 81.8%, reduces approximation ratio error by up to 72x compared to the unified stop condition-applied enhanced LMA-QAOA, and achieves equivalent approximation performance compared to the standard MA-QAOA.

</details>


### [10] [Quantum Channels on Graphs: a Resonant Tunneling Perspective](https://arxiv.org/abs/2601.20044)
*Giuseppe Catalano,Farzad Kianvash,Vittorio Giovannetti*

Main category: quant-ph

TL;DR: Quantum transport on networks shows interference effects that can enhance information flow; resonant concatenation via back-reflections can suppress noise and enable super-activation of quantum capacity.


<details>
  <summary>Details</summary>
Motivation: To understand how quantum interference effects in structured networks influence information propagation and to develop a framework for analyzing quantum transport on graphs as quantum channels.

Method: Develop quantum-information-theoretic framework for scattering on graphs using Redheffer star product to construct global scattering matrices from local ones, identifying resonant concatenation as a nonlinear composition rule generated by internal back-reflections.

Result: Resonant concatenation can suppress noise and produce super-activation of quantum capacity, yielding positive capacity where constituent channels individually have zero capacity, demonstrated through resonant-tunneling-enhanced transport models.

Conclusion: The approach provides a general methodology for analyzing coherent information flow in quantum graphs with relevance for quantum communication, control, and simulation in structured environments.

Abstract: Quantum transport on structured networks is strongly influenced by interference effects, which can dramatically modify how information propagates through a system. We develop a quantum-information-theoretic framework for scattering on graphs in which a full network of connected scattering sites is treated as a quantum channel linking designated input and output ports. Using the Redheffer star product to construct global scattering matrices from local ones, we identify resonant concatenation, a nonlinear composition rule generated by internal back-reflections. In contrast to ordinary channel concatenation, resonant concatenation can suppress noise and even produce super-activation of the quantum capacity, yielding positive capacity in configurations where each constituent channel individually has zero capacity. We illustrate these effects through models exhibiting resonant-tunneling-enhanced transport. Our approach provides a general methodology for analyzing coherent information flow in quantum graphs, with relevance for quantum communication, control, and simulation in structured environments.

</details>


### [11] [Comment on "Determining angle of arrival of radio-frequency fields using subwavelength, amplitude-only measurements of standing waves in a Rydberg atom sensor"](https://arxiv.org/abs/2601.20062)
*M. Chilcott,N. Kjærgaard*

Main category: quant-ph

TL;DR: Excluding allowed RF transitions in field-dressed Rydberg systems leads to inaccurate predictions of optical EIT spectra.


<details>
  <summary>Details</summary>
Motivation: To understand how neglecting allowed RF transitions between substates of field-dressed Rydberg manifolds affects the accuracy of predicted optical EIT spectra.

Method: Analysis of field-dressed Rydberg systems probed via optical electromagnetically induced transparency (EIT), examining consequences of excluding allowed RF transitions between substates.

Result: Excluding allowed RF transitions leads to incorrect predictions of EIT spectra, highlighting the importance of including these transitions for accurate spectral modeling.

Conclusion: Complete modeling of field-dressed Rydberg systems must include allowed RF transitions between substates to accurately predict optical EIT spectra.

Abstract: We discuss the consequence of excluding allowed RF-transition between substates of a field-dressed Rydberg manifold when predicting the spectrum that will be observed if the dressed system is probed in an optical EIT scheme.

</details>


### [12] [Ensemble-Based Quantum Signal Processing for Error Mitigation](https://arxiv.org/abs/2601.20073)
*Suying Liu,Yulong Dong,Dong An,Murphy Yuezhen Niu*

Main category: quant-ph

TL;DR: A noise-resilient framework for Quantum Signal Processing that mitigates coherent errors through ensemble averaging without increasing circuit depth or requiring extra qubits.


<details>
  <summary>Details</summary>
Motivation: Random coherent errors during circuit execution are a dominant noise source in near-term quantum devices, posing a fundamental challenge for deploying quantum algorithms.

Method: Uses ensembles of noisy QSP circuits combined with measurement-level averaging to suppress random phase errors in Z rotations, without increasing circuit depth or ancillary qubit requirements.

Result: Develops robust QSP algorithms for implementing polynomial functions of Hermitian matrices and estimating observables, with applications to Hamiltonian simulation, quantum linear systems, and ground-state preparation.

Conclusion: Establishes a practical pathway for integrating error mitigation into algorithmic design, advancing robust quantum computing for near- and mid-term devices.

Abstract: Despite rapid advances in quantum hardware, noise remains a central obstacle to deploying quantum algorithms on near-term devices. In particular, random coherent errors that accumulate during circuit execution constitute a dominant and fundamentally challenging noise source. We introduce a noise-resilient framework for Quantum Signal Processing (QSP) that mitigates such coherent errors without increasing circuit depth or ancillary qubit requirements. Our approach uses ensembles of noisy QSP circuits combined with measurement-level averaging to suppress random phase errors in Z rotations. Building on this framework, we develop robust QSP algorithms for implementing polynomial functions of Hermitian matrices and for estimating observables, with applications to Hamiltonian simulation, quantum linear systems, and ground-state preparation. We analyze the trade-off between approximation error and hardware noise, which is essential for practical implementation under the stringent depth and coherence constraints of current quantum hardware. Our results establish a practical pathway for integrating error mitigation seamlessly into algorithmic design, advancing the development of robust quantum computing, and enabling the discovery of scientific applications with near- and mid-term quantum devices.

</details>


### [13] [Local Distinguishability of Multipartite Orthogonal Quantum States: Generalized and Simplified](https://arxiv.org/abs/2601.20074)
*Ian George,Mohammad A. Alhejji*

Main category: quant-ph

TL;DR: Extension of Walgate et al.'s finite-dimensional LOCC distinguishability result to infinite dimensions with simpler proof, plus algorithmic construction for bipartite states and connection to channel capacity.


<details>
  <summary>Details</summary>
Motivation: To extend the seminal result by Walgate et al. (PRL 85, 4972) about perfect distinguishability of orthogonal pure multipartite states via one-way LOCC protocols from finite to infinite dimensions, provide constructive algorithms, and clarify connections to quantum channel capacity theory.

Method: 1. Extends the finite-dimensional proof to infinite dimensions using simpler mathematical approach. 2. Constructs explicit O(d_A²d_B²)-time algorithm for bipartite states on ℂ^{d_A×d_A}⊗ℂ^{d_B×d_B} that specifies perfect one-way LOCC protocol. 3. Establishes equivalence between distinguishability result and one-shot environment-assisted classical capacity being ≥1 bit per channel use.

Result: 1. Successfully extends Walgate et al.'s result to infinite dimensions. 2. Provides constructive algorithm for bipartite case with polynomial time complexity. 3. Clarifies literature by proving equivalence between distinguishability and channel capacity results.

Conclusion: The paper demonstrates that perfect one-way LOCC distinguishability of orthogonal pure states holds in infinite dimensions, provides constructive protocols for bipartite systems, and unifies this result with quantum channel capacity theory, with core mathematical insight being that every traceless operator admits a zero-diagonal basis representation.

Abstract: In a seminal work [PRL85.4972], Walgate, Short, Hardy, and Vedral prove in finite dimensions that for every pair of pure multipartite orthogonal quantum states, there exists a one-way local operations and classical communication (LOCC) protocol that perfectly distinguishes the pair. We extend this result to infinite dimensions with a simpler proof. For states on $\mathbb{C}^{d_A \times d_A} \otimes \mathbb{C}^{d_B \times d_B}$, we strengthen this existence result by constructing an $O(d_A^2 d_B^2)$-time algorithm that specifies such a perfect one-way LOCC protocol. Finally, we establish the equivalence between Walgate et al.'s result and the fact that the one-shot environment-assisted classical capacity of every quantum channel is at least 1 bit per channel use, thereby clarifying the literature on these notions. At the core of all of these results is the fact that every operator with vanishing trace admits a basis where its diagonal entries are all zero.

</details>


### [14] [Spectral Transitions and Singular Continuous Spectrum in A New Family of Quasi-periodic Quantum Walks](https://arxiv.org/abs/2601.20081)
*Xinyu Yang,Long Li,Qi Zhou*

Main category: quant-ph

TL;DR: A new class of 1D discrete-time quantum walks governed by parametrized extended CMV matrices, generalizing the unitary almost Mathieu operator and exhibiting rich spectral phase diagrams similar to extended Harper's model, with the first example of a solvable quasi-periodic quantum walk showing stable region of purely singular continuous spectrum.


<details>
  <summary>Details</summary>
Motivation: To introduce and rigorously analyze a new class of quantum walks that generalize existing models and provide the first example of a solvable quasi-periodic quantum walk exhibiting stable purely singular continuous spectrum, addressing gaps in understanding spectral properties of quantum walks.

Method: The paper introduces one-dimensional discrete-time quantum walks whose dynamics are governed by a parametrized family of extended CMV matrices, generalizing the unitary almost Mathieu operator (UAMO). The model is analyzed using rigorous mathematical methods to study its spectral properties.

Result: The model exhibits a richer spectral phase diagram that closely resembles the extended Harper's model. Most significantly, it provides the first example of a solvable quasi-periodic quantum walk that exhibits a stable region of purely singular continuous spectrum.

Conclusion: This work establishes a new class of quantum walks with extended CMV matrix dynamics that generalizes important existing models and demonstrates novel spectral behavior, particularly the stable existence of purely singular continuous spectrum in solvable quasi-periodic quantum walks.

Abstract: This paper introduces and rigorously analyzes a new class of one-dimensional discrete-time quantum walks whose dynamics are governed by a parametrized family of extended CMV matrices. The model generalizes the unitary almost Mathieu operator (UAMO) and exhibits a richer spectral phase diagram, closely resembling the extended Harper's model. It provides the first example of a solvable quasi-periodic quantum walk that exhibits a stable region of purely singular continuous spectrum.

</details>


### [15] [Krypton-sputtered tantalum films for scalable high-performance quantum devices](https://arxiv.org/abs/2601.20091)
*Maciej W. Olszewski,Lingda Kong,Simon Reinhardt,Daniel Tong,Xinyi Du,Gabriele Di Gianluca,Haoran Lu,Saswata Roy,Luojia Zhang,Aleksandra B. Biedron,David A. Muller,Valla Fatemi*

Main category: quant-ph

TL;DR: Tantalum superconducting qubits can now be fabricated at lower temperatures (200°C) using krypton sputtering instead of argon, enabling compatibility with semiconductor fabrication lines while maintaining state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: Tantalum-based superconducting qubits show superior performance but require high deposition temperatures (>400°C) for the desired BCC phase, creating compatibility issues with standard semiconductor fabrication processes that need lower temperatures for back-end-of-the-line integration.

Method: Used krypton (Kr) instead of argon (Ar) as sputter gas to promote BCC tantalum synthesis on silicon substrates at reduced temperatures (as low as 200°C). Characterized films via electronic conductivity measurements, coplanar waveguide resonator testing, and cross-sectional transmission electron microscopy to analyze Ta/Si intermixing.

Result: Kr-sputtered films achieved BCC phase at 200°C with substantially higher electronic conductivity (clean-limit superconductivity). Films deposited at 250°C and 350°C showed tight performance distribution at state-of-the-art levels. Higher temperature films exhibited higher losses correlated with Ta/Si intermixing. Transmon qubits with 20μm capacitor gaps achieved median quality factors up to 14 million.

Conclusion: Kr sputtering enables low-temperature BCC tantalum deposition compatible with semiconductor fabrication standards while maintaining excellent superconducting properties, providing a scalable pathway for high-performance superconducting quantum computing devices.

Abstract: Superconducting qubits based on tantalum (Ta) thin films have demonstrated the highest-performing microwave resonators and qubits. This makes Ta an attractive material for superconducting quantum computing applications, but, so far, direct deposition has largely relied on high substrate temperatures exceeding \SI{400}{\celsius} to achieve the body-centered cubic phase, BCC (\textalpha-Ta). This leads to compatibility issues for scalable fabrication leveraging standard semiconductor fabrication lines. Here, we show that changing the sputter gas from argon (Ar) to krypton (Kr) promotes BCC Ta synthesis on silicon (Si) at temperatures as low as \SI{200}{\celsius}, providing a wide process window compatible with back-end-of-the-line fabrication standards. Furthermore, we find these films to have substantially higher electronic conductivity, consistent with clean-limit superconductivity. We validated the microwave performance through coplanar waveguide resonator measurements, finding that films deposited at \SI{250}{\celsius} and \SI{350}{\celsius} exhibit a tight performance distribution at the state of the art. Higher temperature-grown films exhibit higher losses, in correlation with the degree of Ta/Si intermixing revealed by cross-sectional transmission electron microscopy. Finally, with these films, we demonstrate transmon qubits with a relatively compact, \SI{20}{\micro\meter} capacitor gap, achieving a median quality factor up to 14 million.

</details>


### [16] [Engineering the non-Hermitian SSH model with skin effects in Rydberg atom arrays](https://arxiv.org/abs/2601.20114)
*J. N. Bai,F. Yang,D. Yan,Weibin Li,X. Q. Shao*

Main category: quant-ph

TL;DR: Implementation of a 1D non-Hermitian SSH model using Rydberg atom arrays with three-atom unit cells, achieving robust non-Hermitian skin effect through engineered dissipation.


<details>
  <summary>Details</summary>
Motivation: To establish a practical, controllable quantum simulator for exploring non-Hermitian topological phenomena using neutral atom platforms, addressing the need for experimental realization of non-Hermitian skin effects.

Method: Uses individually addressable Rydberg atom arrays with three-atom unit cells, applies multi-color laser fields to generate synthetic gauge fields, and engineers fast dissipative channels for auxiliary atoms to achieve adiabatic elimination resulting in non-Hermitian skin effects.

Result: Successfully demonstrates robust non-Hermitian skin effect and topological invariant under both open and periodic boundary conditions, with high resilience to experimental parameter fluctuations.

Conclusion: Establishes a versatile, programmable open-system quantum simulator with neutral atoms that provides a clear pathway for exploring rich non-Hermitian topological phenomena.

Abstract: We propose and systematically analyze a practical scheme for implementing a one-dimensional non-Hermitian Su-Schrieffer-Heeger model using individually addressable Rydberg atom arrays. Our setup consists of an atomic chain with three-atom unit cells, in which a synthetic gauge field is generated by applying multi-color laser fields. By engineering fast dissipative channels for one auxiliary atom in each unit cell, the adiabatic elimination effectively gives rise to a non-Hermitian skin effect. We examine how fluctuations in the experimental parameters influence both the skin effect and the topological invariant under open and periodic boundary conditions in real space and find that both features remain highly robust. This work establishes a versatile, controllable, and programmable open-system quantum simulator with neutral atoms, providing a clear route for exploring rich non-Hermitian topological phenomena.

</details>


### [17] [Universal thermodynamic implementation of a process with a variable work cost](https://arxiv.org/abs/2601.20155)
*Philippe Faist*

Main category: quant-ph

TL;DR: The paper presents a thermodynamic implementation protocol for i.i.d. copies of time-covariant quantum channels that achieves optimal per-input work cost, using thermal operations and conditional erasure to handle work-cost decoherence.


<details>
  <summary>Details</summary>
Motivation: To develop a thermodynamic implementation of quantum channels that achieves optimal work cost for any i.i.d. input state while addressing the necessary process decoherence that arises from revealing work consumption.

Method: Leverages techniques from thermodynamic capacity derivations to construct a protocol using thermal operations and conditional erasure, adjusted to yield variable work. The approach handles time-covariant quantum channels and addresses work-cost decoherence effects.

Result: Developed a thermodynamic implementation protocol for n i.i.d. copies of any time-covariant quantum channel that achieves optimal per-input work cost for any i.i.d. input state. The protocol faithfully reproduces desired processes despite work-cost decoherence corrupting correlations with reference systems.

Conclusion: The work establishes optimal thermodynamic implementations for time-covariant quantum channels, recovering previous work extraction results and proposing optimal preparation protocols for time-covariant i.i.d. states, while characterizing the effects of work-cost decoherence.

Abstract: The minimum amount of thermodynamic work required in order to implement a quantum computation or a quantum state transformation can be quantified using frameworks based on the resource theory of thermodynamics, deeply rooted in the works of Landauer and Bennett. For instance, the work we need to invest in order to implement $n$ independent and identically distributed (i.i.d.) copies of a quantum channel is quantified by the thermodynamic capacity of the channel when we require the implementation's accuracy to be guaranteed in diamond norm over the $n$-system input. Recent work showed that work extraction can be implemented universally, meaning the same implementation works for a large class of input states, while achieving a variable work cost that is optimal for each individual i.i.d. input state. Here, we revisit some techniques leading to derivation of the thermodynamic capacity, and leverage them to construct a thermodynamic implementation of $n$ i.i.d. copies of any time-covariant quantum channel, up to some process decoherence that is necessary because the implementation reveals the amount of consumed work. The protocol uses so-called thermal operations and achieves the optimal per-input work cost for any i.i.d. input state; it relies on the conditional erasure protocol in our earlier work, adjusted to yield variable work. We discuss the effect of the work-cost decoherence. While it can significantly corrupt the correlations between the output state and any reference system, we show that for any time-covariant i.i.d. input state, the state on the output system faithfully reproduces that of the desired process to be implemented. As an immediate consequence of our results, we recover recent results for optimal work extraction from i.i.d. states up to the error scaling and implementation specifics, and propose an optimal preparation protocol for time-covariant i.i.d. states.

</details>


### [18] [Contextuality as an Information-Theoretic Obstruction to Classical Probability](https://arxiv.org/abs/2601.20167)
*Song-Ju Kim*

Main category: quant-ph

TL;DR: Contextuality is reinterpreted as an information-theoretic obstruction: classical models reproducing contextual statistics must either embed context-dependence in internal states or use external labels with nonzero information cost, making quantum probability a canonical framework for contextual operations.


<details>
  <summary>Details</summary>
Motivation: To clarify the operational meaning of contextuality by examining it from an information-theoretic perspective, focusing on whether contextual statistics can be explained by classical models under constraints of maintaining consistent internal state semantics across multiple contexts.

Method: Analyze operational models constrained to maintain a single internal state with fixed semantics across multiple contexts. Examine classical models attempting to reproduce contextual statistics under these constraints.

Result: Contextual statistics certify an unavoidable obstruction to classical probabilistic descriptions. Any classical model reproducing such statistics must either: (1) embed contextual dependence into the internal state, or (2) introduce additional external labels carrying nonzero information.

Conclusion: Contextuality is identified as a witness of irreducible information cost in classical representations, rather than purely a nonclassical anomaly. Quantum probability emerges as a canonical framework that accommodates contextual operations without requiring explicit contextual encoding.

Abstract: Contextuality is a central feature distinguishing quantum from classical probability theories, yet its operational meaning remains subject to interpretation. We reconsider contextuality from an information-theoretic perspective, focusing on operational models constrained to maintain a single internal state with fixed semantics across multiple contexts. Under this constraint, we show that contextual statistics certify an unavoidable obstruction to classical probabilistic descriptions. Specifically, any classical model that reproduces such statistics must either embed contextual dependence into the internal state or introduce additional external labels carrying nonzero information. This result identifies contextuality as a witness of irreducible information cost in classical representations, rather than as a purely nonclassical anomaly. From this viewpoint, quantum probability emerges as a canonical framework that accommodates contextual operations without requiring explicit contextual encoding.

</details>


### [19] [A general interpretation of nonlinear connected time crystals: quantum self-sustaining combined with quantum synchronization](https://arxiv.org/abs/2601.20186)
*Song-hai Li,Najmeh Es'haqi-Sani,Xingli Li,Wenlin Li*

Main category: quant-ph

TL;DR: Quantum dephasing enforces time-translation symmetry in nonlinear oscillators, but suppressing it via intercomponent phase correlations enables continuous time crystals through quantum synchronization.


<details>
  <summary>Details</summary>
Motivation: Classical nonlinear systems can sustain oscillations, but their quantization typically yields time-independent steady states that respect time-translation symmetry, preventing time-crystal behavior. The paper aims to understand why and how to overcome this limitation.

Method: Identifies dephasing as the primary symmetry-enforcing mechanism and shows it can be suppressed by intercomponent phase correlations. Proposes quantum synchronization among constituents as sufficient condition. Demonstrates with synchronized array of van der Pol oscillators using semiclassical dynamics and quantum Liouville spectrum analysis.

Result: Shows that continuous time crystals can be realized in nonlinear quantum self-sustaining systems exhibiting quantum synchronization. Demonstrates spontaneous oscillations in synchronized van der Pol oscillator arrays, with both semiclassical and quantum Liouville analyses corroborating the findings.

Conclusion: Provides framework for identifying time crystals in many-body systems by evaluating only two-body correlations, and classifies uncorrelated time crystals as trivial. Establishes quantum synchronization as key mechanism for overcoming dephasing-induced time-translation symmetry.

Abstract: Although classical nonlinear dynamics suggests that sufficiently strong nonlinearity can sustain oscillations, quantization of such model typically yields a time-independent steady state that respects time-translation symmetry and thus precludes time-crystal behavior. We identify dephasing as the primary mechanism enforcing this symmetry, which can be suppressed by intercomponent phase correlations. Consequently, a sufficient condition for realizing a continuous time crystal is a nonlinear quantum self-sustaining system exhibiting quantum synchronization among its constituents. As a concrete example, we demonstrate spontaneous oscillations in a synchronized array of van der Pol oscillators, corroborated by both semiclassical dynamics and the quantum Liouville spectrum. These results reduce the identification of time crystals in many-body systems to the evaluation of only two-body correlations and provide a framework for classifying uncorrelated time crystals as trivial.

</details>


### [20] [Fast state transfer via loop weights](https://arxiv.org/abs/2601.20237)
*Gabor Lippner,Yujia Shi*

Main category: quant-ph

TL;DR: High-fidelity quantum state transfer achieved in near-linear time using loop weights at boundary nodes of spin chain


<details>
  <summary>Details</summary>
Motivation: To achieve fast, high-fidelity quantum state transfer in spin chains, which is crucial for quantum information processing and quantum communication applications

Method: Use loop weights at second and second-to-last nodes of quantum spin chain, provide specific parameter values, and perform careful eigenvector analysis for quantitative estimates

Result: Demonstrates almost-linear-time high-fidelity state transfer is achievable with precise quantitative estimates of transfer time and strength

Conclusion: Loop weights at boundary nodes enable efficient quantum state transfer with near-linear time scaling and high fidelity

Abstract: We prove that almost-linear-time high-fidelity state transfer is achievable in a quantum spin chain using loop weights at the second and second-to-last nodes. We provide specific parameter values, and using a careful analysis of the eigenvectors we make precise quantitative estimates of the transfer time and strength.

</details>


### [21] [Computer Science Challenges in Quantum Computing: Early Fault-Tolerance and Beyond](https://arxiv.org/abs/2601.20247)
*Jens Palsberg,Jason Cong,Yufei Ding,Bill Fefferman,Moinuddin Qureshi,Gokul Subramanian Ravi,Kaitlin N. Smith,Hanrui Wang,Xiaodi Wu,Henry Yuen*

Main category: quant-ph

TL;DR: Early fault-tolerant quantum computing shifts bottlenecks from hardware to computer science, requiring advances in algorithms, error correction, software, and architecture for effective near-term systems.


<details>
  <summary>Details</summary>
Motivation: The paper identifies that as quantum computing enters early fault-tolerant stages, progress will be shaped by computer science advances rather than hardware improvements alone. Near-term systems will have tight constraints on logical qubits, error rates, connectivity, latency, and classical control, making effective utilization dependent on interdisciplinary advances.

Method: The report organizes key research challenges around four fundamental areas: algorithms, error correction, software, and architecture. It identifies central questions for each area to guide computer science research in supporting early fault-tolerant quantum computing systems.

Result: The analysis establishes a framework for computer science research priorities in early fault-tolerant quantum computing, highlighting that system design, integration, and evaluation will become primary bottlenecks rather than just device physics.

Conclusion: Computer science must play a central role in advancing early fault-tolerant quantum computing through coordinated progress across algorithms, error correction, software, and architecture to effectively utilize constrained near-term systems.

Abstract: Quantum computing is entering a period in which progress will be shaped as much by advances in computer science as by improvements in hardware. The central thesis of this report is that early fault-tolerant quantum computing shifts many of the primary bottlenecks from device physics alone to computer-science-driven system design, integration, and evaluation. While large-scale, fully fault-tolerant quantum computers remain a long-term objective, near- and medium-term systems will support early fault-tolerant computation with small numbers of logical qubits and tight constraints on error rates, connectivity, latency, and classical control. How effectively such systems can be used will depend on advances across algorithms, error correction, software, and architecture. This report identifies key research challenges for computer scientists and organizes them around these four areas, each centered on a fundamental question.

</details>


### [22] [A Quantum Photonic Approach to Graph Coloring](https://arxiv.org/abs/2601.20263)
*Jesua Epequin,Pascale Bendotti,Joseph Mikael*

Main category: quant-ph

TL;DR: GBS reformulates graph coloring via independent set formulation, enabling quantum sampling to find cliques in complement graphs, showing competitive performance against classical methods on random and smart-charging graphs.


<details>
  <summary>Details</summary>
Motivation: GBS has demonstrated quantum advantage and needs practical applications; graph coloring is a fundamental NP-hard combinatorial optimization problem with real-world relevance, particularly in resource allocation like smart-charging systems.

Method: Reformulate graph coloring as integer programming using independent set formulation, then use GBS to sample cliques in the complement graph (which correspond to independent sets in original graph). Benchmark against classical heuristics and exact algorithms.

Result: GBS provides competitive solutions compared to classical methods on both Erdős-Rényi random graphs and graphs from smart-charging use cases, demonstrating potential as quantum-enhanced heuristic.

Conclusion: GBS shows promise as a practical quantum-enhanced heuristic for graph-based optimization problems, particularly graph coloring, bridging quantum advantage demonstrations with real-world applications.

Abstract: Gaussian Boson Sampling (GBS) is a quantum computational model that leverages linear optics to solve sampling problems believed to be classically intractable. Recent experimental breakthroughs have demonstrated quantum advantage using GBS, motivating its application to real-world combinatorial optimization problems.
  In this work, we reformulate the graph coloring problem as an integer programming problem using the independent set formulation. This enables the use of GBS to identify cliques in the complement graph, which correspond to independent sets in the original graph. Our method is benchmarked against classical heuristics and exact algorithms on two sets of instances: Erdős-Rényi random graphs and graphs derived from a smart-charging use case. The results demonstrate that GBS can provide competitive solutions, highlighting its potential as a quantum-enhanced heuristic for graph-based optimization.

</details>


### [23] [Fingerprints of classical memory in quantum hysteresis](https://arxiv.org/abs/2601.20287)
*Francesco Caravelli*

Main category: quant-ph

TL;DR: A framework for modeling classical/quantum memory where Hamiltonian depends on past control values via causal kernels, distinguishing control memory from genuine non-Markovian dynamics.


<details>
  <summary>Details</summary>
Motivation: To develop a systematic approach for describing finite-bandwidth or filtered control channels in quantum systems, providing a clear distinction between memory in control parameters and true non-Markovian evolution of quantum states.

Method: Introduces Hamiltonian models with memory: H(t) = H₀ + ∫K(t-s)H₁(s)ds, where K is a causal kernel representing control filtering. Analyzes single-qubit examples like H(t)=σ_z+Φ(t)σ_x with Φ(t)=∫K(t-s)u(s)ds. Derives properties, unitarity conditions, time-local descriptions for exponential kernels, and demonstrates hysteresis in driven qubits.

Result: Develops a framework that cleanly separates control memory from state non-Markovianity, provides mathematical tools for analyzing such systems, and explicitly shows how hysteresis emerges in qubit response due to memory effects in control channels.

Conclusion: The framework offers a principled way to model memory effects in quantum control, distinguishing between instrumental limitations (finite bandwidth) and fundamental non-Markovian dynamics, with applications to quantum information processing and control engineering.

Abstract: We present a simple framework for classical and quantum ``memory'' in which the Hamiltonian at time $t$ depends on past values of a control Hamiltonian through a causal kernel. This structure naturally describes finite-bandwidth or filtered control channels and provides a clean way to distinguish between memory in the control and genuine non-Markovian dynamics of the state. We focus on models where $H(t)=H_0+\int_{-\infty}^{t}K(t-s)\,H_1(s)\,ds$, and illustrate the framework on single-qubit examples such as $H(t)=σ_z+Φ(t)σ_x$ with $Φ(t)=\int_{-\infty}^{t}K(t-s)\,u(s)\,ds$. We derive basic properties of such dynamics, discuss conditions for unitarity, give an equivalent time-local description for exponential kernels, and show explicitly how hysteresis arises in the response of a driven qubit.

</details>


### [24] [Electromagnetically Induced Transparency Spectra of Ladder Four-Level System with Quantum Frequency Mixing](https://arxiv.org/abs/2601.20296)
*Sheng-Xian Xiao,Tao Wang*

Main category: quant-ph

TL;DR: Generalization of quantum frequency mixing to ladder-type four-level systems reveals secondary Autler-Townes splitting in EIT spectra, enabling broadband AC field sensing and demonstrating coexisting Floquet channel interference and loop interference effects.


<details>
  <summary>Details</summary>
Motivation: To extend quantum frequency mixing technology to more complex multi-level quantum systems and explore its effects on electromagnetically induced transparency (EIT) spectra, particularly for developing enhanced AC field sensing capabilities and investigating novel quantum interference phenomena.

Method: Generalized quantum frequency mixing to a ladder-type four-level system, analyzed using multi-mode Floquet theory to derive effective Hamiltonian, and introduced additional periodic driving to create coexisting interference effects.

Result: Observed secondary splitting of Autler-Townes splitting in probing field transmission spectra, achieved continuous tunability of resonant frequency between upper levels for broadband AC field sensing, and demonstrated two distinct quantum interference effects that can be independently read from transmission spectra.

Conclusion: The frequency mixing scheme enables enhanced AC field sensing and establishes a new paradigm for coherent control in multi-level quantum systems by providing complementary readout mechanisms for extracting AC field phases and revealing novel quantum interference phenomena.

Abstract: In this paper, we generalized the quantum frequency mixing technology to a ladder-type four-level system and studied its effect on electromagnetically induced transparency spectra. We found a secondary splitting of Autler-Townes splitting in the probing field transmission spectra, which could be understood by the effective Hamiltonian derived with multi-mode Floquet theory. The Frequency mixing scheme developed here enables continuous tunablity of the resonant frequency between upper levels, which facilitates the broad band sensing of AC field. Furthermore, by introducing an additional periodic driving, we realize an effective model that two distinct quantum interference effects coexist: interference among Floquet channels and loop interference arising from closed coherent pathways. Both interference effects could be read out from the transmission spectra independently. The changing of the distance between double splitting peaks represents the interference of Floquet channels, while their asymmetric linewidth broadening is linked with the total effective phase of the loop. This not only provides complementary readout for extracting the phase of AC field, but also establishes a new paradigm for coherent control in multi-level quantum systems.

</details>


### [25] [Scalable Multi-QPU Circuit Design for Dicke State Preparation: Optimizing Communication Complexity and Local Circuit Costs](https://arxiv.org/abs/2601.20393)
*Ziheng Chen,Junhong Nie,Xiaoming Sun,Jialin Zhang,Jiadong Zhu*

Main category: quant-ph

TL;DR: Distributed quantum circuit for preparing n-qubit k-excitation Dicke states across p QPUs with O(p log k) communication complexity, O(nk) circuit size, and O(p²k + log k log(n/k)) depth, matching fundamental lower bounds.


<details>
  <summary>Details</summary>
Motivation: Large-qubit Dicke states are important for quantum computing and metrology, but single QPU qubit limitations necessitate distributed preparation across multiple QPUs for scalability.

Method: Developed distributed quantum circuit construction across p QPUs (each hosting ~⌈n/p⌉ qubits) using canonical polyadic (CP) rank analysis and communication-efficient protocols.

Result: Achieved logarithmic communication complexity O(p log k) with polynomial circuit size O(nk) and depth O(p²k + log k log(n/k)), matching lower bound of ⌈log(k+1)⌉ for p=2 based on CP-rank analysis.

Conclusion: First construction simultaneously achieving logarithmic communication and polynomial circuit complexity, establishing fundamental limits via CP-rank analysis and providing practical distributed Dicke state preparation.

Abstract: Preparing large-qubit Dicke states is of broad interest in quantum computing and quantum metrology. However, the number of qubits available on a single quantum processing unit (QPU) is limited -- motivating the distributed preparation of such states across multiple QPUs as a practical approach to scalability. In this article, we investigate the distributed preparation of $n$-qubit $k$-excitation Dicke states $D(n,k)$ across a general number $p$ of QPUs, presenting a distributed quantum circuit (each QPU hosting approximately $\lceil n/p \rceil$ qubits) that prepares the state with communication complexity $O(p \log k)$, circuit size $O(nk)$, and circuit depth $O\left(p^2 k + \log k \log (n/k)\right)$. To the best of our knowledge, this is the first construction to simultaneously achieve logarithmic communication complexity and polynomial circuit size and depth. We also establish a lower bound on the communication complexity of $p$-QPU distributed state preparation for a general target state. This lower bound is formulated in terms of the canonical polyadic rank (CP-rank) of a tensor associated with the target state. For the special case $p = 2$, we explicitly compute the CP-rank corresponding to the Dicke state $D(n,k)$ and derive a lower bound of $\lceil\log (k + 1)\rceil$, which shows that the communication complexity of our construction matches this fundamental limit.

</details>


### [26] [Network Nonlocality Sharing in Generalized Star Network from Bipartite Bell Inequalities](https://arxiv.org/abs/2601.20403)
*Hao-Miao Jiang,Xiang-Jiang Chen,Liu-Jun Wang,Qing Chen*

Main category: quant-ph

TL;DR: The paper studies network nonlocality sharing in generalized star networks using bipartite Bell inequalities, developing analytical methods to witness simultaneous violations across multiple parties.


<details>
  <summary>Details</summary>
Motivation: To extend the study of network nonlocality sharing beyond CHSH-type constructions by utilizing diverse bipartite Bell inequalities in generalized star network configurations, enabling more robust demonstrations of quantum correlations across multiple sequential observers.

Method: Developed analytical framework for calculating quantum values of network correlations in $(n,m,k)$ star networks (n branches, m sequential Alices per branch, k measurement settings). Intermediate Alices use optimal weak measurements while final Alice and central Bob use sharp projective measurements. Derived analytical expression for bipartite quantum correlator valid for arbitrary measurement settings and weak-measurement strengths.

Result: Successfully demonstrated network nonlocality sharing for Vértesi inequalities, finding simultaneous violations in $(2,2,6)$ and $(2,2,465)$ configurations. The $(2,2,465)$ case showed greater robustness to measurement imperfections. Streamlined calculation of quantum values enabled practical analysis of diverse Bell inequalities.

Conclusion: The framework provides a practical route for studying network nonlocality sharing using various bipartite Bell inequalities beyond CHSH-type constructions, with potential applications in quantum networks and foundational tests of quantum mechanics.

Abstract: This work investigates network nonlocality sharing for a broad class of bipartite Bell inequalities in a generalized star network with an $(n,m,k)$ configuration, comprising $n$ independent branches, $m$ sequential Alices per branch, and $k$ measurement settings per party. On each branch, the intermediate Alices implement optimal weak measurements, whereas the final Alice and the central Bob perform sharp projective measurements. Network nonlocality sharing is witnessed when the quantum values of the network correlations associated with relevant parties simultaneously violate a star-network Bell inequality generated from the given class of bipartite Bell inequalities. We streamline the calculation of the quantum values of the network correlations and derive an analytical expression for the bipartite quantum correlator, valid for arbitrary measurement settings and weak-measurement strengths. The network nonlocality sharing for Vértesi inequalities has been studied within the framework, and simultaneous violations are found in $(2,2,6)$ and $(2,2,465)$ cases, with the latter exhibiting greater robustness. Our approach suggests a practical route to studying network nonlocality sharing by utilizing diverse bipartite Bell inequalities beyond the commonly used CHSH-type constructions.

</details>


### [27] [Echo Cross Resonance gate error budgeting on a superconducting quantum processor](https://arxiv.org/abs/2601.20458)
*Travers Ward,Russell P. Rundle,Richard Bounds,Norbert Deak,Gavin Dold,Apoorva Hegde,William Howard,Ailsa Keyser,George B. Long,Benjamin Rogers,Jonathan J. Burnett,Bryn A. Bell*

Main category: quant-ph

TL;DR: Error budgeting and suppression techniques reduce two-qubit gate errors by 3.7x on a 32-qubit superconducting quantum computer, improving median error rate from 4.6% to 1.2% through pulse-shaping and compensating gates.


<details>
  <summary>Details</summary>
Motivation: Superconducting quantum processors show broad distributions of gate qualities, with low-performing tails affecting near-term performance and applications. There's a need for practical error suppression techniques that require minimal hardware overhead and calibration effort.

Method: Error budgeting procedure for native two-qubit operations on OQC Toshiko gen-1 system; identification of error sources (coherent error, control qubit leakage); application of error suppression strategies using pulse-shaping and additional compensating gates with no hardware overhead and minimal calibration.

Result: 3.7x average reduction in error rate for two-qubit operations across 16-qubit chain; median error rate improved from 4.6% to 1.2% measured by interleaved randomized benchmarking; largest improvements on previously under-performing qubit pairs, reducing low-performing tail of gate qualities.

Conclusion: Practical error suppression techniques are crucial for achieving consistently good performance across quantum devices, reducing quality variations, and enabling more reliable near-term quantum applications without significant hardware or calibration overhead.

Abstract: High fidelity quantum operations are key to enabling fault-tolerant quantum computation. Superconducting quantum processors have demonstrated high-fidelity operations, but on larger devices there is commonly a broad distribution of qualities, with the low-performing tail affecting near-term performance and applications. Here we present an error budgeting procedure for the native two-qubit operation on a 32-qubit superconducting-qubit-based quantum computer, the OQC Toshiko gen-1 system. We estimate the prevalence of different forms of error such as coherent error and control qubit leakage, then apply error suppression strategies based on the most significant sources of error, making use of pulse-shaping and additional compensating gates. These techniques require no additional hardware overhead and little additional calibration, making them suitable for routine adoption. An average reduction of 3.7x in error rate for two qubit operations is shown across a chain of 16 qubits, with the median error rate improving from 4.6$\%$ to 1.2$\%$ as measured by interleaved randomized benchmarking. The largest improvements are seen on previously under-performing qubit pairs, demonstrating the importance of practical error suppression in reducing the low-performing tail of gate qualities and achieving consistently good performance across a device.

</details>


### [28] [Multiple mobility rings in non-Hermitian Su-Schrieffer-Heeger chain with quasiperiodic potentials](https://arxiv.org/abs/2601.20479)
*Guan-Qiang Li,Zhi-Yu Lin,You-Jiao Dong,Ya-Feng Xue,Chun-Yang Ren,Ping Peng*

Main category: quant-ph

TL;DR: Non-Hermitian SSH chain with quasi-periodic potential shows localization-delocalization transitions controlled by hopping strengths, revealing mobility rings in energy spectra near phase boundaries.


<details>
  <summary>Details</summary>
Motivation: Investigate localization properties in non-Hermitian SSH chains with quasi-periodic potentials, focusing on how hopping strengths control quantum phase transitions between localized and extended states, particularly examining effects of Hermiticity, non-Hermiticity, and mosaic modulation.

Method: Study energy spectra and eigenstate distributions near phase transition boundaries in non-Hermitian SSH chains with quasi-periodic on-site potentials, analyzing critical behaviors and examining effects of intracellular/intercellular hopping strengths, Hermiticity conditions, and mosaic modulation period numbers.

Result: Reveals mobility rings in non-Hermitian SSH chains near phase boundaries, with multiple mobility rings emerging as mosaic modulation period number increases, showing distinct behaviors for Hermitian, non-Hermitian, and mosaic-modulated cases.

Conclusion: The study demonstrates hopping-strength-controlled localization-delocalization transitions in non-Hermitian SSH chains with quasi-periodic potentials, revealing mobility ring phenomena that provide insights into combined effects of non-Hermiticity and quasi-periodicity in SSH-type systems.

Abstract: The localization property of a non-Hermitian Su-Schrieffer-Heeger (SSH) chain with quasi-periodic on-site potential is investigated. In contrast to the preceding investigations, the quantum phase transition between localized state and extended one is achieved by adjusting the strength of intracellular or intercellular hopping. The energy spectra and eigenstate distributions of the system's Hamiltonian near the boundary of the phase transition exhibit different behaviors when the Hermiticity, non-Hermiticity and mosaic modulation of the quasi-periodic potential are considered, respectively. The existence of the mobility ring is revealed in the non-Hermitian SSH chain by studying of the critical behaviors near the boundary. More interestingly, the multiple mobility rings emerge when the period number of the mosaic modulation is increased. The result is helpful for the investigation of the localization-delocalization transition in the SSH-type system under the combined action of the non-Hermiticity and quasi-periodicity.

</details>


### [29] [Will we ever quantize the center of mass of macroscopic systems? A case for a Heisenberg cut in quantum mechanics](https://arxiv.org/abs/2601.20525)
*George E. A. Matsas,Gabriel H. S. Aguiar*

Main category: quant-ph

TL;DR: The paper argues that quantum mechanics cannot describe the center of mass of systems at or above the Planck scale, necessitating a Heisenberg cut between quantum and classical realms.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the conceptual problem that quantum field theory would imply the existence of annihilation and creation operators for macroscopic objects like rocks, which seems unreasonable despite quantum mechanics' success. This creates a need to delineate where quantum description breaks down and classical mechanics takes over.

Method: The method involves revisiting arguments for the necessity of a Heisenberg cut and examining the expected new physics at this boundary between quantum and classical realms.

Result: The analysis suggests that systems with masses exceeding the Planck mass would have their center of mass described by classical mechanics, even if they can exhibit macroscopic quantum phenomena in laboratory settings.

Conclusion: There exists a fundamental boundary (Heisenberg cut) where quantum mechanics transitions to classical mechanics, particularly for systems at or above the Planck scale, and exploring this uncharted region requires new physics beyond current quantum field theory.

Abstract: The concept of quantum particles derives from quantum field theory. Accepting that quantum mechanics is valid all the way implies that not only composite particles (such as protons and neutrons) would be derived from a field theory, but also the center of mass of bodies as heavy as rocks. Despite the fabulous success of quantum mechanics, it is unreasonable to assume the existence of annihilation and creation operators for rocks, and so on. Fortunately, there are strong reasons to doubt that wave mechanics can describe the center of mass of systems at or above the Planck scale, thereby jeopardizing the construction of the corresponding Fock space. As a result, systems with masses exceeding the Planck mass would have their center of mass described through classical mechanics, regardless of being able to harbor macroscopic quantum phenomena as observed in the laboratory. Here, we briefly revisit (i) the arguments for the need for a Heisenberg cut delimitating the boundary between the quantum and classical realms and (ii) the kind of new physics expected at (the uncharted region of) the Heisenberg cut.''

</details>


### [30] [Detector's response to coherent Rindler and Minkowski photons](https://arxiv.org/abs/2601.20557)
*Pradeep Kumar Kumawat,Dipankar Barman,Bibhas Ranjan Majhi*

Main category: quant-ph

TL;DR: The paper investigates differences in transition probabilities for quantum detectors interacting with photons in Rindler vs Minkowski frames, finding dimensional dependence in the classical limit.


<details>
  <summary>Details</summary>
Motivation: To understand the asymmetry in transition probabilities between a static detector interacting with Rindler photons versus a Rindler detector interacting with Minkowski photons, particularly in the classical limit of photon states.

Method: Analysis of two-level quantum detectors interacting with coherent photon states in both (1+1) and (3+1)-dimensional spacetimes, comparing transition probabilities between different detector-photon frame combinations under large acceleration conditions.

Result: In (1+1)D, transition probabilities become identical for the two scenarios in the classical limit when photon and detector frequencies match. In (3+1)D under large acceleration, no such equivalence is observed, revealing dimensional dependence of the detector response.

Conclusion: The detector's response depends on both spacetime dimension and the relative motion between detector and photon frames, with (1+1)D showing special symmetry that doesn't generalize to (3+1)D, highlighting fundamental differences in quantum field theory across dimensions.

Abstract: We observe that the transition probability in a static two-level quantum detector interacting with a coherent Rindler photon is different from the same of the Rindler detector which is in interaction with a coherent Minkowski photon. Situation does not change in the response of quantum detector for the classical limit of the photon state. This we investigate in $(1+1)$ and $(3+1)$-spacetime dimensions. Interestingly, the transition probabilities of the ``classical'' detector in the classical limit of the photon state in $(1+1)$-dimensions, for these two scenarios, appear to be identical when the frequencies of photon mode and detector are taken to be same. However, our obtained detector's transition probabilities in $(3+1)$-dimensions, which are calculated under the large acceleration condition, do not show such signature. The implications of these observations are discussed as well.

</details>


### [31] [Time complexity of a monitored quantum search with resetting](https://arxiv.org/abs/2601.20560)
*Emma C. King,Sayan Roy,Francesco Mattiotti,Maximilian Kiefer-Emmanouilidis,Markus Bläser,Giovanna Morigi*

Main category: quant-ph

TL;DR: Quantum search with continuous monitoring and resetting can achieve rapid convergence for finite databases but doesn't violate Grover's optimality bound when including measurement implementation time.


<details>
  <summary>Details</summary>
Motivation: To determine if feedback (via continuous monitoring and resetting) can improve quantum search time complexity beyond Grover's quadratic speedup, and to understand the quantum analog of randomized algorithms with feedback.

Method: Continuous-time quantum walk on complete graph with target continuously monitored by detector; quantum state reset if detector doesn't click within specified time interval, yielding non-unitary, non-Markovian dynamics. Optimization of search time as function of hopping amplitude, detection rate, and resetting rate.

Result: Identified conditions where time complexity could outperform Grover's scaling, but overall search time doesn't violate Grover's optimality bound when including measurement implementation time. For finite databases, monitoring enables rapid convergence.

Conclusion: Quantum search with feedback via continuous monitoring and resetting provides promising avenue for fault-tolerant quantum searches with rapid convergence for finite databases, but doesn't fundamentally beat Grover's bound when accounting for full physical implementation costs.

Abstract: Searching a database is a central task in computer science and is paradigmatic of transport and optimization problems in physics. For an unstructured search, Grover's algorithm predicts a quadratic speedup, with the search time $τ(N)=Θ(\sqrt{N})$ and $N$ the database size. Numerical studies suggest that the time complexity can change in the presence of feedback, injecting information during the search. Here, we determine the time complexity of the quantum analog of a randomized algorithm, which implements feedback in a simple form. The search is a continuous-time quantum walk on a complete graph, where the target is continuously monitored by a detector. Additionally, the quantum state is reset if the detector does not click within a specified time interval. This yields a non-unitary, non-Markovian dynamics. We optimize the search time as a function of the hopping amplitude, detection rate, and resetting rate, and identify the conditions under which time complexity could outperform Grover's scaling. The overall search time does not violate Grover's optimality bound when including the time budget of the physical implementation of the measurement. For databases of finite sizes monitoring can warrant rapid convergence and provides a promising avenue for fault-tolerant quantum searches.

</details>


### [32] [A Hybrid Jump-Diffusion Model for Coherent Optical Control of Quantum Emitters in hBN](https://arxiv.org/abs/2601.20587)
*Saifian Farooq Bhat,Michael K. Koch,Sachin Negi,Alexander Kubanek,Vibhav Bharadwaj*

Main category: quant-ph

TL;DR: Hybrid stochastic model combining spectral diffusion and discrete jumps explains temperature-dependent linewidth broadening and optical coherence degradation in hBN quantum emitters, predicting critical temperature for overdamped dynamics.


<details>
  <summary>Details</summary>
Motivation: hBN is promising for stable single-photon emission but exhibits temperature-dependent spectral dynamics that limit optical coherence and coherent control capabilities.

Method: Hybrid stochastic framework combining Ornstein-Uhlenbeck detuning fluctuations with temperature-dependent Gaussian-distributed discrete frequency jumps, calibrated to experimental FWHM and g²(τ) measurements under resonant driving.

Result: Model reproduces inhomogeneous linewidth broadening and coherence degradation across 5-30K range, captures cubic temperature dependence of phonon-related diffusion, predicts critical crossover to overdamped dynamics at T_crit ≈ 25.91K.

Conclusion: Hybrid framework quantitatively links spectroscopic observables to noise mechanisms limiting coherent optical control in mechanically decoupled quantum emitters, generalizable to similar systems beyond hBN.

Abstract: Hexagonal boron nitride (hBN) has emerged as a promising two-dimensional host for stable single-photon emission owing to its wide bandgap, high photostability, and compatibility with nanophotonic integration. We present a simulation-based study of temperature-dependent spectral dynamics and optical coherence in a mechanically decoupled quantum emitter in hBN. Employing a hybrid stochastic framework that combines Ornstein--Uhlenbeck detuning fluctuations with temperature-dependent, Gaussian-distributed discrete frequency jumps, motivated by experimentally observed spectral diffusion and blinking, we reproduce the measured evolution of inhomogeneous linewidth broadening and the progressive degradation of photon coherence across the relevant cryogenic range (5-30K). The model captures phonon-related spectral diffusion with a cubic temperature dependence and the onset of jump-like spectral instabilities at higher temperatures. By calibrating the hybrid diffusion, jump parameters to the experimentally measured full width at half maximum (FWHM) of the emission line and analyzing the second-order correlation function $g^{(2)}(τ)$ under resonant driving, we establish a unified phenomenological description that links stochastic detuning dynamics to the decay of optical coherence in a resonantly driven emitter. Analysis of $g^{(2)}(τ)$ under resonant driving reveals an additional dephasing rate $γ_{\mathrm{sd+j}}$ that rises monotonically with temperature and drive strength, leading to a predicted critical crossover to overdamped dynamics at $T_{\mathrm{crit}} \approx 25.91$~K. This hybrid framework provides a quantitative connection between accessible spectroscopic observables and the dominant noise mechanisms limiting coherent optical control in mechanically decoupled quantum emitters, exemplified in hBN and generalizable to similar emitters in other materials.

</details>


### [33] [Enhanced quantum parameter estimation based on the Hardy paradox](https://arxiv.org/abs/2601.20602)
*Ming Ji,Yuxiang Yang,Holger F. Hofmann*

Main category: quant-ph

TL;DR: The paper connects Hardy paradox quantum statistics to post-selected quantum metrology, showing that enhancement efficiency depends on the relationship between weak values and expectation values.


<details>
  <summary>Details</summary>
Motivation: To establish a connection between statistical paradoxes like the Hardy paradox and quantum metrology enhancement via post-selection, specifically investigating how non-positive quasi-probabilities underlie both phenomena.

Method: Introduces a post-selected quantum metrology scenario where the initial state, phase shift dynamics, and post-selection are all inspired by the Hardy paradox, identifying anomalous weak values characteristic of both phenomena.

Result: Finds that enhancement efficiency in phase estimation is reduced when the expectation value associated with the anomalous weak value differs from the inverse of this value, revealing a specific constraint on metrological improvement.

Conclusion: The relationship between enhanced phase estimation and the Hardy paradox requires detailed understanding of the connection between weak values and expectation values, highlighting fundamental quantum statistical constraints.

Abstract: Statistical paradoxes such as the Hardy paradox and the enhancement of phase estimation via post-selection both draw upon the same non-classical features of quantum statistics described by non-positive quasi-probabilities. In this paper, we introduce a post-selected quantum metrology scenario where the initial state, the dynamics associated with the phase shift, and the post-selection are all inspired by the Hardy paradox. Specifically, we identify an anomalous weak value that is characteristic of both the Hardy paradox and the potential enhancement of sensitivity by the post-selection. We find that the efficiency of the enhancement is reduced when the expectation value associated with the anomalous weak value is different from the inverse of this value. We conclude that the relation between enhanced phase estimation and the Hardy paradox requires a detailed understanding of the relation between weak values and expectation values.

</details>


### [34] [Foundations of Quantum Optics for Quantum Information: Crash Course on Nonclassical States and Quantum Correlations](https://arxiv.org/abs/2601.20619)
*Jhoan Eusse,Esteban Vasquez,Tom Rivlin,Elizabeth Agudelo*

Main category: quant-ph

TL;DR: Lecture notes providing an accessible yet rigorous introduction to quantum optics foundations, emphasizing relevance to quantum information science, covering field quantization, bosonic formalism, key quantum states, nonclassicality characterization, Gaussian states, entanglement, and practical computational tools.


<details>
  <summary>Details</summary>
Motivation: To bridge foundational concepts of quantum optics with modern quantum information science, providing both conceptual insight and practical tools for students and researchers entering the field, emphasizing the role of nonclassical states as fundamental resources for quantum phenomena and information protocols.

Method: Develops a unified framework starting from electromagnetic field quantization and bosonic formalism in Fock space. Introduces key families of states (thermal, coherent, squeezed) as paradigmatic examples, presents concepts of convexity, classicality, and quasiprobability representations for characterizing quantumness, extends to Gaussian states and continuous-variable entanglement, and complements theoretical developments with computational simulations using Python library Strawberry Fields and data analysis from simulated experiments.

Result: Provides comprehensive lecture notes that offer an accessible yet rigorous introduction to quantum optics foundations, establishing connections between classical and nonclassical behavior, developing operational notions of P-nonclassicality, and demonstrating how nonclassicality serves as a resource for generating and quantifying quantum correlations in composite systems.

Conclusion: These lecture notes successfully bridge foundational quantum optics concepts with modern quantum information science, offering both theoretical understanding and practical computational tools, emphasizing that nonclassical states of light and their correlations are fundamental resources for exploring quantum phenomena and implementing quantum information protocols.

Abstract: Nonclassical states of light and their correlations lie at the heart of quantum optics, serving as fundamental resources that underpin both the exploration of quantum phenomena and the realisation of quantum information protocols. These lecture notes provide an accessible yet rigorous introduction to the foundations of quantum optics, emphasising their relevance to quantum information science and technology. Starting from the quantisation of the electromagnetic field and the bosonic formalism of Fock space, the notes develop a unified framework for describing and analysing quantum states of light. Key families of states -- thermal, coherent, and squeezed -- are introduced as paradigmatic examples illustrating the transition from classical to nonclassical behaviour. The concepts of convexity, classicality, and quasiprobability representations are presented as complementary tools for characterising quantumness and defining operational notions such as P-nonclassicality. The discussion extends naturally to Gaussian states, composite systems, and continuous-variable entanglement, highlighting how nonclassicality serves as a resource for generating and quantifying quantum correlations. Theoretical developments are complemented by computational and experimental perspectives, including simulations of optical states using the Python library Strawberry Fields and data analysis from simulated data. Together, these notes aim to bridge the foundational concepts of quantum optics and modern quantum information, offering both conceptual insight and practical tools for students and researchers entering the field.

</details>


### [35] [Rydberg Receivers for Space Applications](https://arxiv.org/abs/2601.20631)
*Gianluca Allinson,Mark Bason,Alexis Bonnin,Sebastian Borówka,Petronilo Martin-Iglesias,Manuel Martin Neira,Mateusz Mazelanik,Richard Murchie,Michał Parniak,Sophio Pataraia,Thibaud Ruelle,Sylvain Schwartz,Aaron Strangfeld*

Main category: quant-ph

TL;DR: Rydberg-atom sensors offer SI-traceable RF/microwave/THz-to-optical conversion with high sensitivity and tunability, showing promise for space applications in radiometry, radar, THz sensing, and calibration, but face limitations in shot noise, sparse THz transitions, and SWaP-C constraints.


<details>
  <summary>Details</summary>
Motivation: To assess the potential of Rydberg-atom sensors for space applications by evaluating different sensor architectures against space mission requirements and identifying promising application areas while addressing current limitations.

Method: Comparative analysis of five Rydberg-atom sensor architectures (Autler-Townes, AC-Stark, superheterodyne, radiofrequency-to-optical conversion, and fluorescence) against space application needs, followed by identification of promising roles and key limitations.

Result: Identified promising applications in radiometry, radar, terahertz sensing, and in-orbit calibration. Key limitations include shot noise, sparse terahertz transitions, and currently large Size, Weight, Power and Cost (SWaP-C). Developed a staged roadmap for technology development.

Conclusion: Rydberg-atom sensors show significant potential for space applications but require further development to overcome current limitations. A structured roadmap outlines how research organizations, industry, and space agencies can advance different aspects of the technology.

Abstract: Rydberg-atom sensors convert radiofrequency, microwave and terahertz fields into optical signals with SI-traceable calibration, high sensitivity, and broad tunability. This review assesses their potential for space applications by comparing five general architectures (Autler-Townes, AC-Stark, superheterodyne, radiofrequency-to-optical conversion, and fluorescence) against space application needs. We identify promising roles in radiometry, radar, terahertz sensing, and in-orbit calibration, and outline key limitations, including shot noise, sparse terahertz transitions, and currently large Size, Weight, Power and Cost. A staged roadmap highlights which uncertainties should be resolved first and how research organisations, industry and space agencies could take the lead for the different aspects.

</details>


### [36] [Co-Designed Adaptive Quantum State Preparation Protocols](https://arxiv.org/abs/2601.20681)
*Mafalda Ramôa,Luis Paulo Santos,Nicholas J. Mayhall,Edwin Barnes,Sophia E. Economou*

Main category: quant-ph

TL;DR: Co-ADAPT-VQE co-designs quantum ansatz construction with hardware constraints, achieving up to 97% CNOT reduction for LNN devices while outperforming all-to-all connectivity ADAPT-VQE.


<details>
  <summary>Details</summary>
Motivation: To address quantum hardware limitations including restricted connectivity, short coherence times, and variable gate errors by co-designing ansatz construction with device-specific constraints.

Method: Co-designed variant of ADAPT-VQE (Co-ADAPT-VQE) that incorporates quantum hardware constraints during ansatz construction, specifically demonstrated for linear nearest-neighbor connectivity devices.

Result: Achieved up to 97% CNOT count reduction for 12-14 qubit systems on LNN devices, with greater impact for larger and more strongly correlated systems. Surprisingly, even outperformed original ADAPT-VQE on all-to-all connectivity by over 70% CNOT reduction despite LNN restrictions.

Conclusion: Co-ADAPT-VQE effectively optimizes state preparation circuits for specific quantum hardware, significantly reducing gate counts and addressing device limitations while potentially outperforming unconstrained approaches.

Abstract: We propose a co-designed variant of ADAPT-VQE (Co-ADAPT-VQE) where the quantum hardware is taken into account in the construction of the ansatz. This framework can be readily used to optimize state preparation circuits for any device, addressing shortcomings such as limited connectivity, short coherence times, and variable gate errors. We exemplify the impact of Co-ADAPT-VQE by creating state preparation circuits for devices with linear nearest-neighbor (LNN) connectivity. We show a reduction of the CNOT count of the final circuits by up to 97% for 12-14 qubit systems, with the impact being greater for larger and more strongly correlated systems. Surprisingly, the circuits created by Co-ADAPT-VQE provide an over 70% CNOT count reduction with respect to the original ADAPT-VQE in all-to-all connectivity, despite being restricted to LNN qubit interactions.

</details>


### [37] [Entangled photon pair excitation and time-frequency filtered multidimensional photon correlation spectroscopy as a probe for dissipative exciton kinetics](https://arxiv.org/abs/2601.20700)
*Arunangshu Debnath,Shaul Mukamel*

Main category: quant-ph

TL;DR: Protocol combines entangled photon excitation with time-frequency-filtered coincidence counting to selectively probe exciton dynamics in molecular aggregates, overcoming spectral-temporal bottlenecks.


<details>
  <summary>Details</summary>
Motivation: Monitoring exciton dynamics in molecular aggregates is challenging due to multiple delocalized exciton states interacting with phonons, spread across multiple spectral and temporal windows.

Method: Combines photon-entanglement-enhanced narrowband excitation of two-exciton states with time-frequency-filtered two-photon coincidence counting to prepare and monitor exciton distributions.

Result: Numerical simulations for light-harvesting aggregates demonstrate the protocol's ability to achieve selectivity by suppressing or amplifying specific pathways through tuning filtering parameters.

Conclusion: Combining entangled photonic sources with multidimensional photon counting enables promising applications in spectroscopy and sensing by providing selective pathway monitoring.

Abstract: In molecular aggregates, multiple delocalized exciton states interact with phonons, making the state-resolved spectroscopic monitoring of dynamics challenging. We propose a protocol that combines photon-entanglement-enhanced narrowband excitation of two-exciton states with time-frequency-filtered two-photon coincidence counting. It can alleviate bottlenecks associated with probing exciton dynamics spread across multiple spectral and temporal windows. We demonstrate that non-classical correlations of entangled photon pairs can be used to prepare narrowband two-exciton population distributions, circumventing transport in mediating states. The distributions thus created can be monitored using time-frequency-filtered photon coincidence counting, and the pathways contributing to photon emission events can be classified by tuning filtering parameters. Numerical simulations for a light-harvesting aggregate highlight the ability of this protocol to achieve selectivity by suppressing or amplifying specific pathways. Combining entangled photonic sources and multidimensional photon counting allow promising applications to spectroscopy and sensing.

</details>


### [38] [Spectrum-generating algebra and intertwiners of the resonant Pais-Uhlenbeck oscillator](https://arxiv.org/abs/2601.20752)
*Andreas Fring,Ian Marquette,Takano Taira*

Main category: quant-ph

TL;DR: The resonant Pais-Uhlenbeck oscillator exhibits quantum inequivalence from classically equivalent Hamiltonians due to non-diagonalizability at resonance, revealing hidden su(2) symmetry and spectrum-generating algebra.


<details>
  <summary>Details</summary>
Motivation: To understand the quantum behavior of the Pais-Uhlenbeck oscillator at the resonant (equal-frequency) point where conventional Fock-space construction fails, and to investigate the quantisation ambiguity arising from multiple classical Hamiltonian formulations generating the same equations of motion.

Method: First work in the ghostly two-dimensional Hamiltonian formulation, constructing differential intertwiners that generate a spectrum-generating algebra acting on generalised eigenspaces. This algebra organizes eigenvectors into finite Jordan chains and reveals hidden su(2) Lie algebra at resonance. Then quantize a classically equivalent Hamiltonian to compare quantum theories.

Result: At resonance, the system becomes non-diagonalizable with conventional Fock-space collapse. The spectrum-generating algebra organizes generalised eigenvectors into Jordan chains and closes into a hidden su(2) Lie algebra existing only at resonance. Quantizing a classically equivalent Hamiltonian yields a radically different quantum theory with fully diagonalizable spectrum and genuine degeneracies.

Conclusion: The resonant Pais-Uhlenbeck oscillator provides a concrete example where classically equivalent Hamiltonians define inequivalent quantum theories, demonstrating fundamental quantisation ambiguity and revealing hidden algebraic structures at resonance.

Abstract: We study the quantum Pais-Uhlenbeck oscillator at the resonant (equal-frequency) point, where the dynamics becomes non-diagonalisable and the conventional Fock-space construction collapses. At the classical level, the degenerate system admits more than one Hamiltonian formulation generating the same equations of motion, leading to a nontrivial quantisation ambiguity. Working first in the ghostly two-dimensional Hamiltonian formulation, we construct differential intertwiners that generate a spectrum-generating algebra acting on the generalised eigenspaces of the Hamiltonian. This algebra organises the generalised eigenvectors into finite Jordan chains and closes into a hidden $su(2)$ Lie algebra that exists only at resonance.
  We then show that quantising a classically equivalent Hamiltonian yields a radically different quantum theory, with a fully diagonalisable spectrum and genuine degeneracies. Our results demonstrate that the resonant Pais-Uhlenbeck oscillator provides a concrete example in which classically equivalent Hamiltonians define inequivalent quantum theories.

</details>


### [39] [Neural Quantum States in Mixed Precision](https://arxiv.org/abs/2601.20782)
*Massimo Solinas,Agnes Valenti,Nawaf Bou-Rabee,Roeland Wiersema*

Main category: quant-ph

TL;DR: Mixed-precision arithmetic enables efficient neural-network Variational Monte Carlo for quantum many-body systems by allowing half-precision sampling without accuracy loss.


<details>
  <summary>Details</summary>
Motivation: Hardware accelerators like GPUs favor low-precision formats for better performance, memory efficiency, and energy savings, but scientific computing traditionally uses double precision for accuracy. The paper investigates whether mixed-precision can be applied to neural-network based Variational Monte Carlo for quantum many-body systems.

Method: Derived analytical error bounds for reduced precision in Metropolis-Hastings MCMC, then empirically validated these bounds on Variational Monte Carlo. Demonstrated that quantum state sampling can be executed in half precision without accuracy degradation.

Result: Significant portions of VMC algorithms, particularly quantum state sampling, can run in half precision without loss of accuracy. The work provides a theoretical framework for assessing mixed-precision applicability in MCMC-based machine learning approaches.

Conclusion: Mixed-precision strategies enable more scalable and energy-efficient simulations of quantum many-body systems in VMC, offering a practical approach to leverage hardware accelerators while maintaining scientific accuracy.

Abstract: Scientific computing has long relied on double precision (64-bit floating point) arithmetic to guarantee accuracy in simulations of real-world phenomena. However, the growing availability of hardware accelerators such as Graphics Processing Units (GPUs) has made low-precision formats attractive due to their superior performance, reduced memory footprint, and improved energy efficiency. In this work, we investigate the role of mixed-precision arithmetic in neural-network based Variational Monte Carlo (VMC), a widely used method for solving computationally otherwise intractable quantum many-body systems. We first derive general analytical bounds on the error introduced by reduced precision on Metropolis-Hastings MCMC, and then empirically validate these bounds on the use-case of VMC. We demonstrate that significant portions of the algorithm, in particular, sampling the quantum state, can be executed in half precision without loss of accuracy. More broadly, this work provides a theoretical framework to assess the applicability of mixed-precision arithmetic in machine-learning approaches that rely on MCMC sampling. In the context of VMC, we additionally demonstrate the practical effectiveness of mixed-precision strategies, enabling more scalable and energy-efficient simulations of quantum many-body systems.

</details>


### [40] [Semiclassical effective description of a quantum particle on a sphere with non-central potential](https://arxiv.org/abs/2601.20787)
*Guillermo Chacon-Acosta,H. Hernandez-Hernandez,J. Ruvalcaba-Rascon*

Main category: quant-ph

TL;DR: Quantum-corrected semiclassical dynamics on curved surfaces using momentous quantum mechanics reveals significant quantum back-reaction effects, including measurable phase shifts, amplified potential asymmetries, and accelerated trajectory dynamics compared to classical predictions.


<details>
  <summary>Details</summary>
Motivation: To develop a semiclassical framework for studying quantum particles constrained to curved surfaces, extending beyond classical descriptions to incorporate quantum back-reaction effects that fundamentally alter dynamics in constrained systems.

Method: Uses momentous quantum mechanics formalism to extend classical phase-space with quantum fluctuation variables (moments). Applies this framework to spherical geometry, deriving quantum-corrected Hamiltonians and trajectories that incorporate quantum back-reaction effects.

Result: For free particles: quantum fluctuations induce 8-12% phase shifts in azimuthal precession with uncertainty growth proportional to initial moment correlations. With Makarov potential: quantum corrections dramatically amplify asymmetry; at strong coupling (γ = -1.9), quantum-corrected force drives trajectories 40% faster toward southern hemisphere with up to 3-fold density enhancement in preferred region. Solutions satisfy Heisenberg uncertainty relations.

Conclusion: Quantum effects fundamentally alter semiclassical dynamics in curved constrained systems, with direct implications for charge transport in carbon nanostructures, exciton dynamics in curved quantum wells, and reaction pathways in cyclic molecules.

Abstract: We develop a semiclassical framework for studying quantum particles constrained to curved surfaces using the momentous quantum mechanics formalism, which extends classical phase-space to include quantum fluctuation variables (moments). In a spherical geometry, we derive quantum-corrected Hamiltonians and trajectories that incorporate quantum back-reaction effects absent in classical descriptions. For the free particle, quantum fluctuations induce measurable phase shifts in azimuthal precession of approximately 8-12%, with uncertainty growth rates proportional to initial moment correlations. When a non-central Makarov potential is introduced, quantum corrections dramatically amplify its asymmetry. For strong coupling ($γ$ = -1.9), the quantum-corrected force drives trajectories preferentially toward the southern hemisphere on timescales 40% shorter than classical predictions, with trajectory densities exhibiting up to 3-fold enhancement in the preferred region. Throughout evolution, the solutions rigorously satisfy Heisenberg uncertainty relations, validating the truncation scheme. These results demonstrate that quantum effects fundamentally alter semiclassical dynamics in curved constrained systems, with direct implications for charge transport in carbon nanostructures, exciton dynamics in curved quantum wells, and reaction pathways in cyclic molecules.

</details>


### [41] [Quantum Memory and Autonomous Computation in Two Dimensions](https://arxiv.org/abs/2601.20818)
*Gesa Dünnweber,Georgios Styliaris,Rahul Trivedi*

Main category: quant-ph

TL;DR: A method for autonomous quantum error correction in 2D using quantum cellular automata with local, translation-invariant rules, achieving fault-tolerant quantum computation without active measurements.


<details>
  <summary>Details</summary>
Motivation: Standard quantum error correction requires active maintenance with measurements and classical processing, while passive QEC has only been established in unphysical spatial dimensions. The goal is to achieve autonomous QEC in two spatial dimensions.

Method: Uses hierarchical, self-simulating control elements based on classical schemes from Gács (1986, 1989) combined with a measurement-free concatenated code. Formulated as a quantum cellular automaton with fixed, local, and translation-invariant update rules.

Result: Proves a noise threshold below which logical errors are suppressed arbitrarily with increasing system size, and memory lifetime diverges in the thermodynamic limit. The scheme admits continuous-time implementation as a time-independent, translation-invariant local Lindbladian with engineered dissipative jump operators.

Conclusion: The recursive protocol enables fault-tolerant encoding of arbitrary quantum circuits, constituting a self-correcting universal quantum computer in two spatial dimensions without active measurements.

Abstract: Standard approaches to quantum error correction (QEC) require active maintenance using measurements and classical processing. The possibility of passive QEC has so far only been established in an unphysical number of spatial dimensions. In this work, we present a simple method for autonomous QEC in two spatial dimensions, formulated as a quantum cellular automaton with a fixed, local and translation-invariant update rule. The construction uses hierarchical, self-simulating control elements based on the classical schemes from the seminal results of Gács (1986, 1989) together with a measurement-free concatenated code. We analyze the system under a local noise model and prove a noise threshold below which the logical errors are suppressed arbitrarily with increasing system size and the memory lifetime diverges in the thermodynamic limit. The scheme admits a continuous-time implementation as a time-independent, translation-invariant local Lindbladian with engineered dissipative jump operators. Further, the recursive nature of our protocol allows for the fault-tolerant encoding of arbitrary quantum circuits and thus constitutes a self-correcting universal quantum computer.

</details>


### [42] [Symplectic Optimization on Gaussian States](https://arxiv.org/abs/2601.20832)
*Christopher Willby,Tomohiro Hashizume,Jason Crain,Dieter Jaksch*

Main category: quant-ph

TL;DR: A symplectic optimization framework for computing Gaussian ground states that parameterizes covariance matrices as positive-definite symplectic matrices using unit-triangular factorizations, enabling unconstrained optimization and efficient warm-starting across related Hamiltonians.


<details>
  <summary>Details</summary>
Motivation: Variational optimization for Gaussian ground states is challenging due to uncertainty principle constraints on covariance matrices, making constrained/Riemannian optimization costly, delicate, and difficult to scale, especially for large inhomogeneous systems.

Method: Introduces a symplectic optimization framework that parameterizes covariance matrices directly as positive-definite symplectic matrices using unit-triangular factorizations, enforcing all physical constraints exactly while yielding a globally unconstrained variational formulation.

Result: Demonstrated on weakly dipole-coupled lattices, accurately recovering ground-state energies, covariance matrices, and spectral gaps. The unconstrained structure enables efficient warm-starting, substantially reducing optimization steps for related configurations in crystal lattices, molecular systems, and fluids.

Conclusion: The framework provides a foundation for large-scale approximate treatments of weakly non-quadratic interactions and offers potential scaling advantages through tensor-network enhancements, addressing scalability challenges in Gaussian ground-state computations.

Abstract: Computing Gaussian ground states via variational optimization is challenging because the covariance matrices must satisfy the uncertainty principle, rendering constrained or Riemannian optimization costly, delicate, and thus difficult to scale, particularly in large and inhomogeneous systems. We introduce a symplectic optimization framework that addresses this challenge by parameterizing covariance matrices directly as positive-definite symplectic matrices using unit-triangular factorizations. This approach enforces all physical constraints exactly, yielding a globally unconstrained variational formulation of the bosonic ground-state problem. The unconstrained structure also naturally supports solution reuse across nearby Hamiltonians: warm-starting from previously optimized covariance matrices substantially reduces the number of optimization steps required for convergence in families of related configurations, as encountered in crystal lattices, molecular systems, and fluids. We demonstrate the method on weakly dipole-coupled lattices, recovering ground-state energies, covariance matrices, and spectral gaps accurately. The framework further provides a foundation for large-scale approximate treatments of weakly non-quadratic interactions and offers potential scaling advantages through tensor-network enhancements.

</details>


### [43] [Quantum teleportation in expanding FRW universe](https://arxiv.org/abs/2601.20860)
*Babak Vakili*

Main category: quant-ph

TL;DR: Quantum teleportation fidelity in expanding FRW universes (power-law and de Sitter) is analyzed using field theory and Bogoliubov transformations, showing cosmic expansion degrades quantum information through mode mixing and vacuum structure.


<details>
  <summary>Details</summary>
Motivation: To understand how cosmological expansion affects quantum teleportation processes, specifically examining the impact of spacetime curvature and cosmological background on quantum information transfer between comoving observers in an expanding universe.

Method: Field-theoretical approach using Bogoliubov transformations to analyze quantum correlations between two comoving observers sharing an entangled scalar field mode in Friedmann-Robertson-Walker spacetime, focusing on power-law expansion and de Sitter scenarios.

Result: Spacetime curvature and cosmological background significantly affect teleportation fidelity, with cosmic expansion degrading quantum information through mode mixing and vacuum structure modifications; results are compared with flat Minkowski case to highlight expansion effects.

Conclusion: Cosmic expansion plays a crucial role in quantum teleportation efficiency, with expansion rate, initial entanglement, and mode frequency determining the degradation or preservation of quantum information in cosmological settings.

Abstract: We investigate the process of quantum teleportation in an expanding universe modeled by Friedmann-Robertson-Walker spacetime, focusing on two cosmologically relevant scenarios: a power-law expansion and the de Sitter universe. Adopting a field-theoretical approach, we analyze the quantum correlations between two comoving observers who share an entangled mode of a scalar field. Using the Bogoliubov transformation, we compute the teleportation fidelity and examine its dependence on the expansion rate, initial entanglement, and the mode frequency. Our findings indicate that spacetime curvature and the underlying cosmological background significantly affect the efficiency of quantum teleportation, particularly through mode mixing and vacuum structure. We also compare our results with the flat Minkowski case to highlight the role of cosmic expansion in degrading or preserving quantum information.

</details>
